{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardie85/PHD/Research/code/.venv/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 - Action from Problem Solver\n",
      "Episode 0 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-0.9000,  0.9000,  0.0000,  0.0000,  0.0000, -0.8000,  0.0000],\n",
      "       device='cuda:0')\n",
      "agent 0 action: tensor([[[1.7872e-02, 3.2187e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 1.7872e-02, 3.2187e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([0.0006], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0020e-01,  8.9918e-01, -2.7141e-03, -1.0909e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  1.7872e-02,  3.2187e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 0.9000,  0.9000,  0.0000,  0.0000,  0.0000, -0.8000,  0.0000],\n",
      "       device='cuda:0')\n",
      "agent 1 action: tensor([[[1.7872e-02, 3.2187e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 1.7872e-02, 3.2187e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0022], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0013e-01,  9.0241e-01,  1.7872e-03,  3.2187e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.7141e-02, -1.0909e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 0 - Action from Problem Solver\n",
      "Episode 0 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0020e-01,  8.9918e-01, -2.7141e-03, -1.0909e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  1.7872e-02,  3.2187e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[1.3913e-01, 8.8437e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 1.3913e-01, 8.8437e-02, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0004], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0203e-01,  8.9864e-01, -2.3733e-02, -4.4512e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  1.3913e-01,  8.8437e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0013e-01,  9.0241e-01,  1.7872e-03,  3.2187e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.7141e-02, -1.0909e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[1.3913e-01, 8.8437e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 1.3913e-01, 8.8437e-02, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0033], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0131e-01,  9.0549e-01,  1.5254e-02,  3.2984e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.1697e-01,  3.7308e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 0 - Action from Problem Solver\n",
      "Episode 0 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0203e-01,  8.9864e-01, -2.3733e-02, -4.4512e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  1.3913e-01,  8.8437e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[6.1021e-02, 2.3163e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 6.1021e-02, 2.3163e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0016], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0503e-01,  8.9883e-01, -3.3992e-02,  3.6625e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  6.1021e-02,  2.3163e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0131e-01,  9.0549e-01,  1.5254e-02,  3.2984e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.1697e-01,  3.7308e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[6.1021e-02, 2.3163e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 6.1021e-02, 2.3163e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0045], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0291e-01,  9.0970e-01,  1.7542e-02,  4.7902e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.6193e-01,  7.0009e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 0 - Action from Problem Solver\n",
      "Episode 0 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0503e-01,  8.9883e-01, -3.3992e-02,  3.6625e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  6.1021e-02,  2.3163e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[-2.6437e-02,  1.0036e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 9.9000e+01,  9.9000e+01, -2.6437e-02,  1.0036e-01,  0.0000e+00,\n",
      "           0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0026], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0776e-01,  9.0033e-01, -2.7856e-02,  1.9058e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.6437e-02,  1.0036e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0291e-01,  9.0970e-01,  1.7542e-02,  4.7902e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.6193e-01,  7.0009e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[-2.6437e-02,  1.0036e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 9.9000e+01,  9.9000e+01, -2.6437e-02,  1.0036e-01,  0.0000e+00,\n",
      "           0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0044], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0403e-01,  9.1405e-01,  1.0513e-02,  4.5962e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.3615e-02,  1.6312e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 0 - Action from Problem Solver\n",
      "Episode 0 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0776e-01,  9.0033e-01, -2.7856e-02,  1.9058e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.6437e-02,  1.0036e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[9.2422e-02, 2.2290e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 9.2422e-02, 2.2290e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0029], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0954e-01,  9.0261e-01, -1.6815e-02,  2.5651e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  9.2422e-02,  2.2290e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0403e-01,  9.1405e-01,  1.0513e-02,  4.5962e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.3615e-02,  1.6312e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[9.2422e-02, 2.2290e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 9.2422e-02, 2.2290e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0052], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0551e-01,  9.1917e-01,  1.7127e-02,  5.6762e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  4.0765e-02,  1.1358e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 1 - Action from Problem Solver\n",
      "Episode 1 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-0.9000,  0.9000,  0.0000,  0.0000,  0.0000, -0.8000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "agent 0 action: tensor([[[1.7604e-01, 8.3923e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 1.7604e-01, 8.3923e-02, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0008], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0107e-01,  9.0030e-01, -1.4251e-02,  4.0108e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  1.7604e-01,  8.3923e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 0.9000,  0.9000,  0.0000,  0.0000,  0.0000, -0.8000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "agent 1 action: tensor([[[1.7604e-01, 8.3923e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 1.7604e-01, 8.3923e-02, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0012], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0132e-01,  9.0063e-01,  1.7604e-02,  8.3923e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.4251e-01,  4.0108e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 1 - Action from Problem Solver\n",
      "Episode 1 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0107e-01,  9.0030e-01, -1.4251e-02,  4.0108e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  1.7604e-01,  8.3923e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[ 7.9766e-02, -1.0112e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 9.9000e+01,  9.9000e+01,  7.9766e-02, -1.0112e-01,  0.0000e+00,\n",
      "           0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0010], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0298e-01,  9.0044e-01, -2.1945e-02,  8.1531e-04,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  7.9766e-02, -1.0112e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0132e-01,  9.0063e-01,  1.7604e-02,  8.3923e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.4251e-01,  4.0108e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[ 7.9766e-02, -1.0112e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 9.9000e+01,  9.9000e+01,  7.9766e-02, -1.0112e-01,  0.0000e+00,\n",
      "           0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0008], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0324e-01,  9.0050e-01,  2.1180e-02, -3.8176e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.1256e-01, -2.1928e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 1 - Action from Problem Solver\n",
      "Episode 1 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0298e-01,  9.0044e-01, -2.1945e-02,  8.1531e-04,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  7.9766e-02, -1.0112e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[4.7544e-02, 1.2707e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 4.7544e-02, 1.2707e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0018], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0524e-01,  9.0131e-01, -2.4594e-02,  1.1466e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  4.7544e-02,  1.2707e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0324e-01,  9.0050e-01,  2.1180e-02, -3.8176e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.1256e-01, -2.1928e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[4.7544e-02, 1.2707e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 4.7544e-02, 1.2707e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0015], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0518e-01,  9.0117e-01,  2.0639e-02,  9.8439e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -8.1351e-02,  1.0854e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 1 - Action from Problem Solver\n",
      "Episode 1 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0524e-01,  9.0131e-01, -2.4594e-02,  1.1466e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  4.7544e-02,  1.2707e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[3.4900e-02, 2.2328e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 3.4900e-02, 2.2328e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0022], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0811e-01,  9.0231e-01, -3.2137e-02,  1.0430e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  3.4900e-02,  2.2328e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0518e-01,  9.0117e-01,  2.0639e-02,  9.8439e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -8.1351e-02,  1.0854e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[3.4900e-02, 2.2328e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 3.4900e-02, 2.2328e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0030], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0699e-01,  9.0358e-01,  1.8970e-02,  2.9711e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.3692e-01,  1.8304e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 1 - Action from Problem Solver\n",
      "Episode 1 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0811e-01,  9.0231e-01, -3.2137e-02,  1.0430e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  3.4900e-02,  2.2328e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[9.2460e-02, 1.8904e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 9.2460e-02, 1.8904e-02, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0028], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.1045e-01,  9.0423e-01, -2.3185e-02,  2.3065e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  9.2460e-02,  1.8904e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0699e-01,  9.0358e-01,  1.8970e-02,  2.9711e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.3692e-01,  1.8304e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[9.2460e-02, 1.8904e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 9.2460e-02, 1.8904e-02, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0031], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0911e-01,  9.0595e-01,  2.3473e-02,  2.4173e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  9.1751e-03,  1.5242e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 2 - Action from Problem Solver\n",
      "Episode 2 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-0.9000,  0.9000,  0.0000,  0.0000,  0.0000, -0.8000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "agent 0 action: tensor([[[8.1447e-02, 1.3191e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 8.1447e-02, 1.3191e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0010], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0126e-01,  9.0047e-01, -1.6783e-02,  6.2379e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  8.1447e-02,  1.3191e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 0.9000,  0.9000,  0.0000,  0.0000,  0.0000, -0.8000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "agent 1 action: tensor([[[8.1447e-02, 1.3191e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 8.1447e-02, 1.3191e-01, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0012], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0061e-01,  9.0099e-01,  8.1447e-03,  1.3191e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.6783e-01,  6.2379e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 2 - Action from Problem Solver\n",
      "Episode 2 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0126e-01,  9.0047e-01, -1.6783e-02,  6.2379e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  8.1447e-02,  1.3191e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[ 0.2502,  0.2317,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [99.0000, 99.0000,  0.2502,  0.2317,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0015], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0328e-01,  9.0110e-01, -2.2695e-02,  6.8989e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  2.5021e-01,  2.3173e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0061e-01,  9.0099e-01,  8.1447e-03,  1.3191e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.6783e-01,  6.2379e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[ 0.2502,  0.2317,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [99.0000, 99.0000,  0.2502,  0.2317,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0036], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0310e-01,  9.0372e-01,  3.1129e-02,  3.3067e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.0107e-01,  2.2205e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 2 - Action from Problem Solver\n",
      "Episode 2 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0328e-01,  9.0110e-01, -2.2695e-02,  6.8989e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  2.5021e-01,  2.3173e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[1.5494e-01, 9.6546e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 1.5494e-01, 9.6546e-02, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0021], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.0631e-01,  9.0187e-01, -3.4736e-02,  8.5595e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  1.5494e-01,  9.6546e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0310e-01,  9.0372e-01,  3.1129e-02,  3.3067e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.0107e-01,  2.2205e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[1.5494e-01, 9.6546e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [9.9000e+01, 9.9000e+01, 1.5494e-01, 9.6546e-02, 0.0000e+00,\n",
      "          0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0045], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.0659e-01,  9.0692e-01,  3.8841e-02,  3.4455e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.7715e-01,  3.3853e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 2 - Action from Problem Solver\n",
      "Episode 2 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.0631e-01,  9.0187e-01, -3.4736e-02,  8.5595e-03,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  1.5494e-01,  9.6546e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[ 0.2338,  0.1207,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [99.0000, 99.0000,  0.2338,  0.1207,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0014], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.1048e-01,  9.0118e-01, -4.6962e-02, -1.1378e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  2.3381e-01,  1.2075e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.0659e-01,  9.0692e-01,  3.8841e-02,  3.4455e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -1.7715e-01,  3.3853e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[ 0.2338,  0.1207,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [99.0000, 99.0000,  0.2338,  0.1207,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0053], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.1126e-01,  9.1041e-01,  5.2511e-02,  3.7916e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.0910e-01, -1.7798e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "Episode 2 - Action from Problem Solver\n",
      "Episode 2 - Action from Problem Solver\n",
      "agent 0 old state: tensor([-9.1048e-01,  9.0118e-01, -4.6962e-02, -1.1378e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  2.3381e-01,  1.2075e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 action: tensor([[[-5.1425e-02,  2.5028e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 9.9000e+01,  9.9000e+01, -5.1425e-02,  2.5028e-02,  0.0000e+00,\n",
      "           0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 0 reward: tensor([-0.0015], device='cuda:0')\n",
      "agent 0 new state: tensor([-9.1391e-01,  9.0104e-01, -3.3946e-02,  9.1267e-04,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -5.1425e-02,  2.5028e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 old state: tensor([ 9.1126e-01,  9.1041e-01,  5.2511e-02,  3.7916e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01, -2.0910e-01, -1.7798e-01,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 action: tensor([[[-5.1425e-02,  2.5028e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 9.9000e+01,  9.9000e+01, -5.1425e-02,  2.5028e-02,  0.0000e+00,\n",
      "           0.0000e+00]]], device='cuda:0', dtype=torch.float64)\n",
      "agent 1 reward: tensor([-0.0043], device='cuda:0')\n",
      "agent 1 new state: tensor([ 9.1481e-01,  9.1344e-01,  3.4241e-02,  3.0940e-02,  0.0000e+00,\n",
      "        -8.0000e-01,  9.9000e+01,  9.9000e+01,  1.2760e-02,  9.4465e-02,\n",
      "         0.0000e+00,  0.0000e+00], device='cuda:0', dtype=torch.float64)\n",
      "------------------------------------------\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "Overall success percentage for all agents = 0.0%\n",
      "It took: 0.7379367351531982s for 15 steps across 3 episodes of 1 parallel environments on device cuda for navigation_comm scenario.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/QAAAIjCAYAAACtaVBBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABE1ElEQVR4nO3deZhWdfk/8HsGZgYmVlkFR1BccAWFL4QbkCCaodjXIjeQ3IXLZdQUTRBQsTK1EiVxwRLFJbeCsBFBSykSRDMRU0DUn6yKECgzMOf3RxfPt3EGBIR5OMzrdV1zxfN5Puec+zzcjL2fs+UkSZIEAAAAkCq52S4AAAAA2HoCPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQA7vR49ekSPHj0yrxcuXBg5OTkxfvz4rNW0I315f6vL2WefHW3btq327e7KfKYA7EgCPQDb3fjx4yMnJyfzU6dOndhvv/1iyJAhsWTJkmyXl3qzZ8+OnJyc+PGPf7zJOf/6178iJycniouLq7GybZeTkxNDhgzJdhmbtfGLpFtvvbXK92+44YbIycmJ5cuXf63tvPXWW3HDDTfEwoULv9Z6ANj11c52AQDsukaOHBl77bVXfPHFF/GXv/wl7r777pg8eXK8+eabUVhYuM3rbdOmTXz++eeRl5e3HatNj8MPPzzat28fjzzySNx4441Vznn44YcjIuLMM8+sztL4knHjxkV5eflWLfPWW2/FiBEjokePHo7uA7BZjtADsMOccMIJceaZZ8a5554b48ePj8suuywWLFgQzzzzzNda78aj/rVq1dpOlabPGWecEfPnz4+//vWvVb7/yCOPRPv27ePwww+v5sr4b3l5eVFQUJDtMiIiYu3atdkuAYDtTKAHoNp861vfioiIBQsWRETE+vXrY9SoUdGuXbsoKCiItm3bxrXXXhvr1q3b7Ho2dQ3922+/Hd///vejWbNmUbdu3dh///3juuuui4iIadOmRU5OTjz11FOV1vfwww9HTk5OzJgxY5Pb/OSTT+LKK6+MQw45JOrVqxcNGjSIE044IV5//fUK86ZPnx45OTnx2GOPxU033RR77LFH1KlTJ4499th49913K633nnvuiXbt2kXdunWjS5cu8ec//3mz+77RGWeckan9y2bNmhXz5s3LzHnmmWfixBNPjFatWkVBQUG0a9cuRo0aFRs2bNjsNjbuy/Tp0yuMb+7zP/XUU2O33XaLOnXqROfOnePZZ5/dov3ZEmvWrIkrrrgiioqKoqCgIPbff/+49dZbI0mSCvNKSkriqKOOikaNGkW9evVi//33j2uvvbbCnF/96ldx0EEHRWFhYTRu3Dg6d+5c5Wf5dVV1Df3EiROjU6dOUb9+/WjQoEEccsgh8Ytf/CIi/nO5yve+972IiOjZs2fmspX//ju466674qCDDoqCgoJo1apVDB48OFauXFlhGz169IiDDz44Zs2aFcccc0wUFhbGtddeGwMHDoymTZtGWVlZpVqPO+642H///bfr/gOwYznlHoBq895770VERJMmTSIi4txzz40HH3wwTj311Ljiiivib3/7W4wePTrmzp1bZfDenDfeeCOOPvroyMvLi/PPPz/atm0b7733Xvz+97+Pm266KXr06BFFRUUxYcKEOOWUUyosO2HChGjXrl1069Ztk+ufP39+PP300/G9730v9tprr1iyZEn8+te/ju7du8dbb70VrVq1qjD/lltuidzc3Ljyyivjs88+i5/+9KdxxhlnxN/+9rfMnPvuuy8uuOCCOOKII+Kyyy6L+fPnx0knnRS77bZbFBUVbXZ/99prrzjiiCPisccei9tvv73C2Qobg+npp58eEf8JifXq1Yvi4uKoV69evPDCCzFs2LBYtWpV/OxnP9uyD/gr/POf/4wjjzwyWrduHddcc0184xvfiMceeyz69esXv/vd7yp95lsrSZI46aSTYtq0aXHOOedEx44d47nnnourrroqPvroo7j99tszdXznO9+JQw89NEaOHBkFBQXx7rvvxssvv5xZ17hx4+KSSy6JU089NS699NL44osv4o033oi//e1vmc9sc9auXVvldfJbcgS8pKQkTjvttDj22GPjJz/5SUREzJ07N15++eW49NJL45hjjolLLrkkfvnLX8a1114bBxxwQERE5n9vuOGGGDFiRPTq1SsuuuiimDdvXtx9993x97//PV5++eUKl6GsWLEiTjjhhPjBD34QZ555ZrRo0SK+8Y1vxG9+85t47rnn4jvf+U5m7uLFi+OFF16I4cOHf+U+ALATSQBgO3vggQeSiEief/75ZNmyZckHH3yQTJw4MWnSpElSt27d5MMPP0zmzJmTRERy7rnnVlj2yiuvTCIieeGFFzJj3bt3T7p37555vWDBgiQikgceeCAzdswxxyT169dP3n///QrrKy8vz/x56NChSUFBQbJy5crM2NKlS5PatWsnw4cP3+w+ffHFF8mGDRsqjC1YsCApKChIRo4cmRmbNm1aEhHJAQcckKxbty4z/otf/CKJiOQf//hHkiRJUlpamjRv3jzp2LFjhXn33HNPEhEV9ndTxowZk0RE8txzz2XGNmzYkLRu3Trp1q1bZmzt2rWVlr3ggguSwsLC5IsvvsiMDRw4MGnTpk2lfZk2bVql/f7y53/ssccmhxxySIX1lZeXJ0cccUSy7777fuW+REQyePDgTb7/9NNPJxGR3HjjjRXGTz311CQnJyd59913kyRJkttvvz2JiGTZsmWbXNfJJ5+cHHTQQV9Z05dt3O+v+vnvbX/5M7300kuTBg0aJOvXr9/kdh5//PEqP/elS5cm+fn5yXHHHVehF++8884kIpL7778/M9a9e/ckIpKxY8dWWMeGDRuSPfbYI+nfv3+F8dtuuy3JyclJ5s+fvzUfCQBZ5pR7AHaYXr16RbNmzaKoqCh+8IMfRL169eKpp56K1q1bx+TJkyMiKt2F/YorroiIiEmTJm3xdpYtWxYvvfRS/PCHP4w999yzwns5OTmZPw8YMCDWrVsXTzzxRGbs0UcfjfXr13/lzeMKCgoiN/c//9ncsGFDrFixInM69+zZsyvNHzRoUOTn52deH3300RHxnyP9ERGvvvpqLF26NC688MIK884+++xo2LDhFu13//79Iy8vr8Kp4i+++GJ89NFHmdPtIyLq1q2b+fPq1atj+fLlcfTRR8fatWvj7bff3qJtbc4nn3wSL7zwQnz/+9/PrH/58uWxYsWK6NOnT/zrX/+Kjz766GttY/LkyVGrVq245JJLKoxfccUVkSRJ/PGPf4yIiEaNGkXEfy4z2NTN6Bo1ahQffvhh/P3vf9+mWs4///woKSmp9HPWWWd95bKNGjWKNWvWRElJyVZv9/nnn4/S0tK47LLLMr0YEXHeeedFgwYNKv2bKSgoiEGDBlUYy83NjTPOOCOeffbZWL16dWZ8woQJccQRR8Ree+211XUBkD0CPQA7zJgxY6KkpCSmTZsWb731VsyfPz/69OkTERHvv/9+5Obmxj777FNhmZYtW0ajRo3i/fff3+LtbAzJBx988GbntW/fPv7nf/4nJkyYkBmbMGFCfPOb36xUx5eVl5fH7bffHvvuu28UFBRE06ZNo1mzZvHGG2/EZ599Vmn+l79YaNy4cUREfPrppxERmf3bd999K8zLy8uLvffee7O1bNSkSZPo06dPPPXUU/HFF19ExH9Ot69du3Z8//vfz8z75z//Gaeccko0bNgwGjRoEM2aNct8gVFV7Vvr3XffjSRJ4vrrr49mzZpV+Nl4CvfSpUu/1jbef//9aNWqVdSvX7/C+MZT0Td+nv37948jjzwyzj333GjRokX84Ac/iMcee6xCuL/66qujXr160aVLl9h3331j8ODBFU7J/yr77rtv9OrVq9LPlvy9XXzxxbHffvvFCSecEHvssUf88Ic/jClTpmzRdjfu45evc8/Pz4+999670r+Z1q1bV/iyaKMBAwbE559/nrmsZd68eTFr1qwt+kICgJ2LQA/ADtOlS5fo1atX9OjRIw444IAKRxU3+u8j6NVhwIAB8eKLL8aHH34Y7733Xvz1r3/doke73XzzzVFcXBzHHHNMPPTQQ/Hcc89FSUlJHHTQQVUeCd7UHfiTL93A7es688wzY9WqVfGHP/whSktL43e/+10cd9xx0axZs4iIWLlyZXTv3j1ef/31GDlyZPz+97+PkpKSzPXbm3uk2qb+br58M72N67jyyiurPHJdUlLylV+YbC9169aNl156KZ5//vk466yz4o033oj+/ftH7969M3UfcMABMW/evJg4cWIcddRR8bvf/S6OOuqoarl+vHnz5jFnzpx49tlnM/cEOOGEE2LgwIHbfVv/fWbGfzvwwAOjU6dO8dBDD0VExEMPPRT5+fkVvgQCIB3cFA+ArGjTpk2Ul5fHv/71r8xR1oiIJUuWxMqVK6NNmzZbvK6NR0bffPPNr5z7gx/8IIqLi+ORRx7JPMu+f//+X7ncE088ET179oz77ruvwvjKlSujadOmW1zrRhv371//+lfm7v8REWVlZbFgwYLo0KHDFq3npJNOivr168fDDz8ceXl58emnn1Y43X769OmxYsWKePLJJ+OYY47JjG980sDmbDyr4Mt3UP/ykeCNn39eXl706tVri+reWm3atInnn38+Vq9eXeEo/cZLBv67X3Jzc+PYY4+NY489Nm677ba4+eab47rrrotp06Zl6vvGN74R/fv3j/79+0dpaWl897vfjZtuuimGDh0aderU2SH7sFF+fn707ds3+vbtG+Xl5XHxxRfHr3/967j++utjn3322eQXKRv3cd68eRXOBigtLY0FCxZs1Wc/YMCAKC4ujo8//jgefvjhOPHEEzN/3wCkhyP0AGTFt7/97YiIuOOOOyqM33bbbRERceKJJ27xupo1axbHHHNM3H///bFo0aIK7335iHjTpk3jhBNOiIceeigmTJgQxx9//BYF8lq1alVa1+OPP77N14Z37tw5mjVrFmPHjo3S0tLM+Pjx4ysF6M2pW7dunHLKKTF58uS4++674xvf+EacfPLJFeqOqPg5lJaWxl133fWV627Tpk3UqlUrXnrppQrjX162efPm0aNHj/j1r38dH3/8caX1LFu2bIv3Z1O+/e1vx4YNG+LOO++sMH777bdHTk5OnHDCCRHxn+v5v6xjx44REZnHIa5YsaLC+/n5+XHggQdGkiRVPs5te/rytnNzc+PQQw+tUN83vvGNiKj8RUqvXr0iPz8/fvnLX1b4+7zvvvvis88+26p/M6eddlrk5OTEpZdeGvPnz9+is1QA2Pk4Qg9AVnTo0CEGDhwY99xzT+a08JkzZ8aDDz4Y/fr1i549e27V+n75y1/GUUcdFYcffnicf/75sddee8XChQtj0qRJMWfOnApzBwwYEKeeempERIwaNWqL1v+d73wnRo4cGYMGDYojjjgi/vGPf8SECRO2+Hr3L8vLy4sbb7wxLrjggvjWt74V/fv3jwULFsQDDzyw1es888wzM48iO+OMMzKBMCLiiCOOiMaNG8fAgQPjkksuiZycnPjtb3+7Raf+N2zYML73ve/Fr371q8jJyYl27drFH/7whyqvhx8zZkwcddRRccghh8R5550Xe++9dyxZsiRmzJgRH374Ybz++utfub1XX301brzxxkrjPXr0iL59+0bPnj3juuuui4ULF0aHDh3iT3/6UzzzzDNx2WWXRbt27SIiYuTIkfHSSy/FiSeeGG3atImlS5fGXXfdFXvssUccddRREfGf5623bNkyjjzyyGjRokXMnTs37rzzzjjxxBMrXaO/vZ177rnxySefxLe+9a3YY4894v33349f/epX0bFjx8yZKh07doxatWrFT37yk/jss8+ioKAgvvWtb0Xz5s1j6NChMWLEiDj++OPjpJNOinnz5sVdd90V//M//7NVobxZs2Zx/PHHx+OPPx6NGjXaqi8DANiJZO3++gDssjY+tu7vf//7ZueVlZUlI0aMSPbaa68kLy8vKSoqSoYOHVrh0WdJsmWPrUuSJHnzzTeTU045JWnUqFFSp06dZP/990+uv/76Sttdt25d0rhx46Rhw4bJ559/vkX79MUXXyRXXHFFsvvuuyd169ZNjjzyyGTGjBmVatv4qLfHH3+8wvKbqvmuu+5K9tprr6SgoCDp3Llz8tJLL1Va51dZv359svvuuycRkUyePLnS+y+//HLyzW9+M6lbt27SqlWr5Ec/+lHy3HPPVXo02pcfsZYkSbJs2bLkf//3f5PCwsKkcePGyQUXXJC8+eabVe7Le++9lwwYMCBp2bJlkpeXl7Ru3Tr5zne+kzzxxBNfuQ+xmcfAjRo1KkmSJFm9enVy+eWXJ61atUry8vKSfffdN/nZz35W4dGEU6dOTU4++eSkVatWSX5+ftKqVavktNNOS955553MnF//+tfJMccckzRp0iQpKChI2rVrl1x11VXJZ599ttkaN/4d/uxnP6vy/eHDh3/lY+ueeOKJ5LjjjkuaN2+e5OfnJ3vuuWdywQUXJB9//HGFdY0bNy7Ze++9k1q1alX6e7rzzjuT9u3bJ3l5eUmLFi2Siy66KPn0008rLN+9e/evfDTfY489lkREcv755292HgA7r5wk2c535wGAndz69eujVatW0bdv30rXxENN8cwzz0S/fv3ipZdeyjxWEYB0cQ09ADXO008/HcuWLYsBAwZkuxTImnHjxsXee++duRQBgPRxDT0ANcbf/va3eOONN2LUqFFx2GGHRffu3bNdElS7iRMnxhtvvBGTJk2KX/ziF9X+6EgAth+n3ANQY5x99tnx0EMPRceOHWP8+PFx8MEHZ7skqHY5OTlRr1696N+/f4wdOzZq13Z8ByCtsnrK/UsvvRR9+/aNVq1aRU5OTjz99NNfucz06dPj8MMPj4KCgthnn31i/PjxO7xOAHYN48ePj/Xr18err74qzFNjJUkSq1evjnvvvVeYB0i5rAb6NWvWRIcOHWLMmDFbNH/BggVx4oknRs+ePWPOnDlx2WWXxbnnnhvPPffcDq4UAAAAdi47zSn3OTk58dRTT0W/fv02Oefqq6+OSZMmxZtvvpkZ+8EPfhArV66MKVOmVEOVAAAAsHNI1XlWM2bMiF69elUY69OnT1x22WWbXGbdunWxbt26zOvy8vL45JNPokmTJm4CAwAAwA638XKnVq1aRW7u9jtRPlWBfvHixdGiRYsKYy1atIhVq1bF559/HnXr1q20zOjRo2PEiBHVVSIAAABU6YMPPog99thju60vVYF+WwwdOjSKi4szrz/77LPYc88945133onddtsti5XBjlNWVhbTpk2Lnj17Rl5eXrbLgR1Cn1MT6HNqAn1OTfDJJ5/EfvvtF/Xr19+u601VoG/ZsmUsWbKkwtiSJUuiQYMGVR6dj4goKCiIgoKCSuO77bZbNGnSZIfUCdlWVlYWhYWF0aRJE/9hZJelz6kJ9Dk1gT6nJtnel31n9S73W6tbt24xderUCmMlJSXRrVu3LFUEAAAA2ZHVQP/vf/875syZE3PmzImI/zyWbs6cObFo0aKI+M/p8gMGDMjMv/DCC2P+/Pnxox/9KN5+++2466674rHHHovLL788G+UDAABA1mQ10L/66qtx2GGHxWGHHRYREcXFxXHYYYfFsGHDIiLi448/zoT7iIi99torJk2aFCUlJdGhQ4f4+c9/Hvfee2/06dMnK/UDAABAtmT1GvoePXpEkiSbfH/8+PFVLvPaa6/twKoAAADg/yRJEuvXr48NGzZsck5eXl7UqlWrGqtK2U3xAAAAoDqVlpbGxx9/HGvXrt3svJycnNhjjz2iXr161VSZQA8AAABVKi8vjwULFkStWrWiVatWkZ+fX+Wd6pMkiWXLlsWHH34Y++67b7UdqRfoAQAAoAqlpaVRXl4eRUVFUVhYuNm5zZo1i4ULF0ZZWVm1BfpUPbYOAAAAqltu7ldH5+39jPktIdADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAADAZiRJsl3mbG8CPQAAAFQhLy8vIiLWrl37lXNLS0sjIqrtkXURnkMPAAAAVapVq1Y0atQoli5dGhERhYWFVT6erry8PJYtWxaFhYVRu3b1xWyBHgAAADahZcuWERGZUL8pubm5seeee1br8+gFegAAANiEnJyc2H333aN58+ZRVla2yXn5+fmRm1u9V7UL9AAAAPAVatWqVa3Xx28JN8UDAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEihrAf6MWPGRNu2baNOnTrRtWvXmDlz5mbn33HHHbH//vtH3bp1o6ioKC6//PL44osvqqlaAAAA2DlkNdA/+uijUVxcHMOHD4/Zs2dHhw4dok+fPrF06dIq5z/88MNxzTXXxPDhw2Pu3Llx3333xaOPPhrXXnttNVcOAAAA2ZXVQH/bbbfFeeedF4MGDYoDDzwwxo4dG4WFhXH//fdXOf+VV16JI488Mk4//fRo27ZtHHfccXHaaad95VF9AAAA2NXUztaGS0tLY9asWTF06NDMWG5ubvTq1StmzJhR5TJHHHFEPPTQQzFz5szo0qVLzJ8/PyZPnhxnnXXWJrezbt26WLduXeb1qlWrIiKirKwsysrKttPewM5lY2/rcXZl+pyaQJ9TE+hzaoId1d9ZC/TLly+PDRs2RIsWLSqMt2jRIt5+++0qlzn99NNj+fLlcdRRR0WSJLF+/fq48MILN3vK/ejRo2PEiBGVxqdNmxaFhYVfbydgJ1dSUpLtEmCH0+fUBPqcmkCfsytbu3btDllv1gL9tpg+fXrcfPPNcdddd0XXrl3j3XffjUsvvTRGjRoV119/fZXLDB06NIqLizOvV61aFUVFRdGzZ89o0qRJdZUO1aqsrCxKSkqid+/ekZeXl+1yYIfQ59QE+pyaQJ9TE6xYsWKHrDdrgb5p06ZRq1atWLJkSYXxJUuWRMuWLatc5vrrr4+zzjorzj333IiIOOSQQ2LNmjVx/vnnx3XXXRe5uZVvCVBQUBAFBQWVxvPy8vzCYJenz6kJ9Dk1gT6nJtDn7Mp2VG9n7aZ4+fn50alTp5g6dWpmrLy8PKZOnRrdunWrcpm1a9dWCu21atWKiIgkSXZcsQAAALCTyeop98XFxTFw4MDo3LlzdOnSJe64445Ys2ZNDBo0KCIiBgwYEK1bt47Ro0dHRETfvn3jtttui8MOOyxzyv31118fffv2zQR7AAAAqAmyGuj79+8fy5Yti2HDhsXixYujY8eOMWXKlMyN8hYtWlThiPyPf/zjyMnJiR//+Mfx0UcfRbNmzaJv375x0003ZWsXAAAAICuyflO8IUOGxJAhQ6p8b/r06RVe165dO4YPHx7Dhw+vhsoAAABg55W1a+gBAACAbSfQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAplPdCPGTMm2rZtG3Xq1ImuXbvGzJkzNzt/5cqVMXjw4Nh9992joKAg9ttvv5g8eXI1VQsAAAA7h9rZ3Pijjz4axcXFMXbs2OjatWvccccd0adPn5g3b140b9680vzS0tLo3bt3NG/ePJ544olo3bp1vP/++9GoUaPqLx4AAACyKKuB/rbbbovzzjsvBg0aFBERY8eOjUmTJsX9998f11xzTaX5999/f3zyySfxyiuvRF5eXkREtG3btjpLBgAAgJ1C1gJ9aWlpzJo1K4YOHZoZy83NjV69esWMGTOqXObZZ5+Nbt26xeDBg+OZZ56JZs2axemnnx5XX3111KpVq8pl1q1bF+vWrcu8XrVqVURElJWVRVlZ2XbcI9h5bOxtPc6uTJ9TE+hzagJ9Tk2wo/o7a4F++fLlsWHDhmjRokWF8RYtWsTbb79d5TLz58+PF154Ic4444yYPHlyvPvuu3HxxRdHWVlZDB8+vMplRo8eHSNGjKg0Pm3atCgsLPz6OwI7sZKSkmyXADucPqcm0OfUBPqcXdnatWt3yHqzesr91iovL4/mzZvHPffcE7Vq1YpOnTrFRx99FD/72c82GeiHDh0axcXFmderVq2KoqKi6NmzZzRp0qS6SodqVVZWFiUlJdG7d+/M5Smwq9Hn1AT6nJpAn1MTrFixYoesN2uBvmnTplGrVq1YsmRJhfElS5ZEy5Ytq1xm9913j7y8vAqn1x9wwAGxePHiKC0tjfz8/ErLFBQUREFBQaXxvLw8vzDY5elzagJ9Tk2gz6kJ9Dm7sh3V21l7bF1+fn506tQppk6dmhkrLy+PqVOnRrdu3apc5sgjj4x33303ysvLM2PvvPNO7L777lWGeQAAANhVZfU59MXFxTFu3Lh48MEHY+7cuXHRRRfFmjVrMne9HzBgQIWb5l100UXxySefxKWXXhrvvPNOTJo0KW6++eYYPHhwtnYBAAAAsiKr19D3798/li1bFsOGDYvFixdHx44dY8qUKZkb5S1atChyc//vO4eioqJ47rnn4vLLL49DDz00WrduHZdeemlcffXV2doFAAAAyIqs3xRvyJAhMWTIkCrfmz59eqWxbt26xV//+tcdXBUAAADs3LJ6yj0AAACwbQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJomwL9Bx98EB9++GHm9cyZM+Oyyy6Le+65Z7sVBgAAAGzaNgX6008/PaZNmxYREYsXL47evXvHzJkz47rrrouRI0du1wIBAACAyrYp0L/55pvRpUuXiIh47LHH4uCDD45XXnklJkyYEOPHj9+e9QEAAABV2KZAX1ZWFgUFBRER8fzzz8dJJ50UERHt27ePjz/+ePtVBwAAAFRpmwL9QQcdFGPHjo0///nPUVJSEscff3xERPy///f/okmTJtu1QAAAAKCybQr0P/nJT+LXv/519OjRI0477bTo0KFDREQ8++yzmVPxAQAAgB2n9rYs1KNHj1i+fHmsWrUqGjdunBk///zzo7CwcLsVBwAAAFRtm47Qf/7557Fu3bpMmH///ffjjjvuiHnz5kXz5s23a4EAAABAZdsU6E8++eT4zW9+ExERK1eujK5du8bPf/7z6NevX9x9993btUAAAACgsm0K9LNnz46jjz46IiKeeOKJaNGiRbz//vvxm9/8Jn75y19u1wIBAACAyrYp0K9duzbq168fERF/+tOf4rvf/W7k5ubGN7/5zXj//fe3a4EAAABAZdsU6PfZZ594+umn44MPPojnnnsujjvuuIiIWLp0aTRo0GC7FggAAABUtk2BftiwYXHllVdG27Zto0uXLtGtW7eI+M/R+sMOO2y7FggAAABUtk2PrTv11FPjqKOOio8//jjzDPqIiGOPPTZOOeWU7VYcAAAAULVtCvQRES1btoyWLVvGhx9+GBERe+yxR3Tp0mW7FQYAAABs2jadcl9eXh4jR46Mhg0bRps2baJNmzbRqFGjGDVqVJSXl2/vGgEAAIAv2aYj9Nddd13cd999ccstt8SRRx4ZERF/+ctf4oYbbogvvvgibrrppu1aJAAAAFDRNgX6Bx98MO6999446aSTMmOHHnpotG7dOi6++GKBHgAAAHawbTrl/pNPPon27dtXGm/fvn188sknX7soAAAAYPO2KdB36NAh7rzzzkrjd955Zxx66KFfuygAAABg87bplPuf/vSnceKJJ8bzzz+feQb9jBkz4oMPPojJkydv1wIBAACAyrbpCH337t3jnXfeiVNOOSVWrlwZK1eujO9+97vxz3/+M377299u7xoBAACAL9nm59C3atWq0s3vXn/99bjvvvvinnvu+dqFAQAAAJu2TUfoAQAAgOwS6AEAACCFBHoAAABIoa26hv673/3uZt9fuXLl16kFAAAA2EJbFegbNmz4le8PGDDgaxUEAAAAfLWtCvQPPPDAjqoDAAAA2AquoQcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAUEugBAAAghQR6AAAASCGBHgAAAFJIoAcAAIAU2ikC/ZgxY6Jt27ZRp06d6Nq1a8ycOXOLlps4cWLk5OREv379dmyBAAAAsJPJeqB/9NFHo7i4OIYPHx6zZ8+ODh06RJ8+fWLp0qWbXW7hwoVx5ZVXxtFHH11NlQIAAMDOI+uB/rbbbovzzjsvBg0aFAceeGCMHTs2CgsL4/7779/kMhs2bIgzzjgjRowYEXvvvXc1VgsAAAA7h9rZ3HhpaWnMmjUrhg4dmhnLzc2NXr16xYwZMza53MiRI6N58+ZxzjnnxJ///OfNbmPdunWxbt26zOtVq1ZFRERZWVmUlZV9zT2AndPG3tbj7Mr0OTWBPqcm0OfUBDuqv7Ma6JcvXx4bNmyIFi1aVBhv0aJFvP3221Uu85e//CXuu+++mDNnzhZtY/To0TFixIhK49OmTYvCwsKtrhnSpKSkJNslwA6nz6kJ9Dk1gT5nV7Z27dodst6sBvqttXr16jjrrLNi3Lhx0bRp0y1aZujQoVFcXJx5vWrVqigqKoqePXtGkyZNdlSpkFVlZWVRUlISvXv3jry8vGyXAzuEPqcm0OfUBPqcmmDFihU7ZL1ZDfRNmzaNWrVqxZIlSyqML1myJFq2bFlp/nvvvRcLFy6Mvn37ZsbKy8sjIqJ27doxb968aNeuXYVlCgoKoqCgoNK68vLy/MJgl6fPqQn0OTWBPqcm0OfsynZUb2f1pnj5+fnRqVOnmDp1amasvLw8pk6dGt26das0v3379vGPf/wj5syZk/k56aSTomfPnjFnzpwoKiqqzvIBAAAga7J+yn1xcXEMHDgwOnfuHF26dIk77rgj1qxZE4MGDYqIiAEDBkTr1q1j9OjRUadOnTj44IMrLN+oUaOIiErjAAAAsCvLeqDv379/LFu2LIYNGxaLFy+Ojh07xpQpUzI3ylu0aFHk5mb96XoAAACwU8l6oI+IGDJkSAwZMqTK96ZPn77ZZcePH7/9CwIAAICdnEPfAAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEICPQAAAKSQQA8AAAApJNADAABACgn0AAAAkEI7RaAfM2ZMtG3bNurUqRNdu3aNmTNnbnLuuHHj4uijj47GjRtH48aNo1evXpudDwAAALuirAf6Rx99NIqLi2P48OExe/bs6NChQ/Tp0yeWLl1a5fzp06fHaaedFtOmTYsZM2ZEUVFRHHfccfHRRx9Vc+UAAACQPVkP9Lfddlucd955MWjQoDjwwANj7NixUVhYGPfff3+V8ydMmBAXX3xxdOzYMdq3bx/33ntvlJeXx9SpU6u5cgAAAMie2tnceGlpacyaNSuGDh2aGcvNzY1evXrFjBkztmgda9eujbKysthtt92qfH/dunWxbt26zOtVq1ZFRERZWVmUlZV9jeph57Wxt/U4uzJ9Tk2gz6kJ9Dk1wY7q76wG+uXLl8eGDRuiRYsWFcZbtGgRb7/99hat4+qrr45WrVpFr169qnx/9OjRMWLEiErj06ZNi8LCwq0vGlKkpKQk2yXADqfPqQn0OTWBPmdXtnbt2h2y3qwG+q/rlltuiYkTJ8b06dOjTp06Vc4ZOnRoFBcXZ16vWrUqioqKomfPntGkSZPqKhWqVVlZWZSUlETv3r0jLy8v2+XADqHPqQn0OTWBPqcmWLFixQ5Zb1YDfdOmTaNWrVqxZMmSCuNLliyJli1bbnbZW2+9NW655ZZ4/vnn49BDD93kvIKCgigoKKg0npeX5xcGuzx9Tk2gz6kJ9Dk1gT5nV7ajejurN8XLz8+PTp06Vbih3cYb3HXr1m2Ty/30pz+NUaNGxZQpU6Jz587VUSoAAADsVLJ+yn1xcXEMHDgwOnfuHF26dIk77rgj1qxZE4MGDYqIiAEDBkTr1q1j9OjRERHxk5/8JIYNGxYPP/xwtG3bNhYvXhwREfXq1Yt69eplbT8AAACgOmU90Pfv3z+WLVsWw4YNi8WLF0fHjh1jypQpmRvlLVq0KHJz/+9EgrvvvjtKS0vj1FNPrbCe4cOHxw033FCdpQMAAEDWZD3QR0QMGTIkhgwZUuV706dPr/B64cKFO74gAAAA2Mll9Rp6AAAAYNsI9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCAj0AAACkkEAPAAAAKSTQAwAAQAoJ9AAAAJBCO0WgHzNmTLRt2zbq1KkTXbt2jZkzZ252/uOPPx7t27ePOnXqxCGHHBKTJ0+upkoBAABg55D1QP/oo49GcXFxDB8+PGbPnh0dOnSIPn36xNKlS6uc/8orr8Rpp50W55xzTrz22mvRr1+/6NevX7z55pvVXDkAAABkT9YD/W233RbnnXdeDBo0KA488MAYO3ZsFBYWxv3331/l/F/84hdx/PHHx1VXXRUHHHBAjBo1Kg4//PC48847q7lyAAAAyJ7a2dx4aWlpzJo1K4YOHZoZy83NjV69esWMGTOqXGbGjBlRXFxcYaxPnz7x9NNPVzl/3bp1sW7duszrzz77LCIiPvnkk69ZPey8ysrKYu3atbFixYrIy8vLdjmwQ+hzagJ9Tk2gz6kJNubPJEm263qzGuiXL18eGzZsiBYtWlQYb9GiRbz99ttVLrN48eIq5y9evLjK+aNHj44RI0ZUGt9vv/22sWoAAADYeitWrIiGDRtut/VlNdBXh6FDh1Y4or9y5cpo06ZNLFq0aLt+kLAzWbVqVRQVFcUHH3wQDRo0yHY5sEPoc2oCfU5NoM+pCT777LPYc889Y7fddtuu681qoG/atGnUqlUrlixZUmF8yZIl0bJlyyqXadmy5VbNLygoiIKCgkrjDRs29AuDXV6DBg30Obs8fU5NoM+pCfQ5NUFu7va9jV1Wb4qXn58fnTp1iqlTp2bGysvLY+rUqdGtW7cql+nWrVuF+RERJSUlm5wPAAAAu6Ksn3JfXFwcAwcOjM6dO0eXLl3ijjvuiDVr1sSgQYMiImLAgAHRunXrGD16dEREXHrppdG9e/f4+c9/HieeeGJMnDgxXn311bjnnnuyuRsAAABQrbIe6Pv37x/Lli2LYcOGxeLFi6Njx44xZcqUzI3vFi1aVOG0hCOOOCIefvjh+PGPfxzXXntt7LvvvvH000/HwQcfvEXbKygoiOHDh1d5Gj7sKvQ5NYE+pybQ59QE+pyaYEf1eU6yve+bDwAAAOxwWb2GHgAAANg2Aj0AAACkkEAPAAAAKSTQAwAAQArtkoF+zJgx0bZt26hTp0507do1Zs6cudn5jz/+eLRv3z7q1KkThxxySEyePLmaKoVttzV9Pm7cuDj66KOjcePG0bhx4+jVq9dX/ruAncHW/j7faOLEiZGTkxP9+vXbsQXCdrC1fb5y5coYPHhw7L777lFQUBD77bef/+/CTm9r+/yOO+6I/fffP+rWrRtFRUVx+eWXxxdffFFN1cLWe+mll6Jv377RqlWryMnJiaeffvorl5k+fXocfvjhUVBQEPvss0+MHz9+q7e7ywX6Rx99NIqLi2P48OExe/bs6NChQ/Tp0yeWLl1a5fxXXnklTjvttDjnnHPitddei379+kW/fv3izTffrObKYcttbZ9Pnz49TjvttJg2bVrMmDEjioqK4rjjjouPPvqomiuHLbe1fb7RwoUL48orr4yjjz66miqFbbe1fV5aWhq9e/eOhQsXxhNPPBHz5s2LcePGRevWrau5cthyW9vnDz/8cFxzzTUxfPjwmDt3btx3333x6KOPxrXXXlvNlcOWW7NmTXTo0CHGjBmzRfMXLFgQJ554YvTs2TPmzJkTl112WZx77rnx3HPPbd2Gk11Mly5dksGDB2deb9iwIWnVqlUyevToKud///vfT0488cQKY127dk0uuOCCHVonfB1b2+dftn79+qR+/frJgw8+uKNKhK9tW/p8/fr1yRFHHJHce++9ycCBA5OTTz65GiqFbbe1fX733Xcne++9d1JaWlpdJcLXtrV9Pnjw4ORb3/pWhbHi4uLkyCOP3KF1wvYSEclTTz212Tk/+tGPkoMOOqjCWP/+/ZM+ffps1bZ2qSP0paWlMWvWrOjVq1dmLDc3N3r16hUzZsyocpkZM2ZUmB8R0adPn03Oh2zblj7/srVr10ZZWVnstttuO6pM+Fq2tc9HjhwZzZs3j3POOac6yoSvZVv6/Nlnn41u3brF4MGDo0WLFnHwwQfHzTffHBs2bKiusmGrbEufH3HEETFr1qzMafnz58+PyZMnx7e//e1qqRmqw/bKobW3Z1HZtnz58tiwYUO0aNGiwniLFi3i7bffrnKZxYsXVzl/8eLFO6xO+Dq2pc+/7Oqrr45WrVpV+iUCO4tt6fO//OUvcd9998WcOXOqoUL4+ralz+fPnx8vvPBCnHHGGTF58uR499134+KLL46ysrIYPnx4dZQNW2Vb+vz000+P5cuXx1FHHRVJksT69evjwgsvdMo9u5RN5dBVq1bF559/HnXr1t2i9exSR+iBr3bLLbfExIkT46mnnoo6depkuxzYLlavXh1nnXVWjBs3Lpo2bZrtcmCHKS8vj+bNm8c999wTnTp1iv79+8d1110XY8eOzXZpsN1Mnz49br755rjrrrti9uzZ8eSTT8akSZNi1KhR2S4Ndjq71BH6pk2bRq1atWLJkiUVxpcsWRItW7ascpmWLVtu1XzItm3p841uvfXWuOWWW+L555+PQw89dEeWCV/L1vb5e++9FwsXLoy+fftmxsrLyyMionbt2jFv3rxo167dji0attK2/D7ffffdIy8vL2rVqpUZO+CAA2Lx4sVRWloa+fn5O7Rm2Frb0ufXX399nHXWWXHuuedGRMQhhxwSa9asifPPPz+uu+66yM11TJL021QObdCgwRYfnY/YxY7Q5+fnR6dOnWLq1KmZsfLy8pg6dWp069atymW6detWYX5ERElJySbnQ7ZtS59HRPz0pz+NUaNGxZQpU6Jz587VUSpss63t8/bt28c//vGPmDNnTubnpJNOytw5tqioqDrLhy2yLb/PjzzyyHj33XczX1hFRLzzzjux++67C/PslLalz9euXVsptG/8Eus/9xuD9NtuOXTr7te385s4cWJSUFCQjB8/PnnrrbeS888/P2nUqFGyePHiJEmS5KyzzkquueaazPyXX345qV27dnLrrbcmc+fOTYYPH57k5eUl//jHP7K1C/CVtrbPb7nlliQ/Pz954oknko8//jjzs3r16mztAnylre3zL3OXe9Jga/t80aJFSf369ZMhQ4Yk8+bNS/7whz8kzZs3T2688cZs7QJ8pa3t8+HDhyf169dPHnnkkWT+/PnJn/70p6Rdu3bJ97///WztAnyl1atXJ6+99lry2muvJRGR3Hbbbclrr72WvP/++0mSJMk111yTnHXWWZn58+fPTwoLC5OrrroqmTt3bjJmzJikVq1ayZQpU7Zqu7tcoE+SJPnVr36V7Lnnnkl+fn7SpUuX5K9//Wvmve7duycDBw6sMP+xxx5L9ttvvyQ/Pz856KCDkkmTJlVzxbD1tqbP27Rpk0REpZ/hw4dXf+GwFbb29/l/E+hJi63t81deeSXp2rVrUlBQkOy9997JTTfdlKxfv76aq4atszV9XlZWltxwww1Ju3btkjp16iRFRUXJxRdfnHz66afVXzhsoWnTplX5/7c39vbAgQOT7t27V1qmY8eOSX5+frL33nsnDzzwwFZvNydJnLcCAAAAabNLXUMPAAAANYVADwAAACkk0AMAAEAKCfQAAACQQgI9AAAApJBADwAAACkk0AMAAEAKCfQAAACQQgI9AOyCevToEZdddlm2ywAAdiCBHgCyYFOBe/z48dGoUaNqr2f69OmRk5MTK1eu/NrrWrBgQZx++unRqlWrqFOnTuyxxx5x8sknx9tvvx0REQsXLoycnJyYM2fO194WANRktbNdAACw6ygrK4vevXvH/vvvH08++WTsvvvu8eGHH8Yf//jH7fJlAQDwfxyhB4Cd2Nlnnx39+vWLESNGRLNmzaJBgwZx4YUXRmlpaWbOmjVrYsCAAVGvXr3Yfffd4+c//3ml9fz2t7+Nzp07R/369aNly5Zx+umnx9KlSyPiP0fMe/bsGRERjRs3jpycnDj77LMjIqK8vDxGjx4de+21V9StWzc6dOgQTzzxxCbr/ec//xnvvfde3HXXXfHNb34z2rRpE0ceeWTceOON8c1vfjMiIvbaa6+IiDjssMMiJycnevTokVn+3nvvjQMOOCDq1KkT7du3j7vuuivz3sYj+xMnTowjjjgi6tSpEwcffHC8+OKLmTmffvppnHHGGdGsWbOoW7du7LvvvvHAAw9s5acOAOkg0APATm7q1Kkxd+7cmD59ejzyyCPx5JNPxogRIzLvX3XVVfHiiy/GM888E3/6059i+vTpMXv27ArrKCsri1GjRsXrr78eTz/9dCxcuDAT2ouKiuJ3v/tdRETMmzcvPv744/jFL34RERGjR4+O3/zmNzF27Nj45z//GZdffnmceeaZFUL0f2vWrFnk5ubGE088ERs2bKhyzsyZMyMi4vnnn4+PP/44nnzyyYiImDBhQgwbNixuuummmDt3btx8881x/fXXx4MPPlhh+auuuiquuOKKeO2116Jbt27Rt2/fWLFiRUREXH/99fHWW2/FH//4x5g7d27cfffd0bRp0635uAEgPRIAoNp17949ufTSSyuNP/DAA0nDhg0zrwcOHJjstttuyZo1azJjd999d1KvXr1kw4YNyerVq5P8/Pzksccey7y/YsWKpG7dulWuf6O///3vSUQkq1evTpIkSaZNm5ZERPLpp59m5nzxxRdJYWFh8sorr1RY9pxzzklOO+20Ta77zjvvTAoLC5P69esnPXv2TEaOHJm89957mfcXLFiQRETy2muvVViuXbt2ycMPP1xhbNSoUUm3bt0qLHfLLbdk3i8rK0v22GOP5Cc/+UmSJEnSt2/fZNCgQZusDQB2JY7QA8BOrkOHDlFYWJh53a1bt/j3v/8dH3zwQbz33ntRWloaXbt2zby/2267xf77719hHbNmzYq+ffvGnnvuGfXr14/u3btHRMSiRYs2ud1333031q5dG71794569eplfn7zm9/Ee++9t8nlBg8eHIsXL44JEyZEt27d4vHHH4+DDjooSkpKNrnMmjVr4r333otzzjmnwrZuvPHGStvq1q1b5s+1a9eOzp07x9y5cyMi4qKLLoqJEydGx44d40c/+lG88sorm9wmAKSdm+IBQBY0aNAgPvvss0rjK1eujIYNG27Xba1Zsyb69OkTffr0iQkTJkSzZs1i0aJF0adPnwrX4n/Zv//974iImDRpUrRu3brCewUFBZvdZv369aNv377Rt2/fuPHGG6NPnz5x4403Ru/evTe7rXHjxlX4ciIiolatWl+5jxudcMIJ8f7778fkyZOjpKQkjj322Bg8eHDceuutW7wOAEgLR+gBIAv233//Ste5R0TMnj079ttvvwpjr7/+enz++eeZ13/961+jXr16UVRUFO3atYu8vLz429/+lnn/008/jXfeeSfz+u23344VK1bELbfcEkcffXS0b98+c0O8jfLz8yMiKlz3fuCBB0ZBQUEsWrQo9tlnnwo/RUVFW7yvOTk50b59+1izZs0mt9WiRYto1apVzJ8/v9K2Nt5E77/3f6P169fHrFmz4oADDsiMNWvWLAYOHBgPPfRQ3HHHHXHPPfdsca0AkCaO0ANAFlx00UVx5513xiWXXBLnnntuFBQUxKRJk+KRRx6J3//+9xXmlpaWxjnnnBM//vGPY+HChTF8+PAYMmRI5ObmRr169eKcc86Jq666Kpo0aRLNmzeP6667LnJz/+87+z333DPy8/PjV7/6VVx44YXx5ptvxqhRoypso02bNpGTkxN/+MMf4tvf/nbUrVs36tevH1deeWVcfvnlUV5eHkcddVR89tln8fLLL0eDBg1i4MCBlfZrzpw5MXz48DjrrLPiwAMPjPz8/HjxxRfj/vvvj6uvvjoiIpo3bx5169aNKVOmxB577BF16tSJhg0bxogRI+KSSy6Jhg0bxvHHHx/r1q2LV199NT799NMoLi7ObGPMmDGx7777xgEHHBC33357fPrpp/HDH/4wIiKGDRsWnTp1ioMOOijWrVsXf/jDHyqEfQDYpWT7In4AqKlmzpyZ9O7dO2nWrFnSsGHDpGvXrslTTz1VYc7AgQOTk08+ORk2bFjSpEmTpF69esl5552XfPHFF5k5q1evTs4888yksLAwadGiRfLTn/600k33Hn744aRt27ZJQUFB0q1bt+TZZ5+tdGO6kSNHJi1btkxycnKSgQMHJkmSJOXl5ckdd9yR7L///kleXl7SrFmzpE+fPsmLL75Y5T4tW7YsueSSS5KDDz44qVevXlK/fv3kkEMOSW699dZkw4YNmXnjxo1LioqKktzc3KR79+6Z8QkTJiQdO3ZM8vPzk8aNGyfHHHNM8uSTTyZJ8n83xXv44YeTLl26JPn5+cmBBx6YvPDCC5nlR40alRxwwAFJ3bp1k9122y05+eSTk/nz52/l3wwApENOkiRJtr9UAACqdvbZZ8fKlSvj6aefznYpWbdw4cLYa6+94rXXXouOHTtmuxwAyDrX0AMAAEAKCfQAAACQQk65BwAAgBRyhB4AAABSSKAHAACAFBLoAQAAIIUEegAAAEghgR4AAABSSKAHAACAFBLoAQAAIIUEegAAAEih/w+y0r88O9SHTQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file navigation_comm.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"navigation_comm.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import ast\n",
    "from vmas import make_env\n",
    "from vmas.simulator.core import Agent\n",
    "from vmas.simulator.scenario import BaseScenario\n",
    "from typing import Union\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from IPython.display import HTML, display as ipython_display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.spaces import Discrete\n",
    "import math\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# Actor-Critic Neural Network for PPO\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_size=64):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_dim)\n",
    "        )\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        policy_dist = torch.tanh(self.actor(x))\n",
    "        rounded_policy_dist = self.round_actions(policy_dist, decimal_places=2)\n",
    "        return rounded_policy_dist, value\n",
    "\n",
    "    def round_actions(self, actions, decimal_places=3):\n",
    "        scale_factor = 10 ** decimal_places\n",
    "        return torch.round(actions * scale_factor) / scale_factor\n",
    "\n",
    "\n",
    "# PPO Buffer to store trajectories\n",
    "class PPOBuffer:\n",
    "    def __init__(self, state_dim, action_dim, size, device):\n",
    "        self.states = torch.zeros(size, state_dim, device=device)\n",
    "        self.actions = torch.zeros(size, action_dim, device=device)\n",
    "        self.rewards = torch.zeros(size, device=device)\n",
    "        self.next_states = torch.zeros(size, state_dim, device=device)\n",
    "        self.log_probs = torch.zeros(size, device=device)\n",
    "        self.values = torch.zeros(size, device=device)\n",
    "        self.advantages = torch.zeros(size, device=device)\n",
    "        self.returns = torch.zeros(size, device=device)\n",
    "        self.pointer = 0\n",
    "        self.max_size = size\n",
    "        self.device = device\n",
    "\n",
    "    def store(self, state, action, reward, next_state, log_prob, value):\n",
    "        # print(f\"Buffer pointer before storing: {self.pointer}\")\n",
    "        idx = self.pointer\n",
    "        self.states[idx] = state\n",
    "        self.actions[idx] = action\n",
    "        self.rewards[idx] = reward\n",
    "        self.next_states[idx] = next_state\n",
    "\n",
    "        if log_prob is not None:\n",
    "            self.log_probs[idx] = log_prob\n",
    "        if value is not None:\n",
    "            self.values[idx] = value\n",
    "\n",
    "        self.pointer += 1\n",
    "        # print(f\"Buffer pointer after storing: {self.pointer}\")\n",
    "\n",
    "\n",
    "\n",
    "    def finish_path(self, last_value, gamma, lam):\n",
    "        path_slice = slice(0, self.pointer)\n",
    "        rewards = torch.cat([self.rewards[path_slice], last_value.unsqueeze(0)], dim=0)\n",
    "        values = torch.cat([self.values[path_slice], last_value.unsqueeze(0)], dim=0)\n",
    "        deltas = rewards[:-1] + gamma * values[1:] - values[:-1]\n",
    "        self.advantages[path_slice] = self.discount_cumsum(deltas, lam * gamma)\n",
    "        self.returns[path_slice] = self.discount_cumsum(rewards, gamma)[:-1]\n",
    "\n",
    "    def discount_cumsum(self, x, discount):\n",
    "        return torch.flip(torch.cumsum(torch.flip(x, dims=[0]) * discount, dim=0), dims=[0])\n",
    "\n",
    "    def get(self):\n",
    "        # Retrieve data up to the current pointer position\n",
    "        states = self.states[:self.pointer]\n",
    "        actions = self.actions[:self.pointer]\n",
    "        log_probs = self.log_probs[:self.pointer]\n",
    "        advantages = self.advantages[:self.pointer]\n",
    "        returns = self.returns[:self.pointer]\n",
    "\n",
    "        # Reset the pointer for the next batch of data\n",
    "        self.pointer = 0\n",
    "        \n",
    "        return states, actions, log_probs, advantages, returns\n",
    "\n",
    "\n",
    "\n",
    "# Problem Solver class for PPO\n",
    "class ProblemSolver:\n",
    "    def __init__(self, env, agent_id, state_dim, action_dim, device, alpha=0.1, gamma=0.99, epsilon=0.2, K_epochs=4, batch_size=64, communication_weight=0.5):\n",
    "        self.buffer = PPOBuffer(state_dim, action_dim, size=1000, device=device)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.K_epoch = K_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.env = env\n",
    "        self.agent_id = agent_id\n",
    "        self.device = device\n",
    "\n",
    "        self.policy = ActorCritic(state_dim, action_dim).to(device)\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=alpha)\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        self.policy_loss_history = []\n",
    "        self.value_loss_history = []\n",
    "\n",
    "    def get_action_continuous(self, agent_obs):\n",
    "        state = torch.Tensor(agent_obs[:6]).to(self.device) if not isinstance(agent_obs[:6], torch.Tensor) else agent_obs[:6].to(self.device)\n",
    "        state = state.float()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            policy_dist, value = self.policy_old(state)\n",
    "        \n",
    "        # Assuming Gaussian policy for continuous action space\n",
    "        dist = torch.distributions.Normal(policy_dist, torch.ones_like(policy_dist) * 0.1)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action).sum(dim=-1)  # Sum over actions if multiple\n",
    "        \n",
    "        return action.cpu().numpy(), log_prob, value\n",
    "\n",
    "\n",
    "    def update_action_continuous(self):\n",
    "        if self.buffer.pointer < self.batch_size:\n",
    "            return  # Not enough data to perform an update\n",
    "\n",
    "        states, actions, log_probs, advantages, returns = self.buffer.get()\n",
    "\n",
    "        for _ in range(self.K_epoch):\n",
    "            # Calculate new log probabilities and state values\n",
    "            new_log_probs, state_values = self.policy(states)\n",
    "            \n",
    "            # Sum the log probabilities over the action dimension to reduce to 1D\n",
    "            new_log_probs = new_log_probs.sum(dim=-1)\n",
    "\n",
    "            # Now the shapes should match, and ratios can be computed\n",
    "            ratios = torch.exp(new_log_probs - log_probs)\n",
    "\n",
    "            # Calculate the policy loss using the clipped surrogate objective\n",
    "            surrogate1 = ratios * advantages\n",
    "            surrogate2 = torch.clamp(ratios, 1 - self.epsilon, 1 + self.epsilon) * advantages\n",
    "            policy_loss = -torch.min(surrogate1, surrogate2).mean()\n",
    "\n",
    "            # Calculate the value loss\n",
    "            value_loss = (returns - state_values).pow(2).mean()\n",
    "\n",
    "            # Store the losses for later plotting\n",
    "            self.policy_loss_history.append(policy_loss.item())\n",
    "            self.value_loss_history.append(value_loss.item())\n",
    "\n",
    "            # Total loss and backpropagation\n",
    "            loss = policy_loss + 0.5 * value_loss\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "            print(\"Network Updated!\")\n",
    "\n",
    "\n",
    "\n",
    "    def store_in_buffer(self, state, action, reward, next_state, log_prob, value):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = torch.tensor(state, device=self.device, dtype=torch.float32)\n",
    "        if isinstance(action, np.ndarray):\n",
    "            action = torch.tensor(action, device=self.device, dtype=torch.float32)\n",
    "        if isinstance(next_state, np.ndarray):\n",
    "            next_state = torch.tensor(next_state, device=self.device, dtype=torch.float32)\n",
    "        if isinstance(reward, (float, int)):\n",
    "            reward = torch.tensor(reward, device=self.device, dtype=torch.float32)\n",
    "\n",
    "        # Ensure log_prob is consistent with new_log_probs by summing if necessary\n",
    "        if log_prob is not None and len(log_prob.shape) > 1:\n",
    "            log_prob = log_prob.sum(dim=-1)\n",
    "\n",
    "        self.buffer.store(state, action, reward, next_state, log_prob, value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def finish_path(self, last_value):\n",
    "        self.buffer.finish_path(last_value, self.gamma, lam=0.95)\n",
    "\n",
    "\n",
    "# Case-Based Reasoning class\n",
    "class Case:\n",
    "    added_states = set()\n",
    "\n",
    "    def __init__(self, problem, solution, reward, trust_value=1):\n",
    "        self.problem = problem\n",
    "        self.solution = solution\n",
    "        self.reward = reward\n",
    "        self.trust_value = trust_value\n",
    "\n",
    "    @staticmethod\n",
    "    def sim_q(state1, state2):\n",
    "        state1 = np.atleast_1d(state1)\n",
    "        state2 = np.atleast_1d(state2)\n",
    "        CNDMaxDist = 6\n",
    "        v = state1.size\n",
    "        DistQ = np.sum([Case.dist_q(Objic, Objip) for Objic, Objip in zip(state1, state2)])\n",
    "        similarity = (CNDMaxDist * v - DistQ) / (CNDMaxDist * v)\n",
    "        return similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def dist_q(X1, X2):\n",
    "        return np.min(np.abs(X1 - X2))\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(agent, env, state, case_base, threshold=0.1):\n",
    "        if isinstance(state, torch.Tensor):\n",
    "            state = state.cpu().numpy()\n",
    "\n",
    "        state_list = state.tolist() if isinstance(state, np.ndarray) else state\n",
    "        state_str = json.dumps(state_list)\n",
    "        state = ast.literal_eval(state_str)\n",
    "\n",
    "        similarities = {}\n",
    "        for case in case_base:\n",
    "            problem_numeric = np.array(case.problem, dtype=float)\n",
    "            state_numeric = np.array(state, dtype=float)\n",
    "            similarities[case] = Case.sim_q(state_numeric, problem_numeric)\n",
    "\n",
    "        sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if sorted_similarities:\n",
    "            most_similar_case = sorted_similarities[0][0] if sorted_similarities[0][1] >= threshold else None\n",
    "        else:\n",
    "            most_similar_case = None\n",
    "\n",
    "        return most_similar_case\n",
    "\n",
    "    @staticmethod\n",
    "    def reuse(c, temporary_case_base):\n",
    "        temporary_case_base.append(c)\n",
    "\n",
    "    @staticmethod\n",
    "    def revise(case_base, temporary_case_base, successful_task):\n",
    "        for case in temporary_case_base:\n",
    "            if successful_task and case in case_base:\n",
    "                case.trust_value += 0.1\n",
    "            elif not successful_task and case in case_base:\n",
    "                case.trust_value -= 0.1\n",
    "            case.trust_value = max(0, min(case.trust_value, 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def retain(case_base, temporary_case_base, successful_task, threshold=0.7):\n",
    "        if successful_task:\n",
    "            aggregation_dict = defaultdict(lambda: {'x_velocity_sum': 0, 'y_velocity_sum': 0, 'reward_sum': 0, 'count': 0})\n",
    "            for case in temporary_case_base:\n",
    "                state = tuple(np.atleast_1d(case.problem))\n",
    "                aggregation_dict[state]['x_velocity_sum'] += case.solution[0]\n",
    "                aggregation_dict[state]['y_velocity_sum'] += case.solution[1]\n",
    "                aggregation_dict[state]['reward_sum'] += case.reward\n",
    "                aggregation_dict[state]['count'] += 1\n",
    "            \n",
    "            for state, values in aggregation_dict.items():\n",
    "                aggregated_case = Case(\n",
    "                    problem=state,\n",
    "                    solution=[values['x_velocity_sum'] / values['count'], values['y_velocity_sum'] / values['count']],\n",
    "                    reward=values['reward_sum'] / values['count'],\n",
    "                    trust_value=np.nan\n",
    "                )\n",
    "                if state not in Case.added_states:\n",
    "                    case_base.append(aggregated_case)\n",
    "                    Case.added_states.add(state)\n",
    "                else:\n",
    "                    existing_index = next((i for i, c in enumerate(case_base) if tuple(np.atleast_1d(c.problem)) == state), None)\n",
    "                    if existing_index is not None:\n",
    "                        existing_case = case_base[existing_index]\n",
    "                        existing_case.solution = aggregated_case.solution\n",
    "                        existing_case.reward = aggregated_case.reward\n",
    "                        existing_case.trust_value = np.nan\n",
    "        case_base = [case for case in case_base if case.trust_value >= threshold]\n",
    "        return case_base\n",
    "\n",
    "\n",
    "# Main runner for VMAS environment\n",
    "class QCBRLVmasRunner:\n",
    "    def __init__(\n",
    "        self,\n",
    "        render: bool,\n",
    "        num_envs: int,\n",
    "        num_episodes: int,\n",
    "        max_steps_per_episode: int,\n",
    "        device: str,\n",
    "        scenario: Union[str, BaseScenario],\n",
    "        continuous_actions: bool,\n",
    "        random_action: bool,\n",
    "        n_agents: int,\n",
    "        obs_discrete: bool = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.render = render\n",
    "        self.num_envs = num_envs\n",
    "        self.num_episodes = num_episodes\n",
    "        self.max_steps_per_episode = max_steps_per_episode\n",
    "        self.device = device\n",
    "        self.scenario = scenario\n",
    "        self.continuous_actions = continuous_actions\n",
    "        self.random_action = random_action\n",
    "        self.obs_discrete = obs_discrete\n",
    "        self.kwargs = kwargs\n",
    "        self.frame_list = []\n",
    "        self.problem_solver_agents = []\n",
    "        self.rewards_history = []\n",
    "        self.action_counts = {i: {} for i in range(n_agents)}\n",
    "        self.agent_rewards_history = {i: [] for i in range(n_agents)}\n",
    "        self.successful_episodes_individual = {i: 0 for i in range(n_agents)}\n",
    "        self.successful_episodes_all_agents = 0\n",
    "        self.case_base = {i: [] for i in range(n_agents)}\n",
    "        self.temporary_case_base = {i: [] for i in range(n_agents)}\n",
    "\n",
    "    def get_distance_category(self, distance):\n",
    "        if distance == 0:\n",
    "            distance_qualitative = 0 #at\n",
    "        elif distance < 0.1:\n",
    "            distance_qualitative = 1 #very close\n",
    "        elif distance < 0.25:\n",
    "            distance_qualitative = 2 #close\n",
    "        elif distance < 0.5:\n",
    "            distance_qualitative = 3 #far\n",
    "        elif distance < 75:\n",
    "            distance_qualitative = 4 #very far\n",
    "        else:\n",
    "            distance_qualitative = 5 #farthest\n",
    "        return distance_qualitative\n",
    "        \n",
    "    def get_direction_category(self, agent_x, agent_y, target_x, target_y):\n",
    "        dx = target_x - agent_x\n",
    "        dy = target_y - agent_y\n",
    "\n",
    "        if dy > 0:\n",
    "            if dx > 0:\n",
    "                direction_qualitative = 1 #top right\n",
    "            elif dx < 0:\n",
    "                direction_qualitative = 2 #top left\n",
    "            else:\n",
    "                direction_qualitative = 3 #top\n",
    "        elif dy < 0:\n",
    "            if dx > 0:\n",
    "                direction_qualitative = 4 #bottom right\n",
    "            elif dx < 0:\n",
    "                direction_qualitative = 5 #bottom left\n",
    "            else:\n",
    "                direction_qualitative = 6 #bottom\n",
    "        else:\n",
    "            if dx > 0:\n",
    "                direction_qualitative = 7 #right\n",
    "            elif dx < 0:\n",
    "                direction_qualitative = 8 #left\n",
    "            else:\n",
    "                direction_qualitative = 0 #at\n",
    "            \n",
    "        return direction_qualitative\n",
    "\n",
    "    def _get_qualitative_position(self, env, observation):\n",
    "        pos_x = observation[0:1]\n",
    "        pos_y = observation[1:2]\n",
    "        goal_x = observation[4:5]\n",
    "        goal_y = observation[5:6]    \n",
    "\n",
    "        distance = math.sqrt((goal_x - pos_x)**2 + (goal_y - pos_y)**2) #Euclidean distance\n",
    "        distance_category = self.get_distance_category(distance)\n",
    "        direction_category = self.get_direction_category(pos_x, pos_y, goal_x, goal_y)\n",
    "      \n",
    "        return distance_category, direction_category\n",
    "\n",
    "    def _get_action(self, agent, env, agent_id, obs_qualitative, obs_quantitative, device, episode):\n",
    "        physical_action = []\n",
    "        comm_action_length = 4\n",
    "\n",
    "        case = Case.retrieve(agent, env, obs_qualitative, self.case_base[agent_id], threshold=0.1)\n",
    "                        \n",
    "        if case:\n",
    "            physical_action = case.solution\n",
    "            log_prob, value = None, None  # No log_prob or value for case-based actions\n",
    "            print(f\"Episode {episode} - Action from Case Base\")\n",
    "        else:    \n",
    "            physical_obs_quantitative = obs_quantitative[0:6]\n",
    "\n",
    "            if self.continuous_actions:\n",
    "                physical_action, log_prob, value = self.problem_solver_agents[agent_id].get_action_continuous(physical_obs_quantitative)\n",
    "                if isinstance(physical_action, np.ndarray):\n",
    "                    physical_action = torch.tensor(physical_action, device=self.device, dtype=torch.float32)\n",
    "                \n",
    "                # Store valid data in the buffer\n",
    "                if log_prob is not None and value is not None:\n",
    "                    self.problem_solver_agents[agent_id].store_in_buffer(physical_obs_quantitative, physical_action, log_prob, value, None, None)\n",
    "            else:\n",
    "                physical_action = self.problem_solver_agents[agent_id].get_action_discrete(agent, env, agent_id, physical_obs_quantitative, device)\n",
    "                log_prob, value = None, None  # No log_prob or value for discrete actions\n",
    "                \n",
    "\n",
    "            print(f\"Episode {episode} - Action from Problem Solver\")\n",
    "        \n",
    "        \n",
    "        physical_action_tensor = torch.tensor(physical_action, device=self.device)\n",
    "        zero_tensor = torch.zeros(comm_action_length, dtype=torch.float64, device=self.device)\n",
    "        physical_action_tensor_padded = torch.cat((physical_action_tensor, zero_tensor))\n",
    "\n",
    "        if agent.silent:\n",
    "            action = physical_action_tensor_padded\n",
    "        else:\n",
    "            if not case:\n",
    "                obs_qualitative_tensor = torch.tensor([float(99), float(99)], device=self.device)\n",
    "                reward_tensor = torch.tensor([float(0)], device=self.device)\n",
    "                trust_value_tensor = torch.tensor([float(0)], device=self.device)\n",
    "            else:  \n",
    "                obs_qualitative_tensor = torch.tensor(case.problem, device=self.device)\n",
    "                reward_tensor = torch.tensor(case.reward, device=self.device)\n",
    "                trust_value_tensor = torch.tensor(case.trust_value, device=self.device)\n",
    "\n",
    "            comm_action_tensor = torch.cat([obs_qualitative_tensor, physical_action_tensor, reward_tensor, trust_value_tensor], dim=0)\n",
    "            action = torch.stack((physical_action_tensor_padded, comm_action_tensor)).unsqueeze(0)\n",
    "\n",
    "        # Store in buffer only if log_prob and value are not None\n",
    "        if log_prob is not None and value is not None:\n",
    "            self.problem_solver_agents[agent_id].store_in_buffer(physical_obs_quantitative, physical_action, log_prob, value, None, None)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def save_case_base(self, agent_id):\n",
    "        filename = f\"cases/case_base_{agent_id}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.case_base[agent_id]:\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.tolist() if case.solution.numel() > 1 else int(case.solution.item())\n",
    "            else:\n",
    "                solution = int(case.solution)\n",
    "            \n",
    "            if torch.is_tensor(case.reward):\n",
    "                reward = case.reward.tolist() if case.reward.numel() > 1 else float(case.reward.item())\n",
    "            else:\n",
    "                reward = float(case.reward)\n",
    "\n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"reward\": reward,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Case base saved successfully.\")\n",
    "\n",
    "    def save_case_base_eps(self, agent_id, eps):\n",
    "        filename = f\"cases/case_base_{agent_id}_{eps}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.case_base[agent_id]:\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.tolist() if case.solution.numel() > 1 else int(case.solution.item())\n",
    "            else:\n",
    "                solution = int(case.solution)\n",
    "            \n",
    "            if torch.is_tensor(case.reward):\n",
    "                reward = case.reward.tolist() if case.reward.numel() > 1 else float(case.reward.item())\n",
    "            else:\n",
    "                reward = float(case.reward)\n",
    "            \n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"reward\": reward,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Case base saved successfully.\")\n",
    "\n",
    "\n",
    "    def save_case_base_temporary(self, agent_id,):\n",
    "        filename = f\"cases/case_base_temporary_{agent_id}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.temporary_case_base[agent_id]:\n",
    "\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.tolist() if case.solution.numel() > 1 else int(case.solution.item())\n",
    "            else:\n",
    "                solution = int(case.solution)\n",
    "\n",
    "            if torch.is_tensor(case.reward):\n",
    "                reward = case.reward.tolist() if case.reward.numel() > 1 else float(case.reward.item())\n",
    "            else:\n",
    "                reward = float(case.reward)\n",
    "            \n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"reward\": reward,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Temporary case base saved successfully.\")\n",
    "\n",
    "    def save_case_base_temporary_eps(self, agent_id, eps):\n",
    "        filename = f\"cases/case_base_temporary_{agent_id}_{eps}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.temporary_case_base[agent_id]:\n",
    "\n",
    "            # print (f\"case - problem: {case.problem}\")\n",
    "            # print (f\"case - solution: {case.solution}\")\n",
    "            # print (f\"case - reward: {case.reward}\")\n",
    "            # print (f\"case - trust_value: {case.trust_value}\")\n",
    "\n",
    "\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            precision = 4  # Adjust the precision as needed\n",
    "\n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.cpu().numpy().tolist() if case.solution.numel() > 1 else case.solution.item()\n",
    "                solution = [round(val, precision) for val in solution] if isinstance(solution, list) else round(solution, precision)\n",
    "            else:\n",
    "                solution = round(float(case.solution), precision)\n",
    "\n",
    "            \n",
    "            if torch.is_tensor(case.reward):\n",
    "                reward = case.reward.tolist() if case.reward.numel() > 1 else float(case.reward.item())\n",
    "            else:\n",
    "                reward = float(case.reward)\n",
    "            \n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            # print (f\"case - problem then: {problem}\")\n",
    "            # print (f\"case - solution then: {solution}\")\n",
    "            # print (f\"case - reward then: {reward}\")\n",
    "            # print (f\"case - trust_value then: {trust_value}\")\n",
    "\n",
    "\n",
    "\n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"reward\": reward,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Temporary case base saved successfully.\")\n",
    "\n",
    "        \n",
    "    def load_case_base(self, agent_id):\n",
    "        filename = f\"cases/case_base_{agent_id}.json\"\n",
    "        try:\n",
    "            with open(filename, 'r') as file:\n",
    "                case_base_data = json.load(file)\n",
    "            self.case_base[agent_id] = [Case(problem=np.array(case[\"problem\"]) if isinstance(case[\"problem\"], list) else case[\"problem\"],\n",
    "                                            solution=case[\"solution\"],reward=case[\"reward\"],\n",
    "                                            trust_value=case[\"trust_value\"]) for case in case_base_data]\n",
    "        except FileNotFoundError:\n",
    "            self.case_base[agent_id] = []\n",
    "\n",
    "    \n",
    "    def plot_action_distribution(self):\n",
    "        num_agents = len(self.action_counts)\n",
    "        for agent_id, counts in self.action_counts.items():\n",
    "            unique_actions, action_counts = np.unique(list(counts.values()), return_counts=True)\n",
    "            action_dict = dict(zip(unique_actions, action_counts))\n",
    "            plt.bar(action_dict.keys(), action_dict.values(), label=f'Agent {agent_id}', alpha=0.7)\n",
    "        plt.xlabel('Action')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Action Distribution for Each Agent')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_rewards_history(self):\n",
    "        num_agents = len(self.agent_rewards_history)\n",
    "        for agent_id, rewards in self.agent_rewards_history.items():\n",
    "            if len(rewards) > 0:  # Ensure that the rewards list is not empty\n",
    "                plt.plot(range(1, len(rewards) + 1), rewards, label=f'Agent {agent_id}')\n",
    "            else:\n",
    "                print(f\"Warning: No rewards recorded for Agent {agent_id}. Skipping plot.\")\n",
    "\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.title('Total Reward per Episode for Each Agent')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_loss_history(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for agent_id, agent in enumerate(self.problem_solver_agents):\n",
    "            if len(agent.policy_loss_history) > 0:\n",
    "                plt.plot(agent.policy_loss_history, label=f'Agent {agent_id} Policy Loss')\n",
    "            if len(agent.value_loss_history) > 0:\n",
    "                plt.plot(agent.value_loss_history, label=f'Agent {agent_id} Value Loss')\n",
    "        plt.xlabel('Update Steps')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Policy and Value Loss History')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def generate_gif(self, scenario_name):\n",
    "        fps = 25\n",
    "        clip = ImageSequenceClip(self.frame_list, fps=fps)\n",
    "        clip.write_gif(f'{scenario_name}.gif', fps=fps)\n",
    "        return HTML(f'<img src=\"{scenario_name}.gif\">')\n",
    "\n",
    "    def run_vmas_env(self):\n",
    "        scenario_name = self.scenario if isinstance(self.scenario, str) else self.scenario.__class__.__name__\n",
    "\n",
    "        env = make_env(\n",
    "            scenario=self.scenario,\n",
    "            num_envs=self.num_envs,\n",
    "            device=self.device,\n",
    "            continuous_actions=self.continuous_actions,\n",
    "            **self.kwargs\n",
    "        )\n",
    "        \n",
    "        states = env.reset()\n",
    "        first_agent_state = states[0][0:6]\n",
    "        state_dim = first_agent_state.shape[0]\n",
    "        action_dim = len(env.action_space)\n",
    "        \n",
    "        for agent_id, agent in enumerate(env.agents):\n",
    "            self.problem_solver_agents.append(ProblemSolver(env, agent_id, state_dim, action_dim, self.device, communication_weight=0.5))\n",
    "\n",
    "        init_time = time.time()\n",
    "        total_steps = 0\n",
    "\n",
    "        for episode in range(self.num_episodes):\n",
    "            obs_cont = env.reset()\n",
    "            dones = torch.tensor([False] * self.num_envs, device=self.device)\n",
    "            step = 0\n",
    "            \n",
    "            episode_rewards = {i: 0 for i in range(len(self.problem_solver_agents))}\n",
    "            episode_dones_counts = {i: 0 for i in range(len(env.agents))}\n",
    "            self.temporary_case_base = {i: [] for i in range(len(env.agents))}\n",
    "            \n",
    "            while not torch.all(dones).item() and step < self.max_steps_per_episode:\n",
    "                step += 1\n",
    "                total_steps += 1\n",
    "\n",
    "                actions = []\n",
    "                for agent_id, agent in enumerate(env.agents):\n",
    "                    if self.obs_discrete:\n",
    "                        obs_qualitative = self._get_qualitative_position(env, obs_cont[agent_id])\n",
    "                    action = self._get_action(agent, env, agent_id, obs_qualitative, obs_cont[agent_id], self.device, episode)\n",
    "                    actions.append(action)\n",
    "\n",
    "                next_obs_cont, rewards, dones, info = env.step(actions)\n",
    "\n",
    "                for agent_id, agent in enumerate(env.agents):\n",
    "                    print (f\"agent {agent_id} old state: {obs_cont[agent_id]}\")\n",
    "                    print (f\"agent {agent_id} action: {action}\")\n",
    "                    print (f\"agent {agent_id} reward: {rewards[agent_id]}\")\n",
    "                    print (f\"agent {agent_id} new state: {next_obs_cont[agent_id]}\")\n",
    "\n",
    "\n",
    "                    if self.obs_discrete:\n",
    "                        obs_qualitative = self._get_qualitative_position(env, obs_cont[agent_id])\n",
    "                        discrete_next_obs = self._get_qualitative_position(env, next_obs_cont[agent_id])\n",
    "\n",
    "                    problem = obs_qualitative\n",
    "                    physical_action = actions[agent_id][0,0,0:2]\n",
    "                    reward = rewards[agent_id]\n",
    "                    done = dones[0][agent_id]\n",
    "\n",
    "                    new_case = Case(problem, physical_action, reward)\n",
    "                    Case.reuse(new_case, self.temporary_case_base[agent_id])\n",
    "\n",
    "                    if self.continuous_actions:\n",
    "                        # print(f\"Tes update block\")\n",
    "                        self.problem_solver_agents[agent_id].update_action_continuous()\n",
    "                    else:\n",
    "                        self.problem_solver_agents[agent_id].update_action_discrete(agent, env, agent_id,\n",
    "                            obs_cont[agent_id], physical_action, rewards[agent_id].item(), next_obs_cont[agent_id]\n",
    "                        )\n",
    "\n",
    "                    # Accumulate rewards for each agent within the episode\n",
    "                    episode_rewards[agent_id] += rewards[agent_id].item()\n",
    "\n",
    "                    if dones[0][agent_id]:\n",
    "                        episode_dones_counts[agent_id] += 1\n",
    "                \n",
    "                obs_cont = next_obs_cont\n",
    "                if self.render:\n",
    "                    frame = env.render(mode=\"rgb_array\", agent_index_focus=None)\n",
    "                    self.frame_list.append(frame)\n",
    "\n",
    "            # Append the accumulated rewards for each agent to the history after each episode\n",
    "            for agent_id in range(len(env.agents)):\n",
    "                self.agent_rewards_history[agent_id].append(episode_rewards[agent_id])\n",
    "\n",
    "                Case.revise(self.case_base[agent_id], self.temporary_case_base[agent_id], dones[0][agent_id])\n",
    "                self.case_base[agent_id] = Case.retain(self.case_base[agent_id], self.temporary_case_base[agent_id], dones[0][agent_id])\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"------------------------------------------\")\n",
    "        for agent_id, agent in enumerate(env.agents):\n",
    "            self.save_case_base_temporary(agent_id)\n",
    "            self.save_case_base(agent_id)\n",
    "\n",
    "        overall_success_percentage = self.successful_episodes_all_agents / self.num_episodes * 100\n",
    "        print(f\"Overall success percentage for all agents = {overall_success_percentage}%\")\n",
    "\n",
    "        total_time = time.time() - init_time\n",
    "        print(\n",
    "            f\"It took: {total_time}s for {total_steps} steps across {self.num_episodes} episodes of {self.num_envs} parallel environments on device {self.device} \"\n",
    "            f\"for {scenario_name} scenario.\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scenario_name = \"navigation_comm\"\n",
    "    use_cuda = True\n",
    "\n",
    "    env_runner = QCBRLVmasRunner( \n",
    "        render=True,\n",
    "        num_envs=1,\n",
    "        num_episodes=3,\n",
    "        max_steps_per_episode=5,\n",
    "        device=torch.device(\"cuda\" if use_cuda else \"cpu\"),\n",
    "        scenario=scenario_name,\n",
    "        continuous_actions=True,\n",
    "        random_action=False,\n",
    "        n_agents=2,\n",
    "        obs_discrete=True,\n",
    "        agents_with_same_goal=2,\n",
    "        collisions=False,\n",
    "        shared_rew=False,\n",
    "    )\n",
    "\n",
    "    env_runner.run_vmas_env()\n",
    "    env_runner.plot_rewards_history()\n",
    "    env_runner.plot_loss_history()\n",
    "    ipython_display(env_runner.generate_gif(scenario_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
