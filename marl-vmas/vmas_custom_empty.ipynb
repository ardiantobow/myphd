{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 02:45:28,971 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n",
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n",
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n",
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n",
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n",
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n",
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n",
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n",
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode_reward_mean = 0:   0%|          | 0/60000 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensordict_data: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 100, 2, 2]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100, 2]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([60, 100]), device=cuda:0, dtype=torch.int64, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                            batch_size=torch.Size([60, 100, 2]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        observation: Tensor(shape=torch.Size([60, 100, 2, 18]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([60, 100, 2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
      "                    batch_size=torch.Size([60, 100, 2]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                done: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([60, 100]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([60, 100, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([60, 100]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "No episode_reward_done data found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import multiprocessing\n",
    "from torchrl.envs.libs.vmas import VmasEnv\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.envs import RewardSum, TransformedEnv\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import PIL.Image as PILImage\n",
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class QNetwork(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_shape,\n",
    "        action_shape,\n",
    "        n_agents,\n",
    "        device,\n",
    "        depth=2,\n",
    "        num_cells=256,\n",
    "        activation_class=torch.nn.Tanh,\n",
    "    ):\n",
    "        super(QNetwork, self).__init__()\n",
    "\n",
    "        self.q_net = MultiAgentMLP(\n",
    "            n_agent_inputs=observation_shape + action_shape,\n",
    "            n_agent_outputs=1,\n",
    "            n_agents=n_agents,\n",
    "            centralised=False,\n",
    "            share_params=True,\n",
    "            device=device,\n",
    "            depth=depth,\n",
    "            num_cells=num_cells,\n",
    "            activation_class=activation_class,\n",
    "        )\n",
    "\n",
    "    def forward(self, observation, action):\n",
    "        q_value = self.q_net(torch.cat([observation, action], dim=-1))\n",
    "        return q_value\n",
    "\n",
    "\n",
    "class QLearningLoss:\n",
    "    def __init__(self, q_network, optimizer, gamma):\n",
    "        self.q_network = q_network\n",
    "        self.optimizer = optimizer\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def calculate_and_optimize_loss(self, subdata):\n",
    "        observation = subdata.get((\"agents\", \"observation\"))\n",
    "        action = subdata.get((\"agents\", \"action\"))\n",
    "        reward = subdata.get((\"agents\", \"reward\"))\n",
    "        next_observation = subdata.get((\"next\", \"agents\", \"observation\"))\n",
    "        done = subdata.get((\"next\", \"agents\", \"done\"))\n",
    "\n",
    "        current_q = self.q_network(observation, action)\n",
    "        with torch.no_grad():\n",
    "            next_q = self.q_network(next_observation, action)\n",
    "            target_q = reward + (1 - done) * self.gamma * next_q\n",
    "\n",
    "        loss_value = torch.nn.functional.mse_loss(current_q, target_q)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "\n",
    "class QLearningTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        q_network,\n",
    "        replay_buffer,\n",
    "        optimizer,\n",
    "        loss_module,\n",
    "        collector,\n",
    "        num_epochs,\n",
    "        minibatch_size,\n",
    "        frames_per_batch,\n",
    "        device,\n",
    "        total_frames,\n",
    "        gamma,\n",
    "        env,\n",
    "        visualization_handler=None,\n",
    "    ):\n",
    "        self.q_network = q_network\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_module = loss_module\n",
    "        self.collector = collector\n",
    "        self.num_epochs = num_epochs\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.frames_per_batch = frames_per_batch\n",
    "        self.device = device\n",
    "        self.total_frames = total_frames\n",
    "        self.gamma = gamma\n",
    "        self.env = env\n",
    "        self.visualization_handler = visualization_handler\n",
    "\n",
    "    def train(self, max_steps):\n",
    "        pbar = tqdm(total=self.total_frames, desc=\"episode_reward_mean = 0\")\n",
    "        episode_reward_mean_list = []\n",
    "\n",
    "        for tensordict_data in self.collector:\n",
    "            print(\"tensordict_data:\", tensordict_data)  # Print statement added\n",
    "            \n",
    "            if (\"next\", \"agents\", \"done\") not in tensordict_data.keys(include_nested=True):\n",
    "                # If \"done\" key is missing, set it to a tensor of all False\n",
    "                done = torch.zeros_like(tensordict_data.get((\"next\", \"agents\", \"episode_reward\")), dtype=torch.bool)\n",
    "            else:\n",
    "                done = tensordict_data.get((\"next\", \"agents\", \"done\"))\n",
    "                \n",
    "            episode_reward = tensordict_data.get((\"next\", \"agents\", \"episode_reward\"))\n",
    "\n",
    "            # Ensure episode_reward[done] has the same batch size as done\n",
    "            episode_reward_done = episode_reward.squeeze(3)[done.squeeze(3)]\n",
    "            \n",
    "            # Check if episode_reward_done is not empty before setting it\n",
    "            if episode_reward_done.numel() > 0:\n",
    "                tensordict_data.set(\n",
    "                    (\"agents\", \"reward\"),\n",
    "                    episode_reward_done,\n",
    "                )\n",
    "                data_view = tensordict_data.reshape(-1)\n",
    "                self.replay_buffer.extend(data_view)\n",
    "\n",
    "                for _ in range(self.num_epochs):\n",
    "                    for _ in range(self.frames_per_batch // self.minibatch_size):\n",
    "                        subdata = self.replay_buffer.sample()\n",
    "                        loss_value = self.loss_module.calculate_and_optimize_loss(subdata)\n",
    "\n",
    "                done = tensordict_data.get((\"next\", \"agents\", \"done\"))\n",
    "                episode_reward_mean = (\n",
    "                    tensordict_data.get((\"next\", \"agents\", \"episode_reward\"))[done].mean().item()\n",
    "                )\n",
    "                episode_reward_mean_list.append(episode_reward_mean)\n",
    "                pbar.set_description(f\"episode_reward_mean = {episode_reward_mean}\", refresh=True)\n",
    "                pbar.update(self.frames_per_batch)\n",
    "\n",
    "                if self.visualization_handler is not None:\n",
    "                    self.visualization_handler.render_and_save_gif(self.env, self.q_network, max_steps)\n",
    "            else:\n",
    "                print(\"No episode_reward_done data found\")\n",
    "        \n",
    "\n",
    "        pbar.close()\n",
    "        return episode_reward_mean_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    torch.manual_seed(0)\n",
    "    is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "    device = (\n",
    "        torch.device(0)\n",
    "        if torch.cuda.is_available() and not is_fork\n",
    "        else torch.device(\"cpu\")\n",
    "    )\n",
    "    vmas_device = device\n",
    "    print(vmas_device)\n",
    "\n",
    "    # Sampling\n",
    "    frames_per_batch = 6_000\n",
    "    n_iters = 10\n",
    "    total_frames = frames_per_batch * n_iters\n",
    "\n",
    "    # Training\n",
    "    num_epochs = 1\n",
    "    minibatch_size = 400\n",
    "    lr = 0.0003\n",
    "    gamma = 0.9\n",
    "\n",
    "    max_steps = 100\n",
    "    num_vmas_envs = frames_per_batch // max_steps\n",
    "    scenario_name = \"navigation\"\n",
    "    n_agents = 2\n",
    "\n",
    "    env = VmasEnv(\n",
    "        scenario=scenario_name,\n",
    "        num_envs=num_vmas_envs,\n",
    "        continuous_actions=True,\n",
    "        max_steps=max_steps,\n",
    "        device=device,\n",
    "        n_agents=n_agents,\n",
    "    )\n",
    "\n",
    "    env = TransformedEnv(\n",
    "        env,\n",
    "        RewardSum(in_keys=[env.reward_key], out_keys=[(\"agents\", \"episode_reward\")]),\n",
    "    )\n",
    "\n",
    "    check_env_specs(env)\n",
    "\n",
    "    q_network = QNetwork(\n",
    "        observation_shape=env.observation_spec[\"agents\", \"observation\"].shape[-1],\n",
    "        action_shape=env.action_spec.shape[-1],\n",
    "        n_agents=env.n_agents,\n",
    "        device=device,\n",
    "        depth=2,\n",
    "        num_cells=256,\n",
    "        activation_class=torch.nn.Tanh,\n",
    "    )\n",
    "\n",
    "    q_optimizer = torch.optim.Adam(q_network.parameters(), lr=lr)\n",
    "\n",
    "    q_learning_loss = QLearningLoss(q_network=q_network, optimizer=q_optimizer, gamma=gamma)\n",
    "\n",
    "    collector = SyncDataCollector(\n",
    "        env,\n",
    "        policy=None,  # Not needed for Q-learning\n",
    "        device=vmas_device,\n",
    "        storing_device=device,\n",
    "        frames_per_batch=frames_per_batch,\n",
    "        total_frames=total_frames,\n",
    "    )\n",
    "\n",
    "    replay_buffer = ReplayBuffer(\n",
    "        storage=LazyTensorStorage(frames_per_batch, device=device),\n",
    "        sampler=SamplerWithoutReplacement(),\n",
    "        batch_size=minibatch_size,\n",
    "    )\n",
    "\n",
    "    gif_path = f\"{scenario_name}.gif\"\n",
    "    visualization_handler = None  # No visualization needed for Q-learning\n",
    "\n",
    "    q_learning_trainer = QLearningTrainer(\n",
    "        q_network=q_network,\n",
    "        replay_buffer=replay_buffer,\n",
    "        optimizer=q_optimizer,\n",
    "        loss_module=q_learning_loss,\n",
    "        collector=collector,\n",
    "        num_epochs=num_epochs,\n",
    "        minibatch_size=minibatch_size,\n",
    "        frames_per_batch=frames_per_batch,\n",
    "        device=device,\n",
    "        total_frames=total_frames,\n",
    "        gamma=gamma,\n",
    "        env=env,\n",
    "        visualization_handler=visualization_handler,\n",
    "    )\n",
    "\n",
    "    episode_reward_mean_list = q_learning_trainer.train(max_steps)\n",
    "\n",
    "    plt.plot(episode_reward_mean_list)\n",
    "    plt.xlabel(\"Training iterations\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Episode reward mean\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
