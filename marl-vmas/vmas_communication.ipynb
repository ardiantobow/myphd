{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright (c) 2022-2024.\n",
    "#  ProrokLab (https://www.proroklab.org/)\n",
    "#  All rights reserved.\n",
    "\n",
    "import torch\n",
    "\n",
    "from vmas.simulator.core import Agent, Landmark, World\n",
    "from vmas.simulator.scenario import BaseScenario\n",
    "\n",
    "\n",
    "class Scenario(BaseScenario):\n",
    "    def make_world(self, batch_dim: int, device: torch.device, **kwargs):\n",
    "        world = World(batch_dim=batch_dim, device=device, dim_c=10)\n",
    "\n",
    "        n_agents = 2\n",
    "        n_landmarks = 3\n",
    "\n",
    "        # Add agents\n",
    "        for i in range(n_agents):\n",
    "            agent = Agent(name=f\"agent_{i}\", collide=False, silent=False)\n",
    "            world.add_agent(agent)\n",
    "        # Add landmarks\n",
    "        for i in range(n_landmarks):\n",
    "            landmark = Landmark(\n",
    "                name=f\"landmark {i}\",\n",
    "                collide=False,\n",
    "            )\n",
    "            world.add_landmark(landmark)\n",
    "\n",
    "        return world\n",
    "\n",
    "    def reset_world_at(self, env_index: int = None):\n",
    "        if env_index is None:\n",
    "            # assign goals to agents\n",
    "            for agent in self.world.agents:\n",
    "                agent.goal_a = None\n",
    "                agent.goal_b = None\n",
    "            # want other agent to go to the goal landmark\n",
    "            self.world.agents[0].goal_a = self.world.agents[1]\n",
    "            self.world.agents[0].goal_b = self.world.landmarks[\n",
    "                torch.randint(0, len(self.world.landmarks), (1,)).item()\n",
    "            ]\n",
    "            self.world.agents[1].goal_a = self.world.agents[0]\n",
    "            self.world.agents[1].goal_b = self.world.landmarks[\n",
    "                torch.randint(0, len(self.world.landmarks), (1,)).item()\n",
    "            ]\n",
    "            # random properties for agents\n",
    "            for agent in self.world.agents:\n",
    "                agent.color = torch.tensor(\n",
    "                    [0.25, 0.25, 0.25],\n",
    "                    device=self.world.device,\n",
    "                    dtype=torch.float32,\n",
    "                )\n",
    "            # random properties for landmarks\n",
    "            self.world.landmarks[0].color = torch.tensor(\n",
    "                [0.75, 0.25, 0.25],\n",
    "                device=self.world.device,\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "            self.world.landmarks[1].color = torch.tensor(\n",
    "                [0.25, 0.75, 0.25],\n",
    "                device=self.world.device,\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "            self.world.landmarks[2].color = torch.tensor(\n",
    "                [0.25, 0.25, 0.75],\n",
    "                device=self.world.device,\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "            # special colors for goals\n",
    "            self.world.agents[0].goal_a.color = self.world.agents[0].goal_b.color\n",
    "            self.world.agents[1].goal_a.color = self.world.agents[1].goal_b.color\n",
    "\n",
    "        # set random initial states\n",
    "        for agent in self.world.agents:\n",
    "            agent.set_pos(\n",
    "                torch.zeros(\n",
    "                    (\n",
    "                        (1, self.world.dim_p)\n",
    "                        if env_index is not None\n",
    "                        else (self.world.batch_dim, self.world.dim_p)\n",
    "                    ),\n",
    "                    device=self.world.device,\n",
    "                    dtype=torch.float32,\n",
    "                ).uniform_(\n",
    "                    -1.0,\n",
    "                    1.0,\n",
    "                ),\n",
    "                batch_index=env_index,\n",
    "            )\n",
    "        for landmark in self.world.landmarks:\n",
    "            landmark.set_pos(\n",
    "                torch.zeros(\n",
    "                    (\n",
    "                        (1, self.world.dim_p)\n",
    "                        if env_index is not None\n",
    "                        else (self.world.batch_dim, self.world.dim_p)\n",
    "                    ),\n",
    "                    device=self.world.device,\n",
    "                    dtype=torch.float32,\n",
    "                ).uniform_(\n",
    "                    -1.0,\n",
    "                    1.0,\n",
    "                ),\n",
    "                batch_index=env_index,\n",
    "            )\n",
    "\n",
    "    def reward(self, agent: Agent):\n",
    "        is_first = agent == self.world.agents[0]\n",
    "        if is_first:\n",
    "            self.rew = torch.zeros(self.world.batch_dim, device=self.world.device)\n",
    "            for a in self.world.agents:\n",
    "                if a.goal_a is None or a.goal_b is None:\n",
    "                    return torch.zeros(\n",
    "                        self.world.batch_dim,\n",
    "                        device=self.world.device,\n",
    "                        dtype=torch.float32,\n",
    "                    )\n",
    "                self.rew += -torch.sqrt(\n",
    "                    torch.sum(\n",
    "                        torch.square(a.goal_a.state.pos - a.goal_b.state.pos),\n",
    "                        dim=-1,\n",
    "                    )\n",
    "                )\n",
    "        return self.rew\n",
    "\n",
    "    def observation(self, agent: Agent):\n",
    "        # goal color\n",
    "        goal_color = agent.goal_b.color\n",
    "\n",
    "        # get positions of all entities in this agent's reference frame\n",
    "        entity_pos = []\n",
    "        for entity in self.world.landmarks:\n",
    "            entity_pos.append(entity.state.pos - agent.state.pos)\n",
    "\n",
    "        # communication of all other agents\n",
    "        comm = []\n",
    "        for other in self.world.agents:\n",
    "            if other is agent:\n",
    "                continue\n",
    "            comm.append(other.state.c)\n",
    "        return torch.cat(\n",
    "            [\n",
    "                agent.state.vel,\n",
    "                *entity_pos,\n",
    "                goal_color.repeat(self.world.batch_dim, 1),\n",
    "                *comm,\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
