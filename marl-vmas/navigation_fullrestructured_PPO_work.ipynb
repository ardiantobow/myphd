{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:35:23,695 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_spec: CompositeSpec(\n",
      "    agents: CompositeSpec(\n",
      "        action: BoundedTensorSpec(\n",
      "            shape=torch.Size([60, 3, 2]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([60, 3])), device=cpu, shape=torch.Size([60]))\n",
      "reward_spec: CompositeSpec(\n",
      "    agents: CompositeSpec(\n",
      "        reward: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([60, 3, 1]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([60, 3])), device=cpu, shape=torch.Size([60]))\n",
      "done_spec: CompositeSpec(\n",
      "    done: DiscreteTensorSpec(\n",
      "        shape=torch.Size([60, 1]),\n",
      "        space=DiscreteBox(n=2),\n",
      "        device=cpu,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    terminated: DiscreteTensorSpec(\n",
      "        shape=torch.Size([60, 1]),\n",
      "        space=DiscreteBox(n=2),\n",
      "        device=cpu,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete), device=cpu, shape=torch.Size([60]))\n",
      "observation_spec: CompositeSpec(\n",
      "    agents: CompositeSpec(\n",
      "        observation: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([60, 3, 18]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        info: CompositeSpec(\n",
      "            pos_rew: UnboundedContinuousTensorSpec(\n",
      "                shape=torch.Size([60, 3, 1]),\n",
      "                space=None,\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            final_rew: UnboundedContinuousTensorSpec(\n",
      "                shape=torch.Size([60, 3, 1]),\n",
      "                space=None,\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            agent_collisions: UnboundedContinuousTensorSpec(\n",
      "                shape=torch.Size([60, 3, 1]),\n",
      "                space=None,\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous), device=cpu, shape=torch.Size([60, 3])), device=cpu, shape=torch.Size([60, 3])), device=cpu, shape=torch.Size([60]))\n",
      "action_keys: [('agents', 'action')]\n",
      "reward_keys: [('agents', 'reward')]\n",
      "done_keys: ['done', 'terminated']\n",
      "rollout of three steps: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 5, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([60, 5, 3]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([60, 5, 3, 18]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([60, 5, 3]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([60, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                            batch_size=torch.Size([60, 5, 3]),\n",
      "                            device=cpu,\n",
      "                            is_shared=False),\n",
      "                        observation: Tensor(shape=torch.Size([60, 5, 3, 18]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        reward: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([60, 5, 3]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([60, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([60, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([60, 5]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([60, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([60, 5]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Shape of the rollout TensorDict: torch.Size([60, 5])\n",
      "Running policy: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([60, 3]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                loc: Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([60, 3, 18]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                sample_log_prob: Tensor(shape=torch.Size([60, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                scale: Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([60, 3]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([60, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([60, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([60]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Running value: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([60, 3]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([60, 3, 18]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                state_value: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([60, 3]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([60, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([60, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([60]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode_reward_mean = 0.10111597925424576: 100%|██████████| 10/10 [00:34<00:00,  3.71s/it]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 321\u001b[0m\n\u001b[1;32m    318\u001b[0m     display(Image(gif_path))\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 321\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 292\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    289\u001b[0m env\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 292\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrendering_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_cast_to_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# Convert frames to PIL Image objects if necessary\u001b[39;00m\n\u001b[1;32m    301\u001b[0m env\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m [PILImage\u001b[38;5;241m.\u001b[39mfromarray(frame) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m frame \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m env\u001b[38;5;241m.\u001b[39mframes]\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/torchrl/envs/common.py:2432\u001b[0m, in \u001b[0;36mEnvBase.rollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, return_contiguous, tensordict, out)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     tensordicts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rollout_stop_early(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2432\u001b[0m     tensordicts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rollout_nonstop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2433\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;28;01mif\u001b[39;00m tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_contiguous:\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/torchrl/envs/common.py:2524\u001b[0m, in \u001b[0;36mEnvBase._rollout_nonstop\u001b[0;34m(self, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[0m\n\u001b[1;32m   2522\u001b[0m     tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(tensordict_)\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2524\u001b[0m     tensordict, tensordict_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_and_maybe_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2525\u001b[0m tensordicts\u001b[38;5;241m.\u001b[39mappend(tensordict)\n\u001b[1;32m   2526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m max_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;66;03m# we don't truncated as one could potentially continue the run\u001b[39;00m\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/torchrl/envs/common.py:2576\u001b[0m, in \u001b[0;36mEnvBase.step_and_maybe_reset\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   2534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_and_maybe_reset\u001b[39m(\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;28mself\u001b[39m, tensordict: TensorDictBase\n\u001b[1;32m   2536\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[TensorDictBase, TensorDictBase]:\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a step in the environment and (partially) resets it if needed.\u001b[39;00m\n\u001b[1;32m   2538\u001b[0m \n\u001b[1;32m   2539\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;124;03m            is_shared=False)\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2576\u001b[0m     tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;66;03m# done and truncated are in done_keys\u001b[39;00m\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;66;03m# We read if any key is done.\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m     tensordict_ \u001b[38;5;241m=\u001b[39m step_mdp(\n\u001b[1;32m   2580\u001b[0m         tensordict,\n\u001b[1;32m   2581\u001b[0m         keep_other\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2586\u001b[0m         done_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone_keys,\n\u001b[1;32m   2587\u001b[0m     )\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/torchrl/envs/common.py:1409\u001b[0m, in \u001b[0;36mEnvBase.step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_tensordict_shape(tensordict)\n\u001b[1;32m   1407\u001b[0m next_preset \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1409\u001b[0m next_tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m next_tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_proc_data(next_tensordict)\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;66;03m# the necessary keys\u001b[39;00m\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/torchrl/envs/transforms/transforms.py:738\u001b[0m, in \u001b[0;36mTransformedEnv._step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    736\u001b[0m next_preset \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    737\u001b[0m tensordict_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39minv(tensordict)\n\u001b[0;32m--> 738\u001b[0m next_tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# the necessary keys\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     next_tensordict\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    744\u001b[0m         next_preset\u001b[38;5;241m.\u001b[39mexclude(\u001b[38;5;241m*\u001b[39mnext_tensordict\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    745\u001b[0m     )\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/torchrl/envs/libs/vmas.py:541\u001b[0m, in \u001b[0;36mVmasWrapper._step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    538\u001b[0m     action_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m group_action_list\n\u001b[1;32m    539\u001b[0m action \u001b[38;5;241m=\u001b[39m [action_list[agent_indices[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_agents)]\n\u001b[0;32m--> 541\u001b[0m obs, rews, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_done(dones)\n\u001b[1;32m    545\u001b[0m source \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m: dones, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminated\u001b[39m\u001b[38;5;124m\"\u001b[39m: dones\u001b[38;5;241m.\u001b[39mclone()}\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/vmas/simulator/environment/environment.py:231\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 231\u001b[0m obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_from_scenario\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_rewards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_dones\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    233\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# print(\"\\nStep results in unwrapped environment\")\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# print(\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m#     f\"Actions len (n_agents): {len(actions)}, \"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# print(f\"Dones len (n_envs): {len(dones)}, dones[0] (done env 0): {dones[0]}\")\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# print(f\"Info len (n_agents): {len(infos)}, info[0] (infos agent 0): {infos[0]}\")\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, rewards, dones, infos\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/vmas/simulator/environment/environment.py:149\u001b[0m, in \u001b[0;36mEnvironment.get_from_scenario\u001b[0;34m(self, get_observations, get_rewards, get_infos, get_dones, dict_agent_names)\u001b[0m\n\u001b[1;32m    147\u001b[0m         rewards\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_observations:\n\u001b[0;32m--> 149\u001b[0m     observation \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscenario\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dict_agent_names:\n\u001b[1;32m    151\u001b[0m         obs\u001b[38;5;241m.\u001b[39mupdate({agent\u001b[38;5;241m.\u001b[39mname: observation})\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/vmas/scenarios/navigation.py:230\u001b[0m, in \u001b[0;36mScenario.observation\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     goal_poses\u001b[38;5;241m.\u001b[39mappend(agent\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m-\u001b[39m agent\u001b[38;5;241m.\u001b[39mgoal\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mpos)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    224\u001b[0m     [\n\u001b[1;32m    225\u001b[0m         agent\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mpos,\n\u001b[1;32m    226\u001b[0m         agent\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mvel,\n\u001b[1;32m    227\u001b[0m     ]\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;241m+\u001b[39m goal_poses\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m--> 230\u001b[0m         [agent\u001b[38;5;241m.\u001b[39msensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_max_range \u001b[38;5;241m-\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollisions\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    233\u001b[0m     ),\n\u001b[1;32m    234\u001b[0m     dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    235\u001b[0m )\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/vmas/simulator/sensors.py:90\u001b[0m, in \u001b[0;36mLidar.measure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m dists \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m angle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_angles:\n\u001b[1;32m     89\u001b[0m     dists\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 90\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_world\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast_ray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mentity_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m measurement \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(dists, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_measurement \u001b[38;5;241m=\u001b[39m measurement\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/vmas/simulator/core.py:1287\u001b[0m, in \u001b[0;36mWorld.cast_ray\u001b[0;34m(self, entity, angles, max_range, entity_filter)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m currently not handled by cast_ray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1286\u001b[0m     dists\u001b[38;5;241m.\u001b[39mappend(d)\n\u001b[0;32m-> 1287\u001b[0m dist, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dist\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Torch\n",
    "import torch\n",
    "\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "\n",
    "# Tensordict modules\n",
    "from torch import multiprocessing\n",
    "\n",
    "# Data collection\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "\n",
    "# Env\n",
    "from torchrl.envs import RewardSum, TransformedEnv\n",
    "from torchrl.envs.libs.vmas import VmasEnv\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "\n",
    "# Multi-agent network\n",
    "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
    "\n",
    "# Loss\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "\n",
    "# Utils\n",
    "torch.manual_seed(0)\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Devices\n",
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "vmas_device = device  # The device where the simulator is run (VMAS can run on GPU)\n",
    "\n",
    "import os\n",
    "import PIL.Image as PILImage\n",
    "\n",
    "\n",
    "# Add this import at the top of your script\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "\n",
    "\n",
    "# Modify the rendering callback function\n",
    "def rendering_callback(env, td):\n",
    "    frame = env.render(mode=\"rgb_array\")\n",
    "    env.frames.append(frame)\n",
    "\n",
    "def main():\n",
    "    # Sampling\n",
    "    frames_per_batch = 6_000  # Number of team frames collected per training iteration\n",
    "    n_iters = 10  # Number of sampling and training iterations\n",
    "    total_frames = frames_per_batch * n_iters\n",
    "\n",
    "    # Training\n",
    "    num_epochs = 1  # Number of optimization steps per training iteration\n",
    "    minibatch_size = 400  # Size of the mini-batches in each optimization step\n",
    "    lr = 0.0003  # Learning rate\n",
    "    max_grad_norm = 1.0  # Maximum norm for the gradients\n",
    "\n",
    "    # PPO\n",
    "    clip_epsilon = 0.2  # clip value for PPO loss\n",
    "    gamma = 0.9  # discount factor\n",
    "    lmbda = 0.9  # lambda for generalised advantage estimation\n",
    "    entropy_eps = 1e-4  # coefficient of the entropy term in the PPO loss\n",
    "\n",
    "    max_steps = 100  # Episode steps before done\n",
    "    num_vmas_envs = (\n",
    "        frames_per_batch // max_steps\n",
    "    )  # Number of vectorized envs. frames_per_batch should be divisible by this number\n",
    "    scenario_name = \"navigation\"\n",
    "    n_agents = 3\n",
    "\n",
    "    env = VmasEnv(\n",
    "        scenario=scenario_name,\n",
    "        num_envs=num_vmas_envs,\n",
    "        continuous_actions=True,  # VMAS supports both continuous and discrete actions\n",
    "        max_steps=max_steps,\n",
    "        device=vmas_device,\n",
    "        # Scenario kwargs\n",
    "        n_agents=n_agents,  # These are custom kwargs that change for each VMAS scenario, see the VMAS repo to know more.\n",
    "    )\n",
    "\n",
    "    print(\"action_spec:\", env.full_action_spec)\n",
    "    print(\"reward_spec:\", env.full_reward_spec)\n",
    "    print(\"done_spec:\", env.full_done_spec)\n",
    "    print(\"observation_spec:\", env.observation_spec)\n",
    "\n",
    "    print(\"action_keys:\", env.action_keys)\n",
    "    print(\"reward_keys:\", env.reward_keys)\n",
    "    print(\"done_keys:\", env.done_keys)\n",
    "\n",
    "    env = TransformedEnv(\n",
    "        env,\n",
    "        RewardSum(in_keys=[env.reward_key], out_keys=[(\"agents\", \"episode_reward\")]),\n",
    "    )\n",
    "\n",
    "    check_env_specs(env)\n",
    "\n",
    "    n_rollout_steps = 5\n",
    "    rollout = env.rollout(n_rollout_steps)\n",
    "    print(\"rollout of three steps:\", rollout)\n",
    "    print(\"Shape of the rollout TensorDict:\", rollout.batch_size)\n",
    "\n",
    "\n",
    "    share_parameters_policy = True\n",
    "\n",
    "    policy_net = torch.nn.Sequential(\n",
    "        MultiAgentMLP(\n",
    "            n_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[\n",
    "                -1\n",
    "            ],  # n_obs_per_agent\n",
    "            n_agent_outputs=2 * env.action_spec.shape[-1],  # 2 * n_actions_per_agents\n",
    "            n_agents=env.n_agents,\n",
    "            centralised=False,  # the policies are decentralised (ie each agent will act from its observation)\n",
    "            share_params=share_parameters_policy,\n",
    "            device=device,\n",
    "            depth=2,\n",
    "            num_cells=256,\n",
    "            activation_class=torch.nn.Tanh,\n",
    "        ),\n",
    "        NormalParamExtractor(),  # this will just separate the last dimension into two outputs: a loc and a non-negative scale\n",
    "    )\n",
    "\n",
    "    policy_module = TensorDictModule(\n",
    "        policy_net,\n",
    "        in_keys=[(\"agents\", \"observation\")],\n",
    "        out_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
    "    )\n",
    "\n",
    "\n",
    "    policy = ProbabilisticActor(\n",
    "        module=policy_module,\n",
    "        spec=env.unbatched_action_spec,\n",
    "        in_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
    "        out_keys=[env.action_key],\n",
    "        distribution_class=TanhNormal,\n",
    "        distribution_kwargs={\n",
    "            \"min\": env.unbatched_action_spec[env.action_key].space.low,\n",
    "            \"max\": env.unbatched_action_spec[env.action_key].space.high,\n",
    "        },\n",
    "        return_log_prob=True,\n",
    "        log_prob_key=(\"agents\", \"sample_log_prob\"),\n",
    "    )  # we'll need the log-prob for the PPO loss\n",
    "\n",
    "    share_parameters_critic = True\n",
    "    mappo = True  # IPPO if False\n",
    "\n",
    "    critic_net = MultiAgentMLP(\n",
    "        n_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[-1],\n",
    "        n_agent_outputs=1,  # 1 value per agent\n",
    "        n_agents=env.n_agents,\n",
    "        centralised=mappo,\n",
    "        share_params=share_parameters_critic,\n",
    "        device=device,\n",
    "        depth=2,\n",
    "        num_cells=256,\n",
    "        activation_class=torch.nn.Tanh,\n",
    "    )\n",
    "\n",
    "    critic = TensorDictModule(\n",
    "        module=critic_net,\n",
    "        in_keys=[(\"agents\", \"observation\")],\n",
    "        out_keys=[(\"agents\", \"state_value\")],\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"Running policy:\", policy(env.reset()))\n",
    "    print(\"Running value:\", critic(env.reset()))\n",
    "\n",
    "    collector = SyncDataCollector(\n",
    "        env,\n",
    "        policy,\n",
    "        device=vmas_device,\n",
    "        storing_device=device,\n",
    "        frames_per_batch=frames_per_batch,\n",
    "        total_frames=total_frames,\n",
    "    )\n",
    "\n",
    "    replay_buffer = ReplayBuffer(\n",
    "        storage=LazyTensorStorage(\n",
    "            frames_per_batch, device=device\n",
    "        ),  # We store the frames_per_batch collected at each iteration\n",
    "        sampler=SamplerWithoutReplacement(),\n",
    "        batch_size=minibatch_size,  # We will sample minibatches of this size\n",
    "    )\n",
    "\n",
    "    loss_module = ClipPPOLoss(\n",
    "        actor_network=policy,\n",
    "        critic_network=critic,\n",
    "        clip_epsilon=clip_epsilon,\n",
    "        entropy_coef=entropy_eps,\n",
    "        normalize_advantage=False,  # Important to avoid normalizing across the agent dimension\n",
    "    )\n",
    "    loss_module.set_keys(  # We have to tell the loss where to find the keys\n",
    "        reward=env.reward_key,\n",
    "        action=env.action_key,\n",
    "        sample_log_prob=(\"agents\", \"sample_log_prob\"),\n",
    "        value=(\"agents\", \"state_value\"),\n",
    "        # These last 2 keys will be expanded to match the reward shape\n",
    "        done=(\"agents\", \"done\"),\n",
    "        terminated=(\"agents\", \"terminated\"),\n",
    "    )\n",
    "\n",
    "\n",
    "    loss_module.make_value_estimator(\n",
    "        ValueEstimators.GAE, gamma=gamma, lmbda=lmbda\n",
    "    )  # We build GAE\n",
    "\n",
    "    GAE = loss_module.value_estimator\n",
    "\n",
    "    optim = torch.optim.Adam(loss_module.parameters(), lr)\n",
    "\n",
    "    pbar = tqdm(total=n_iters, desc=\"episode_reward_mean = 0\")\n",
    "\n",
    "    episode_reward_mean_list = []\n",
    "    for tensordict_data in collector:\n",
    "        tensordict_data.set(\n",
    "            (\"next\", \"agents\", \"done\"),\n",
    "            tensordict_data.get((\"next\", \"done\"))\n",
    "            .unsqueeze(-1)\n",
    "            .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "        )\n",
    "        tensordict_data.set(\n",
    "            (\"next\", \"agents\", \"terminated\"),\n",
    "            tensordict_data.get((\"next\", \"terminated\"))\n",
    "            .unsqueeze(-1)\n",
    "            .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "        )\n",
    "        # We need to expand the done and terminated to match the reward shape (this is expected by the value estimator)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            GAE(\n",
    "                tensordict_data,\n",
    "                params=loss_module.critic_network_params,\n",
    "                target_params=loss_module.target_critic_network_params,\n",
    "            )  # Compute GAE and add it to the data\n",
    "\n",
    "        data_view = tensordict_data.reshape(-1)  # Flatten the batch size to shuffle data\n",
    "        replay_buffer.extend(data_view)\n",
    "\n",
    "        for _ in range(num_epochs):\n",
    "            for _ in range(frames_per_batch // minibatch_size):\n",
    "                subdata = replay_buffer.sample()\n",
    "                loss_vals = loss_module(subdata)\n",
    "\n",
    "                loss_value = (\n",
    "                    loss_vals[\"loss_objective\"]\n",
    "                    + loss_vals[\"loss_critic\"]\n",
    "                    + loss_vals[\"loss_entropy\"]\n",
    "                )\n",
    "\n",
    "                loss_value.backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    loss_module.parameters(), max_grad_norm\n",
    "                )  # Optional\n",
    "\n",
    "                optim.step()\n",
    "                optim.zero_grad()\n",
    "\n",
    "        collector.update_policy_weights_()\n",
    "\n",
    "        # Logging\n",
    "        done = tensordict_data.get((\"next\", \"agents\", \"done\"))\n",
    "        episode_reward_mean = (\n",
    "            tensordict_data.get((\"next\", \"agents\", \"episode_reward\"))[done].mean().item()\n",
    "        )\n",
    "        episode_reward_mean_list.append(episode_reward_mean)\n",
    "        pbar.set_description(f\"episode_reward_mean = {episode_reward_mean}\", refresh=False)\n",
    "        pbar.update()\n",
    "\n",
    "\n",
    "    plt.plot(episode_reward_mean_list)\n",
    "    plt.xlabel(\"Training iterations\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Episode reward mean\")\n",
    "    plt.show()\n",
    "\n",
    "    env.frames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        env.rollout(\n",
    "            max_steps=max_steps,\n",
    "            policy=policy,\n",
    "            callback=rendering_callback,\n",
    "            auto_cast_to_device=True,\n",
    "            break_when_any_done=False,\n",
    "        )\n",
    "\n",
    "    # Convert frames to PIL Image objects if necessary\n",
    "    env.frames = [PILImage.fromarray(frame) if isinstance(frame, np.ndarray) else frame for frame in env.frames]\n",
    "\n",
    "\n",
    "    # Generate GIF from captured frames\n",
    "    gif_path = f\"{scenario_name}.gif\"\n",
    "    # display(Image(gif_path))\n",
    "    \n",
    "    # Create GIF from frames\n",
    "    frames = env.frames\n",
    "    frames[0].save(\n",
    "        gif_path,\n",
    "        save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        duration=300,  # Duration between frames in milliseconds\n",
    "        loop=0,  # 0 means loop indefinitely\n",
    "    )\n",
    "\n",
    "    display(Image(gif_path))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
