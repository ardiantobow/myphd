{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardie85/PHD/Research/code/.venv/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "Step 1 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.0034977197647094727, next_obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 2 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.006926417350769043, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 3 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00598454475402832, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 4 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004441261291503906, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 5 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0033042430877685547, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 6 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002463221549987793, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 7 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0018388032913208008, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 8 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0013742446899414062, next_obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 9 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010280609130859375, next_obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 10 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.004190802574157715, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 11 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0039566755294799805, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 12 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002939939498901367, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 13 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0031458139419555664, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.005577683448791504, next_obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 14 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0031991004943847656, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005024433135986328, next_obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 15 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.004241228103637695, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0037654638290405273, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 16 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.008249878883361816, next_obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002822279930114746, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 17 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007001757621765137, next_obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0021157264709472656, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 18 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005227088928222656, next_obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0015861988067626953, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 19 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003906369209289551, next_obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0011894702911376953, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 20 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.0062226057052612305, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008918046951293945, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 21 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005444765090942383, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006688833236694336, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 22 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004052639007568359, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005015134811401367, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 23 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003021717071533203, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00037610530853271484, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 24 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.005440235137939453, next_obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00028204917907714844, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 25 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.001675724983215332, next_obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.009844303131103516, next_obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 26 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.0027060508728027344, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00990307331085205, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 27 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0028437376022338867, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.017502784729003906, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 28 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002147078514099121, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.015659451484680176, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 29 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0016181468963623047, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.011753559112548828, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 30 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0012181997299194336, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.008820056915283203, next_obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 31 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.002324700355529785, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.01671910285949707, next_obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 32 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.0057364702224731445, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.015076875686645508, next_obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 33 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.00817263126373291, next_obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.004667997360229492, next_obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 34 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.003708958625793457, next_obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.011994361877441406, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 35 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.005053400993347168, next_obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.01156163215637207, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 36 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.007500052452087402, next_obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.002089977264404297, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 37 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0062563419342041016, next_obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0065364837646484375, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 38 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004616737365722656, next_obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 2.8252601623535156e-05, next_obs (0.9592, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 39 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003420114517211914, next_obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.005259156227111816, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 40 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0025408267974853516, next_obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.008418083190917969, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 41 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.002262592315673828, next_obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.01069629192352295, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 42 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.0068808794021606445, next_obs (-0.6735, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.012272953987121582, next_obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 43 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007470130920410156, next_obs (-0.6735, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.003229498863220215, next_obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 44 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005529642105102539, next_obs (-0.6735, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.002814769744873047, next_obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 45 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004105925559997559, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0032241344451904297, next_obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 46 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003056049346923828, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.004221558570861816, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 47 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0022786855697631836, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0048105716705322266, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 48 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017017126083374023, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0032455921173095703, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 49 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012718439102172852, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004177570343017578, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 50 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009517669677734375, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0031560659408569336, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 51 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007123947143554688, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.004475593566894531, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 52 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005334615707397461, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.011920452117919922, next_obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 53 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00039970874786376953, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010649323463439941, next_obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 54 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002994537353515625, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 5, reward 0.004191756248474121, next_obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 55 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00022470951080322266, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0021589994430541992, next_obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 56 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.002654552459716797, next_obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.008473038673400879, next_obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 57 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.01211082935333252, next_obs (-0.5918, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.001802206039428711, next_obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 58 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01140439510345459, next_obs (-0.5918, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003823518753051758, next_obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 59 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008514642715454102, next_obs (-0.5918, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.003992438316345215, next_obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 60 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0063637495040893555, next_obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01154947280883789, next_obs (0.7551, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 61 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004760265350341797, next_obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010352253913879395, next_obs (0.7551, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 62 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0035630464553833008, next_obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00774991512298584, next_obs (0.7551, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 63 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0026682615280151367, next_obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005803942680358887, next_obs (0.7551, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 64 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0019989013671875, next_obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0043485164642333984, next_obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 65 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.006343364715576172, next_obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003258824348449707, next_obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 66 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00592803955078125, next_obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002442479133605957, next_obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 67 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.00913238525390625, next_obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0018310546875, next_obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 68 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007907390594482422, next_obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0013728141784667969, next_obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 69 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005852103233337402, next_obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.00892794132232666, next_obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 70 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0052651166915893555, next_obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.009194612503051758, next_obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 71 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0064198970794677734, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward -0.0033218860626220703, next_obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 72 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004857182502746582, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.0017862319946289062, next_obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 73 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0033407211303710938, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.005310416221618652, next_obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 74 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.011218428611755371, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.00795137882232666, next_obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 75 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01709568500518799, next_obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0067293643951416016, next_obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 76 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.007555723190307617, next_obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004998207092285156, next_obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 77 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0030449628829956055, next_obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0037211179733276367, next_obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 78 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.010986924171447754, next_obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.009361743927001953, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 79 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.009985089302062988, next_obs (-0.6735, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008637666702270508, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 80 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.004742622375488281, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006458878517150879, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 81 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.00408327579498291, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004833102226257324, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 82 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.004900693893432617, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0036187171936035156, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 83 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0008842945098876953, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0027104616165161133, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 84 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.009377479553222656, next_obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0020308494567871094, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 85 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.015720367431640625, next_obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0015219449996948242, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 86 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01349937915802002, next_obs (-0.6735, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0011408329010009766, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 87 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010104775428771973, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008553266525268555, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 88 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007567167282104492, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006412267684936523, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 89 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0056688785552978516, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004807710647583008, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 90 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00424802303314209, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0003604888916015625, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 91 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0031839609146118164, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002703666687011719, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 92 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0023865699768066406, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002028942108154297, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 93 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017895698547363281, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0001519918441772461, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 94 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0013415813446044922, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00011408329010009766, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 95 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010058879852294922, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 8.547306060791016e-05, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 96 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007543563842773438, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 6.413459777832031e-05, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 97 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005658864974975586, next_obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.010177254676818848, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 98 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00042426586151123047, next_obs (-0.6735, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.013016700744628906, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 99 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.004289984703063965, next_obs (-0.6735, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.010503768920898438, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 100 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.0071294307708740234, next_obs (-0.6735, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.007900595664978027, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 101 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.00903928279876709, next_obs (-0.6735, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.005937814712524414, next_obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 102 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.010387897491455078, next_obs (-0.6327, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0021125078201293945, next_obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 103 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 8, reward 0.0042803287506103516, next_obs (-0.6327, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.009790301322937012, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 104 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0023691654205322266, next_obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008972883224487305, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 105 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0032262802124023438, next_obs (-0.551, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006722450256347656, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 106 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002647876739501953, next_obs (-0.551, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.015247106552124023, next_obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 107 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0049817562103271484, next_obs (-0.551, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.013986706733703613, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 108 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.012567639350891113, next_obs (-0.551, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.013354659080505371, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 109 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011191606521606445, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.013431549072265625, next_obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 110 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00838935375213623, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010583043098449707, next_obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 111 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006289362907409668, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007821440696716309, next_obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 112 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0047158002853393555, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005800366401672363, next_obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 113 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0035358667373657227, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0043125152587890625, next_obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 114 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0026515722274780273, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.009577274322509766, next_obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 115 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0019882917404174805, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01506960391998291, next_obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 116 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0014911890029907227, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012822151184082031, next_obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 117 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001118302345275879, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009576082229614258, next_obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 118 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008386373519897461, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007158875465393066, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 119 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006289482116699219, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005355954170227051, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 120 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004715919494628906, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004009604454040527, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 121 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00035381317138671875, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003002762794494629, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 122 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002652406692504883, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0022498369216918945, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 123 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.002171754837036133, next_obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016859769821166992, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 124 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.007257699966430664, next_obs (-0.5102, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001263737678527832, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 125 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007817745208740234, next_obs (-0.5102, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009474754333496094, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 126 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.015363454818725586, next_obs (-0.5102, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007102489471435547, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 127 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.021001815795898438, next_obs (-0.5102, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.0036469697952270508, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 128 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.017529010772705078, next_obs (-0.4694, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0038057565689086914, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 129 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.013146281242370605, next_obs (-0.4694, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002870798110961914, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 130 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009859442710876465, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0021622180938720703, next_obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 131 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00739443302154541, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.002618074417114258, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 132 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0015761852264404297, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0030145645141601562, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 133 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.0017974376678466797, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0022541284561157227, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 134 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0024995803833007812, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016869306564331055, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 135 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0018492937088012695, next_obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012631416320800781, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 136 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0013720989227294922, next_obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009462833404541016, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 137 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010211467742919922, next_obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007089376449584961, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 138 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007611513137817383, next_obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.000531315803527832, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 139 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005681514739990234, next_obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00039827823638916016, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 140 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004247426986694336, next_obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002987384796142578, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 141 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00031769275665283203, next_obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002237558364868164, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 142 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.002736210823059082, next_obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0001678466796875, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 143 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0026471614837646484, next_obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.000125885009765625, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 144 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001966118812561035, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 9.453296661376953e-05, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 145 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0014636516571044922, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 7.069110870361328e-05, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 146 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010914802551269531, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 5.3048133850097656e-05, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 147 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008153915405273438, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.00619661808013916, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 148 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006093978881835938, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.006217241287231445, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 149 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004559755325317383, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.01506185531616211, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 150 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0003412961959838867, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.024289369583129883, next_obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 151 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00025582313537597656, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.020817875862121582, next_obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 152 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00019156932830810547, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.009377598762512207, next_obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 153 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.0048743486404418945, next_obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.01171422004699707, next_obs (0.9592, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 154 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0047789812088012695, next_obs (-0.4694, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.010343313217163086, next_obs (0.9592, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 155 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.010618805885314941, next_obs (-0.5102, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.01816403865814209, next_obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 156 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009687185287475586, next_obs (-0.5102, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.016226530075073242, next_obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 157 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0072373151779174805, next_obs (-0.5102, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 7, reward -0.01017463207244873, next_obs (1.0, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 158 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005411744117736816, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.007202744483947754, next_obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 159 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00404965877532959, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0006954669952392578, next_obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 160 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0030319690704345703, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.008100271224975586, next_obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 161 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0022710561752319336, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.013581156730651855, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 162 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017017126083374023, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011591196060180664, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 163 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001275181770324707, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008623719215393066, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 164 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009559392929077148, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.00043892860412597656, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 165 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007166862487792969, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.001172184944152832, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 166 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005372762680053711, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0008800029754638672, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 167 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004029273986816406, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0006603002548217773, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 168 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0003020763397216797, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0004953145980834961, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 169 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00022661685943603516, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00037169456481933594, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 170 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00016987323760986328, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0017714500427246094, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 171 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00012755393981933594, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0017601251602172852, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 172 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 9.548664093017578e-05, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0013581514358520508, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 173 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 7.164478302001953e-05, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0010401010513305664, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 174 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 5.3763389587402344e-05, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.009678959846496582, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 175 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 4.029273986816406e-05, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009862542152404785, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 176 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.0279159545898438e-05, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007387638092041016, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 177 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.2649765014648438e-05, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00553584098815918, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 178 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.6927719116210938e-05, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004148960113525391, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 179 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.2874603271484375e-05, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0031099319458007812, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 180 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 9.417533874511719e-06, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0023316144943237305, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 181 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 7.152557373046875e-06, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001748204231262207, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 182 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 5.4836273193359375e-06, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0005209445953369141, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 183 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.933906555175781e-06, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0009167194366455078, next_obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 184 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.004327297210693359, next_obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0007320642471313477, next_obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 185 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.008444428443908691, next_obs (-0.5102, 0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.003615736961364746, next_obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 186 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, 0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00715947151184082, next_obs (-0.551, 0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.007819890975952148, next_obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 187 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005227088928222656, next_obs (-0.551, 0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.010827183723449707, next_obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 188 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0038393735885620117, next_obs (-0.551, 0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0013854503631591797, next_obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 189 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0028333663940429688, next_obs (-0.551, 0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0026665925979614258, next_obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 190 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.4286, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.008937358856201172, next_obs (-0.551, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.009948253631591797, next_obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 191 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008371710777282715, next_obs (-0.5918, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009052515029907227, next_obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 192 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.009867072105407715, next_obs (-0.5918, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006788849830627441, next_obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 193 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.011580824851989746, next_obs (-0.5918, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005091428756713867, next_obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 194 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0009075403213500977, next_obs (-0.6327, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003818511962890625, next_obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 195 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003511786460876465, next_obs (-0.6327, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002863764762878418, next_obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 196 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0037522315979003906, next_obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.008501648902893066, next_obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 197 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004286408424377441, next_obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007954597473144531, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 198 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0031126737594604492, next_obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005959033966064453, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 199 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0022764205932617188, next_obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004465341567993164, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 200 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016744136810302734, next_obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0033469200134277344, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 201 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.011523246765136719, next_obs (-0.6735, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0025087594985961914, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 202 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.004767298698425293, next_obs (-0.6735, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0018808841705322266, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 203 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0019561052322387695, next_obs (-0.6735, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001410365104675293, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 204 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.005011200904846191, next_obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010576248168945312, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 205 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.001667618751525879, next_obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.009571194648742676, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 206 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.00979626178741455, next_obs (-0.6327, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.009773612022399902, next_obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 207 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009796380996704102, next_obs (-0.6327, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.0010418891906738281, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 208 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007284760475158691, next_obs (-0.6327, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007731914520263672, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 209 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0054274797439575195, next_obs (-0.5918, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.0035706758499145508, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 210 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.007156491279602051, next_obs (-0.5918, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0099945068359375, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 211 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.009075284004211426, next_obs (-0.6327, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.009062647819519043, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 212 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007356882095336914, next_obs (-0.6327, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.006800055503845215, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 213 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005392193794250488, next_obs (-0.6327, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.0009200572967529297, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 214 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003972530364990234, next_obs (-0.6327, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.006581306457519531, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 215 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00293886661529541, next_obs (-0.6327, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.002314448356628418, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 216 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0021810531616210938, next_obs (-0.6327, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0013539791107177734, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 217 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.0022966861724853516, next_obs (-0.6735, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0046967267990112305, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 218 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002772212028503418, next_obs (-0.6735, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.011307239532470703, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 219 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.004201054573059082, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.016232609748840332, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 220 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004659175872802734, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.013692021369934082, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 221 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0034486055374145508, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010246992111206055, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 222 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0025604963302612305, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.0015106201171875, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 223 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0019055604934692383, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.004684329032897949, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 224 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0014208555221557617, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004599213600158691, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 225 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010609626770019531, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.006989598274230957, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 226 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007930994033813477, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.013979196548461914, next_obs (0.9184, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 227 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005933046340942383, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011999130249023438, next_obs (0.9184, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 228 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00044405460357666016, next_obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008988022804260254, next_obs (0.9184, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 229 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.005873918533325195, next_obs (-0.7143, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006734967231750488, next_obs (0.9184, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 230 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0002510547637939453, next_obs (-0.7143, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.006705760955810547, next_obs (0.9184, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 231 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.007939934730529785, next_obs (-0.7143, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.006861209869384766, next_obs (0.9592, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 232 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.013646483421325684, next_obs (-0.7143, 0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.009848475456237793, next_obs (0.9592, 0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 233 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011715412139892578, next_obs (-0.7143, 0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.4286, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.009749054908752441, next_obs (0.9592, 0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 234 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008747100830078125, next_obs (-0.7143, 0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.4286, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.008545875549316406, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 235 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006537675857543945, next_obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0063135623931884766, next_obs (1.0, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 236 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0055855512619018555, next_obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004499912261962891, next_obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 237 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.006825447082519531, next_obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0032416582107543945, next_obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 238 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0008984804153442383, next_obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0023555755615234375, next_obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 239 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.012640714645385742, next_obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017242431640625, next_obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 240 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.007553696632385254, next_obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012688636779785156, next_obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 241 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.014984965324401855, next_obs (-0.7143, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009380578994750977, next_obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 242 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.007919907569885254, next_obs (-0.7143, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006959438323974609, next_obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 243 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.001482248306274414, next_obs (-0.7143, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.011113524436950684, next_obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 244 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.008598089218139648, next_obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.02157890796661377, next_obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 245 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.0024858713150024414, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.029429316520690918, next_obs (1.0, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 246 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004428982734680176, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.02472090721130371, next_obs (0.9592, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 247 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00328671932220459, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01854074001312256, next_obs (0.9592, 0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 248 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0024451017379760742, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.2653, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.008362889289855957, next_obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 249 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0018224716186523438, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004868268966674805, next_obs (0.9184, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 250 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001360774040222168, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00363922119140625, next_obs (0.9184, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 251 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010167360305786133, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.002285003662109375, next_obs (0.9184, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 252 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.0035746097564697266, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002974390983581543, next_obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 253 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0037877559661865234, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002235889434814453, next_obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 254 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0028557777404785156, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.001680135726928711, next_obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 255 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0021501779556274414, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.001261591911315918, next_obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 256 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0016171932220458984, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0045812129974365234, next_obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 257 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0012155771255493164, next_obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01028299331665039, next_obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 258 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.005370497703552246, next_obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.2245, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.014454126358032227, next_obs (0.9592, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 259 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.005317091941833496, next_obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012084126472473145, next_obs (0.9592, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 260 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.01710188388824463, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008989572525024414, next_obs (0.9592, 0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 261 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.015449762344360352, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.1837, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.01730644702911377, next_obs (0.9592, 0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 262 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011586189270019531, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.015607476234436035, next_obs (0.9592, 0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 263 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008689284324645996, next_obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011691689491271973, next_obs (0.9184, 0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 264 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006516575813293457, next_obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.1429, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.0034128427505493164, next_obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 265 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004887104034423828, next_obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0011792182922363281, next_obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 266 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003665328025817871, next_obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008561611175537109, next_obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 267 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.007761478424072266, next_obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006262063980102539, next_obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 268 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.008451104164123535, next_obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.005613803863525391, next_obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 269 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.0017943382263183594, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.010931968688964844, next_obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 270 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00023317337036132812, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.015027642250061035, next_obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 271 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00019049644470214844, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01262056827545166, next_obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 272 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00015163421630859375, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00945436954498291, next_obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 273 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00011861324310302734, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00708460807800293, next_obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 274 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -9.167194366455078e-05, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0053098201751708984, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 275 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -7.033348083496094e-05, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003980278968811035, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 276 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -5.364418029785156e-05, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002984166145324707, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 277 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -4.076957702636719e-05, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0022374391555786133, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 278 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -3.075599670410156e-05, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.008927702903747559, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 279 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.3365020751953125e-05, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.009347319602966309, next_obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 280 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.7404556274414062e-05, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.012401461601257324, next_obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 281 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.3232231140136719e-05, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.010666847229003906, next_obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 282 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -9.894371032714844e-06, next_obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.008011698722839355, next_obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 283 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.010470032691955566, next_obs (-0.6327, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.006015181541442871, next_obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 284 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01046907901763916, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0006232261657714844, next_obs (0.9592, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 285 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007849931716918945, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.008884191513061523, next_obs (0.9592, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 286 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0058863162994384766, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00933384895324707, next_obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 287 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004413962364196777, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.0014896392822265625, next_obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 288 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0033102035522460938, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.0057517290115356445, next_obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 289 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0024824142456054688, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.01109778881072998, next_obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 290 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0018616914749145508, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01479804515838623, next_obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 291 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0013962984085083008, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.017571568489074707, next_obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 292 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010471343994140625, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.014464139938354492, next_obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 293 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007853507995605469, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010841131210327148, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 294 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005888938903808594, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00812673568725586, next_obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 295 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004417896270751953, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006092667579650879, next_obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 296 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0003312826156616211, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004568219184875488, next_obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 297 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002485513687133789, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0034254789352416992, next_obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 298 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0001862049102783203, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 5, reward 0.0028868913650512695, next_obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 299 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.0044901371002197266, next_obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0021622180938720703, next_obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 300 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0044182538986206055, next_obs (-0.5918, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0015671253204345703, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 301 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0032892227172851562, next_obs (-0.5918, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0011444091796875, next_obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 302 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.012879729270935059, next_obs (-0.5918, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008410215377807617, next_obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 303 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.02265775203704834, next_obs (-0.551, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006209611892700195, next_obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 304 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.029961049556732178, next_obs (-0.551, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.010146379470825195, next_obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 305 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.027145683765411377, next_obs (-0.551, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.01026451587677002, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 306 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.020850181579589844, next_obs (-0.5102, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0077849626541137695, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 307 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.011350929737091064, next_obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.005966067314147949, next_obs (0.8367, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 308 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007342994213104248, next_obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 7, reward -0.004289031028747559, next_obs (0.8776, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 309 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005438268184661865, next_obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003172159194946289, next_obs (0.8776, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 310 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004039168357849121, next_obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0029790401458740234, next_obs (0.8776, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 311 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0030068159103393555, next_obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003530263900756836, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 312 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0022422075271606445, next_obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002617955207824707, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 313 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016744732856750488, next_obs (-0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001946568489074707, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 314 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012516975402832031, next_obs (-0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0014505386352539062, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 315 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.011441171169281006, next_obs (-0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010824203491210938, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 316 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.021708190441131592, next_obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008088350296020508, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 317 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.018902122974395752, next_obs (-0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.010001182556152344, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 318 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367), action 5, reward 0.0036783218383789062, next_obs (-0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.010153055191040039, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 319 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.01036447286605835, next_obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.002259492874145508, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 320 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.010402202606201172, next_obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0003731250762939453, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 321 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.007804214954376221, next_obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00029158592224121094, next_obs (0.8776, 0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 322 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.005854547023773193, next_obs (-0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.102, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.005070805549621582, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 323 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.006116032600402832, next_obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005117893218994141, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 324 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.013185620307922363, next_obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003832578659057617, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 325 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.017289340496063232, next_obs (-0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0028711557388305664, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 326 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.014374792575836182, next_obs (-0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0021516084671020508, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 327 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.011779487133026123, next_obs (-0.5102, -0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016126632690429688, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 328 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008801937103271484, next_obs (-0.5102, -0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012089014053344727, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 329 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006404697895050049, next_obs (-0.551, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009063482284545898, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 330 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004690051078796387, next_obs (-0.551, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006794929504394531, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 331 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003452479839324951, next_obs (-0.551, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005096197128295898, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 332 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.00800234079360962, next_obs (-0.551, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.005745410919189453, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 333 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.012608528137207031, next_obs (-0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005629539489746094, next_obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 334 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010588645935058594, next_obs (-0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.014814972877502441, next_obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 335 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007807731628417969, next_obs (-0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.0612, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01904773712158203, next_obs (0.8367, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 336 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.010881602764129639, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.015599966049194336, next_obs (0.8367, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 337 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00926661491394043, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011694073677062988, next_obs (0.8367, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 338 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006838440895080566, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008767247200012207, next_obs (0.8367, 0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 339 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.004166722297668457, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0065735578536987305, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 340 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0025560855865478516, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004928946495056152, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 341 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016921758651733398, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0036960840225219727, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 342 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 8, reward 0.0025833845138549805, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002771735191345215, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 343 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002264082431793213, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0020786523818969727, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 344 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016824603080749512, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0015588998794555664, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 345 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012529492378234863, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001168966293334961, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 346 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009347200393676758, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008767843246459961, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 347 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006982088088989258, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006575584411621094, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 348 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005220770835876465, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.000493168830871582, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 349 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00039064884185791016, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0003699064254760742, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 350 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.004437506198883057, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00027740001678466797, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 351 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.015131950378417969, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.010813355445861816, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 352 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.009202957153320312, next_obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010761380195617676, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 353 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00570070743560791, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008070945739746094, next_obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 354 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00427776575088501, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006053328514099121, next_obs (0.7959, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 355 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0032095909118652344, next_obs (-0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004539966583251953, next_obs (0.7959, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 356 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.0033565163612365723, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003404855728149414, next_obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 357 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0039324164390563965, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002553701400756836, next_obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 358 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002931952476501465, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0019152164459228516, next_obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 359 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002189040184020996, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001436471939086914, next_obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 360 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001636207103729248, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.004153132438659668, next_obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 361 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012239813804626465, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004448413848876953, next_obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 362 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009161233901977539, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0033532381057739258, next_obs (0.7551, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 363 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 8, reward 0.0013117790222167969, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002524137496948242, next_obs (0.7551, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 364 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009616613388061523, next_obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0034023523330688477, next_obs (0.7551, -0.0204, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 365 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006036758422851562, next_obs (-0.5102, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0204, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.009122252464294434, next_obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 366 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00038635730743408203, next_obs (-0.5102, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.013286948204040527, next_obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 367 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002524256706237793, next_obs (-0.5102, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.0612, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.016239643096923828, next_obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 368 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00016826391220092773, next_obs (-0.5102, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.008221983909606934, next_obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 369 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00011432170867919922, next_obs (-0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.005727887153625488, next_obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 370 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 7.909536361694336e-05, next_obs (-0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.0036330223083496094, next_obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 371 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -9.08970832824707e-05, next_obs (-0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.0003638267517089844, next_obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 372 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0003020167350769043, next_obs (-0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0009872913360595703, next_obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 373 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.00519174337387085, next_obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.005803346633911133, next_obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 374 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005266904830932617, next_obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.004932045936584473, next_obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 375 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0039479732513427734, next_obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.016921401023864746, next_obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 376 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.00797581672668457, next_obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7551, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.02592945098876953, next_obs (0.7143, -0.102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 377 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0071776509284973145, next_obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7143, -0.102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.022091269493103027, next_obs (0.7143, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 378 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01100379228591919, next_obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7143, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.016564607620239258, next_obs (0.7143, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 379 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4694, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009661674499511719, next_obs (-0.4286, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7143, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012421250343322754, next_obs (0.6735, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 380 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4286, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.012182772159576416, next_obs (-0.4286, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.6735, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.014720618724822998, next_obs (0.6735, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 381 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4286, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.015176057815551758, next_obs (-0.4286, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.6735, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 8, reward 0.001747727394104004, next_obs (0.6735, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 382 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.4286, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.017138779163360596, next_obs (-0.3878, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.6735, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.0039501190185546875, next_obs (0.6735, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 383 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3878, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.013722002506256104, next_obs (-0.3878, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.6735, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.009446501731872559, next_obs (0.6327, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 384 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3878, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.004018843173980713, next_obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.6327, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008233129978179932, next_obs (0.6327, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 385 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012255311012268066, next_obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.6327, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.011154890060424805, next_obs (0.5918, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 386 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007511377334594727, next_obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009461402893066406, next_obs (0.5918, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 387 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004684925079345703, next_obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00698322057723999, next_obs (0.5918, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 388 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00029784440994262695, next_obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0051724910736083984, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 389 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3469, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00019317865371704102, next_obs (-0.3469, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0038421154022216797, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 390 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3469, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00012791156768798828, next_obs (-0.3469, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002860426902770996, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 391 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3469, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0024610161781311035, next_obs (-0.3061, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002133309841156006, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 392 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002725660800933838, next_obs (-0.3061, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0015930533409118652, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 393 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.004374086856842041, next_obs (-0.3061, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0011909008026123047, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 394 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.011467993259429932, next_obs (-0.3061, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008910894393920898, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 395 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.016778647899627686, next_obs (-0.3061, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006670951843261719, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 396 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.016823291778564453, next_obs (-0.3061, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.006279706954956055, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 397 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.015069007873535156, next_obs (-0.3061, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.016700327396392822, next_obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 398 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010926485061645508, next_obs (-0.3061, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.1429, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.025726377964019775, next_obs (0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 399 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.012169122695922852, next_obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.02193528413772583, next_obs (0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 400 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010138660669326782, next_obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.1837, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02216923236846924, next_obs (0.5102, -0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 401 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.0016709864139556885, next_obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.018019437789916992, next_obs (0.5102, -0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 402 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0002218484878540039, next_obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.2245, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.013488948345184326, next_obs (0.4694, -0.2245, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 403 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00016748905181884766, next_obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4694, -0.2245, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0004850625991821289, next_obs (0.4694, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 404 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0015456974506378174, next_obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4694, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0030240416526794434, next_obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 405 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0017547905445098877, next_obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0022759437561035156, next_obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 406 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00147247314453125, next_obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0017113685607910156, next_obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 407 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.001191556453704834, next_obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0042610764503479, next_obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 408 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0009423494338989258, next_obs (-0.3061, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.010008513927459717, next_obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 409 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.3061, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.003296375274658203, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.2653, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.014116644859313965, next_obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 410 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0033173859119415283, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011702895164489746, next_obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 411 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002380877733230591, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0019745826721191406, next_obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 412 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017244219779968262, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004212677478790283, next_obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 413 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001258552074432373, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003203868865966797, next_obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 414 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009241402149200439, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002427339553833008, next_obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 415 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006819665431976318, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.001834273338317871, next_obs (0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 416 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005051493644714355, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 7, reward -0.0019878745079040527, next_obs (0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 417 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00037530064582824707, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0018422603607177734, next_obs (0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 418 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.00323331356048584, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0015117526054382324, next_obs (0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 419 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.013238519430160522, next_obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.01175910234451294, next_obs (0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 420 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012434005737304688, next_obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.006791353225708008, next_obs (0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 421 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009294897317886353, next_obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004022836685180664, next_obs (0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 422 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.000549018383026123, next_obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.001448988914489746, next_obs (0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 423 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.011491894721984863, next_obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.00810539722442627, next_obs (0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 424 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.011195659637451172, next_obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.013597548007965088, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 425 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.008398324251174927, next_obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01170271635055542, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 426 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.012710243463516235, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00877445936203003, next_obs (0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 427 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 7, reward -0.0008904933929443359, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.003921329975128174, next_obs (0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 428 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.012067615985870361, next_obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.005572915077209473, next_obs (0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 429 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2653, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.021670401096343994, next_obs (-0.2245, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.00033169984817504883, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 430 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2245, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 8, reward 0.015257477760314941, next_obs (-0.2245, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0013470053672790527, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 431 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.2245, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 8, reward 0.005946695804595947, next_obs (-0.1837, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009902715682983398, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 432 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.1837, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0025272369384765625, next_obs (-0.1429, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007312893867492676, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 433 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.1429, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004823863506317139, next_obs (-0.1429, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005421042442321777, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 434 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.1429, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.003171592950820923, next_obs (-0.102, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004030466079711914, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 435 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.102, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.009620636701583862, next_obs (-0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00030028820037841797, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 436 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.01027175784111023, next_obs (-0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00022399425506591797, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 437 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.008533746004104614, next_obs (-0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00016736984252929688, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 438 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.006841778755187988, next_obs (-0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0001251697540283203, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 439 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0021300017833709717, next_obs (-0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 9.363889694213867e-05, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 440 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.004158616065979004, next_obs (-0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 7.015466690063477e-05, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 441 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.012931764125823975, next_obs (0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 5.257129669189453e-05, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 442 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.011916041374206543, next_obs (0.0204, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.933906555175781e-05, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 443 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.009087443351745605, next_obs (0.0204, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.944469451904297e-05, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 444 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0005614757537841797, next_obs (0.0204, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.01047593355178833, next_obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 445 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.008723258972167969, next_obs (0.0612, -0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5918, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010465443134307861, next_obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 446 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007858723402023315, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007845878601074219, next_obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 447 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005686551332473755, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005882441997528076, next_obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 448 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0041439831256866455, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004410684108734131, next_obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 449 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0030381381511688232, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.00945889949798584, next_obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 450 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0022386014461517334, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008610188961029053, next_obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 451 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016560852527618408, next_obs (0.102, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.551, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006442904472351074, next_obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 452 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012290477752685547, next_obs (0.102, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004823565483093262, next_obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 453 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.000914454460144043, next_obs (0.102, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0036128759384155273, next_obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 454 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.009662657976150513, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0027068257331848145, next_obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 455 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00944441556930542, next_obs (0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.012507617473602295, next_obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 456 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00705033540725708, next_obs (0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.5102, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.022471368312835693, next_obs (0.4694, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 457 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.002093285322189331, next_obs (0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4694, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.015069007873535156, next_obs (0.4694, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 458 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003439277410507202, next_obs (0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4694, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.00567549467086792, next_obs (0.4694, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 459 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0025970041751861572, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4694, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.013511478900909424, next_obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 460 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.001957446336746216, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012696146965026855, next_obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 461 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.00026300549507141113, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0094834566116333, next_obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 462 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -5.060434341430664e-05, next_obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.0059258341789245605, next_obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 463 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0001399517059326172, next_obs (0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0040354132652282715, next_obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 464 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3469, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.007290095090866089, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002948760986328125, next_obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 465 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007309764623641968, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4286, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0021671056747436523, next_obs (0.4286, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 466 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005471140146255493, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4286, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.007660031318664551, next_obs (0.4286, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 467 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0040968358516693115, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.4286, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.013259947299957275, next_obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 468 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0030688047409057617, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011379778385162354, next_obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 469 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0022994279861450195, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008488357067108154, next_obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 470 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017233192920684814, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006338894367218018, next_obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 471 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012917816638946533, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0047380924224853516, next_obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 472 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009684562683105469, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3878, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.014093369245529175, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 473 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007261037826538086, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01320621371269226, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 474 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.008630037307739258, next_obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00990450382232666, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 475 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008373945951461792, next_obs (0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007428228855133057, next_obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 476 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006197184324264526, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005571097135543823, next_obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 477 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004598855972290039, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004178255796432495, next_obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 478 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0034205615520477295, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.0027087926864624023, next_obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 479 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.0026164650917053223, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0035395920276641846, next_obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 480 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017576515674591064, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002685070037841797, next_obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 481 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001171886920928955, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0066033899784088135, next_obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 482 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007958412170410156, next_obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.006131201982498169, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 483 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005498528480529785, next_obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00462004542350769, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 484 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0003858208656311035, next_obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0034768879413604736, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 485 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.0007959604263305664, next_obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002614140510559082, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 486 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006395280361175537, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.001964181661605835, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 487 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.00707322359085083, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.006278723478317261, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 488 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.007214933633804321, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.005993843078613281, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 489 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.0056352317333221436, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004548579454421997, next_obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 490 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00435301661491394, next_obs (-0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0034404397010803223, next_obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 491 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.3878, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.004174560308456421, next_obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.007659733295440674, next_obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 492 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0049690306186676025, next_obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00712054967880249, next_obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 493 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0037065446376800537, next_obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.0002079010009765625, next_obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 494 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.01078939437866211, next_obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.006553232669830322, next_obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 495 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.01030886173248291, next_obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.011553376913070679, next_obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 496 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4286, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.014923036098480225, next_obs (-0.0204, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3469, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.01501128077507019, next_obs (0.3061, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 497 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012802332639694214, next_obs (-0.0204, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3061, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012232959270477295, next_obs (0.3061, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 498 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009435921907424927, next_obs (-0.0204, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3061, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.0032418668270111084, next_obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 499 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0069755613803863525, next_obs (0.0204, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006759166717529297, next_obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 500 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005170941352844238, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.006237030029296875, next_obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 501 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0038423240184783936, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.012043178081512451, next_obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 502 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002860844135284424, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.016314715147018433, next_obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 503 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002133578062057495, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.4694, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0192621648311615, next_obs (0.2653, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 504 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0015932023525238037, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01558607816696167, next_obs (0.2653, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 505 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00119096040725708, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011491626501083374, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 506 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008910000324249268, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008496850728988647, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 507 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006669163703918457, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006299346685409546, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 508 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004994869232177734, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004680991172790527, next_obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 509 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00037422776222229004, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0034854114055633545, next_obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 510 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002804100513458252, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0025992989540100098, next_obs (0.2245, -0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 511 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00021016597747802734, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.5918, 0.0, 0.0, -0.0204, -0.8367), action 5, reward 0.002168029546737671, next_obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 512 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.007604032754898071, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0014349520206451416, next_obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 513 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007561385631561279, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009121894836425781, next_obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 514 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005668610334396362, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.0010116100311279297, next_obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 515 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004250138998031616, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007337331771850586, next_obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 516 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003186732530593872, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.01013687252998352, next_obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 517 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002389580011367798, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.010297149419784546, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 518 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017918944358825684, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0077450573444366455, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 519 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001343756914138794, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.005820512771606445, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 520 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010077059268951416, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00437164306640625, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 521 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.007752746343612671, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0032821595668792725, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 522 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00808095932006836, next_obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.002598375082015991, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 523 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.5102, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.0025957822799682617, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.00801229476928711, next_obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 524 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0041024088859558105, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.011592060327529907, next_obs (0.2653, -0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 525 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0030609965324401855, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009310930967330933, next_obs (0.2653, -0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 526 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002286553382873535, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006618678569793701, next_obs (0.2653, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 527 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017097294330596924, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004747152328491211, next_obs (0.2653, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 528 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012791752815246582, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0034331679344177246, next_obs (0.2653, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 529 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009576380252838135, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.0039595067501068115, next_obs (0.3061, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 530 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007172822952270508, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3061, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004743248224258423, next_obs (0.3061, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 531 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005373954772949219, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3061, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.00017249584197998047, next_obs (0.3061, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 532 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00040271878242492676, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3061, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00041726231575012207, next_obs (0.3061, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 533 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.008684933185577393, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3061, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00010472536087036133, next_obs (0.3061, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 534 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008440256118774414, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3061, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.009786784648895264, next_obs (0.3061, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 535 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0018738210201263428, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3061, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.01924687623977661, next_obs (0.3061, -0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 536 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0034674108028411865, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.3061, -0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.016457319259643555, next_obs (0.2653, -0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 537 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0026202797889709473, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012060046195983887, next_obs (0.2653, -0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 538 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.001975923776626587, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008865594863891602, next_obs (0.2653, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 539 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0014878511428833008, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.015602320432662964, next_obs (0.2653, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 540 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.0002771615982055664, next_obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2653, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.02234157919883728, next_obs (0.2245, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 541 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00016620755195617676, next_obs (-0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.018125250935554504, next_obs (0.2245, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 542 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00023496150970458984, next_obs (-0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.2245, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012968897819519043, next_obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 543 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.00725516676902771, next_obs (-0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009309142827987671, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 544 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.014781355857849121, next_obs (-0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006714314222335815, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 545 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02044340968132019, next_obs (-0.0204, -0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004869833588600159, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 546 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.017200201749801636, next_obs (-0.0204, -0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0035520046949386597, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 547 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012895643711090088, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002604365348815918, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 548 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009668782353401184, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0019183456897735596, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 549 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007249519228935242, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0014185011386871338, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 550 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0021535754203796387, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0010522156953811646, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 551 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003836214542388916, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007825195789337158, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 552 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003077968955039978, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005830973386764526, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 553 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0024160444736480713, next_obs (-0.0612, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004351586103439331, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 554 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0018701553344726562, next_obs (-0.0612, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00032514333724975586, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 555 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.0004420429468154907, next_obs (-0.0612, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.0010483860969543457, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 556 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0612, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.00722251832485199, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007114261388778687, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 557 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007201701402664185, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0003504902124404907, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 558 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.0019056648015975952, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0001592189073562622, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 559 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.003236919641494751, next_obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 6.0945749282836914e-05, next_obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 560 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002857580780982971, next_obs (0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.2800097465515137e-05, next_obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 561 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012683570384979248, next_obs (0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.007928192615509033, next_obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 562 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004474371671676636, next_obs (0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.008271783590316772, next_obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 563 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 4.9620866775512695e-05, next_obs (0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.005459994077682495, next_obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 564 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00012379884719848633, next_obs (0.0204, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003916844725608826, next_obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 565 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00018328428268432617, next_obs (0.0612, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0037255287170410156, next_obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 566 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.0031439512968063354, next_obs (0.0612, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.004280254244804382, next_obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 567 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003539353609085083, next_obs (0.0612, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.01229625940322876, next_obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 568 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0035909265279769897, next_obs (0.0612, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1837, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.018229693174362183, next_obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 569 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.00029803812503814697, next_obs (0.102, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.015285685658454895, next_obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 570 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0022140443325042725, next_obs (0.102, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.004090219736099243, next_obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 571 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0032772868871688843, next_obs (0.102, -0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.001230493187904358, next_obs (0.1429, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 572 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.007958739995956421, next_obs (0.102, -0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1429, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009088516235351562, next_obs (0.1429, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 573 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.7143, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.0037684589624404907, next_obs (0.1429, -0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1429, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.009982779622077942, next_obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 574 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0007271319627761841, next_obs (0.1429, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009681165218353271, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 575 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0024380534887313843, next_obs (0.1429, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007156580686569214, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 576 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.0010742247104644775, next_obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005298703908920288, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 577 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.001966729760169983, next_obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003930270671844482, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 578 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.0021774619817733765, next_obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0029206350445747375, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 579 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0027301907539367676, next_obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0021741092205047607, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 580 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0022021830081939697, next_obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.00699857622385025, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 581 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.0024677813053131104, next_obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00762428343296051, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 582 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.004806309938430786, next_obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.005840867757797241, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 583 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8367, 0.0, 0.0, -0.0204, -0.8367), action 6, reward -0.0023300349712371826, next_obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00444108247756958, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 584 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.003755122423171997, next_obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.0038185715675354004, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 585 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.005015239119529724, next_obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004563957452774048, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 586 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0023235827684402466, next_obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.00572514533996582, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 587 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.005937054753303528, next_obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004675820469856262, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 588 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.013231590390205383, next_obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0033583641052246094, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 589 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.1429, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.018464207649230957, next_obs (0.102, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002428025007247925, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 590 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.015253141522407532, next_obs (0.102, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017667189240455627, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 591 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011170029640197754, next_obs (0.102, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012930408120155334, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 592 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008182317018508911, next_obs (0.102, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009511783719062805, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 593 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.102, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00600268691778183, next_obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.008126169443130493, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 594 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004413940012454987, next_obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007948629558086395, next_obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 595 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0032545700669288635, next_obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005960643291473389, next_obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 596 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.002406485378742218, next_obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004469931125640869, next_obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 597 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017840936779975891, next_obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.005440637469291687, next_obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 598 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.00712934136390686, next_obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.006652258336544037, next_obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 599 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006452411413192749, next_obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.014775045216083527, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 600 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0612, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.004565775394439697, next_obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.013938888907432556, next_obs (0.102, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 601 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0032436102628707886, next_obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0106678307056427, next_obs (0.102, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 602 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0023181363940238953, next_obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward -0.004825994372367859, next_obs (0.102, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 603 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016681849956512451, next_obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.006840601563453674, next_obs (0.102, -0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 604 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012088119983673096, next_obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7551, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.016542762517929077, next_obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 605 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.000881686806678772, next_obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.102, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.021064214408397675, next_obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 606 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006466805934906006, next_obs (0.0204, -0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01690208911895752, next_obs (0.0612, -0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "done status for agent 0: True\n",
      "done status for agent 1: True\n",
      "Success percentage of each agent at the end of episode 0:\n",
      "Agent 0: 1.4851485148514851%\n",
      "Agent 1: 0.825082508250825%\n",
      "Overall success percentage for all agents up to episode 0: 100.0%\n",
      "done status for agent 0: True\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "done status for agent 1: True\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "Episode 1\n",
      "Step 1 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.0034977197647094727, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.010140061378479004, next_obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 2 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.006926417350769043, next_obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.020295023918151855, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 3 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.00937199592590332, next_obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.014226198196411133, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 4 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.011052250862121582, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.006270289421081543, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 5 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.012143969535827637, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.0003947019577026367, next_obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 6 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.012787342071533203, next_obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0028133392333984375, next_obs (0.8776, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 7 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.013090252876281738, next_obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0065871477127075195, next_obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 8 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010238885879516602, next_obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0006525516510009766, next_obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 9 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007475137710571289, next_obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.008841395378112793, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 10 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.01523733139038086, next_obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.015097856521606445, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 11 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.02344536781311035, next_obs (-0.6735, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.019831180572509766, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 12 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.019870877265930176, next_obs (-0.6327, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02338230609893799, next_obs (0.7959, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 13 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0218508243560791, next_obs (-0.6327, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.022833704948425293, next_obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 14 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.025157809257507324, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.02141857147216797, next_obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 15 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02766287326812744, next_obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.020034074783325195, next_obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 16 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.022505760192871094, next_obs (-0.5918, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.015492916107177734, next_obs (0.8367, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 17 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.016878843307495117, next_obs (-0.5918, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011389732360839844, next_obs (0.8367, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 18 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012658953666687012, next_obs (-0.5918, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008410215377807617, next_obs (0.8367, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 19 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01652371883392334, next_obs (-0.5918, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.009109735488891602, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 20 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02116572856903076, next_obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.010072946548461914, next_obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 21 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.017614006996154785, next_obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007891416549682617, next_obs (0.9184, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 22 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01320028305053711, next_obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01208043098449707, next_obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 23 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009894251823425293, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01679074764251709, next_obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 24 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007417440414428711, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.020266175270080566, next_obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 25 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005561113357543945, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 8, reward 0.006175875663757324, next_obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 26 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0041697025299072266, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.006105184555053711, next_obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 27 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0031267404556274414, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.009825468063354492, next_obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 28 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0023447275161743164, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.012607097625732422, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 29 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0017582178115844727, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01670849323272705, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 30 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0013186931610107422, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0203249454498291, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 31 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009888410568237305, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02301967144012451, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 32 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0007416009902954102, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.024988532066345215, next_obs (0.8776, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 33 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005562305450439453, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.020236968994140625, next_obs (0.8776, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 34 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0004171133041381836, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01514291763305664, next_obs (0.8776, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 35 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00031280517578125, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.013113856315612793, next_obs (0.8776, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 36 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002346038818359375, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.011754631996154785, next_obs (0.9184, 0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 37 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00017595291137695312, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.4286, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.010304570198059082, next_obs (0.9184, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 38 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00013196468353271484, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0075876712799072266, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 39 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 9.906291961669922e-05, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005383610725402832, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 40 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 7.414817810058594e-05, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003863096237182617, next_obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 41 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 5.5670738220214844e-05, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00279843807220459, next_obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 42 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 4.184246063232422e-05, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0020428895950317383, next_obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 43 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.135204315185547e-05, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0015003681182861328, next_obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 44 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.3484230041503906e-05, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0011076927185058594, next_obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 45 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.7642974853515625e-05, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0008203983306884766, next_obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 46 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.3232231140136719e-05, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.011195063591003418, next_obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 47 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 9.775161743164062e-06, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.02162623405456543, next_obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 48 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 7.510185241699219e-06, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.013229846954345703, next_obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 49 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 5.602836608886719e-06, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.0028302669525146484, next_obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 50 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 4.172325134277344e-06, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.005056858062744141, next_obs (0.9184, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 51 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.0994415283203125e-06, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0053102970123291016, next_obs (0.9184, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 52 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.2649765014648438e-06, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0040378570556640625, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 53 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.6689300537109375e-06, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0030591487884521484, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 54 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.430511474609375e-06, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00231170654296875, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 55 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 9.5367431640625e-07, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0017431974411010742, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 56 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 8.344650268554688e-07, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0013129711151123047, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 57 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 4.76837158203125e-07, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0009876489639282227, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 58 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 4.76837158203125e-07, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0007423162460327148, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 59 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.5762786865234375e-07, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0005578994750976562, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 60 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.384185791015625e-07, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0004189014434814453, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 61 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.384185791015625e-07, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00031435489654541016, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 62 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00023615360260009766, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 63 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.384185791015625e-07, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00017702579498291016, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 64 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0001329183578491211, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 65 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -9.965896606445312e-05, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 66 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -7.486343383789062e-05, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 67 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -5.602836608886719e-05, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 68 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -4.208087921142578e-05, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 69 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -3.147125244140625e-05, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 70 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.372264862060547e-05, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 71 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.7762184143066406e-05, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 72 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.33514404296875e-05, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 73 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -9.894371032714844e-06, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 74 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -7.510185241699219e-06, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 75 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -5.7220458984375e-06, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 76 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -4.172325134277344e-06, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 77 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -3.2186508178710938e-06, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 78 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.384185791015625e-06, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 79 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.6689300537109375e-06, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 80 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.430511474609375e-06, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 81 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -9.5367431640625e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 82 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -8.344650268554688e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 83 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -5.960464477539062e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 84 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -3.5762786865234375e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 85 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -3.5762786865234375e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 86 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.384185791015625e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 87 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.384185791015625e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 88 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.384185791015625e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 89 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 90 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 91 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.384185791015625e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 92 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 93 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 94 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 95 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.1920928955078125e-07, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 96 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 97 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 98 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 99 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 100 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 101 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 102 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 103 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 104 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 105 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 106 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 107 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 108 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 109 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 110 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 111 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 112 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 113 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 114 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 115 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 116 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 117 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 118 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 119 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 120 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 121 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 122 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 123 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 124 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 125 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 126 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 127 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 128 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 129 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 130 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 131 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 132 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 133 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 134 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 135 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 136 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 137 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 138 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 139 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 140 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 141 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 142 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 143 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 144 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 145 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 146 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 147 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 148 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 149 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 150 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 151 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 152 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 153 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 154 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 155 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 156 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 157 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 158 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 159 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 160 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 161 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 162 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 163 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 164 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 165 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 166 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 167 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 168 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 169 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 170 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 171 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 172 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 173 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 174 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 175 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 176 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 177 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 178 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 179 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 180 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 181 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 182 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 183 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 184 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 185 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 186 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 187 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 188 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 189 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 190 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 191 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 192 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 193 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 194 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 195 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 196 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 197 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 198 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 199 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 200 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 201 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 202 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 203 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 204 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 205 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 206 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 207 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 208 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 209 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 210 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 211 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 212 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 213 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 214 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 215 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 216 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 217 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 218 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 219 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 220 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 221 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 222 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 223 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 224 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 225 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 226 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 227 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 228 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 229 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 230 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 231 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 232 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 233 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 234 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 235 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 236 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 237 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 238 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 239 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 240 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 241 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 242 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 243 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 244 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 245 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 246 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 247 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 248 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 249 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 250 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 251 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 252 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 253 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 254 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 255 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 256 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 257 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 258 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 259 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 260 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 261 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 262 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 263 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 264 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 265 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 266 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 267 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 268 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 269 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 270 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 271 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 272 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 273 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 274 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 275 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 276 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 277 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 278 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 279 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 280 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 281 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 282 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 283 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 284 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 285 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 286 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 287 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 288 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 289 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 290 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 291 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 292 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 293 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 294 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 295 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 296 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 297 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 298 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 299 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 300 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 301 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 302 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 303 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 304 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 305 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 306 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 307 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 308 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 309 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 310 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 311 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 312 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 313 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 314 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 315 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 316 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 317 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 318 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 319 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 320 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 321 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 322 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 323 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 324 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 325 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 326 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 327 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 328 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 329 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 330 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 331 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 332 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 333 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 334 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 335 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 336 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 337 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 338 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 339 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 340 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 341 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 342 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 343 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 344 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 345 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 346 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 347 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 348 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 349 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 350 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 351 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 352 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 353 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 354 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 355 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 356 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 357 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 358 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 359 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 360 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 361 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 362 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 363 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 364 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 365 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 366 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 367 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 368 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 369 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 370 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 371 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 372 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 373 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 374 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 375 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 376 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 377 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 378 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 379 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 380 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 381 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 382 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 383 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 384 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 385 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 386 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 387 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 388 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 389 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 390 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 391 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 392 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 393 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 394 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 395 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 396 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 397 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 398 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 399 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 400 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 401 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 402 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 403 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 404 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 405 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 406 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 407 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 408 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 409 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 410 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 411 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 412 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 413 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 414 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 415 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 416 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 417 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 418 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 419 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 420 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 421 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 422 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 423 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 424 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 425 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 426 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 427 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 428 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 429 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 430 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 431 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 432 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 433 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 434 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 435 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 436 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 437 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 438 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 439 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 440 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 441 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 442 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 443 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 444 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 445 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 446 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 447 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 448 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 449 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 450 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 451 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 452 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 453 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 454 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 455 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 456 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 457 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 458 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 459 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 460 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 461 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 462 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 463 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 464 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 465 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 466 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 467 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 468 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 469 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 470 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 471 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 472 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 473 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 474 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 475 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 476 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 477 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 478 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 479 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 480 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 481 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 482 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 483 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 484 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 485 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 486 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 487 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 488 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 489 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 490 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 491 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 492 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 493 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 494 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 495 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 496 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 497 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 498 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 499 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 500 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 501 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 502 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 503 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 504 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 505 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 506 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 507 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 508 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 509 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 510 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 511 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 512 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 513 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 514 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 515 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 516 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 517 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 518 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 519 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 520 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 521 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 522 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 523 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 524 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 525 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 526 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 527 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 528 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 529 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 530 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 531 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 532 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 533 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 534 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 535 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 536 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 537 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 538 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 539 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 540 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 541 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 542 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 543 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 544 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 545 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 546 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 547 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 548 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 549 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 550 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 551 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 552 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 553 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 554 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 555 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 556 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 557 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 558 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 559 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 560 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 561 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 562 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 563 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 564 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 565 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 566 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 567 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 568 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 569 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 570 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 571 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 572 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 573 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 574 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 575 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 576 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 577 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 578 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 579 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 580 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 581 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 582 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 583 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 584 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 585 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 586 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 587 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 588 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 589 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 590 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 591 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 592 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 593 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 594 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 595 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 596 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 597 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 598 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 599 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 600 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 601 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 602 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 603 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 604 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 605 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 606 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 607 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 608 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 609 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 610 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 611 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 612 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 613 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 614 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 615 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 616 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 617 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 618 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 619 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 620 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 621 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 622 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 623 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 624 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 625 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 626 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 627 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 628 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 629 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 630 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 631 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 632 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 633 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 634 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 635 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 636 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 637 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 638 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 639 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 640 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 641 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 642 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 643 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 644 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 645 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 646 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 647 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 648 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 649 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 650 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 651 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 652 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 653 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 654 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 655 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 656 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 657 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 658 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 659 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 660 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 661 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 662 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 663 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 664 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 665 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 666 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 667 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 668 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 669 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 670 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 671 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 672 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 673 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 674 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 675 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 676 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 677 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 678 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 679 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 680 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 681 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 682 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 683 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 684 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 685 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 686 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 687 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 688 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 689 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 690 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 691 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 692 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 693 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 694 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 695 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 696 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 697 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 698 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 699 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 700 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 701 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 702 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 703 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 704 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 705 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 706 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 707 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 708 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 709 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 710 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 711 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 712 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 713 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 714 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 715 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 716 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 717 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 718 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 719 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 720 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 721 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 722 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 723 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 724 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 725 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 726 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 727 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 728 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 729 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 730 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 731 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 732 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 733 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 734 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 735 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 736 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 737 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 738 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 739 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 740 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 741 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 742 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 743 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 744 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 745 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 746 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 747 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 748 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 749 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 750 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 751 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 752 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 753 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 754 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 755 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 756 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 757 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 758 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 759 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 760 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 761 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 762 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 763 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 764 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 765 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 766 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 767 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 768 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 769 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 770 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 771 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 772 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 773 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 774 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 775 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 776 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 777 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 778 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 779 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 780 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 781 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 782 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 783 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 784 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 785 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 786 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 787 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 788 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 789 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 790 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 791 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 792 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 793 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 794 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 795 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 796 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 797 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 798 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 799 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 800 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 801 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 802 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 803 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 804 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 805 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 806 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 807 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 808 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 809 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 810 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 811 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 812 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 813 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 814 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 815 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 816 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 817 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 818 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 819 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 820 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 821 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 822 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 823 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 824 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 825 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 826 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 827 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 828 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 829 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 830 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 831 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 832 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 833 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 834 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 835 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 836 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 837 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 838 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 839 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 840 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 841 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 842 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 843 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 844 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 845 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 846 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 847 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 848 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 849 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 850 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 851 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 852 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 853 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 854 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 855 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 856 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 857 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 858 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 859 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 860 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 861 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 862 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 863 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 864 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 865 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 866 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 867 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 868 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 869 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 870 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 871 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 872 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 873 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 874 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 875 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 876 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 877 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 878 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 879 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 880 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 881 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 882 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 883 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 884 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 885 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 886 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 887 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 888 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 889 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 890 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 891 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 892 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 893 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 894 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 895 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 896 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 897 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 898 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 899 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 900 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 901 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 902 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 903 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 904 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 905 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 906 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 907 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 908 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 909 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 910 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 911 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 912 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 913 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 914 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 915 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 916 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 917 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 918 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 919 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 920 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 921 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 922 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 923 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 924 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 925 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 926 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 927 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 928 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 929 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 930 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 931 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 932 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 933 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 934 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 935 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 936 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 937 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 938 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 939 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 940 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 941 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 942 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 943 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 944 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 945 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 946 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 947 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 948 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 949 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 950 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 951 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 952 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 953 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 954 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 955 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 956 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 957 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 958 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 959 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 960 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 961 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 962 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 963 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 964 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 965 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 966 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 967 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 968 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 969 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 970 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 971 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 972 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 973 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 974 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 975 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 976 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 977 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 978 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 979 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 980 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 981 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 982 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 983 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 984 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 985 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 986 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 987 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 988 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 989 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 990 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 991 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 992 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 993 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 994 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 995 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 996 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 997 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 998 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 999 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1000 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1001 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1002 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1003 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1004 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1005 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1006 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1007 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1008 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1009 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1010 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1011 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1012 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1013 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1014 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1015 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1016 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1017 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1018 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1019 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1020 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1021 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1022 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1023 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1024 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1025 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1026 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1027 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1028 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1029 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1030 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1031 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1032 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1033 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1034 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1035 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1036 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1037 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1038 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1039 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1040 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1041 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1042 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1043 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1044 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1045 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1046 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1047 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1048 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1049 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1050 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1051 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1052 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1053 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1054 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1055 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1056 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1057 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1058 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1059 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1060 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1061 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1062 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1063 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1064 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1065 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1066 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1067 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1068 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1069 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1070 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1071 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1072 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1073 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1074 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1075 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1076 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1077 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1078 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1079 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1080 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1081 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1082 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1083 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1084 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1085 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1086 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1087 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1088 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1089 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1090 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1091 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1092 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1093 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1094 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1095 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1096 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1097 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1098 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1099 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1100 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1101 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1102 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1103 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1104 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1105 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1106 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1107 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1108 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1109 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1110 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1111 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1112 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1113 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1114 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1115 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1116 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1117 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1118 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1119 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1120 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1121 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1122 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1123 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1124 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1125 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1126 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1127 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1128 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1129 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1130 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1131 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1132 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1133 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1134 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1135 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1136 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1137 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1138 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1139 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1140 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1141 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1142 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1143 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1144 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1145 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1146 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1147 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1148 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1149 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1150 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1151 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1152 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1153 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1154 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1155 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1156 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1157 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1158 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1159 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1160 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1161 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1162 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1163 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1164 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1165 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1166 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1167 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1168 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1169 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1170 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1171 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1172 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1173 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1174 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1175 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1176 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1177 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1178 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1179 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1180 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1181 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1182 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1183 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1184 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1185 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1186 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1187 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1188 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1189 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1190 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1191 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1192 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1193 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1194 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1195 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1196 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1197 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1198 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1199 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1200 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1201 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1202 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1203 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1204 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1205 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1206 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1207 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1208 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1209 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1210 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1211 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1212 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1213 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1214 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1215 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1216 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1217 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1218 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1219 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1220 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1221 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1222 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1223 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1224 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1225 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1226 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1227 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1228 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1229 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1230 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1231 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1232 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1233 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1234 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1235 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1236 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1237 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1238 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1239 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1240 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1241 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1242 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1243 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1244 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1245 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1246 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1247 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1248 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1249 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1250 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1251 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1252 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1253 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1254 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1255 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1256 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1257 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1258 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1259 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1260 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1261 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1262 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1263 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1264 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1265 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1266 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1267 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1268 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1269 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1270 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1271 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1272 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1273 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1274 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1275 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1276 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1277 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1278 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1279 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1280 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1281 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1282 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1283 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1284 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1285 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1286 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1287 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1288 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1289 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1290 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1291 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1292 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1293 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1294 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1295 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1296 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1297 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1298 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1299 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1300 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1301 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1302 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1303 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1304 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1305 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1306 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1307 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1308 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1309 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1310 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1311 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1312 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1313 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1314 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1315 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1316 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1317 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1318 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1319 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1320 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1321 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1322 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1323 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1324 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1325 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1326 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1327 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1328 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1329 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1330 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1331 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1332 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1333 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1334 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1335 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1336 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1337 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1338 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1339 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1340 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1341 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1342 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1343 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1344 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1345 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1346 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1347 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1348 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1349 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1350 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1351 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1352 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1353 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1354 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1355 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1356 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1357 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1358 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1359 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1360 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1361 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1362 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1363 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1364 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1365 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1366 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1367 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1368 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1369 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1370 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1371 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1372 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1373 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1374 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1375 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1376 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1377 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1378 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1379 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1380 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1381 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1382 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1383 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1384 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1385 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1386 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1387 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1388 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1389 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1390 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1391 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1392 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1393 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1394 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1395 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1396 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1397 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1398 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1399 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1400 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1401 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1402 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1403 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1404 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1405 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1406 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1407 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1408 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1409 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1410 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1411 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1412 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1413 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1414 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1415 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1416 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1417 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1418 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1419 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1420 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1421 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1422 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1423 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1424 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1425 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1426 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1427 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1428 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1429 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1430 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1431 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1432 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1433 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1434 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1435 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1436 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1437 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1438 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1439 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1440 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1441 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1442 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1443 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1444 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1445 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1446 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1447 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1448 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1449 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1450 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1451 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1452 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1453 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1454 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1455 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1456 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1457 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1458 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1459 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1460 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1461 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1462 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1463 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1464 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1465 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1466 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1467 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1468 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1469 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1470 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1471 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1472 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1473 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1474 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1475 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1476 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1477 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1478 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1479 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1480 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1481 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1482 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1483 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1484 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1485 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1486 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1487 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1488 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1489 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1490 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1491 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1492 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1493 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1494 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1495 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1496 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1497 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1498 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1499 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1500 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1501 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1502 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1503 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1504 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1505 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1506 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1507 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1508 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1509 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1510 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1511 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1512 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1513 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1514 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1515 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1516 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1517 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1518 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1519 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1520 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1521 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1522 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1523 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1524 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1525 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1526 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1527 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1528 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1529 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1530 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1531 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1532 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1533 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1534 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1535 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1536 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1537 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1538 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1539 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1540 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1541 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1542 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1543 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1544 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1545 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1546 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1547 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1548 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1549 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1550 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1551 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1552 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1553 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1554 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1555 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1556 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1557 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1558 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1559 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1560 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1561 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1562 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1563 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1564 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1565 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1566 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1567 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1568 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1569 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1570 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1571 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1572 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1573 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1574 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1575 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1576 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1577 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1578 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1579 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1580 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1581 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1582 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1583 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1584 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1585 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1586 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1587 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1588 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1589 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1590 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1591 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1592 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1593 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1594 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1595 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1596 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1597 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1598 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1599 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1600 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1601 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1602 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1603 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1604 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1605 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1606 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1607 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1608 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1609 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1610 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1611 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1612 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1613 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1614 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1615 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1616 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1617 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1618 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1619 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1620 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1621 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1622 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1623 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1624 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1625 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1626 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1627 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1628 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1629 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1630 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1631 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1632 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1633 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1634 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1635 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1636 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1637 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1638 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1639 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1640 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1641 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1642 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1643 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1644 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1645 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1646 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1647 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1648 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1649 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1650 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1651 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1652 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1653 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1654 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1655 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1656 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1657 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1658 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1659 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1660 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1661 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1662 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1663 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1664 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1665 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1666 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1667 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1668 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1669 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1670 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1671 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1672 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1673 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1674 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1675 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1676 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1677 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1678 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1679 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1680 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1681 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1682 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1683 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1684 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1685 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1686 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1687 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1688 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1689 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1690 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1691 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1692 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1693 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1694 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1695 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1696 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1697 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1698 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1699 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1700 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1701 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1702 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1703 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1704 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1705 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1706 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1707 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1708 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1709 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1710 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1711 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1712 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1713 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1714 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1715 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1716 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1717 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1718 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1719 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1720 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1721 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1722 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1723 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1724 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1725 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1726 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1727 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1728 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1729 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1730 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1731 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1732 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1733 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1734 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1735 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1736 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1737 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1738 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1739 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1740 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1741 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1742 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1743 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1744 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1745 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1746 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1747 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1748 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1749 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1750 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1751 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1752 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1753 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1754 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1755 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1756 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1757 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1758 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1759 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1760 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1761 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1762 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1763 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1764 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1765 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1766 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1767 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1768 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1769 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1770 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1771 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1772 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1773 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1774 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1775 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1776 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1777 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1778 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1779 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1780 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1781 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1782 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1783 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1784 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1785 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1786 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1787 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1788 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1789 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1790 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1791 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1792 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1793 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1794 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1795 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1796 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1797 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1798 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1799 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1800 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1801 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1802 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1803 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1804 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1805 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1806 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1807 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1808 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1809 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1810 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1811 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1812 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1813 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1814 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1815 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1816 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1817 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1818 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1819 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1820 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1821 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1822 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1823 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1824 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1825 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1826 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1827 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1828 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1829 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1830 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1831 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1832 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1833 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1834 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1835 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1836 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1837 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1838 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1839 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1840 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1841 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1842 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1843 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1844 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1845 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1846 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1847 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1848 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1849 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1850 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1851 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1852 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1853 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1854 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1855 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1856 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1857 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1858 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1859 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1860 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1861 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1862 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1863 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1864 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1865 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1866 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1867 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1868 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1869 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1870 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1871 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1872 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1873 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1874 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1875 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1876 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1877 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1878 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1879 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1880 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1881 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1882 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1883 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1884 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1885 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1886 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1887 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1888 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1889 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1890 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1891 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1892 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1893 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1894 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1895 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1896 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1897 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1898 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1899 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1900 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1901 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1902 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1903 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1904 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1905 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1906 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1907 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1908 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1909 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1910 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1911 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1912 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1913 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1914 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1915 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1916 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1917 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1918 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1919 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1920 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1921 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1922 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1923 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1924 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1925 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1926 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1927 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1928 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1929 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1930 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1931 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1932 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1933 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1934 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1935 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1936 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1937 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1938 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1939 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1940 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1941 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1942 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1943 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1944 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1945 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1946 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1947 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1948 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1949 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1950 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1951 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1952 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1953 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1954 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1955 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1956 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1957 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1958 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1959 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1960 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1961 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1962 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1963 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1964 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1965 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1966 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1967 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1968 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1969 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1970 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1971 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1972 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1973 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1974 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1975 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1976 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1977 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1978 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1979 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1980 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1981 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1982 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1983 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1984 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1985 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1986 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1987 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1988 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1989 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1990 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1991 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1992 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1993 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1994 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1995 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1996 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1997 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1998 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1999 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 2000 of Episode 1\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9184, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "done status for agent 0: False\n",
      "done status for agent 1: False\n",
      "Success percentage of each agent at the end of episode 1:\n",
      "Agent 0: 0.7425742574257426%\n",
      "Agent 1: 0.4125412541254125%\n",
      "Overall success percentage for all agents up to episode 1: 50.0%\n",
      "done status for agent 0: False\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "done status for agent 1: False\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "Episode 2\n",
      "Step 1 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.0034977197647094727, next_obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.010140061378479004, next_obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 2 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.9184, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.006926417350769043, next_obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 8, reward -0.020295023918151855, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 3 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.00937199592590332, next_obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.014226198196411133, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 4 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.8776, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.011052250862121582, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.006270289421081543, next_obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 5 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.012143969535827637, next_obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 3, reward -0.0003947019577026367, next_obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 6 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.8367, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.012787342071533203, next_obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0028133392333984375, next_obs (0.8776, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 7 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 6, reward 0.013090252876281738, next_obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 5, reward -0.0065871477127075195, next_obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 8 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.010238885879516602, next_obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0006525516510009766, next_obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 9 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7551, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007475137710571289, next_obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.008841395378112793, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 10 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.01523733139038086, next_obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.015097856521606445, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 11 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.7143, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.02344536781311035, next_obs (-0.6735, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.019831180572509766, next_obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 12 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.6735, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.019870877265930176, next_obs (-0.6327, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9592, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02338230609893799, next_obs (0.7959, 0.9184, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 13 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0218508243560791, next_obs (-0.6327, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.9184, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.022833704948425293, next_obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 14 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.025157809257507324, next_obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.02141857147216797, next_obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 15 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.6327, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02766287326812744, next_obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.7959, 0.8776, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.020034074783325195, next_obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 16 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.022505760192871094, next_obs (-0.5918, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.8367, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.015492916107177734, next_obs (0.8367, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 17 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.016878843307495117, next_obs (-0.5918, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.011389732360839844, next_obs (0.8367, 0.7959, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 18 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012658953666687012, next_obs (-0.5918, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.7959, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.008410215377807617, next_obs (0.8367, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 19 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01652371883392334, next_obs (-0.5918, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8367, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.009109735488891602, next_obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 20 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02116572856903076, next_obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7551, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.010072946548461914, next_obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 21 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.017614006996154785, next_obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.007891416549682617, next_obs (0.9184, 0.7143, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 22 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01320028305053711, next_obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.7143, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01208043098449707, next_obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 23 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009894251823425293, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01679074764251709, next_obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 24 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.014410734176635742, next_obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6735, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.020266175270080566, next_obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 25 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01952493190765381, next_obs (-0.5918, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 8, reward 0.006175875663757324, next_obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 26 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.016363978385925293, next_obs (-0.5918, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.6327, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.006105184555053711, next_obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 27 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.012257099151611328, next_obs (-0.5918, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.009825468063354492, next_obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 28 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.009183406829833984, next_obs (-0.5918, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 3, reward 0.012607097625732422, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 29 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.006882309913635254, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.01670849323272705, next_obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 30 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005158782005310059, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.5918, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.0203249454498291, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 31 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0038672685623168945, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.02301967144012451, next_obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 32 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0028995275497436523, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 1, reward 0.024988532066345215, next_obs (0.8776, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 33 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0021741390228271484, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.020236968994140625, next_obs (0.8776, 0.5102, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 34 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0016303062438964844, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.5102, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.01514291763305664, next_obs (0.8776, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 35 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0012224912643432617, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.013113856315612793, next_obs (0.8776, 0.4694, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 36 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0009167194366455078, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.8776, 0.4694, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.011754631996154785, next_obs (0.9184, 0.4286, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 37 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0006874799728393555, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.4286, 0.0, 0.0, -0.0204, -0.8367), action 7, reward 0.010304570198059082, next_obs (0.9184, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 38 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0005155801773071289, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9184, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0075876712799072266, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 39 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00038683414459228516, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.005383610725402832, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 40 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0002900362014770508, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.003863096237182617, next_obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 41 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.000217437744140625, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00279843807220459, next_obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 42 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00016307830810546875, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0020428895950317383, next_obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 43 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.00012242794036865234, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0015003681182861328, next_obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 44 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 9.167194366455078e-05, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (1.0, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 4, reward 0.01168978214263916, next_obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 45 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 6.878376007080078e-05, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 2, reward 0.00575566291809082, next_obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 46 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 5.161762237548828e-05, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.0027768611907958984, next_obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 47 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.8743019104003906e-05, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3061, 0.0, 0.0, -0.0204, -0.8367), action 2, reward -0.009247541427612305, next_obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 48 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.8967857360839844e-05, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00843358039855957, next_obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 49 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.181529998779297e-05, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.006368160247802734, next_obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 50 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.633167266845703e-05, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3469, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.004799842834472656, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 51 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.2159347534179688e-05, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0036133527755737305, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 52 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 9.298324584960938e-06, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.002717256546020508, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 53 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 6.794929504394531e-06, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0020421743392944336, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 54 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 5.245208740234375e-06, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0015339851379394531, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 55 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.814697265625e-06, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0011518001556396484, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 56 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.9802322387695312e-06, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0008646249771118164, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 57 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.1457672119140625e-06, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0006487369537353516, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 58 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.5497207641601562e-06, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0004868507385253906, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 59 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.3113021850585938e-06, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00036525726318359375, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 60 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 8.344650268554688e-07, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0002740621566772461, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 61 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 7.152557373046875e-07, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00020563602447509766, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 62 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 4.76837158203125e-07, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.00015413761138916016, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 63 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.5762786865234375e-07, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -0.0001157522201538086, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 64 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 3.5762786865234375e-07, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -8.678436279296875e-05, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 65 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.384185791015625e-07, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -6.508827209472656e-05, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 66 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.1920928955078125e-07, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -4.863739013671875e-05, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 67 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 1.1920928955078125e-07, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -3.6716461181640625e-05, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 68 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.7418136596679688e-05, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 69 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 2.384185791015625e-07, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.0623207092285156e-05, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 70 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.52587890625e-05, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 71 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.1682510375976562e-05, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 72 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -8.702278137207031e-06, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 73 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -6.4373016357421875e-06, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 74 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -4.887580871582031e-06, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 75 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -3.6954879760742188e-06, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 76 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.7418136596679688e-06, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 77 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.1457672119140625e-06, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 78 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.5497207641601562e-06, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 79 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.1920928955078125e-06, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 80 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -8.344650268554688e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 81 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -7.152557373046875e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 82 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -4.76837158203125e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 83 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.384185791015625e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 84 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -3.5762786865234375e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 85 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -2.384185791015625e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 86 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.1920928955078125e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 87 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.1920928955078125e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 88 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.1920928955078125e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 89 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.1920928955078125e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 90 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 91 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward -1.1920928955078125e-07, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 92 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 93 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 94 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 95 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 96 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 97 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 98 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 99 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 100 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 101 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 102 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 103 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 104 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 105 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 106 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 107 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 108 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 109 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 110 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 111 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 112 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 113 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 114 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 115 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 116 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 117 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 118 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 119 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 120 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 121 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 122 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 123 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 124 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 125 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 126 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 127 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 128 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 129 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 130 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 131 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 132 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 133 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 134 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 135 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 136 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 137 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 138 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 139 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 140 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 141 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 142 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 143 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 144 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 145 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 146 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 147 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 148 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 149 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 150 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 151 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 152 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 153 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 154 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 155 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 156 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 157 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 158 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 159 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 160 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 161 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 162 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 163 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 164 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 165 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 166 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 167 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 168 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 169 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 170 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 171 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 172 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 173 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 174 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 175 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 176 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 177 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 178 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 179 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 180 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 181 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 182 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 183 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 184 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 185 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 186 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 187 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 188 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 189 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 190 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 191 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 192 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 193 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 194 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 195 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 196 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 197 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 198 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 199 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 200 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 201 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 202 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 203 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 204 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 205 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 206 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 207 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 208 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 209 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 210 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 211 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 212 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 213 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 214 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 215 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 216 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 217 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 218 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 219 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 220 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 221 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 222 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 223 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 224 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 225 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 226 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 227 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 228 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 229 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 230 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 231 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 232 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 233 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 234 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 235 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 236 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 237 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 238 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 239 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 240 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 241 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 242 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 243 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 244 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 245 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 246 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 247 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 248 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 249 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 250 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 251 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 252 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 253 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 254 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 255 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 256 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 257 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 258 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 259 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 260 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 261 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 262 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 263 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 264 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 265 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 266 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 267 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 268 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 269 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 270 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 271 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 272 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 273 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 274 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 275 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 276 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 277 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 278 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 279 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 280 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 281 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 282 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 283 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 284 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 285 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 286 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 287 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 288 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 289 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 290 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 291 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 292 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 293 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 294 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 295 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 296 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 297 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 298 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 299 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 300 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 301 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 302 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 303 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 304 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 305 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 306 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 307 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 308 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 309 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 310 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 311 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 312 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 313 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 314 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 315 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 316 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 317 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 318 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 319 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 320 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 321 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 322 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 323 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 324 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 325 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 326 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 327 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 328 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 329 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 330 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 331 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 332 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 333 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 334 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 335 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 336 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 337 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 338 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 339 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 340 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 341 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 342 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 343 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 344 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 345 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 346 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 347 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 348 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 349 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 350 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 351 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 352 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 353 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 354 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 355 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 356 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 357 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 358 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 359 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 360 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 361 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 362 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 363 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 364 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 365 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 366 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 367 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 368 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 369 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 370 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 371 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 372 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 373 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 374 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 375 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 376 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 377 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 378 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 379 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 380 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 381 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 382 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 383 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 384 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 385 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 386 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 387 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 388 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 389 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 390 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 391 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 392 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 393 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 394 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 395 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 396 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 397 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 398 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 399 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 400 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 401 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 402 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 403 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 404 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 405 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 406 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 407 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 408 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 409 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 410 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 411 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 412 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 413 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 414 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 415 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 416 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 417 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 418 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 419 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 420 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 421 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 422 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 423 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 424 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 425 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 426 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 427 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 428 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 429 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 430 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 431 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 432 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 433 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 434 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 435 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 436 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 437 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 438 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 439 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 440 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 441 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 442 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 443 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 444 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 445 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 446 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 447 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 448 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 449 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 450 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 451 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 452 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 453 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 454 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 455 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 456 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 457 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 458 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 459 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 460 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 461 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 462 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 463 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 464 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 465 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 466 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 467 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 468 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 469 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 470 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 471 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 472 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 473 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 474 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 475 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 476 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 477 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 478 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 479 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 480 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 481 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 482 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 483 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 484 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 485 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 486 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 487 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 488 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 489 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 490 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 491 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 492 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 493 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 494 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 495 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 496 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 497 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 498 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 499 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 500 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 501 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 502 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 503 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 504 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 505 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 506 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 507 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 508 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 509 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 510 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 511 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 512 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 513 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 514 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 515 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 516 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 517 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 518 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 519 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 520 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 521 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 522 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 523 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 524 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 525 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 526 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 527 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 528 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 529 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 530 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 531 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 532 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 533 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 534 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 535 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 536 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 537 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 538 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 539 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 540 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 541 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 542 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 543 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 544 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 545 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 546 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 547 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 548 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 549 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 550 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 551 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 552 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 553 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 554 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 555 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 556 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 557 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 558 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 559 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 560 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 561 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 562 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 563 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 564 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 565 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 566 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 567 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 568 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 569 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 570 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 571 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 572 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 573 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 574 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 575 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 576 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 577 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 578 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 579 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 580 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 581 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 582 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 583 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 584 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 585 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 586 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 587 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 588 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 589 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 590 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 591 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 592 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 593 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 594 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 595 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 596 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 597 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 598 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 599 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 600 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 601 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 602 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 603 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 604 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 605 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 606 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 607 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 608 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 609 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 610 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 611 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 612 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 613 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 614 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 615 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 616 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 617 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 618 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 619 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 620 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 621 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 622 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 623 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 624 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 625 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 626 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 627 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 628 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 629 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 630 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 631 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 632 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 633 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 634 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 635 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 636 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 637 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 638 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 639 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 640 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 641 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 642 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 643 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 644 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 645 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 646 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 647 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 648 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 649 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 650 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 651 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 652 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 653 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 654 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 655 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 656 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 657 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 658 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 659 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 660 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 661 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 662 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 663 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 664 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 665 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 666 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 667 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 668 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 669 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 670 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 671 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 672 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 673 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 674 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 675 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 676 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 677 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 678 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 679 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 680 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 681 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 682 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 683 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 684 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 685 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 686 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 687 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 688 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 689 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 690 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 691 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 692 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 693 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 694 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 695 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 696 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 697 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 698 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 699 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 700 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 701 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 702 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 703 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 704 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 705 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 706 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 707 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 708 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 709 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 710 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 711 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 712 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 713 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 714 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 715 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 716 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 717 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 718 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 719 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 720 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 721 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 722 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 723 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 724 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 725 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 726 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 727 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 728 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 729 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 730 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 731 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 732 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 733 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 734 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 735 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 736 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 737 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 738 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 739 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 740 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 741 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 742 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 743 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 744 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 745 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 746 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 747 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 748 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 749 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 750 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 751 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 752 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 753 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 754 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 755 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 756 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 757 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 758 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 759 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 760 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 761 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 762 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 763 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 764 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 765 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 766 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 767 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 768 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 769 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 770 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 771 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 772 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 773 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 774 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 775 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 776 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 777 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 778 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 779 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 780 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 781 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 782 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 783 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 784 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 785 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 786 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 787 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 788 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 789 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 790 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 791 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 792 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 793 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 794 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 795 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 796 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 797 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 798 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 799 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 800 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 801 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 802 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 803 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 804 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 805 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 806 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 807 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 808 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 809 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 810 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 811 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 812 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 813 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 814 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 815 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 816 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 817 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 818 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 819 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 820 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 821 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 822 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 823 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 824 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 825 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 826 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 827 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 828 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 829 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 830 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 831 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 832 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 833 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 834 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 835 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 836 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 837 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 838 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 839 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 840 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 841 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 842 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 843 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 844 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 845 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 846 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 847 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 848 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 849 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 850 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 851 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 852 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 853 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 854 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 855 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 856 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 857 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 858 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 859 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 860 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 861 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 862 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 863 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 864 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 865 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 866 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 867 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 868 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 869 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 870 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 871 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 872 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 873 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 874 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 875 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 876 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 877 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 878 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 879 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 880 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 881 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 882 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 883 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 884 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 885 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 886 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 887 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 888 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 889 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 890 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 891 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 892 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 893 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 894 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 895 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 896 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 897 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 898 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 899 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 900 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 901 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 902 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 903 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 904 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 905 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 906 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 907 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 908 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 909 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 910 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 911 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 912 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 913 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 914 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 915 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 916 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 917 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 918 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 919 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 920 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 921 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 922 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 923 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 924 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 925 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 926 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 927 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 928 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 929 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 930 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 931 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 932 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 933 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 934 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 935 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 936 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 937 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 938 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 939 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 940 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 941 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 942 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 943 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 944 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 945 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 946 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 947 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 948 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 949 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 950 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 951 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 952 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 953 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 954 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 955 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 956 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 957 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 958 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 959 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 960 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 961 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 962 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 963 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 964 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 965 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 966 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 967 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 968 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 969 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 970 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 971 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 972 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 973 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 974 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 975 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 976 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 977 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 978 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 979 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 980 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 981 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 982 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 983 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 984 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 985 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 986 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 987 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 988 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 989 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 990 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 991 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 992 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 993 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 994 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 995 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 996 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 997 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 998 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 999 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1000 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1001 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1002 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1003 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1004 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1005 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1006 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1007 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1008 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1009 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1010 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1011 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1012 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1013 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1014 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1015 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1016 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1017 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1018 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1019 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1020 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1021 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1022 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1023 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1024 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1025 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1026 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1027 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1028 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1029 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1030 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1031 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1032 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1033 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1034 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1035 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1036 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1037 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1038 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1039 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1040 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1041 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1042 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1043 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1044 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1045 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1046 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1047 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1048 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1049 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1050 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1051 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1052 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1053 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1054 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1055 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1056 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1057 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1058 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1059 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1060 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1061 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1062 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1063 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1064 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1065 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1066 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1067 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1068 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1069 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1070 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1071 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1072 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1073 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1074 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1075 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1076 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1077 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1078 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1079 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1080 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1081 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1082 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1083 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1084 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1085 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1086 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1087 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1088 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1089 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1090 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1091 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1092 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1093 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1094 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1095 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1096 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1097 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1098 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1099 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1100 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1101 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1102 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1103 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1104 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1105 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1106 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1107 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1108 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1109 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1110 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1111 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1112 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1113 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1114 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1115 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1116 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1117 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1118 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1119 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1120 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1121 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1122 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1123 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1124 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1125 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1126 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1127 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1128 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1129 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1130 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1131 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1132 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1133 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1134 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1135 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1136 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1137 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1138 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1139 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1140 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1141 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1142 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1143 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1144 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1145 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1146 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1147 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1148 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1149 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1150 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1151 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1152 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1153 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1154 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1155 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1156 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1157 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1158 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1159 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1160 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1161 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1162 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1163 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1164 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1165 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1166 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1167 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1168 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1169 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1170 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1171 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1172 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1173 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1174 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1175 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1176 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1177 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1178 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1179 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1180 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1181 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1182 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1183 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1184 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1185 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1186 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1187 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1188 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1189 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1190 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1191 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1192 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1193 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1194 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1195 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1196 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1197 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1198 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1199 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1200 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1201 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1202 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1203 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1204 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1205 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1206 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1207 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1208 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1209 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1210 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1211 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1212 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1213 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1214 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1215 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1216 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1217 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1218 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1219 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1220 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1221 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1222 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1223 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1224 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1225 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1226 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1227 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1228 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1229 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1230 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1231 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1232 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1233 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1234 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1235 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1236 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1237 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1238 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1239 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1240 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1241 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1242 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1243 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1244 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1245 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1246 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1247 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1248 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1249 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1250 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1251 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1252 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1253 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1254 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1255 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1256 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1257 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1258 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1259 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1260 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1261 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1262 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1263 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1264 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1265 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1266 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1267 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1268 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1269 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1270 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1271 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1272 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1273 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1274 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1275 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1276 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1277 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1278 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1279 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1280 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1281 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1282 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1283 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1284 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1285 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1286 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1287 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1288 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1289 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1290 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1291 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1292 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1293 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1294 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1295 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1296 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1297 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1298 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1299 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1300 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1301 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1302 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1303 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1304 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1305 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1306 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1307 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1308 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1309 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1310 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1311 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1312 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1313 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1314 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1315 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1316 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1317 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1318 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1319 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1320 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1321 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1322 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1323 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1324 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1325 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1326 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1327 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1328 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1329 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1330 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1331 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1332 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1333 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1334 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1335 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1336 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1337 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1338 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1339 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1340 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1341 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1342 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1343 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1344 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1345 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1346 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1347 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1348 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1349 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1350 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1351 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1352 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1353 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1354 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1355 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1356 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1357 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1358 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1359 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1360 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1361 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1362 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1363 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1364 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1365 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1366 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1367 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1368 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1369 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1370 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1371 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1372 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1373 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1374 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1375 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1376 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1377 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1378 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1379 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1380 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1381 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1382 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1383 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1384 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1385 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1386 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1387 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1388 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1389 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1390 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1391 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1392 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1393 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1394 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1395 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1396 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1397 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1398 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1399 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1400 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1401 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1402 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1403 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1404 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1405 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1406 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1407 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1408 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1409 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1410 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1411 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1412 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1413 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1414 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1415 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1416 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1417 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1418 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1419 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1420 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1421 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1422 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1423 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1424 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1425 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1426 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1427 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1428 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1429 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1430 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1431 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1432 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1433 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1434 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1435 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1436 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1437 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1438 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1439 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1440 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1441 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1442 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1443 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1444 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1445 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1446 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1447 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1448 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1449 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1450 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1451 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1452 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1453 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1454 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1455 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1456 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1457 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1458 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1459 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1460 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1461 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1462 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1463 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1464 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1465 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1466 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1467 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1468 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1469 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1470 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1471 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1472 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1473 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1474 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1475 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1476 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1477 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1478 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1479 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1480 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1481 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1482 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1483 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1484 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1485 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1486 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1487 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1488 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1489 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1490 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1491 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1492 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1493 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1494 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1495 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1496 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1497 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1498 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1499 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1500 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1501 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1502 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1503 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1504 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1505 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1506 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1507 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1508 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1509 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1510 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1511 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1512 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1513 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1514 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1515 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1516 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1517 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1518 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1519 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1520 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1521 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1522 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1523 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1524 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1525 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1526 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1527 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1528 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1529 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1530 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1531 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1532 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1533 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1534 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1535 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1536 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1537 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1538 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1539 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1540 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1541 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1542 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1543 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1544 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1545 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1546 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1547 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1548 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1549 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1550 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1551 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1552 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1553 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1554 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1555 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1556 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1557 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1558 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1559 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1560 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1561 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1562 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1563 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1564 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1565 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1566 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1567 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1568 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1569 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1570 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1571 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1572 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1573 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1574 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1575 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1576 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1577 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1578 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1579 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1580 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1581 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1582 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1583 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1584 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1585 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1586 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1587 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1588 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1589 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1590 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1591 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1592 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1593 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1594 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1595 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1596 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1597 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1598 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1599 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1600 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1601 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1602 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1603 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1604 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1605 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1606 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1607 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1608 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1609 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1610 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1611 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1612 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1613 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1614 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1615 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1616 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1617 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1618 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1619 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1620 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1621 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1622 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1623 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1624 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1625 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1626 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1627 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1628 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1629 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1630 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1631 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1632 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1633 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1634 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1635 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1636 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1637 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1638 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1639 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1640 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1641 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1642 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1643 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1644 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1645 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1646 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1647 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1648 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1649 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1650 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1651 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1652 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1653 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1654 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1655 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1656 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1657 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1658 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1659 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1660 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1661 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1662 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1663 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1664 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1665 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1666 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1667 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1668 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1669 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1670 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1671 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1672 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1673 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1674 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1675 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1676 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1677 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1678 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1679 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1680 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1681 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1682 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1683 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1684 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1685 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1686 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1687 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1688 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1689 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1690 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1691 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1692 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1693 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1694 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1695 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1696 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1697 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1698 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1699 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1700 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1701 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1702 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1703 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1704 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1705 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1706 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1707 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1708 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1709 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1710 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1711 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1712 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1713 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1714 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1715 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1716 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1717 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1718 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1719 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1720 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1721 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1722 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1723 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1724 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1725 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1726 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1727 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1728 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1729 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1730 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1731 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1732 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1733 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1734 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1735 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1736 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1737 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1738 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1739 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1740 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1741 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1742 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1743 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1744 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1745 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1746 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1747 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1748 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1749 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1750 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1751 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1752 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1753 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1754 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1755 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1756 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1757 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1758 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1759 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1760 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1761 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1762 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1763 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1764 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1765 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1766 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1767 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1768 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1769 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1770 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1771 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1772 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1773 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1774 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1775 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1776 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1777 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1778 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1779 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1780 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1781 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1782 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1783 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1784 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1785 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1786 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1787 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1788 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1789 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1790 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1791 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1792 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1793 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1794 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1795 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1796 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1797 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1798 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1799 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1800 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1801 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1802 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1803 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1804 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1805 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1806 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1807 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1808 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1809 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1810 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1811 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1812 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1813 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1814 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1815 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1816 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1817 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1818 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1819 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1820 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1821 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1822 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1823 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1824 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1825 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1826 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1827 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1828 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1829 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1830 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1831 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1832 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1833 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1834 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1835 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1836 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1837 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1838 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1839 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1840 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1841 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1842 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1843 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1844 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1845 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1846 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1847 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1848 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1849 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1850 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1851 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1852 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1853 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1854 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1855 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1856 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1857 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1858 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1859 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1860 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1861 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1862 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1863 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1864 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1865 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1866 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1867 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1868 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1869 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1870 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1871 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1872 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1873 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1874 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1875 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1876 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1877 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1878 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1879 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1880 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1881 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1882 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1883 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1884 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1885 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1886 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1887 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1888 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1889 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1890 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1891 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1892 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1893 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1894 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1895 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1896 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1897 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1898 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1899 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1900 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1901 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1902 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1903 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1904 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1905 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1906 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1907 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1908 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1909 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1910 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1911 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1912 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1913 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1914 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1915 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1916 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1917 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1918 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1919 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1920 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1921 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1922 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1923 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1924 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1925 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1926 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1927 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1928 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1929 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1930 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1931 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1932 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1933 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1934 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1935 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1936 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1937 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1938 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1939 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1940 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1941 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1942 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1943 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1944 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1945 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1946 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1947 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1948 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1949 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1950 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1951 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1952 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1953 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1954 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1955 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1956 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1957 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1958 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1959 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1960 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1961 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1962 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1963 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1964 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1965 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1966 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1967 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1968 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1969 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1970 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1971 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1972 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1973 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1974 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1975 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1976 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1977 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1978 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1979 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1980 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1981 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1982 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1983 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1984 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1985 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1986 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1987 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1988 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1989 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1990 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1991 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1992 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1993 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1994 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1995 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1996 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1997 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1998 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 1999 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Step 2000 of Episode 2\n",
      "action type of agent 0: case base\n",
      "action type of agent 1: case base\n",
      "Agent 0 - Updated Q-table for obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (-0.5918, 0.551, 0.0, 0.0, -0.0204, -0.8367)\n",
      "Agent 1 - Updated Q-table for obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367), action 0, reward 0.0, next_obs (0.9592, 0.3878, 0.0, 0.0, -0.0204, -0.8367)\n",
      "done status for agent 0: False\n",
      "done status for agent 1: False\n",
      "Success percentage of each agent at the end of episode 2:\n",
      "Agent 0: 0.49504950495049505%\n",
      "Agent 1: 0.275027502750275%\n",
      "Overall success percentage for all agents up to episode 2: 33.33333333333333%\n",
      "done status for agent 0: False\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "done status for agent 1: False\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "Overall success percentage for all agents = 33.33333333333333%\n",
      "It took: 59.364309549331665s for 4606 steps across 3 episodes of 1 parallel environments on device cuda for navigation_comm scenario.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import ast\n",
    "from vmas import make_env\n",
    "from vmas.simulator.core import Agent\n",
    "from vmas.simulator.scenario import BaseScenario\n",
    "from typing import Union\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from IPython.display import HTML, display as ipython_display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.spaces import Discrete \n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, env, agent_id, alpha=0.1, gamma=0.99, epsilon=0.2, communication_weight=0.5):\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.q_table = {}\n",
    "        self.env = env\n",
    "        self.agent_id = agent_id\n",
    "        self.communication_weight = communication_weight  # Weight parameter for incorporating messages\n",
    "\n",
    "    def get_action(self, agent, env, agent_id, agent_obs):\n",
    "        agent_obs_cpu = agent_obs[:6].cpu().numpy()  # Transfer only the required slice to CPU\n",
    "        agent_obs = tuple(np.round(agent_obs_cpu, decimals=5))  # Round the observation\n",
    "\n",
    "        if agent_obs not in self.q_table:\n",
    "            self.q_table[agent_obs] = np.zeros(self.env.action_space[self.agent_id].n)\n",
    "\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Select a random action\n",
    "            action = np.random.randint(env.action_space[self.agent_id].n)\n",
    "        else:\n",
    "            # Select the action with the highest Q-value\n",
    "            action = np.argmax(self.q_table[agent_obs])\n",
    "        \n",
    "        return (action,)  # Return as a tuple\n",
    "\n",
    "    def update_q_table(self,  agent, env, agent_id, obs, action, reward, next_obs):\n",
    "        obs_key = tuple(np.round(obs.cpu().numpy(), decimals=5))  # Only transfer to CPU when necessary\n",
    "        next_obs_key = tuple(np.round(next_obs.cpu().numpy(), decimals=5))\n",
    "        action = int(action.item())  # Convert tensor to Python scalar\n",
    "\n",
    "        # print (f\"reward obtained = {reward}\")\n",
    "\n",
    "        if isinstance(self.env.action_space[self.agent_id], Discrete):\n",
    "            action_space_size = self.env.action_space[self.agent_id].n\n",
    "        else:\n",
    "            raise ValueError(\"This Q-learning implementation requires a discrete action space.\")\n",
    "\n",
    "        if obs_key not in self.q_table:\n",
    "            self.q_table[obs_key] = np.zeros(action_space_size)\n",
    "\n",
    "        if next_obs_key not in self.q_table:\n",
    "            self.q_table[next_obs_key] = np.zeros(action_space_size)\n",
    "\n",
    "        best_next_action = np.argmax(self.q_table[next_obs_key])\n",
    "        td_target = reward + self.gamma * self.q_table[next_obs_key][best_next_action]\n",
    "\n",
    "        td_error = td_target - self.q_table[obs_key][action]\n",
    "        self.q_table[obs_key][action] += self.alpha * td_error\n",
    "\n",
    "        print(f\"Agent {self.agent_id} - Updated Q-table for obs {obs_key}, action {action}, reward {reward}, next_obs {next_obs_key}\")\n",
    "\n",
    "    \n",
    "    def print_q_table(self):\n",
    "        print(f\"Q-table for Agent {self.agent_id}:\")\n",
    "        for state, actions in self.q_table.items():\n",
    "            print(f\"  State: {state}\")\n",
    "            for action, q_value in enumerate(actions):\n",
    "                print(f\"    Action: {action}, Q-value: {q_value:.5f}\")\n",
    "        print(f\"End of Q-table for Agent {self.agent_id}\\n\")\n",
    "\n",
    "class Case:\n",
    "    added_states = set()  # Class attribute to store states already added to the case base\n",
    "\n",
    "    def __init__(self, problem, solution, trust_value=1):\n",
    "        self.problem = problem if isinstance(problem, list) else ast.literal_eval(problem)  # Convert problem to numpy array\n",
    "        self.solution = solution\n",
    "        self.trust_value = trust_value\n",
    "    \n",
    "    @staticmethod\n",
    "    def sim_q(state1, state2):\n",
    "        state1 = np.atleast_1d(state1)\n",
    "        state2 = np.atleast_1d(state2)\n",
    "        CNDMaxDist = 6  # Maximum distance between two nodes in the-0.9, 0.7, 0.0, 0.0, 0.0, -0.9) CND based on EOPRA reference\n",
    "        v = state1.size  # Total number of objects the agent can perceive\n",
    "        DistQ = np.sum([Case.dist_q(Objic, Objip) for Objic, Objip in zip(state1, state2)])\n",
    "        similarity = (CNDMaxDist * v - DistQ) / (CNDMaxDist * v)\n",
    "        return similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def dist_q(X1, X2):\n",
    "        return np.min(np.abs(X1 - X2))\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(agent, env, state, case_base, threshold=0.1):\n",
    "\n",
    "        # Convert the state to numpy if it's a tensor\n",
    "        if isinstance(state, torch.Tensor):\n",
    "            state = state.cpu().numpy()\n",
    "\n",
    "        # Slice the physical observations\n",
    "        physical_obs = state[:6]\n",
    "\n",
    "        if not agent.silent:\n",
    "            comm_obs = state[6:]\n",
    "            # Convert comm_obs to a numpy array if it is a tensor\n",
    "            if isinstance(comm_obs, torch.Tensor):\n",
    "                comm_obs = comm_obs.cpu().numpy()\n",
    "\n",
    "        # print(f\"physical_obs = {physical_obs}\")\n",
    "\n",
    "        # Ensure the state is in a list format to avoid issues with ast.literal_eval\n",
    "        state_list = state.tolist() if isinstance(state, np.ndarray) else state\n",
    "        state_str = json.dumps(state_list)  # Convert list to a JSON string for ast.literal_eval\n",
    "\n",
    "        # Use ast.literal_eval safely to convert the string back to a list\n",
    "        state = ast.literal_eval(state_str)\n",
    "\n",
    "        similarities = {}\n",
    "        for case in case_base:\n",
    "            problem_numeric = np.array(case.problem, dtype=float)\n",
    "            state_numeric = np.array(state, dtype=float)\n",
    "            \n",
    "            # print(f\"state received = {state_numeric}\")\n",
    "            # print(f\"case received = {problem_numeric}\")\n",
    "            # print(\"---------\")\n",
    "           \n",
    "            similarities[case] = Case.sim_q(state_numeric, problem_numeric)  # Compare state with the problem part of the case\n",
    "\n",
    "        sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if sorted_similarities:\n",
    "            most_similar_case = sorted_similarities[0][0] if sorted_similarities[0][1] >= threshold else None\n",
    "        else:\n",
    "            most_similar_case = None\n",
    "\n",
    "        return most_similar_case\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def reuse(c, temporary_case_base):\n",
    "        temporary_case_base.append(c)\n",
    "\n",
    "    @staticmethod\n",
    "    def revise(case_base, temporary_case_base, successfull_task):\n",
    "        for case in temporary_case_base:\n",
    "            if successfull_task and case in case_base:\n",
    "                case.trust_value += 0.1  # Increment trust value if the episode ended successfully and the case is in the case base\n",
    "            elif not successfull_task and case in case_base:\n",
    "                case.trust_value -= 0.1  # Decrement trust value if the episode ended unsuccessfully and the case is in the case base\n",
    "            case.trust_value = max(0, min(case.trust_value, 1))  # Ensure trust value is within [0, 1]\n",
    "\n",
    "    @staticmethod\n",
    "    def retain(case_base, temporary_case_base, successfull_task, threshold=0.7):\n",
    "        if successfull_task:\n",
    "            # Iterate through the temporary case base to find the last occurrence of each unique state\n",
    "            for case in reversed(temporary_case_base):\n",
    "                state = tuple(np.atleast_1d(case.problem))\n",
    "                # Check if the state is already in the case base or has been added previously\n",
    "                if state not in Case.added_states:\n",
    "                    # Add the case to the case base if the state is new\n",
    "                    case_base.append(case)\n",
    "                    Case.added_states.add(state)\n",
    "                else:\n",
    "                    # Find the index of the existing case in the case base\n",
    "                    existing_index = next((i for i, c in enumerate(case_base) if tuple(np.atleast_1d(c.problem)) == state), None)\n",
    "                    if existing_index is not None:\n",
    "                        # Get the existing case from the case base\n",
    "                        existing_case = case_base[existing_index]\n",
    "                        # Update the trust value of the existing case with the new value from the revise step\n",
    "                        existing_case.trust_value = case.trust_value\n",
    "\n",
    "        # Filter case_base based on trust_value\n",
    "        case_base = [case for case in case_base if case.trust_value >= threshold]\n",
    "        return case_base\n",
    "\n",
    "\n",
    "class QCBRLVmasRunner:\n",
    "    def __init__(\n",
    "        self,\n",
    "        render: bool,\n",
    "        num_envs: int,\n",
    "        num_episodes: int,\n",
    "        max_steps_per_episode: int,\n",
    "        device: str,\n",
    "        scenario: Union[str, BaseScenario],\n",
    "        continuous_actions: bool,\n",
    "        random_action: bool,\n",
    "        n_agents: int,\n",
    "        obs_discrete: bool = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.render = render\n",
    "        self.num_envs = num_envs\n",
    "        self.num_episodes = num_episodes\n",
    "        self.max_steps_per_episode = max_steps_per_episode\n",
    "        self.device = device\n",
    "        self.scenario = scenario\n",
    "        self.continuous_actions = continuous_actions\n",
    "        self.random_action = random_action\n",
    "        self.obs_discrete = obs_discrete\n",
    "        self.kwargs = kwargs\n",
    "        self.frame_list = []  \n",
    "        self.problem_solver_agents = []\n",
    "        self.rewards_history = []  \n",
    "        self.action_counts = {i: {} for i in range(n_agents)}  \n",
    "        self.agent_rewards_history = {i: [] for i in range(n_agents)}\n",
    "        self.successful_episodes_individual = {i: 0 for i in range(n_agents)}  # Track successful episodes for each agent\n",
    "        self.successful_episodes_all_agents = 0  # Track episodes where all agents succeed\n",
    "        self.case_base = {i: [] for i in range(n_agents)}  # Separate case base for each agent\n",
    "        self.temporary_case_base = {i: [] for i in range(n_agents)}  # Separate temporary case base for each agent\n",
    "\n",
    "    def discretize(self, data, bins):\n",
    "        bins = np.array(bins)\n",
    "        if np.isscalar(data):\n",
    "            data = np.array([data])\n",
    "        bin_indices = np.digitize(data, bins) - 1  # np.digitize returns indices starting from 1\n",
    "        bin_indices = np.clip(bin_indices, 0, len(bins) - 1)  # Ensure indices are within the valid range\n",
    "        bin_values = bins[bin_indices]\n",
    "        bin_values = np.round(bin_values, 4)  \n",
    "        return bin_indices, bin_values\n",
    "\n",
    "    def discretize_tensor_slice(self, tensor_slice, bins):\n",
    "        tensor_np = tensor_slice.cpu().numpy()  # Convert to numpy for easier handling\n",
    "        indices, values = self.discretize(tensor_np, bins)\n",
    "        indices = torch.tensor(indices, device=tensor_slice.device)\n",
    "        values = torch.tensor(values, device=tensor_slice.device)\n",
    "        return indices, values\n",
    "\n",
    "    def _get_deterministic_obs(self, env, observation):\n",
    "        pos_bins = np.linspace(-1, 1, num=50)\n",
    "        vel_bins = np.linspace(0, 0, num=50)\n",
    "        lidar_bins = np.linspace(0, 1, num=50)\n",
    "\n",
    "        pos = observation[0:2]\n",
    "        vel = observation[2:4]\n",
    "        goal_pose = observation[4:6]\n",
    "        comms_data = observation[6:13]\n",
    "        sensor_data = observation[13:]\n",
    "\n",
    "        discrete_pos_indices, discrete_pos_values = self.discretize_tensor_slice(pos, pos_bins)\n",
    "        discrete_vel_indices, discrete_vel_values = self.discretize_tensor_slice(vel, vel_bins)\n",
    "        discrete_goal_pose_indices, discrete_goal_pose_values = self.discretize_tensor_slice(goal_pose, pos_bins)\n",
    "        discrete_sensor_data_indices, discrete_sensor_data_values = self.discretize_tensor_slice(sensor_data, lidar_bins)\n",
    "\n",
    "        concatenated_tensor_values = torch.cat(\n",
    "            [discrete_pos_values, discrete_vel_values, discrete_goal_pose_values, comms_data, discrete_sensor_data_values],\n",
    "            dim=0\n",
    "        )\n",
    "\n",
    "        return concatenated_tensor_values\n",
    "\n",
    "    def _get_deterministic_action(self, agent: Agent, env, agent_id, agent_obs):\n",
    "        if self.continuous_actions:\n",
    "            if agent.silent:\n",
    "                action = torch.tensor([[-1, 0.5]], device=env.device)\n",
    "            else:\n",
    "                if agent_id == 0:\n",
    "                    action = torch.tensor([[-1, 0.5, 2]], device=env.device)\n",
    "                else:\n",
    "                    action = torch.tensor([[-1, 0.5, 1]], device=env.device)\n",
    "        else:\n",
    "            physical_obs = agent_obs[0:6]\n",
    "\n",
    "            if not agent.silent:\n",
    "                comm_obs = agent_obs[6:]\n",
    "            \n",
    "            physical_action = self.problem_solver_agents[agent_id].get_action(agent, env, agent_id, physical_obs)\n",
    "            physical_action_tensor = torch.tensor(physical_action, device=self.device)\n",
    "\n",
    "            if agent.silent:\n",
    "                action = physical_action_tensor\n",
    "            else:\n",
    "                physical_obs_tensor = torch.tensor(physical_obs, device=self.device)\n",
    "                comm_action_tensor = torch.cat([physical_obs_tensor, physical_action_tensor], dim=0) \n",
    "\n",
    "                zero_tensor = torch.zeros(6, dtype=torch.float64, device=self.device)\n",
    "                first_row = torch.cat((physical_action_tensor, zero_tensor))\n",
    "                action = torch.stack((first_row, comm_action_tensor)).unsqueeze(0)\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "    def save_case_base(self, agent_id):\n",
    "        filename = f\"case_base_{agent_id}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.case_base[agent_id]:\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.tolist() if case.solution.numel() > 1 else int(case.solution.item())\n",
    "            else:\n",
    "                solution = int(case.solution)\n",
    "            \n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Case base saved successfully.\")\n",
    "\n",
    "    def save_case_base_eps(self, agent_id, eps):\n",
    "        filename = f\"case_base_{agent_id}_{eps}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.case_base[agent_id]:\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.tolist() if case.solution.numel() > 1 else int(case.solution.item())\n",
    "            else:\n",
    "                solution = int(case.solution)\n",
    "            \n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Case base saved successfully.\")\n",
    "\n",
    "\n",
    "    def save_case_base_temporary(self, agent_id,):\n",
    "        filename = f\"case_base_temporary_{agent_id}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.temporary_case_base[agent_id]:\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.tolist() if case.solution.numel() > 1 else int(case.solution.item())\n",
    "            else:\n",
    "                solution = int(case.solution)\n",
    "            \n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Temporary case base saved successfully.\")\n",
    "\n",
    "    def save_case_base_temporary_eps(self, agent_id, eps):\n",
    "        filename = f\"case_base_temporary_{agent_id}_{eps}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.temporary_case_base[agent_id]:\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.tolist() if case.solution.numel() > 1 else int(case.solution.item())\n",
    "            else:\n",
    "                solution = int(case.solution)\n",
    "            \n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Temporary case base saved successfully.\")\n",
    "\n",
    "        \n",
    "    def load_case_base(self, agent_id):\n",
    "        filename = f\"case_base_{agent_id}.json\"\n",
    "        try:\n",
    "            with open(filename, 'r') as file:\n",
    "                case_base_data = json.load(file)\n",
    "            self.case_base[agent_id] = [Case(problem=np.array(case[\"problem\"]) if isinstance(case[\"problem\"], list) else case[\"problem\"],\n",
    "                                            solution=case[\"solution\"],\n",
    "                                            trust_value=case[\"trust_value\"]) for case in case_base_data]\n",
    "        except FileNotFoundError:\n",
    "            self.case_base[agent_id] = []\n",
    "\n",
    "\n",
    "    def generate_gif(self, scenario_name):\n",
    "        fps = 25\n",
    "        clip = ImageSequenceClip(self.frame_list, fps=fps)\n",
    "        clip.write_gif(f'{scenario_name}.gif', fps=fps)\n",
    "        return HTML(f'<img src=\"{scenario_name}.gif\">')\n",
    "\n",
    "    def plot_action_distribution(self):\n",
    "        num_agents = len(self.action_counts)\n",
    "\n",
    "        for agent_id, counts in self.action_counts.items():\n",
    "            unique_actions, action_counts = np.unique(list(counts.values()), return_counts=True)\n",
    "            action_dict = dict(zip(unique_actions, action_counts))\n",
    "            plt.bar(action_dict.keys(), action_dict.values(), label=f'Agent {agent_id}', alpha=0.7)\n",
    "\n",
    "        plt.xlabel('Action')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Action Distribution for Each Agent')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_rewards_history(self):\n",
    "        num_agents = len(self.agent_rewards_history)\n",
    "\n",
    "        for agent_id, rewards in self.agent_rewards_history.items():\n",
    "            plt.plot(range(1, self.num_episodes + 1), rewards, label=f'Agent {agent_id}')\n",
    "\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.title('Total Reward per Episode for Each Agent')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def run_vmas_env(self):\n",
    "        scenario_name = self.scenario if isinstance(self.scenario, str) else self.scenario.__class__.__name__\n",
    "\n",
    "        env = make_env(\n",
    "            scenario=self.scenario,\n",
    "            num_envs=self.num_envs,\n",
    "            device=self.device,\n",
    "            continuous_actions=self.continuous_actions,\n",
    "            **self.kwargs\n",
    "        )\n",
    "        \n",
    "        for agent_id, agent in enumerate(env.agents):\n",
    "            self.problem_solver_agents.append(ProblemSolver(env, agent_id, communication_weight=0.5))\n",
    "\n",
    "        init_time = time.time()\n",
    "        total_steps = 0\n",
    "        is_episode_success = False\n",
    "\n",
    "        for episode in range(self.num_episodes):\n",
    "            print(f\"Episode {episode}\")\n",
    "            obs_cont = env.reset()\n",
    "\n",
    "            done = torch.tensor([False] * self.num_envs, device=self.device)\n",
    "            step = 0\n",
    "            \n",
    "            episode_rewards = {i: 0 for i in range(len(self.problem_solver_agents))}\n",
    "            episode_done_counts = {i: 0 for i in range(len(env.agents))}  # Track done counts for each agent\n",
    "            \n",
    "            self.temporary_case_base = {i: [] for i in range(len(env.agents))}\n",
    "            \n",
    "            while not torch.all(done).item() and step < self.max_steps_per_episode:\n",
    "                step += 1\n",
    "                total_steps += 1\n",
    "                print(f\"Step {step} of Episode {episode}\")\n",
    "\n",
    "                actions = []\n",
    "               \n",
    "\n",
    "                for i, agent in enumerate(env.agents):\n",
    "                    if self.obs_discrete:\n",
    "                        discrete_obs = self._get_deterministic_obs(env, obs_cont[i])\n",
    "                        \n",
    "                    # print(f\"observation continuous agent{i} = {obs_cont[i]}\")\n",
    "                    # print(f\"observation discrete agent{i} = {discrete_obs}\")\n",
    "\n",
    "                    case = Case.retrieve(agent, env, discrete_obs[0:6], self.case_base[i], threshold=0.1)\n",
    "                    \n",
    "                    if case:\n",
    "                        action = case.solution\n",
    "                        Case.reuse(case, self.temporary_case_base[i])\n",
    "                        print(f\"action type of agent {i}: case base\")\n",
    "                    else:\n",
    "                        if self.random_action:\n",
    "                            action = env.get_random_action(agent)\n",
    "                        else:\n",
    "                            action = self._get_deterministic_action(agent, env, i, discrete_obs)\n",
    "                        print(f\"action type of agent {i}: problem solver\")\n",
    "\n",
    "                    problem = discrete_obs[0:6].cpu().numpy().tolist()\n",
    "                    new_case = Case(problem, action)\n",
    "                    self.temporary_case_base[i].append(new_case)\n",
    "\n",
    "                    actions.append(action)\n",
    "                \n",
    "                next_obs_cont, rews, dones, info = env.step(actions)\n",
    "                # print(f\"next obs all agents = {next_obs_cont}\")\n",
    "                # print(f\"reward all agents = {rews}\")\n",
    "                \n",
    "                done = dones\n",
    "                # print(f\"dones status for all agents = {done}\")\n",
    "                # print(\"--------------------\")\n",
    "\n",
    "                for i, agent in enumerate(env.agents):\n",
    "                    if self.obs_discrete:\n",
    "                        discrete_obs = self._get_deterministic_obs(env, obs_cont[i])\n",
    "                        discrete_next_obs = self._get_deterministic_obs(env, next_obs_cont[i])\n",
    "                        \n",
    "                    physical_obs_for_update = discrete_obs[0:6]\n",
    "                    physical_nextobs_for_update = discrete_next_obs[0:6]\n",
    "                    physical_actions_for_update = actions[i][0, 0, 0].unsqueeze(0)\n",
    "\n",
    "                    self.problem_solver_agents[i].update_q_table(agent, env, i,\n",
    "                        physical_obs_for_update, physical_actions_for_update, rews[i].item(), physical_nextobs_for_update\n",
    "                    )\n",
    "                    # Accumulate rewards for each agent within the episode\n",
    "                    episode_rewards[i] += rews[i].item()\n",
    "\n",
    "                    if (done[0][i]):  # Increment individual agent's done count\n",
    "                        episode_done_counts[i] += 1\n",
    "\n",
    "                obs_cont = next_obs_cont\n",
    "\n",
    "                if self.render:\n",
    "                    frame = env.render(\n",
    "                        mode=\"rgb_array\",\n",
    "                        agent_index_focus=None,\n",
    "                    )\n",
    "                    self.frame_list.append(frame)\n",
    "\n",
    "                # print(\"-----------------\")\n",
    "            # Update rewards history after each episode\n",
    "            for agent_id, total_reward in episode_rewards.items():\n",
    "                self.agent_rewards_history[agent_id].append(total_reward)\n",
    "\n",
    "            # Update success based on individual agent's done status\n",
    "            for agent_id in range(len(env.agents)):\n",
    "                print(f\"done status for agent {agent_id}: {done[0][agent_id]}\")\n",
    "                # print(f\"done status for agent {agent_id} v2: {done[0, agent_id]}\")\n",
    "                if done[0,agent_id]:\n",
    "                    self.successful_episodes_individual[agent_id] += episode_done_counts[agent_id] / step  # Calculate success rate for the agent\n",
    "\n",
    "            # Update success based on all agents' done status\n",
    "            if torch.all(done).item():\n",
    "                self.successful_episodes_all_agents += 1\n",
    "            \n",
    "            # Calculate success percentages for each agent\n",
    "            success_percents = [self.successful_episodes_individual[i] / (episode + 1) * 100 for i in range(len(env.agents))]\n",
    "            overall_success_percent = self.successful_episodes_all_agents / (episode + 1) * 100\n",
    "\n",
    "            print(f\"Success percentage of each agent at the end of episode {episode}:\")\n",
    "            \n",
    "            for i, percent in enumerate(success_percents):\n",
    "                print(f\"Agent {i}: {percent}%\")\n",
    "\n",
    "            print(f\"Overall success percentage for all agents up to episode {episode}: {overall_success_percent}%\")\n",
    "\n",
    "\n",
    "            for i in range(len(env.agents)):\n",
    "                print(f\"done status for agent {i}: {done[0][i]}\")\n",
    "                \n",
    "                # Case.revise(self.case_base[i], self.temporary_case_base[i], torch.any(done).item())\n",
    "                # self.case_base[i] = Case.retain(\n",
    "                #     self.case_base[i], self.temporary_case_base[i], torch.any(done).item()\n",
    "                # )\n",
    "\n",
    "                Case.revise(self.case_base[i], self.temporary_case_base[i], done[0][i])\n",
    "                self.case_base[i] = Case.retain(\n",
    "                    self.case_base[i], self.temporary_case_base[i], done[0][i]\n",
    "                )\n",
    "\n",
    "                # for case in self.temporary_case_base[i]:\n",
    "                #     print(f\"Step {step} -- Problem Stored in Temp CB: {case.problem}, Solution Stored in Temp CB: {case.solution}\")\n",
    "\n",
    "                # for case in self.case_base[i]:\n",
    "                #     print(f\"Step {step} -- Problem Stored in CB: {case.problem}, Solution Stored in CB: {case.solution}\")\n",
    "\n",
    "                self.save_case_base_temporary_eps(i, episode)  # Save temporary case base after each episode\n",
    "                self.save_case_base_eps(i, episode)  # Save case base after each episode\n",
    "            \n",
    "            torch.cuda.empty_cache()  # Free up unused memory\n",
    "\n",
    "        \n",
    "        for agent_id, agent in enumerate(env.agents):\n",
    "            self.save_case_base_temporary(agent_id)  # Save temporary case base after training\n",
    "            self.save_case_base(agent_id)  # Save case base after training\n",
    "\n",
    "        # Print final success percentages for each agent-0.9, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
    "        \n",
    "        # Print overall success percentage for all agents\n",
    "        overall_success_percentage = self.successful_episodes_all_agents / self.num_episodes * 100\n",
    "        print(f\"Overall success percentage for all agents = {overall_success_percentage}%\")\n",
    "\n",
    "\n",
    "\n",
    "        total_time = time.time() - init_time\n",
    "        print(\n",
    "            f\"It took: {total_time}s for {total_steps} steps across {self.num_episodes} episodes of {self.num_envs} parallel environments on device {self.device} \"\n",
    "            f\"for {scenario_name} scenario.\"\n",
    "        )\n",
    "\n",
    "        # success_percentage = (self.successful_episodes / self.num_episodes) * 100\n",
    "        # print(f\"Percentage of successful episodes: {success_percentage}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scenario_name = \"navigation_comm\"\n",
    "    use_cuda = True\n",
    "\n",
    "    env_runner = QCBRLVmasRunner( \n",
    "        render=True,\n",
    "        num_envs=1,\n",
    "        num_episodes=3,\n",
    "        max_steps_per_episode=2000,\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\"),\n",
    "        scenario=scenario_name,\n",
    "        continuous_actions=False,\n",
    "        random_action=False,\n",
    "        n_agents=2,\n",
    "        obs_discrete=True,\n",
    "        agents_with_same_goal=2,\n",
    "        collisions=False,\n",
    "        shared_rew=False,\n",
    "    )\n",
    "\n",
    "    env_runner.run_vmas_env()\n",
    "    # for agent in env_runner.problem_solver_agents:\n",
    "    #     agent.print_q_table()\n",
    "    env_runner.plot_rewards_history()\n",
    "\n",
    "    # ipython_display(env_runner.generate_gif(scenario_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
