{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "Step 1 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.0, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.0, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 2 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 8, reward -0.0031458139419555664, next_obs (-0.9, 0.9, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.0, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 3 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 0, reward -0.0031991004943847656, next_obs (-0.9, 0.9, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.0, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 4 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.004241228103637695, next_obs (-0.9, 0.9, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.0, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 5 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.011517524719238281, next_obs (-0.9, 0.9, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.0, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 6 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.010304689407348633, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.0066252946853637695, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 7 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.0143890380859375, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.01323080062866211, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 8 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.01909351348876953, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.018149375915527344, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 9 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.022583484649658203, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.021793246269226074, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 10 of Episode 0\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.02515435218811035, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.024476051330566406, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "done status for agent 0: False\n",
      "done status for agent 1: False\n",
      "Success percentage of each agent at the end of episode 0:\n",
      "Agent 0: 0.0%\n",
      "Agent 1: 0.0%\n",
      "Overall success percentage for all agents up to episode 0: 0.0%\n",
      "done status for agent 0: False\n",
      "done status for agent 1: False\n",
      "Episode 1\n",
      "Step 1 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.0066252946853637695, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 5, reward -0.0031458139419555664, next_obs (0.8, 0.9, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 2 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.01323080062866211, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.9, 0.0, 0.0, 0.0, -0.9), action 0, reward -0.0031991004943847656, next_obs (0.8, 0.9, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 3 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 5, reward 0.0013884305953979492, next_obs (-1.0, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.9, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.004241228103637695, next_obs (0.8, 0.9, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 4 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.00503993034362793, next_obs (-1.0, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.9, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.011517524719238281, next_obs (0.8, 0.9, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 5 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.011922478675842285, next_obs (-1.0, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.9, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.016968607902526855, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 6 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.017033696174621582, next_obs (-1.0, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.021029114723205566, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 7 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.020813822746276855, next_obs (-1.0, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.024035215377807617, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 8 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.017137885093688965, next_obs (-1.0, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 4, reward 0.029790401458740234, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 9 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.019228696823120117, next_obs (-1.0, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.03147327899932861, next_obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 10 of Episode 1\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.02235889434814453, next_obs (-1.0, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.025232315063476562, next_obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "done status for agent 0: False\n",
      "done status for agent 1: False\n",
      "Success percentage of each agent at the end of episode 1:\n",
      "Agent 0: 0.0%\n",
      "Agent 1: 0.0%\n",
      "Overall success percentage for all agents up to episode 1: 0.0%\n",
      "done status for agent 0: False\n",
      "done status for agent 1: False\n",
      "Episode 2\n",
      "Step 1 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.0066252946853637695, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.0066252946853637695, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 2 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.01323080062866211, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.01323080062866211, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 3 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.018149375915527344, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.018149375915527344, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 4 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.021793246269226074, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.021793246269226074, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 5 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.024476051330566406, next_obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.024476051330566406, next_obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 6 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.02643418312072754, next_obs (-0.9, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.02643418312072754, next_obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 7 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.027846097946166992, next_obs (-0.9, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.021365046501159668, next_obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 8 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.028844833374023438, next_obs (-0.9, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.015967845916748047, next_obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 9 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.02953159809112549, next_obs (-0.9, 0.6, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9), action 0, reward 0.011943340301513672, next_obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "Step 10 of Episode 2\n",
      "action type of agent 0: problem solver\n",
      "action type of agent 1: problem solver\n",
      "Agent 0 - Updated Q-table for obs (-0.9, 0.8, 0.0, 0.0, 0.0, -0.9), action 1, reward 0.029980778694152832, next_obs (-0.9, 0.6, 0.0, 0.0, 0.0, -0.9)\n",
      "Agent 1 - Updated Q-table for obs (0.8, 0.7, 0.0, 0.0, 0.0, -0.9), action 8, reward -0.0013481378555297852, next_obs (0.9, 0.7, 0.0, 0.0, 0.0, -0.9)\n",
      "done status for agent 0: False\n",
      "done status for agent 1: False\n",
      "Success percentage of each agent at the end of episode 2:\n",
      "Agent 0: 0.0%\n",
      "Agent 1: 0.0%\n",
      "Overall success percentage for all agents up to episode 2: 0.0%\n",
      "done status for agent 0: False\n",
      "done status for agent 1: False\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "Temporary case base saved successfully.\n",
      "Case base saved successfully.\n",
      "Success percentage for agent 0 = 0.0%\n",
      "Success percentage for agent 1 = 0.0%\n",
      "Overall success percentage for all agents = 0.0%\n",
      "It took: 0.3104367256164551s for 30 steps across 3 episodes of 1 parallel environments on device cuda for navigation_comm scenario.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import ast\n",
    "from vmas import make_env\n",
    "from vmas.simulator.core import Agent\n",
    "from vmas.simulator.scenario import BaseScenario\n",
    "from typing import Union\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from IPython.display import HTML, display as ipython_display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.spaces import Discrete \n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, env, agent_id, alpha=0.1, gamma=0.99, epsilon=0.2, communication_weight=0.5):\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.q_table = {}\n",
    "        self.env = env\n",
    "        self.agent_id = agent_id\n",
    "        self.communication_weight = communication_weight  # Weight parameter for incorporating messages\n",
    "\n",
    "    def get_action(self, agent, env, agent_id, agent_obs):\n",
    "        agent_obs_cpu = agent_obs[:6].cpu().numpy()  # Transfer only the required slice to CPU\n",
    "        agent_obs = tuple(np.round(agent_obs_cpu, decimals=5))  # Round the observation\n",
    "\n",
    "        if agent_obs not in self.q_table:\n",
    "            self.q_table[agent_obs] = np.zeros(self.env.action_space[self.agent_id].n)\n",
    "\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Select a random action\n",
    "            action = np.random.randint(env.action_space[self.agent_id].n)\n",
    "        else:\n",
    "            # Select the action with the highest Q-value\n",
    "            action = np.argmax(self.q_table[agent_obs])\n",
    "        \n",
    "        return (action,)  # Return as a tuple\n",
    "\n",
    "    def update_q_table(self,  agent, env, agent_id, obs, action, reward, next_obs):\n",
    "        obs_key = tuple(np.round(obs.cpu().numpy(), decimals=5))  # Only transfer to CPU when necessary\n",
    "        next_obs_key = tuple(np.round(next_obs.cpu().numpy(), decimals=5))\n",
    "        action = int(action.item())  # Convert tensor to Python scalar\n",
    "\n",
    "        # print (f\"reward obtained = {reward}\")\n",
    "\n",
    "        if isinstance(self.env.action_space[self.agent_id], Discrete):\n",
    "            action_space_size = self.env.action_space[self.agent_id].n\n",
    "        else:\n",
    "            raise ValueError(\"This Q-learning implementation requires a discrete action space.\")\n",
    "\n",
    "        if obs_key not in self.q_table:\n",
    "            self.q_table[obs_key] = np.zeros(action_space_size)\n",
    "\n",
    "        if next_obs_key not in self.q_table:\n",
    "            self.q_table[next_obs_key] = np.zeros(action_space_size)\n",
    "\n",
    "        best_next_action = np.argmax(self.q_table[next_obs_key])\n",
    "        td_target = reward + self.gamma * self.q_table[next_obs_key][best_next_action]\n",
    "\n",
    "        td_error = td_target - self.q_table[obs_key][action]\n",
    "        self.q_table[obs_key][action] += self.alpha * td_error\n",
    "\n",
    "        print(f\"Agent {self.agent_id} - Updated Q-table for obs {obs_key}, action {action}, reward {reward}, next_obs {next_obs_key}\")\n",
    "\n",
    "    \n",
    "    def print_q_table(self):\n",
    "        print(f\"Q-table for Agent {self.agent_id}:\")\n",
    "        for state, actions in self.q_table.items():\n",
    "            print(f\"  State: {state}\")\n",
    "            for action, q_value in enumerate(actions):\n",
    "                print(f\"    Action: {action}, Q-value: {q_value:.5f}\")\n",
    "        print(f\"End of Q-table for Agent {self.agent_id}\\n\")\n",
    "\n",
    "class Case:\n",
    "    added_states = set()  # Class attribute to store states already added to the case base\n",
    "\n",
    "    def __init__(self, problem, solution, trust_value=1):\n",
    "        self.problem = problem if isinstance(problem, list) else ast.literal_eval(problem)  # Convert problem to numpy array\n",
    "        self.solution = solution\n",
    "        self.trust_value = trust_value\n",
    "    \n",
    "    @staticmethod\n",
    "    def sim_q(state1, state2):\n",
    "        state1 = np.atleast_1d(state1)\n",
    "        state2 = np.atleast_1d(state2)\n",
    "        CNDMaxDist = 6  # Maximum distance between two nodes in the CND based on EOPRA reference\n",
    "        v = state1.size  # Total number of objects the agent can perceive\n",
    "        DistQ = np.sum([Case.dist_q(Objic, Objip) for Objic, Objip in zip(state1, state2)])\n",
    "        similarity = (CNDMaxDist * v - DistQ) / (CNDMaxDist * v)\n",
    "        return similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def dist_q(X1, X2):\n",
    "        return np.min(np.abs(X1 - X2))\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(agent, env, state, case_base, threshold=0.1):\n",
    "\n",
    "        # Convert the state to numpy if it's a tensor\n",
    "        if isinstance(state, torch.Tensor):\n",
    "            state = state.cpu().numpy()\n",
    "\n",
    "        # Slice the physical observations\n",
    "        physical_obs = state[:6]\n",
    "\n",
    "        if not agent.silent:\n",
    "            comm_obs = state[6:]\n",
    "            # Convert comm_obs to a numpy array if it is a tensor\n",
    "            if isinstance(comm_obs, torch.Tensor):\n",
    "                comm_obs = comm_obs.cpu().numpy()\n",
    "\n",
    "        # print(f\"physical_obs = {physical_obs}\")\n",
    "\n",
    "        # Ensure the state is in a list format to avoid issues with ast.literal_eval\n",
    "        state_list = state.tolist() if isinstance(state, np.ndarray) else state\n",
    "        state_str = json.dumps(state_list)  # Convert list to a JSON string for ast.literal_eval\n",
    "\n",
    "        # Use ast.literal_eval safely to convert the string back to a list\n",
    "        state = ast.literal_eval(state_str)\n",
    "\n",
    "        similarities = {}\n",
    "        for case in case_base:\n",
    "            problem_numeric = np.array(case.problem, dtype=float)\n",
    "            state_numeric = np.array(state, dtype=float)\n",
    "            \n",
    "            # print(f\"state received = {state_numeric}\")\n",
    "            # print(f\"case received = {problem_numeric}\")\n",
    "            # print(\"---------\")\n",
    "           \n",
    "            similarities[case] = Case.sim_q(state_numeric, problem_numeric)  # Compare state with the problem part of the case\n",
    "\n",
    "        sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if sorted_similarities:\n",
    "            most_similar_case = sorted_similarities[0][0] if sorted_similarities[0][1] >= threshold else None\n",
    "        else:\n",
    "            most_similar_case = None\n",
    "\n",
    "        return most_similar_case\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def reuse(c, temporary_case_base):\n",
    "        temporary_case_base.append(c)\n",
    "\n",
    "    @staticmethod\n",
    "    def revise(case_base, temporary_case_base, successfull_task):\n",
    "        for case in temporary_case_base:\n",
    "            if successfull_task and case in case_base:\n",
    "                case.trust_value += 0.1  # Increment trust value if the episode ended successfully and the case is in the case base\n",
    "            elif not successfull_task and case in case_base:\n",
    "                case.trust_value -= 0.1  # Decrement trust value if the episode ended unsuccessfully and the case is in the case base\n",
    "            case.trust_value = max(0, min(case.trust_value, 1))  # Ensure trust value is within [0, 1]\n",
    "\n",
    "    @staticmethod\n",
    "    def retain(case_base, temporary_case_base, successfull_task, threshold=0.7):\n",
    "        if successfull_task:\n",
    "            # Iterate through the temporary case base to find the last occurrence of each unique state\n",
    "            for case in reversed(temporary_case_base):\n",
    "                state = tuple(np.atleast_1d(case.problem))\n",
    "                # Check if the state is already in the case base or has been added previously\n",
    "                if state not in Case.added_states:\n",
    "                    # Add the case to the case base if the state is new\n",
    "                    case_base.append(case)\n",
    "                    Case.added_states.add(state)\n",
    "                else:\n",
    "                    # Find the index of the existing case in the case base\n",
    "                    existing_index = next((i for i, c in enumerate(case_base) if tuple(np.atleast_1d(c.problem)) == state), None)\n",
    "                    if existing_index is not None:\n",
    "                        # Get the existing case from the case base\n",
    "                        existing_case = case_base[existing_index]\n",
    "                        # Update the trust value of the existing case with the new value from the revise step\n",
    "                        existing_case.trust_value = case.trust_value\n",
    "\n",
    "        # Filter case_base based on trust_value\n",
    "        case_base = [case for case in case_base if case.trust_value >= threshold]\n",
    "        return case_base\n",
    "\n",
    "\n",
    "class QCBRLVmasRunner:\n",
    "    def __init__(\n",
    "        self,\n",
    "        render: bool,\n",
    "        num_envs: int,\n",
    "        num_episodes: int,\n",
    "        max_steps_per_episode: int,\n",
    "        device: str,\n",
    "        scenario: Union[str, BaseScenario],\n",
    "        continuous_actions: bool,\n",
    "        random_action: bool,\n",
    "        n_agents: int,\n",
    "        obs_discrete: bool = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.render = render\n",
    "        self.num_envs = num_envs\n",
    "        self.num_episodes = num_episodes\n",
    "        self.max_steps_per_episode = max_steps_per_episode\n",
    "        self.device = device\n",
    "        self.scenario = scenario\n",
    "        self.continuous_actions = continuous_actions\n",
    "        self.random_action = random_action\n",
    "        self.obs_discrete = obs_discrete\n",
    "        self.kwargs = kwargs\n",
    "        self.frame_list = []  \n",
    "        self.problem_solver_agents = []\n",
    "        self.rewards_history = []  \n",
    "        self.action_counts = {i: {} for i in range(n_agents)}  \n",
    "        self.agent_rewards_history = {i: [] for i in range(n_agents)}\n",
    "        self.successful_episodes_individual = {i: 0 for i in range(n_agents)}  # Track successful episodes for each agent\n",
    "        self.successful_episodes_all_agents = 0  # Track episodes where all agents succeed\n",
    "        self.case_base = {i: [] for i in range(n_agents)}  # Separate case base for each agent\n",
    "        self.temporary_case_base = {i: [] for i in range(n_agents)}  # Separate temporary case base for each agent\n",
    "\n",
    "    def discretize(self, data, bins):\n",
    "        bins = np.array(bins)\n",
    "        if np.isscalar(data):\n",
    "            data = np.array([data])\n",
    "        bin_indices = np.digitize(data, bins) - 1  # np.digitize returns indices starting from 1\n",
    "        bin_indices = np.clip(bin_indices, 0, len(bins) - 1)  # Ensure indices are within the valid range\n",
    "        bin_values = bins[bin_indices]\n",
    "        bin_values = np.round(bin_values, 2)  # Round the bin values to two decimal places\n",
    "        return bin_indices, bin_values\n",
    "\n",
    "    def discretize_tensor_slice(self, tensor_slice, bins):\n",
    "        tensor_np = tensor_slice.cpu().numpy()  # Convert to numpy for easier handling\n",
    "        indices, values = self.discretize(tensor_np, bins)\n",
    "        indices = torch.tensor(indices, device=tensor_slice.device)\n",
    "        values = torch.tensor(values, device=tensor_slice.device)\n",
    "        return indices, values\n",
    "\n",
    "    def _get_deterministic_obs(self, env, observation):\n",
    "        pos_bins = np.linspace(-1, 1, num=21)\n",
    "        vel_bins = np.linspace(0, 0, num=21)\n",
    "        lidar_bins = np.linspace(0, 1, num=11)\n",
    "\n",
    "        pos = observation[0:2]\n",
    "        vel = observation[2:4]\n",
    "        goal_pose = observation[4:6]\n",
    "        comms_data = observation[6:13]\n",
    "        sensor_data = observation[13:]\n",
    "\n",
    "        discrete_pos_indices, discrete_pos_values = self.discretize_tensor_slice(pos, pos_bins)\n",
    "        discrete_vel_indices, discrete_vel_values = self.discretize_tensor_slice(vel, vel_bins)\n",
    "        discrete_goal_pose_indices, discrete_goal_pose_values = self.discretize_tensor_slice(goal_pose, pos_bins)\n",
    "        discrete_sensor_data_indices, discrete_sensor_data_values = self.discretize_tensor_slice(sensor_data, lidar_bins)\n",
    "\n",
    "        concatenated_tensor_values = torch.cat(\n",
    "            [discrete_pos_values, discrete_vel_values, discrete_goal_pose_values, comms_data, discrete_sensor_data_values],\n",
    "            dim=0\n",
    "        )\n",
    "\n",
    "        return concatenated_tensor_values\n",
    "\n",
    "    def _get_deterministic_action(self, agent: Agent, env, agent_id, agent_obs):\n",
    "        if self.continuous_actions:\n",
    "            if agent.silent:\n",
    "                action = torch.tensor([[-1, 0.5]], device=env.device)\n",
    "            else:\n",
    "                if agent_id == 0:\n",
    "                    action = torch.tensor([[-1, 0.5, 2]], device=env.device)\n",
    "                else:\n",
    "                    action = torch.tensor([[-1, 0.5, 1]], device=env.device)\n",
    "        else:\n",
    "            physical_obs = agent_obs[0:6]\n",
    "\n",
    "            if not agent.silent:\n",
    "                comm_obs = agent_obs[6:]\n",
    "            \n",
    "            physical_action = self.problem_solver_agents[agent_id].get_action(agent, env, agent_id, physical_obs)\n",
    "            physical_action_tensor = torch.tensor(physical_action, device=self.device)\n",
    "\n",
    "            if agent.silent:\n",
    "                action = physical_action_tensor\n",
    "            else:\n",
    "                physical_obs_tensor = torch.tensor(physical_obs, device=self.device)\n",
    "                comm_action_tensor = torch.cat([physical_obs_tensor, physical_action_tensor], dim=0) \n",
    "\n",
    "                zero_tensor = torch.zeros(6, dtype=torch.float64, device=self.device)\n",
    "                first_row = torch.cat((physical_action_tensor, zero_tensor))\n",
    "                action = torch.stack((first_row, comm_action_tensor)).unsqueeze(0)\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "    def save_case_base(self, agent_id):\n",
    "        filename = f\"case_base_{agent_id}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.case_base[agent_id]:\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.tolist() if case.solution.numel() > 1 else int(case.solution.item())\n",
    "            else:\n",
    "                solution = int(case.solution)\n",
    "            \n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Case base saved successfully.\")\n",
    "\n",
    "\n",
    "    def save_case_base_temporary(self, agent_id):\n",
    "        filename = f\"case_base_temporary_{agent_id}.json\"\n",
    "        case_base_data = []\n",
    "        for case in self.temporary_case_base[agent_id]:\n",
    "            problem = case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem\n",
    "            \n",
    "            if torch.is_tensor(case.solution):\n",
    "                solution = case.solution.tolist() if case.solution.numel() > 1 else int(case.solution.item())\n",
    "            else:\n",
    "                solution = int(case.solution)\n",
    "            \n",
    "            if torch.is_tensor(case.trust_value):\n",
    "                trust_value = case.trust_value.tolist() if case.trust_value.numel() > 1 else float(case.trust_value.item())\n",
    "            else:\n",
    "                trust_value = float(case.trust_value)\n",
    "            \n",
    "            case_base_data.append({\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"trust_value\": trust_value\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "        print(\"Temporary case base saved successfully.\")\n",
    "\n",
    "        \n",
    "    def load_case_base(self, agent_id):\n",
    "        filename = f\"case_base_{agent_id}.json\"\n",
    "        try:\n",
    "            with open(filename, 'r') as file:\n",
    "                case_base_data = json.load(file)\n",
    "            self.case_base[agent_id] = [Case(problem=np.array(case[\"problem\"]) if isinstance(case[\"problem\"], list) else case[\"problem\"],\n",
    "                                            solution=case[\"solution\"],\n",
    "                                            trust_value=case[\"trust_value\"]) for case in case_base_data]\n",
    "        except FileNotFoundError:\n",
    "            self.case_base[agent_id] = []\n",
    "\n",
    "\n",
    "    def generate_gif(self, scenario_name):\n",
    "        fps = 25\n",
    "        clip = ImageSequenceClip(self.frame_list, fps=fps)\n",
    "        clip.write_gif(f'{scenario_name}.gif', fps=fps)\n",
    "        return HTML(f'<img src=\"{scenario_name}.gif\">')\n",
    "\n",
    "    def plot_action_distribution(self):\n",
    "        num_agents = len(self.action_counts)\n",
    "\n",
    "        for agent_id, counts in self.action_counts.items():\n",
    "            unique_actions, action_counts = np.unique(list(counts.values()), return_counts=True)\n",
    "            action_dict = dict(zip(unique_actions, action_counts))\n",
    "            plt.bar(action_dict.keys(), action_dict.values(), label=f'Agent {agent_id}', alpha=0.7)\n",
    "\n",
    "        plt.xlabel('Action')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Action Distribution for Each Agent')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_rewards_history(self):\n",
    "        num_agents = len(self.agent_rewards_history)\n",
    "\n",
    "        for agent_id, rewards in self.agent_rewards_history.items():\n",
    "            plt.plot(range(1, self.num_episodes + 1), rewards, label=f'Agent {agent_id}')\n",
    "\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.title('Total Reward per Episode for Each Agent')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def run_vmas_env(self):\n",
    "        scenario_name = self.scenario if isinstance(self.scenario, str) else self.scenario.__class__.__name__\n",
    "\n",
    "        env = make_env(\n",
    "            scenario=self.scenario,\n",
    "            num_envs=self.num_envs,\n",
    "            device=self.device,\n",
    "            continuous_actions=self.continuous_actions,\n",
    "            **self.kwargs\n",
    "        )\n",
    "        \n",
    "        for agent_id, agent in enumerate(env.agents):\n",
    "            self.problem_solver_agents.append(ProblemSolver(env, agent_id, communication_weight=0.5))\n",
    "\n",
    "        init_time = time.time()\n",
    "        total_steps = 0\n",
    "        is_episode_success = False\n",
    "\n",
    "        for episode in range(self.num_episodes):\n",
    "            print(f\"Episode {episode}\")\n",
    "            obs_cont = env.reset()\n",
    "\n",
    "            done = torch.tensor([False] * self.num_envs, device=self.device)\n",
    "            step = 0\n",
    "            \n",
    "            episode_rewards = {i: 0 for i in range(len(self.problem_solver_agents))}\n",
    "            episode_done_counts = {i: 0 for i in range(len(env.agents))}  # Track done counts for each agent\n",
    "            \n",
    "            self.temporary_case_base = {i: [] for i in range(len(env.agents))}\n",
    "            \n",
    "            while not torch.all(done).item() and step < self.max_steps_per_episode:\n",
    "                step += 1\n",
    "                total_steps += 1\n",
    "                print(f\"Step {step} of Episode {episode}\")\n",
    "\n",
    "                actions = []\n",
    "               \n",
    "\n",
    "                for i, agent in enumerate(env.agents):\n",
    "                    if self.obs_discrete:\n",
    "                        discrete_obs = self._get_deterministic_obs(env, obs_cont[i])\n",
    "                        \n",
    "                    # print(f\"observation continuous agent{i} = {obs_cont[i]}\")\n",
    "                    # print(f\"observation discrete agent{i} = {discrete_obs}\")\n",
    "\n",
    "                    case = Case.retrieve(agent, env, discrete_obs[0:6], self.case_base[i], threshold=0.1)\n",
    "                    \n",
    "                    if case:\n",
    "                        action = case.solution\n",
    "                        Case.reuse(case, self.temporary_case_base[i])\n",
    "                        print(f\"action type of agent {i}: case base\")\n",
    "                    else:\n",
    "                        if self.random_action:\n",
    "                            action = env.get_random_action(agent)\n",
    "                        else:\n",
    "                            action = self._get_deterministic_action(agent, env, i, discrete_obs)\n",
    "                        print(f\"action type of agent {i}: problem solver\")\n",
    "\n",
    "                    problem = discrete_obs[0:6].cpu().numpy().tolist()\n",
    "                    new_case = Case(problem, action)\n",
    "                    self.temporary_case_base[i].append(new_case)\n",
    "\n",
    "                    actions.append(action)\n",
    "                \n",
    "                next_obs_cont, rews, dones, info = env.step(actions)\n",
    "                # print(f\"next obs all agents = {next_obs_cont}\")\n",
    "                # print(f\"reward all agents = {rews}\")\n",
    "                \n",
    "                done = dones\n",
    "                # print(f\"dones status for all agents = {done}\")\n",
    "                # print(\"--------------------\")\n",
    "\n",
    "                for i, agent in enumerate(env.agents):\n",
    "                    if self.obs_discrete:\n",
    "                        discrete_obs = self._get_deterministic_obs(env, obs_cont[i])\n",
    "                        discrete_next_obs = self._get_deterministic_obs(env, next_obs_cont[i])\n",
    "                        \n",
    "                    physical_obs_for_update = discrete_obs[0:6]\n",
    "                    physical_nextobs_for_update = discrete_next_obs[0:6]\n",
    "                    physical_actions_for_update = actions[i][0, 0, 0].unsqueeze(0)\n",
    "\n",
    "                    self.problem_solver_agents[i].update_q_table(agent, env, i,\n",
    "                        physical_obs_for_update, physical_actions_for_update, rews[i].item(), physical_nextobs_for_update\n",
    "                    )\n",
    "                    # Accumulate rewards for each agent within the episode\n",
    "                    episode_rewards[i] += rews[i].item()\n",
    "\n",
    "                    if (done[0][i]):  # Increment individual agent's done count\n",
    "                        episode_done_counts[i] += 1\n",
    "\n",
    "                obs_cont = next_obs_cont\n",
    "\n",
    "                if self.render:\n",
    "                    frame = env.render(\n",
    "                        mode=\"rgb_array\",\n",
    "                        agent_index_focus=None,\n",
    "                    )\n",
    "                    self.frame_list.append(frame)\n",
    "\n",
    "                # print(\"-----------------\")\n",
    "            # Update rewards history after each episode\n",
    "            for agent_id, total_reward in episode_rewards.items():\n",
    "                self.agent_rewards_history[agent_id].append(total_reward)\n",
    "\n",
    "            # Update success based on individual agent's done status\n",
    "            for agent_id in range(len(env.agents)):\n",
    "                print(f\"done status for agent {agent_id}: {done[0][agent_id]}\")\n",
    "                # print(f\"done status for agent {agent_id} v2: {done[0, agent_id]}\")\n",
    "                if done[0,agent_id]:\n",
    "                    self.successful_episodes_individual[agent_id] += episode_done_counts[agent_id] / step  # Calculate success rate for the agent\n",
    "\n",
    "            # Update success based on all agents' done status\n",
    "            if torch.all(done).item():\n",
    "                self.successful_episodes_all_agents += 1\n",
    "            \n",
    "            # Calculate success percentages for each agent\n",
    "            success_percents = [self.successful_episodes_individual[i] / (episode + 1) * 100 for i in range(len(env.agents))]\n",
    "            overall_success_percent = self.successful_episodes_all_agents / (episode + 1) * 100\n",
    "\n",
    "            print(f\"Success percentage of each agent at the end of episode {episode}:\")\n",
    "            \n",
    "            for i, percent in enumerate(success_percents):\n",
    "                print(f\"Agent {i}: {percent}%\")\n",
    "\n",
    "            print(f\"Overall success percentage for all agents up to episode {episode}: {overall_success_percent}%\")\n",
    "\n",
    "\n",
    "            for i in range(len(env.agents)):\n",
    "                print(f\"done status for agent {i}: {done[0][i]}\")\n",
    "                \n",
    "                # Case.revise(self.case_base[i], self.temporary_case_base[i], torch.any(done).item())\n",
    "                # self.case_base[i] = Case.retain(\n",
    "                #     self.case_base[i], self.temporary_case_base[i], torch.any(done).item()\n",
    "                # )\n",
    "\n",
    "                Case.revise(self.case_base[i], self.temporary_case_base[i], done[0][i])\n",
    "                self.case_base[i] = Case.retain(\n",
    "                    self.case_base[i], self.temporary_case_base[i], done[0][i]\n",
    "                )\n",
    "\n",
    "                # for case in self.temporary_case_base[i]:\n",
    "                #     print(f\"Step {step} -- Problem Stored in Temp CB: {case.problem}, Solution Stored in Temp CB: {case.solution}\")\n",
    "\n",
    "                # for case in self.case_base[i]:\n",
    "                #     print(f\"Step {step} -- Problem Stored in CB: {case.problem}, Solution Stored in CB: {case.solution}\")\n",
    "\n",
    "\n",
    "            torch.cuda.empty_cache()  # Free up unused memory\n",
    "\n",
    "        \n",
    "        for agent_id, agent in enumerate(env.agents):\n",
    "            self.save_case_base_temporary(agent_id)  # Save temporary case base after training\n",
    "            self.save_case_base(agent_id)  # Save case base after training\n",
    "\n",
    "        # Print final success percentages for each agent\n",
    "        for agent_id, count in self.successful_episodes_individual.items():\n",
    "            print(f\"Success percentage for agent {agent_id} = {count / self.num_episodes * 100}%\")\n",
    "        \n",
    "        # Print overall success percentage for all agents\n",
    "        overall_success_percentage = self.successful_episodes_all_agents / self.num_episodes * 100\n",
    "        print(f\"Overall success percentage for all agents = {overall_success_percentage}%\")\n",
    "\n",
    "\n",
    "\n",
    "        total_time = time.time() - init_time\n",
    "        print(\n",
    "            f\"It took: {total_time}s for {total_steps} steps across {self.num_episodes} episodes of {self.num_envs} parallel environments on device {self.device} \"\n",
    "            f\"for {scenario_name} scenario.\"\n",
    "        )\n",
    "\n",
    "        # success_percentage = (self.successful_episodes / self.num_episodes) * 100\n",
    "        # print(f\"Percentage of successful episodes: {success_percentage}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scenario_name = \"navigation_comm\"\n",
    "    use_cuda = True\n",
    "\n",
    "    env_runner = QCBRLVmasRunner( \n",
    "        render=True,\n",
    "        num_envs=1,\n",
    "        num_episodes=30,\n",
    "        max_steps_per_episode=300,\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\"),\n",
    "        scenario=scenario_name,\n",
    "        continuous_actions=False,\n",
    "        random_action=False,\n",
    "        n_agents=2,\n",
    "        obs_discrete=True,\n",
    "        agents_with_same_goal=2,\n",
    "        collisions=False,\n",
    "        shared_rew=False,\n",
    "    )\n",
    "\n",
    "    env_runner.run_vmas_env()\n",
    "    # for agent in env_runner.problem_solver_agents:\n",
    "    #     agent.print_q_table()\n",
    "    env_runner.plot_rewards_history()\n",
    "\n",
    "    # ipython_display(env_runner.generate_gif(scenario_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
