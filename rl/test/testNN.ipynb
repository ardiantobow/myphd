{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0579, 0.0917],\n",
      "         [0.0579, 0.1145],\n",
      "         [0.0586, 0.0932],\n",
      "         [0.0588, 0.1147],\n",
      "         [0.0516, 0.1367],\n",
      "         [0.0466, 0.1623],\n",
      "         [0.0518, 0.1385],\n",
      "         [0.0463, 0.1650],\n",
      "         [0.0432, 0.1920],\n",
      "         [0.0449, 0.1697]]], grad_fn=<ViewBackward0>) tensor([[[-0.0540],\n",
      "         [-0.0617],\n",
      "         [-0.0546],\n",
      "         [-0.0617],\n",
      "         [-0.0781],\n",
      "         [-0.0909],\n",
      "         [-0.0780],\n",
      "         [-0.0910],\n",
      "         [-0.1020],\n",
      "         [-0.0912]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "\n",
    "# Create environment\n",
    "env = gym.make('CartPole-v1')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__() #fc: fully connected\n",
    "        self.fc1 = nn.Linear(state_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.actor = nn.Linear(64, action_dim)\n",
    "        self.critic = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        logits = self.actor(x)\n",
    "        value = self.critic(x)\n",
    "        # logits = 1\n",
    "        # value = 3\n",
    "        return logits, value\n",
    "    \n",
    "\n",
    "# Initialize PPO agent\n",
    "policy = ActorCritic()\n",
    "\n",
    "# state = env.reset()\n",
    "state = [[ 0.04433184, -0.22282164, -0.031273  ,  0.24055558],\n",
    "         [ 0.03987541, -0.4174832 , -0.02646189,  0.52321243],\n",
    "         [ 0.03152574, -0.22199902, -0.01599764,  0.2223099 ],\n",
    "         [ 0.02708576, -0.4168887 , -0.01155144,  0.5099039 ],\n",
    "         [ 0.01874799, -0.611846  , -0.00135336,  0.7989243 ],\n",
    "         [ 0.00651107, -0.8069494 ,  0.01462512,  1.0911813 ],\n",
    "         [-0.00962792, -0.61202323,  0.03644875,  0.8031229 ],\n",
    "         [-0.02186839, -0.8076255 ,  0.0525112 ,  1.1070449 ],\n",
    "         [-0.0380209 , -1.003397  ,  0.07465211,  1.4157286 ],\n",
    "         [-0.05808884, -0.8092748 ,  0.10296667,  1.1472837 ],]\n",
    "\n",
    "state = torch.FloatTensor(state).unsqueeze(0)\n",
    "logits, _ = policy(state)\n",
    "\n",
    "print(logits, _)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
