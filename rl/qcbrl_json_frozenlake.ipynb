{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 1 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 2 finished after 9 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 3 finished after 9 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 4 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 5 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 6 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 1\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 7 finished after 7 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 8 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 9 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 1\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 10 finished after 8 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 11 finished after 12 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 12 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 13 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 14 finished after 13 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 3\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 2\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 15 finished after 6 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 1\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 3\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 16 finished after 7 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 17 finished after 6 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 18 finished after 19 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 19 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 0\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 0\n",
      "next_state: 14\n",
      "Reward: 0.0\n",
      "State: 14\n",
      "Action: 0\n",
      "next_state: 13\n",
      "Reward: 0.0\n",
      "State: 13\n",
      "Action: 0\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 20 finished after 15 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 3\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 21 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 22 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 3\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 2\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 2\n",
      "next_state: 14\n",
      "Reward: 0.0\n",
      "State: 14\n",
      "Action: 2\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 0\n",
      "next_state: 14\n",
      "Reward: 0.0\n",
      "State: 14\n",
      "Action: 0\n",
      "next_state: 14\n",
      "Reward: 0.0\n",
      "State: 14\n",
      "Action: 1\n",
      "next_state: 14\n",
      "Reward: 0.0\n",
      "State: 14\n",
      "Action: 3\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 0\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 1\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 1\n",
      "next_state: 11\n",
      "Reward: 0.0\n",
      "Episode 23 finished after 34 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 24 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 3\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 25 finished after 12 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 26 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 27 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 3\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 28 finished after 15 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 3\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 29 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 0\n",
      "next_state: 13\n",
      "Reward: 0.0\n",
      "State: 13\n",
      "Action: 0\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 30 finished after 14 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 31 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 32 finished after 15 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 3\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 3\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 1\n",
      "next_state: 13\n",
      "Reward: 0.0\n",
      "State: 13\n",
      "Action: 2\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 33 finished after 12 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 34 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 35 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 36 finished after 4 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 37 finished after 6 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 38 finished after 6 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 39 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 3\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 1\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 40 finished after 15 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 41 finished after 15 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 42 finished after 13 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 43 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 44 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 45 finished after 15 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 46 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 47 finished after 7 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 1\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 48 finished after 9 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 49 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 1\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 50 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 51 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 52 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 2\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 53 finished after 4 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 54 finished after 8 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 55 finished after 11 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 56 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 57 finished after 4 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 1\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 2\n",
      "next_state: 14\n",
      "Reward: 0.0\n",
      "State: 14\n",
      "Action: 0\n",
      "next_state: 13\n",
      "Reward: 0.0\n",
      "State: 13\n",
      "Action: 1\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 58 finished after 17 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 59 finished after 10 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 60 finished after 10 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 61 finished after 7 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 0\n",
      "next_state: 13\n",
      "Reward: 0.0\n",
      "State: 13\n",
      "Action: 3\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 3\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 1\n",
      "next_state: 11\n",
      "Reward: 0.0\n",
      "Episode 62 finished after 11 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 63 finished after 14 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 1\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 3\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 64 finished after 11 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 65 finished after 6 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 66 finished after 10 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 67 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 68 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 0\n",
      "next_state: 13\n",
      "Reward: 0.0\n",
      "State: 13\n",
      "Action: 3\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 3\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 0\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 69 finished after 16 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 70 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 71 finished after 22 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 3\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 1\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 2\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 72 finished after 14 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 3\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 73 finished after 15 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 0\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 0\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 74 finished after 6 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 75 finished after 13 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 76 finished after 4 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 77 finished after 2 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 78 finished after 3 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 1\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 3\n",
      "next_state: 6\n",
      "Reward: 0.0\n",
      "State: 6\n",
      "Action: 2\n",
      "next_state: 10\n",
      "Reward: 0.0\n",
      "State: 10\n",
      "Action: 0\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 9\n",
      "Reward: 0.0\n",
      "State: 9\n",
      "Action: 3\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 0\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 79 finished after 19 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 80 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 1\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 81 finished after 5 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 3\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 82 finished after 8 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 0\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 2\n",
      "next_state: 8\n",
      "Reward: 0.0\n",
      "State: 8\n",
      "Action: 2\n",
      "next_state: 12\n",
      "Reward: 0.0\n",
      "Episode 83 finished after 9 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 2\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 84 finished after 4 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n",
      "State: 4\n",
      "Action: 1\n",
      "next_state: 5\n",
      "Reward: 0.0\n",
      "Episode 85 finished after 4 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 3\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 1\n",
      "next_state: 1\n",
      "Reward: 0.0\n",
      "State: 1\n",
      "Action: 3\n",
      "next_state: 2\n",
      "Reward: 0.0\n",
      "State: 2\n",
      "Action: 2\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 1\n",
      "next_state: 3\n",
      "Reward: 0.0\n",
      "State: 3\n",
      "Action: 0\n",
      "next_state: 7\n",
      "Reward: 0.0\n",
      "Episode 86 finished after 10 steps with total reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 0\n",
      "next_state: 0\n",
      "Reward: 0.0\n",
      "State: 0\n",
      "Action: 2\n",
      "next_state: 4\n",
      "Reward: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 138\u001b[0m\n\u001b[1;32m    136\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m  \u001b[38;5;66;03m# Example number of actions\u001b[39;00m\n\u001b[1;32m    137\u001b[0m agent \u001b[38;5;241m=\u001b[39m QCBRL(actions)\n\u001b[0;32m--> 138\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m agent\u001b[38;5;241m.\u001b[39msave_case_base(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcase_base.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 69\u001b[0m, in \u001b[0;36mQCBRL.train\u001b[0;34m(self, episodes, max_steps)\u001b[0m\n\u001b[1;32m     67\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_steps\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Render the environment\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(state))\n\u001b[1;32m     71\u001b[0m     action, next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake_action(state)\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/gym/core.py:286\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/gym/core.py:286\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/gym/envs/toy_text/frozen_lake.py:242\u001b[0m, in \u001b[0;36mFrozenLakeEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_text(desc)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_gui\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PHD/Research/code/.venv/lib/python3.10/site-packages/gym/envs/toy_text/frozen_lake.py:342\u001b[0m, in \u001b[0;36mFrozenLakeEnv._render_gui\u001b[0;34m(self, desc, mode)\u001b[0m\n\u001b[1;32m    340\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[1;32m    341\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m--> 342\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# rgb_array\u001b[39;00m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[1;32m    345\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_surface)), axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    346\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, actions, epsilon=0.1, gamma=0.99, alpha=0.1, lambd=0.9):\n",
    "        self.actions = actions\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.lambd = lambd\n",
    "        self.Q = {}  # Q-values table\n",
    "        self.e = {}  # Eligibility traces table\n",
    "\n",
    "    def choose_action(self, sq):\n",
    "        sq_tuple = sq  # Convert numpy array to tuple\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.actions)\n",
    "        else:\n",
    "            if sq_tuple in self.Q:  # Use the tuple as the key\n",
    "                return np.argmax(self.Q[sq_tuple])\n",
    "            else:\n",
    "                return np.random.choice(self.actions)\n",
    "\n",
    "\n",
    "    def update_Q(self, sq, action, reward, next_sq, next_action):\n",
    "        if sq not in self.Q:\n",
    "            self.Q[sq] = np.zeros(self.actions)\n",
    "            self.e[sq] = np.zeros(self.actions)\n",
    "\n",
    "        delta = reward + self.gamma * self.Q.get(next_sq, np.zeros(self.actions))[next_action] - self.Q[sq][action]\n",
    "        self.e[sq][action] += 1\n",
    "\n",
    "        for state in self.Q:\n",
    "            for a in range(self.actions):\n",
    "                self.Q[state][a] += self.alpha * delta * self.e[state][a]\n",
    "                self.e[state][a] *= self.gamma * self.lambd\n",
    "\n",
    "    def solve_problem(self, sq, reward, next_sq):\n",
    "        action = self.choose_action(sq)\n",
    "        if reward is not None:  # If reward is received\n",
    "            next_action = self.choose_action(next_sq)\n",
    "            self.update_Q(sq, action, reward, next_sq, next_action)\n",
    "            sq = next_sq\n",
    "            return action, sq\n",
    "        else:\n",
    "            return action, sq\n",
    "\n",
    "def sim_q(sq, c):\n",
    "    # Example of a similarity function comparing qualitative states\n",
    "    similarity = np.random.rand()  # Replace this with your own similarity calculation\n",
    "    return similarity\n",
    "\n",
    "class QCBRL:\n",
    "    def __init__(self, actions, threshold=0.5, epsilon=0.1, gamma=0.99, alpha=0.1, lambd=0.9):\n",
    "        self.problem_solver = ProblemSolver(actions, epsilon, gamma, alpha, lambd)\n",
    "        self.C_B = {}\n",
    "        self.threshold = threshold\n",
    "        self.env = gym.make('FrozenLake-v1')\n",
    "\n",
    "    def train(self, episodes, max_steps):\n",
    "        total_rewards = []  # List to store total rewards for each episode\n",
    "\n",
    "        for episode in range(1, episodes+1):\n",
    "            state = self.env.reset()\n",
    "            total_reward = 0\n",
    "            for step in range(1, max_steps+1):\n",
    "                self.env.render()  # Render the environment\n",
    "                print(\"State: {}\".format(state))\n",
    "                action, next_state = self.take_action(state)\n",
    "                print(\"Action: {}\".format(action))\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                print(\"next_state: {}\".format(next_state))\n",
    "                print(\"Reward: {}\".format(reward))\n",
    "                total_reward += reward\n",
    "                c = (state, action, reward, next_state)\n",
    "                self.reuse(c)\n",
    "                # Determine if the episode ended successfully\n",
    "                episode_ended_successfully = done\n",
    "                if episode_ended_successfully:\n",
    "                    new_C_B = {}\n",
    "                    for key, value in self.C_B.items():\n",
    "                        if isinstance(key, tuple):\n",
    "                            new_key = key\n",
    "                        else:\n",
    "                            new_key = (key,)\n",
    "                        new_C_B[new_key] = value\n",
    "                    self.C_B = new_C_B\n",
    "                    break  # Exit loop if episode ends\n",
    "                state = next_state\n",
    "            total_rewards.append(total_reward)  # Append total reward for current episode\n",
    "            print(f\"Episode {episode} finished after {step} steps with total reward: {total_reward}\")\n",
    "\n",
    "        # Plot the graph\n",
    "        plt.plot(range(1, episodes + 1), total_rewards)\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.title('Agent Performance Over Episodes')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def take_action(self, state):\n",
    "        action, _ = self.problem_solver.solve_problem(state, None, None)\n",
    "        return action, state\n",
    "\n",
    "    def reuse(self, c):\n",
    "        hashed_c = tuple(array.tobytes() if isinstance(array, np.ndarray) else array for array in c)\n",
    "        self.C_B[hashed_c] = c\n",
    "\n",
    "    def convert_to_serializable(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            converted_dict = {}\n",
    "            for k, v in obj.items():\n",
    "                if isinstance(k, tuple):\n",
    "                    k = '_'.join(map(str, k))  # Convert tuple keys to strings\n",
    "                converted_dict[self.convert_to_serializable(k)] = self.convert_to_serializable(v)\n",
    "            return converted_dict\n",
    "        elif isinstance(obj, list):\n",
    "            return [self.convert_to_serializable(item) for item in obj]\n",
    "        elif isinstance(obj, tuple):\n",
    "            return tuple(self.convert_to_serializable(item) for item in obj)\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def save_case_base(self, filename):\n",
    "        # Convert NumPy arrays to lists and tuple keys to string keys\n",
    "        converted_case_base = self.convert_to_serializable(self.C_B)\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(converted_case_base, file)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    actions = 4  # Example number of actions\n",
    "    agent = QCBRL(actions)\n",
    "    agent.train(episodes=200, max_steps=1000)\n",
    "    agent.save_case_base(\"case_base.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
