{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1358, -0.0014],\n",
      "        [ 0.1239, -0.0101],\n",
      "        [ 0.1233, -0.0235],\n",
      "        [ 0.1248, -0.0106],\n",
      "        [ 0.1248, -0.0246]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[5.0189, 5.0189, 5.0189, 5.0189, 5.0189],\n",
      "        [4.0506, 4.0506, 4.0506, 4.0506, 4.0506],\n",
      "        [3.0865, 3.0865, 3.0865, 3.0865, 3.0865],\n",
      "        [2.0996, 2.0996, 2.0996, 2.0996, 2.0996],\n",
      "        [1.1035, 1.1035, 1.1035, 1.1035, 1.1035]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[5.0189, 5.0189, 5.0189, 5.0189, 5.0189],\n",
      "        [4.0506, 4.0506, 4.0506, 4.0506, 4.0506],\n",
      "        [3.0865, 3.0865, 3.0865, 3.0865, 3.0865],\n",
      "        [2.0996, 2.0996, 2.0996, 2.0996, 2.0996],\n",
      "        [1.1035, 1.1035, 1.1035, 1.1035, 1.1035]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -3.0718154907226562\n",
      "tensor([[ 0.1434, -0.0470],\n",
      "        [ 0.1566, -0.0659],\n",
      "        [ 0.1458, -0.0508],\n",
      "        [ 0.1608, -0.0697],\n",
      "        [ 0.1817, -0.0887]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.9772, 4.9772, 4.9772, 4.9772, 4.9772],\n",
      "        [4.0285, 4.0285, 4.0285, 4.0285, 4.0285],\n",
      "        [3.0426, 3.0426, 3.0426, 3.0426, 3.0426],\n",
      "        [2.0476, 2.0476, 2.0476, 2.0476, 2.0476],\n",
      "        [1.0670, 1.0670, 1.0670, 1.0670, 1.0670]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.9772, 4.9772, 4.9772, 4.9772, 4.9772],\n",
      "        [4.0285, 4.0285, 4.0285, 4.0285, 4.0285],\n",
      "        [3.0426, 3.0426, 3.0426, 3.0426, 3.0426],\n",
      "        [2.0476, 2.0476, 2.0476, 2.0476, 2.0476],\n",
      "        [1.0670, 1.0670, 1.0670, 1.0670, 1.0670]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -3.0325839519500732\n",
      "tensor([[ 0.1414, -0.0014],\n",
      "        [ 0.1335, -0.0161],\n",
      "        [ 0.1241, -0.0287]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[3.0695, 3.0695, 3.0695],\n",
      "        [2.0797, 2.0797, 2.0797],\n",
      "        [1.0821, 1.0821, 1.0821]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[3.0695, 3.0695, 3.0695],\n",
      "        [2.0797, 2.0797, 2.0797],\n",
      "        [1.0821, 1.0821, 1.0821]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -2.077141284942627\n",
      "tensor([[ 0.1426, -0.0506],\n",
      "        [ 0.1572, -0.0704],\n",
      "        [ 0.1457, -0.0534],\n",
      "        [ 0.1609, -0.0735],\n",
      "        [ 0.1490, -0.0579]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.9553, 4.9553, 4.9553, 4.9553, 4.9553],\n",
      "        [4.0089, 4.0089, 4.0089, 4.0089, 4.0089],\n",
      "        [3.0204, 3.0204, 3.0204, 3.0204, 3.0204],\n",
      "        [2.0547, 2.0547, 2.0547, 2.0547, 2.0547],\n",
      "        [1.0448, 1.0448, 1.0448, 1.0448, 1.0448]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.9553, 4.9553, 4.9553, 4.9553, 4.9553],\n",
      "        [4.0089, 4.0089, 4.0089, 4.0089, 4.0089],\n",
      "        [3.0204, 3.0204, 3.0204, 3.0204, 3.0204],\n",
      "        [2.0547, 2.0547, 2.0547, 2.0547, 2.0547],\n",
      "        [1.0448, 1.0448, 1.0448, 1.0448, 1.0448]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -3.0168063640594482\n",
      "tensor([[ 0.1410, -0.0140],\n",
      "        [ 0.1529,  0.0021]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[2.0694, 2.0694],\n",
      "        [1.0831, 1.0831]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[2.0694, 2.0694],\n",
      "        [1.0831, 1.0831]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -1.576277256011963\n",
      "tensor([[ 0.1430, -0.0183],\n",
      "        [ 0.1542, -0.0017],\n",
      "        [ 0.1775,  0.0096],\n",
      "        [ 0.1539, -0.0025],\n",
      "        [ 0.1771,  0.0089]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.9718, 4.9718, 4.9718, 4.9718, 4.9718],\n",
      "        [3.9899, 3.9899, 3.9899, 3.9899, 3.9899],\n",
      "        [3.0415, 3.0415, 3.0415, 3.0415, 3.0415],\n",
      "        [2.0396, 2.0396, 2.0396, 2.0396, 2.0396],\n",
      "        [1.0716, 1.0716, 1.0716, 1.0716, 1.0716]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.9718, 4.9718, 4.9718, 4.9718, 4.9718],\n",
      "        [3.9899, 3.9899, 3.9899, 3.9899, 3.9899],\n",
      "        [3.0415, 3.0415, 3.0415, 3.0415, 3.0415],\n",
      "        [2.0396, 2.0396, 2.0396, 2.0396, 2.0396],\n",
      "        [1.0716, 1.0716, 1.0716, 1.0716, 1.0716]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -3.022853374481201\n",
      "tensor([[ 0.1553, -0.0063],\n",
      "        [ 0.1793,  0.0042],\n",
      "        [ 0.1554, -0.0068],\n",
      "        [ 0.1454, -0.0234],\n",
      "        [ 0.1323, -0.0308]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.9395, 4.9395, 4.9395, 4.9395, 4.9395],\n",
      "        [4.0024, 4.0024, 4.0024, 4.0024, 4.0024],\n",
      "        [3.0356, 3.0356, 3.0356, 3.0356, 3.0356],\n",
      "        [2.0482, 2.0482, 2.0482, 2.0482, 2.0482],\n",
      "        [1.0652, 1.0652, 1.0652, 1.0652, 1.0652]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.9395, 4.9395, 4.9395, 4.9395, 4.9395],\n",
      "        [4.0024, 4.0024, 4.0024, 4.0024, 4.0024],\n",
      "        [3.0356, 3.0356, 3.0356, 3.0356, 3.0356],\n",
      "        [2.0482, 2.0482, 2.0482, 2.0482, 2.0482],\n",
      "        [1.0652, 1.0652, 1.0652, 1.0652, 1.0652]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -3.0181961059570312\n",
      "tensor([[ 0.1472, -0.0263],\n",
      "        [ 0.1344, -0.0340],\n",
      "        [ 0.1474, -0.0261],\n",
      "        [ 0.1350, -0.0343],\n",
      "        [ 0.1478, -0.0260]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.9492, 4.9492, 4.9492, 4.9492, 4.9492],\n",
      "        [3.9961, 3.9961, 3.9961, 3.9961, 3.9961],\n",
      "        [3.0171, 3.0171, 3.0171, 3.0171, 3.0171],\n",
      "        [2.0453, 2.0453, 2.0453, 2.0453, 2.0453],\n",
      "        [1.0455, 1.0455, 1.0455, 1.0455, 1.0455]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.9492, 4.9492, 4.9492, 4.9492, 4.9492],\n",
      "        [3.9961, 3.9961, 3.9961, 3.9961, 3.9961],\n",
      "        [3.0171, 3.0171, 3.0171, 3.0171, 3.0171],\n",
      "        [2.0453, 2.0453, 2.0453, 2.0453, 2.0453],\n",
      "        [1.0455, 1.0455, 1.0455, 1.0455, 1.0455]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -3.0106289386749268\n",
      "tensor([[ 0.1376, -0.0377],\n",
      "        [ 0.1433, -0.0581],\n",
      "        [ 0.1605, -0.0790],\n",
      "        [ 0.1810, -0.0969],\n",
      "        [ 0.2042, -0.1175]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.9259, 4.9259, 4.9259, 4.9259, 4.9259],\n",
      "        [3.9448, 3.9448, 3.9448, 3.9448, 3.9448],\n",
      "        [2.9534, 2.9534, 2.9534, 2.9534, 2.9534],\n",
      "        [1.9530, 1.9530, 1.9530, 1.9530, 1.9530],\n",
      "        [0.9391, 0.9391, 0.9391, 0.9391, 0.9391]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.9259, 4.9259, 4.9259, 4.9259, 4.9259],\n",
      "        [3.9448, 3.9448, 3.9448, 3.9448, 3.9448],\n",
      "        [2.9534, 2.9534, 2.9534, 2.9534, 2.9534],\n",
      "        [1.9530, 1.9530, 1.9530, 1.9530, 1.9530],\n",
      "        [0.9391, 0.9391, 0.9391, 0.9391, 0.9391]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -2.9432384967803955\n",
      "tensor([[ 0.1499, -0.0272],\n",
      "        [ 0.1638, -0.0155]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[2.0184, 2.0184],\n",
      "        [1.0035, 1.0035]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[2.0184, 2.0184],\n",
      "        [1.0035, 1.0035]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -1.5109341144561768\n",
      "tensor([[ 0.1910, -0.0125],\n",
      "        [ 0.2110, -0.0110],\n",
      "        [ 0.2177, -0.0109],\n",
      "        [ 0.2096, -0.0152],\n",
      "        [ 0.1926, -0.0152]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.8673, 4.8673, 4.8673, 4.8673, 4.8673],\n",
      "        [3.8861, 3.8861, 3.8861, 3.8861, 3.8861],\n",
      "        [2.9332, 2.9332, 2.9332, 2.9332, 2.9332],\n",
      "        [1.9799, 1.9799, 1.9799, 1.9799, 1.9799],\n",
      "        [1.0195, 1.0195, 1.0195, 1.0195, 1.0195]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.8673, 4.8673, 4.8673, 4.8673, 4.8673],\n",
      "        [3.8861, 3.8861, 3.8861, 3.8861, 3.8861],\n",
      "        [2.9332, 2.9332, 2.9332, 2.9332, 2.9332],\n",
      "        [1.9799, 1.9799, 1.9799, 1.9799, 1.9799],\n",
      "        [1.0195, 1.0195, 1.0195, 1.0195, 1.0195]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -2.9371907711029053\n",
      "tensor([[ 0.1678, -0.0257],\n",
      "        [ 0.1958, -0.0215],\n",
      "        [ 0.1691, -0.0266],\n",
      "        [ 0.1550, -0.0386],\n",
      "        [ 0.1407, -0.0456]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.8770, 4.8770, 4.8770, 4.8770, 4.8770],\n",
      "        [3.9482, 3.9482, 3.9482, 3.9482, 3.9482],\n",
      "        [2.9876, 2.9876, 2.9876, 2.9876, 2.9876],\n",
      "        [2.0083, 2.0083, 2.0083, 2.0083, 2.0083],\n",
      "        [1.0169, 1.0169, 1.0169, 1.0169, 1.0169]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.8770, 4.8770, 4.8770, 4.8770, 4.8770],\n",
      "        [3.9482, 3.9482, 3.9482, 3.9482, 3.9482],\n",
      "        [2.9876, 2.9876, 2.9876, 2.9876, 2.9876],\n",
      "        [2.0083, 2.0083, 2.0083, 2.0083, 2.0083],\n",
      "        [1.0169, 1.0169, 1.0169, 1.0169, 1.0169]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -2.9675915241241455\n",
      "tensor([[ 0.1565, -0.0411],\n",
      "        [ 0.1423, -0.0485],\n",
      "        [ 0.1339, -0.0582],\n",
      "        [ 0.1486, -0.0801],\n",
      "        [ 0.1714, -0.0954]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.9104, 4.9104, 4.9104, 4.9104, 4.9104],\n",
      "        [3.9415, 3.9415, 3.9415, 3.9415, 3.9415],\n",
      "        [2.9527, 2.9527, 2.9527, 2.9527, 2.9527],\n",
      "        [1.9508, 1.9508, 1.9508, 1.9508, 1.9508],\n",
      "        [0.9381, 0.9381, 0.9381, 0.9381, 0.9381]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.9104, 4.9104, 4.9104, 4.9104, 4.9104],\n",
      "        [3.9415, 3.9415, 3.9415, 3.9415, 3.9415],\n",
      "        [2.9527, 2.9527, 2.9527, 2.9527, 2.9527],\n",
      "        [1.9508, 1.9508, 1.9508, 1.9508, 1.9508],\n",
      "        [0.9381, 0.9381, 0.9381, 0.9381, 0.9381]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -2.938694953918457\n",
      "tensor([[ 0.1961, -0.1162],\n",
      "        [ 0.2204, -0.1372],\n",
      "        [ 0.1972, -0.1215],\n",
      "        [ 0.2233, -0.1434],\n",
      "        [ 0.2512, -0.1679]], grad_fn=<AddmmBackward0>)\n",
      "surr1: tensor([[4.8000, 4.8000, 4.8000, 4.8000, 4.8000],\n",
      "        [3.8624, 3.8624, 3.8624, 3.8624, 3.8624],\n",
      "        [2.8624, 2.8624, 2.8624, 2.8624, 2.8624],\n",
      "        [1.8524, 1.8524, 1.8524, 1.8524, 1.8524],\n",
      "        [0.8363, 0.8363, 0.8363, 0.8363, 0.8363]], grad_fn=<MulBackward0>)\n",
      "surr2: tensor([[4.8000, 4.8000, 4.8000, 4.8000, 4.8000],\n",
      "        [3.8624, 3.8624, 3.8624, 3.8624, 3.8624],\n",
      "        [2.8624, 2.8624, 2.8624, 2.8624, 2.8624],\n",
      "        [1.8524, 1.8524, 1.8524, 1.8524, 1.8524],\n",
      "        [0.8363, 0.8363, 0.8363, 0.8363, 0.8363]], grad_fn=<MulBackward0>)\n",
      "actor_loss: -2.842696189880371\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define hyperparameters\n",
    "gamma = 0.99\n",
    "learning_rate = 0.0005\n",
    "n_epochs = 4\n",
    "update_timestep = 5\n",
    "kl_constraint = 0.01  # KL divergence constraint\n",
    "\n",
    "# Create environment\n",
    "env = gym.make('CartPole-v1')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "# Actor-critic network architecture\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.actor = nn.Linear(64, action_dim)\n",
    "        self.critic = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        logits = self.actor(x)\n",
    "        value = self.critic(x)\n",
    "        return logits, value\n",
    "\n",
    "# Trust Region Policy Optimization (TRPO) algorithm\n",
    "class TRPO:\n",
    "    def __init__(self):\n",
    "        self.policy = ActorCritic()\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=learning_rate)\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        logits, _ = self.policy(state)\n",
    "        action_probs = torch.softmax(logits, dim=-1)\n",
    "        action = torch.multinomial(action_probs, 1)\n",
    "        return action.item()\n",
    "\n",
    "    def train(self, states, actions, advantages):\n",
    "        states = torch.FloatTensor(states)\n",
    "        actions = torch.LongTensor(actions)\n",
    "        advantages = torch.FloatTensor(advantages).unsqueeze(1)\n",
    "\n",
    "        # Compute old action probabilities\n",
    "        logits, _ = self.policy(states)\n",
    "        print(logits)\n",
    "        action_probs = torch.softmax(logits, dim=-1)\n",
    "        old_action_probs = action_probs.gather(1, actions.unsqueeze(1)).squeeze() # probs of action selected\n",
    "        # print(\"Action Probs: {}\".format(action_probs))\n",
    "        # print(\"Old Action Probs: {}\".format(old_action_probs))\n",
    "\n",
    "        # Compute gradients of policy parameters\n",
    "        logits, values = self.policy(states)\n",
    "        # print(logits)\n",
    "        values = values.squeeze()\n",
    "        # print(values)\n",
    "\n",
    "        action_probs = torch.softmax(logits, dim=-1)\n",
    "        new_action_probs = action_probs.gather(1, actions.unsqueeze(1)).squeeze()\n",
    "        # print(\"New Action Probs: {}\".format(new_action_probs))\n",
    "        ratio = new_action_probs / old_action_probs\n",
    "        # print(\"Ratio: {}\".format(ratio))\n",
    "\n",
    "        # Compute surrogate loss\n",
    "        surr1 = ratio * advantages\n",
    "        print(\"surr1: {}\".format(surr1))\n",
    "        surr2 = torch.clamp(ratio, 1 - kl_constraint, 1 + kl_constraint) * advantages\n",
    "        print(\"surr2: {}\".format(surr2))\n",
    "        actor_loss = -torch.min(surr1, surr2).mean()\n",
    "        print(\"actor_loss: {}\".format(actor_loss))\n",
    "\n",
    "        # Compute value function loss\n",
    "        critic_loss = nn.MSELoss()(values, torch.FloatTensor(returns))\n",
    "\n",
    "        # Compute total loss\n",
    "        loss = actor_loss + critic_loss\n",
    "\n",
    "        # Perform backpropagation\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "    def trust_region_update(self, loss):\n",
    "        # Placeholder for trust region update\n",
    "        pass\n",
    "\n",
    "# Initialize TRPO agent\n",
    "trpo_agent = TRPO()\n",
    "\n",
    "# Main training loop\n",
    "total_timesteps = 0\n",
    "for epoch in range(n_epochs):\n",
    "    states, actions, rewards, action_probs, dones, next_states = [], [], [], [], [], []\n",
    "    episode_reward = 0\n",
    "    state = env.reset()\n",
    "\n",
    "    while True:\n",
    "        action = trpo_agent.select_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "        next_states.append(next_state)\n",
    "\n",
    "\n",
    "        episode_reward += reward\n",
    "        state = next_state\n",
    "\n",
    "        total_timesteps += 1\n",
    "\n",
    "        if total_timesteps % update_timestep == 0:\n",
    "            # print(next_states)\n",
    "            _, next_value = trpo_agent.policy(torch.FloatTensor(next_states))\n",
    "            # print(\"Next Value: {}\".format(next_value))\n",
    "            returns, advantages = [], []\n",
    "            discounted_sum = 0\n",
    "\n",
    "            # print(rewards)    \n",
    "            # print(1 - dones[i])\n",
    "            for i in range(len(rewards) - 1, -1, -1):\n",
    "                # discounted_sum = rewards[i] + gamma * discounted_sum * (1 - dones[i])\n",
    "                discounted_sum = rewards[i] + gamma * discounted_sum\n",
    "                # print(discounted_sum)\n",
    "                advantage = discounted_sum - next_value[i].item()\n",
    "                advantages.insert(0, advantage)\n",
    "                returns.insert(0, discounted_sum)\n",
    "\n",
    "            trpo_agent.train(states, actions, advantages)\n",
    "\n",
    "            states, actions, rewards, action_probs, dones, next_states = [], [], [], [], [], []\n",
    "\n",
    "        # env.render()\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # print(f\"Epoch: {epoch + 1}, Total Timesteps: {total_timesteps}, Episode Reward: {episode_reward}\")\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
