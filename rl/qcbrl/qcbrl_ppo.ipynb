{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 0, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 1, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 2, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 3, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 4, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 5, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 6, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 7, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 9\n",
      "Episode: 8, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 9, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 10, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 11, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 12, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 13, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 14, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 15, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 16, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 17, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 18, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 19, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 20, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 21, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 22, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 23, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 24, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 3\n",
      "Episode: 25, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 26, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 27, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 9\n",
      "Episode: 28, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 29, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 30, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 31, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 32, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20998/1685069740.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  advantages_tensor = torch.tensor(advantages, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 33, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 10\n",
      "Episode: 34, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 10\n",
      "Episode: 35, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]\n",
      "Shape before Advantages: 14\n",
      "Episode: 36, Reward: 1, Success: True\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 37, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 38, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 39, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 40, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 41, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 42, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 43, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 44, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 45, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])]\n",
      "Shape before Advantages: 13\n",
      "Episode: 46, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 47, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 48, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 49, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 50, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 51, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 52, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 53, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 54, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 55, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 56, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 57, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 58, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 9\n",
      "Episode: 59, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 60, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 61, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 62, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 63, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 64, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 65, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 3\n",
      "Episode: 66, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 67, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 68, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 10\n",
      "Episode: 69, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 70, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 3\n",
      "Episode: 71, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 72, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 9\n",
      "Episode: 73, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 74, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 3\n",
      "Episode: 75, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 76, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 77, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 78, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 10\n",
      "Episode: 79, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 80, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 81, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 82, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 83, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 84, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 85, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 86, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 10\n",
      "Episode: 87, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 8\n",
      "Episode: 88, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 89, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])]\n",
      "Shape before Advantages: 13\n",
      "Episode: 90, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 91, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 92, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 93, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 94, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 1\n",
      "Episode: 95, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 6\n",
      "Episode: 96, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 9\n",
      "Episode: 97, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 3\n",
      "Episode: 98, Reward: -5, Success: False\n",
      "States: [tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "Shape before Advantages: 4\n",
      "Episode: 99, Reward: -5, Success: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 1.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Register the custom FrozenLake environment\n",
    "register(\n",
    "    id='CustomRewardFrozenLake-v1',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name': '4x4', 'is_slippery': False},\n",
    "    max_episode_steps=100,\n",
    "    reward_threshold=0.78,  # Adjust the reward threshold if needed\n",
    ")\n",
    "\n",
    "# Define the custom FrozenLake environment with modified rewards\n",
    "class CustomRewardFrozenLake(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"CustomRewardFrozenLake-v1\")\n",
    "        self.observation_space = self.env.observation_space\n",
    "        self.action_space = self.env.action_space\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, done, info = self.env.step(action)\n",
    "        if reward == 0 and not done:\n",
    "            reward = 0\n",
    "        elif reward == 0 and done:\n",
    "            reward = -5\n",
    "        elif reward == 1:\n",
    "            reward = 1\n",
    "        return state, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "\n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "\n",
    "# Define Actor Network\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Define Critic Network\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define Experience Buffer\n",
    "class ExperienceBuffer:\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "    def add(self, state, action, log_prob, value, reward, done):\n",
    "        self.buffer.append((state, action, log_prob, value, reward, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, log_probs, values, rewards, dones = zip(*batch)\n",
    "        return states, actions, log_probs, values, rewards, dones\n",
    "\n",
    "# PPO loss function\n",
    "def calculate_ppo_loss(actor, critic, states, actions, log_probs_old, values_old, advantages, epsilon=0.2, c1=0.5, c2=0.01):\n",
    "    policy = actor(states)\n",
    "    dist = torch.distributions.Categorical(policy)\n",
    "\n",
    "    log_probs = dist.log_prob(actions)\n",
    "    ratios = torch.exp(log_probs - log_probs_old)\n",
    "    surr1 = ratios * advantages\n",
    "    surr2 = torch.clamp(ratios, 1.0 - epsilon, 1.0 + epsilon) * advantages\n",
    "\n",
    "    actor_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "    values = critic(states)\n",
    "    critic_loss = (values - values_old).pow(2).mean()\n",
    "\n",
    "    entropy = dist.entropy().mean()\n",
    "\n",
    "    total_loss = actor_loss + c1 * critic_loss - c2 * entropy\n",
    "\n",
    "    return actor_loss, critic_loss\n",
    "\n",
    "# Discounted rewards function\n",
    "def discount_rewards(rewards, gamma=0.99):\n",
    "    discounted_rewards = []\n",
    "    running_add = 0\n",
    "    for r in reversed(rewards):\n",
    "        running_add = running_add * gamma + r\n",
    "        discounted_rewards.insert(0, running_add)\n",
    "    return discounted_rewards\n",
    "\n",
    "# Function to compute advantages\n",
    "def compute_advantages(critic, states, rewards):\n",
    "    values = critic(states).squeeze()\n",
    "    rewards_tensor = torch.tensor(rewards, dtype=torch.float32)  # Convert rewards to a PyTorch tensor\n",
    "    advantages = rewards_tensor - values\n",
    "    return advantages\n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.actor = Actor(env.observation_space.n, env.action_space.n)\n",
    "        self.critic = Critic(env.observation_space.n)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=0.001)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=0.001)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state_one_hot = torch.zeros(1, self.env.observation_space.n)\n",
    "        state_one_hot[0, state] = 1\n",
    "        policy = self.actor(state_one_hot)\n",
    "        action_probs = torch.softmax(policy, dim=-1)\n",
    "        action = np.random.choice(env.action_space.n, p=action_probs.detach().numpy().flatten())\n",
    "        return action\n",
    "\n",
    "    def update(self, states, actions, log_probs, values, rewards, dones):\n",
    "        discounted_rewards = discount_rewards(rewards)\n",
    "\n",
    "        print(f\"Shape before Advantages: {states}\")\n",
    "        advantages = compute_advantages(self.critic, torch.stack(states), discounted_rewards)\n",
    "        \n",
    "        actions_tensor = torch.tensor(actions, dtype=torch.int64)\n",
    "        log_probs_tensor = torch.cat(log_probs)\n",
    "        values_tensor = torch.cat(values)\n",
    "        advantages_tensor = torch.tensor(advantages, dtype=torch.float32)\n",
    "\n",
    "        actor_loss, critic_loss = calculate_ppo_loss(self.actor, self.critic, torch.stack(states), actions_tensor, log_probs_tensor, values_tensor, advantages_tensor)\n",
    "\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        critic_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = CustomRewardFrozenLake()\n",
    "    solver = ProblemSolver(env)\n",
    "    num_episodes = 100\n",
    "    episode_rewards = []\n",
    "    success_count = 0\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        # print(f\"State: {state}\")\n",
    "        states = []\n",
    "        actions = []\n",
    "        log_probs = []\n",
    "        values = []\n",
    "        rewards = []\n",
    "        dones = []\n",
    "\n",
    "        while True:\n",
    "            action = solver.choose_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            state_one_hot = torch.zeros(1, env.observation_space.n)\n",
    "            state_one_hot[0, state] = 1\n",
    "            states.append(state_one_hot)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "\n",
    "            policy = solver.actor(state_one_hot)\n",
    "            dist = torch.distributions.Categorical(policy)\n",
    "            log_prob = dist.log_prob(torch.tensor(action))\n",
    "            log_probs.append(log_prob)\n",
    "            value = solver.critic(state_one_hot)\n",
    "            values.append(value)\n",
    "\n",
    "            if done:\n",
    "                if reward == 1:\n",
    "                    success_count += 1\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "        print(f\"States: {states}\")\n",
    "        solver.update(states, actions, log_probs, values, rewards, dones)\n",
    "        episode_rewards.append(sum(rewards))\n",
    "\n",
    "        print(f\"Episode: {episode}, Reward: {sum(rewards)}, Success: {reward == 1}\")\n",
    "\n",
    "    plt.plot(episode_rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.title('Rewards Obtained per Episode')\n",
    "    plt.show()\n",
    "\n",
    "    success_rate = success_count / num_episodes * 100\n",
    "    print(f\"Success rate: {success_rate}%\")\n",
    "    env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
