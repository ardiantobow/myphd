{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardie85/PHD/Research/code/.venv/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 255\u001b[0m\n\u001b[1;32m    253\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m  \u001b[38;5;66;03m# Number of actions in FrozenLake-v1\u001b[39;00m\n\u001b[1;32m    254\u001b[0m agent \u001b[38;5;241m=\u001b[39m QCBRL(actions)\n\u001b[0;32m--> 255\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 175\u001b[0m, in \u001b[0;36mQCBRL.train\u001b[0;34m(self, episodes, max_steps, render)\u001b[0m\n\u001b[1;32m    172\u001b[0m         episode_ended_successfully \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    174\u001b[0m Case\u001b[38;5;241m.\u001b[39mrevise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcase_base, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporary_case_base, episode_ended_successfully)\n\u001b[0;32m--> 175\u001b[0m \u001b[43mCase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcase_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemporary_case_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_ended_successfully\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m memory_usage\u001b[38;5;241m.\u001b[39mappend(psutil\u001b[38;5;241m.\u001b[39mvirtual_memory()\u001b[38;5;241m.\u001b[39mpercent)\n\u001b[1;32m    178\u001b[0m gpu_memory_usage\u001b[38;5;241m.\u001b[39mappend(pynvml\u001b[38;5;241m.\u001b[39mnvmlDeviceGetMemoryInfo(handle)\u001b[38;5;241m.\u001b[39mused \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 99\u001b[0m, in \u001b[0;36mCase.retain\u001b[0;34m(case_base, temporary_case_base, episode_ended_successfully, threshold)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Iterate through the temporary case base to find the last occurrence of each unique state-action pair\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(temporary_case_base):\n\u001b[0;32m---> 99\u001b[0m     state_action_pair \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, case\u001b[38;5;241m.\u001b[39msolution)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_action_pair \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m state_action_pairs:\n\u001b[1;32m    101\u001b[0m         state_action_pairs[state_action_pair] \u001b[38;5;241m=\u001b[39m case\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import pynvml\n",
    "from collections import Counter\n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, actions, epsilon=0.1, gamma=0.99, alpha=0.1, lambd=0.9):\n",
    "        self.actions = actions\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.lambd = lambd\n",
    "        self.Q = {}  # Q-values table\n",
    "        self.e = {}  # Eligibility traces table\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.isscalar(state):  # Check if state is a scalar (integer or float)\n",
    "            state_array = np.array([state])  # Convert scalar to numpy array\n",
    "        else:\n",
    "            state_array = np.asarray(state)  # Ensure state is a numpy array\n",
    "\n",
    "        state_tuple = (state_array.item(),) if state_array.ndim == 0 else tuple(state_array.tolist())\n",
    "\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.actions)\n",
    "        else:\n",
    "            if state_tuple in self.Q:  # Use the tuple as the key\n",
    "                return np.argmax(self.Q[state_tuple])\n",
    "            else:\n",
    "                return np.random.choice(self.actions)\n",
    "\n",
    "    def update_Q(self, state, action, reward, next_state, next_action):\n",
    "        state_array = np.asarray(state)  # Ensure state is a numpy array\n",
    "        state_tuple = tuple(state_array.tolist())  # Convert numpy array to tuple\n",
    "\n",
    "        if state_tuple not in self.Q:\n",
    "            self.Q[state_tuple] = np.zeros(self.actions)\n",
    "            self.e[state_tuple] = np.zeros(self.actions)\n",
    "\n",
    "        delta = reward + self.gamma * self.Q.get(tuple(np.array(next_state).tolist()), np.zeros(self.actions))[next_action] - self.Q[state_tuple][action]\n",
    "        self.e[state_tuple][action] += 1\n",
    "\n",
    "        for s in self.Q:\n",
    "            for a in range(self.actions):\n",
    "                self.Q[s][a] += self.alpha * delta * self.e[s][a]\n",
    "                self.e[s][a] *= self.gamma * self.lambd\n",
    "\n",
    "class Case:\n",
    "    def __init__(self, problem, solution, trust_value=1):\n",
    "        self.problem = np.array(problem)  # Convert problem to numpy array\n",
    "        self.solution = solution\n",
    "        self.trust_value = trust_value\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(state, case_base, threshold=0.5):\n",
    "        similarities = {}\n",
    "        for case in case_base:\n",
    "            similarities[case] = Case.sim_q(state, case.problem)  # Compare state with the problem part of the case\n",
    "        \n",
    "        sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        if sorted_similarities:\n",
    "            most_similar_case = sorted_similarities[0][0] if sorted_similarities[0][1] >= threshold else None\n",
    "        else:\n",
    "            most_similar_case = None\n",
    "        \n",
    "        return most_similar_case\n",
    "\n",
    "    @staticmethod\n",
    "    def reuse(c, case_base, temporary_case_base):\n",
    "        # Store the new case from the problem solver\n",
    "        if c not in temporary_case_base:\n",
    "            temporary_case_base.append(c)\n",
    "        \n",
    "        # Check if there are similar cases in case_base\n",
    "        similar_cases = [case for case in case_base if np.array_equal(case.problem, c.problem)]\n",
    "        for similar_case in similar_cases:\n",
    "            if similar_case not in temporary_case_base:\n",
    "                temporary_case_base.append(similar_case)\n",
    "\n",
    "    @staticmethod\n",
    "    def revise(case_base, temporary_case_base, episode_ended_successfully):\n",
    "        for case in temporary_case_base:\n",
    "            if episode_ended_successfully and case in case_base:\n",
    "                case.trust_value += 0.1  # Increment trust value if the episode ended successfully and the case is in the case base\n",
    "            elif not episode_ended_successfully and case in case_base:\n",
    "                case.trust_value -= 0.1  # Decrement trust value if the episode ended unsuccessfully and the case is in the case base\n",
    "            case.trust_value = max(0, min(case.trust_value,1))  # Ensure trust value is within[0,1]\n",
    "\n",
    "    @staticmethod\n",
    "    def retain(case_base, temporary_case_base, episode_ended_successfully, threshold=0):\n",
    "        # print(f\"temporary case base {temporary_case_base}\")\n",
    "        for case in temporary_case_base:\n",
    "            # print(f\"case {case}\")\n",
    "            # if episode_ended_successfully and case not in case_base:\n",
    "            if case not in case_base:\n",
    "                case_base.append(case)  # Insert case into case base if the episode ended successfully and it's not already in the case base\n",
    "\n",
    "        # Remove cases with trust value < threshold\n",
    "        case_base[:] = [case for case in case_base if case.trust_value >= threshold]\n",
    "        print(f\"case after loop {case.problem.tolist()}\")\n",
    "        print(f\"case base after loop {case_base}\")\n",
    "\n",
    "        # Generate case_base_data\n",
    "        case_base_data = [{\"problem\": case.problem.tolist(), \"solution\": case.solution, \"trust_value\": case.trust_value} for case in case_base]\n",
    "\n",
    "        # Save case base after each episode\n",
    "        QCBRL.save_case_base(case_base) \n",
    "        # filename = \"case_base.json\"\n",
    "        # with open(filename, 'w') as file:\n",
    "        #     json.dump(case_base_data, file)\n",
    "        # print(\"Case base saved successfully.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def sim_q(state1, state2):\n",
    "        state1 = np.atleast_1d(state1)  # Ensure state1 is at least 1-dimensional\n",
    "        state2 = np.atleast_1d(state2)  # Ensure state2 is at least 1-dimensional\n",
    "        CNDMaxDist = 6  # Maximum distance between two nodes in the CND\n",
    "        v = state1.size  # Total number of objects the agent can perceive\n",
    "        DistQ = np.sum([Case.Dmin_phi(Objic, Objip) for Objic, Objip in zip(state1, state2)])\n",
    "        similarity = (CNDMaxDist * v - DistQ) / (CNDMaxDist * v)\n",
    "        return similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def Dmin_phi(X1, X2):\n",
    "        return np.max(np.abs(X1 - X2))\n",
    "\n",
    "class QCBRL:\n",
    "    def __init__(self, actions, threshold=0.5, epsilon=0.1, gamma=0.99, alpha=0.1, lambd=0.9):\n",
    "        self.problem_solver = ProblemSolver(actions, epsilon, gamma, alpha, lambd)\n",
    "        self.case_base = []\n",
    "        self.threshold = threshold\n",
    "        self.temporary_case_base = []\n",
    "\n",
    "    def train(self, episodes, max_steps, render=False):\n",
    "        env = gym.make('FrozenLake-v1')\n",
    "        rewards = []\n",
    "        episode_rewards = []\n",
    "        memory_usage = []\n",
    "        gpu_memory_usage = []\n",
    "\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # GPU Index\n",
    "\n",
    "        for episode in range(1, episodes + 1):\n",
    "            state = env.reset()\n",
    "            total_reward = 0\n",
    "            self.temporary_case_base = []\n",
    "\n",
    "            for step in range(max_steps):\n",
    "                if render:\n",
    "                    env.render()\n",
    "                action, next_state = self.take_action(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                next_state = np.array(next_state)\n",
    "                total_reward += reward\n",
    "\n",
    "                state = next_state\n",
    "                \n",
    "                if done:\n",
    "                    rewards.append(total_reward)\n",
    "                    episode_rewards.append(total_reward)\n",
    "                    print(f\"Episode {episode} ended after {step + 1} steps with total reward: {total_reward}\")\n",
    "                    break\n",
    "                \n",
    "                if done and reward == 1.0:\n",
    "                    episode_ended_successfully = True\n",
    "                else:\n",
    "                    episode_ended_successfully = False\n",
    "\n",
    "            Case.revise(self.case_base, self.temporary_case_base, episode_ended_successfully)\n",
    "            Case.retain(self.case_base, self.temporary_case_base, episode_ended_successfully, self.threshold)\n",
    "\n",
    "            memory_usage.append(psutil.virtual_memory().percent)\n",
    "            gpu_memory_usage.append(pynvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**2)\n",
    "\n",
    "        self.save_case_base_temporary()  # Save temporary case base after training\n",
    "        # self.save_case_base()  # Save case base after training\n",
    "\n",
    "        env.close()\n",
    "        self.plot_rewards(episode_rewards)\n",
    "        self.plot_resources(memory_usage, gpu_memory_usage)\n",
    "\n",
    "    def take_action(self, state):\n",
    "        if np.isscalar(state):\n",
    "            state_array = np.array([state])\n",
    "        else:\n",
    "            state_array = np.asarray(state)\n",
    "\n",
    "        similar_solution = Case.retrieve(state_array, self.case_base)\n",
    "        if similar_solution is not None:\n",
    "            action = similar_solution.solution\n",
    "            next_state = state\n",
    "        else:\n",
    "            action = self.problem_solver.choose_action(state_array)\n",
    "            next_state = state_array\n",
    "\n",
    "        if not isinstance(next_state, np.ndarray):\n",
    "            next_state = np.array(next_state)\n",
    "\n",
    "        # Add new case and similar cases to temporary_case_base\n",
    "        c = Case(state, action)\n",
    "        Case.reuse(c, self.case_base, self.temporary_case_base)\n",
    "\n",
    "        return action, next_state\n",
    "\n",
    "    def save_case_base_temporary(self):\n",
    "        filename = \"case_base_temporary.json\"\n",
    "        case_base_data = [{\"problem\": case.problem.tolist(), \"solution\": case.solution, \"trust_value\": case.trust_value} for case in self.temporary_case_base]\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "    def save_case_base(case_base):\n",
    "        filename = \"case_base.json\"\n",
    "        case_base_data = [{\"problem\": case.problem.tolist(), \"solution\": case.solution, \"trust_value\": case.trust_value} for case in case_base]\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(case_base_data, file)\n",
    "\n",
    "            print(\"Case base saved successfully.\")  # Add this line to check if the case base is being saved\n",
    "        \n",
    "    def load_case_base(self):\n",
    "        filename = \"case_base.json\"\n",
    "        try:\n",
    "            with open(filename, 'r') as file:\n",
    "                case_base_data = json.load(file)\n",
    "                self.case_base = [Case(np.array(case[\"problem\"]), case[\"solution\"], case[\"trust_value\"]) for case in case_base_data]\n",
    "                print(\"Case base loaded successfully.\")  # Add this line to check if the case base is being loaded\n",
    "        except FileNotFoundError:\n",
    "            print(\"Case base file not found. Starting with an empty case base.\")\n",
    "\n",
    "    def plot_rewards(self, rewards):\n",
    "        plt.plot(rewards)\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.title('Rewards over Episodes')\n",
    "        plt.grid(True)\n",
    "        plt.show() \n",
    "\n",
    "    def plot_resources(self, memory_usage, gpu_memory_usage):\n",
    "        plt.plot(memory_usage, label='Memory (%)')\n",
    "        plt.plot(gpu_memory_usage, label='GPU Memory (MB)')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Resource Usage')\n",
    "        plt.title('Resource Usage over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    actions = 4  # Number of actions in FrozenLake-v1\n",
    "    agent = QCBRL(actions)\n",
    "    agent.train(episodes=10, max_steps=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
