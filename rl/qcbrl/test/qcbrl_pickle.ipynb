{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, actions, epsilon=0.1, gamma=0.99, alpha=0.1, lambd=0.9):\n",
    "        self.actions = actions\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.lambd = lambd\n",
    "        self.Q = {}  # Q-values table\n",
    "        self.e = {}  # Eligibility traces table\n",
    "\n",
    "    def choose_action(self, sq):\n",
    "        sq_tuple = tuple(sq)  # Convert numpy array to tuple\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.actions)\n",
    "        else:\n",
    "            if sq_tuple in self.Q:  # Use the tuple as the key\n",
    "                return np.argmax(self.Q[sq_tuple])\n",
    "            else:\n",
    "                return np.random.choice(self.actions)\n",
    "\n",
    "\n",
    "    def update_Q(self, sq, action, reward, next_sq, next_action):\n",
    "        if sq not in self.Q:\n",
    "            self.Q[sq] = np.zeros(self.actions)\n",
    "            self.e[sq] = np.zeros(self.actions)\n",
    "\n",
    "        delta = reward + self.gamma * self.Q.get(next_sq, np.zeros(self.actions))[next_action] - self.Q[sq][action]\n",
    "        self.e[sq][action] += 1\n",
    "\n",
    "        for state in self.Q:\n",
    "            for a in range(self.actions):\n",
    "                self.Q[state][a] += self.alpha * delta * self.e[state][a]\n",
    "                self.e[state][a] *= self.gamma * self.lambd\n",
    "\n",
    "    def solve_problem(self, sq, reward, next_sq):\n",
    "        action = self.choose_action(sq)\n",
    "        if reward is not None:  # If reward is received\n",
    "            next_action = self.choose_action(next_sq)\n",
    "            self.update_Q(sq, action, reward, next_sq, next_action)\n",
    "            sq = next_sq\n",
    "            return action, sq\n",
    "        else:\n",
    "            return action, sq\n",
    "\n",
    "def Retrieve(sq, C_B, threshold=0.5):\n",
    "    sim_candidates = []\n",
    "\n",
    "    for c in C_B:\n",
    "        sim_value = SimQ(sq, c)\n",
    "        if sim_value == 1:\n",
    "            return c\n",
    "        elif sim_value > threshold:\n",
    "            sim_candidates.append((sim_value, c))\n",
    "\n",
    "    if not sim_candidates:\n",
    "        return None\n",
    "\n",
    "    sim_candidates.sort(reverse=True)  # Sort in descending order of similarity value\n",
    "    return sim_candidates[0][1]  # Return the case with the highest similarity value\n",
    "\n",
    "def Reuse(c, tc):\n",
    "    hashed_c = tuple(array.tobytes() if isinstance(array, np.ndarray) else array for array in c)\n",
    "    tc[hashed_c] = c\n",
    "\n",
    "def revise(self, episode_ended_successfully):\n",
    "    new_C_B = {}  # Create a new dictionary to store revised cases\n",
    "    for key, value in self.C_B.items():\n",
    "        if isinstance(key, np.ndarray):\n",
    "            key_tuple = tuple(key.tolist())  # Convert numpy arrays to tuples\n",
    "        elif not isinstance(key, tuple):\n",
    "            key_tuple = (key,)  # Wrap non-tuple keys in a tuple\n",
    "        else:\n",
    "            key_tuple = key\n",
    "        \n",
    "        if episode_ended_successfully and key_tuple in self.C_B:\n",
    "            new_C_B[key_tuple] = value + 1  # Increment trust value of the case\n",
    "        elif not episode_ended_successfully and key_tuple in self.C_B:\n",
    "            new_C_B[key_tuple] = value - 1  # Decrement trust value of the case\n",
    "    return new_C_B\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Retain(tc, C_B, episode_ended_successfully, threshold=0):\n",
    "    for c in tc:\n",
    "        if episode_ended_successfully:  # Check if episode ended successfully\n",
    "            # Convert keys to tuples if necessary\n",
    "            key = tuple(array.tolist() if isinstance(array, np.ndarray) else array for array in c)\n",
    "            if key not in C_B:\n",
    "                C_B[key] = 1  # Insert c into C_B with initial trust value 1\n",
    "            else:\n",
    "                C_B[key] += 1  # Increment trust value of c in C_B\n",
    "\n",
    "    # Remove cases from C_B with trust value less than threshold\n",
    "    cases_to_remove = [key for key, trust_value in C_B.items() if trust_value < threshold]\n",
    "    for key in cases_to_remove:\n",
    "        del C_B[key]\n",
    "\n",
    "\n",
    "\n",
    "def SimQ(sq, c):\n",
    "    # Example of a similarity function comparing qualitative states\n",
    "    similarity = np.random.rand()  # Replace this with your own similarity calculation\n",
    "    return similarity\n",
    "\n",
    "class QCBRL:\n",
    "    def __init__(self, actions, threshold=0.5, epsilon=0.1, gamma=0.99, alpha=0.1, lambd=0.9):\n",
    "        self.problem_solver = ProblemSolver(actions, epsilon, gamma, alpha, lambd)\n",
    "        self.C_B = {}\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def train(self, episodes, max_steps):\n",
    "        for _ in range(episodes):\n",
    "            state = self.reset_environment()\n",
    "            for _ in range(max_steps):\n",
    "                action, next_state = self.take_action(state)\n",
    "                reward, next_state = self.observe_reward(next_state)\n",
    "                c = (state, action, reward, next_state)\n",
    "                self.reuse(c)\n",
    "                # Determine if the episode ended successfully\n",
    "                episode_ended_successfully = (reward is not None)\n",
    "                if episode_ended_successfully:\n",
    "                    new_C_B = {}\n",
    "                    for key, value in self.C_B.items():\n",
    "                        if isinstance(key, tuple):\n",
    "                            new_key = key\n",
    "                        else:\n",
    "                            new_key = (key,)\n",
    "                        new_C_B[new_key] = value\n",
    "                    self.C_B = new_C_B\n",
    "                state = next_state\n",
    "                if reward is not None:\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "    def reset_environment(self):\n",
    "        return np.random.rand(4)  # Example of resetting the environment, replace with your environment's reset function\n",
    "\n",
    "    def take_action(self, state):\n",
    "        action, next_state = self.problem_solver.solve_problem(state, None, None)\n",
    "        return action, next_state\n",
    "\n",
    "    def observe_reward(self, state):\n",
    "        # Example of taking an action in the environment and getting the reward and next state\n",
    "        next_state = state + np.random.randn(4)  # Random next state\n",
    "        reward = np.random.randn()  # Random reward\n",
    "        return reward, next_state\n",
    "\n",
    "    def reuse(self, c):\n",
    "        Reuse(c, self.C_B)\n",
    "\n",
    "    def revise(self, episode_ended_successfully):\n",
    "        Revise(self.C_B, episode_ended_successfully)\n",
    "\n",
    "    def retain(self, episode_ended_successfully):\n",
    "        Retain(self.C_B, episode_ended_successfully, self.threshold)\n",
    "\n",
    "    def save_case_base(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.C_B, f)\n",
    "\n",
    "    def load_case_base(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.C_B = pickle.load(f)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    actions = 3  # Example number of actions\n",
    "    agent = QCBRL(actions)\n",
    "    agent.train(episodes=100, max_steps=100)\n",
    "    agent.save_case_base(\"case_base.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
