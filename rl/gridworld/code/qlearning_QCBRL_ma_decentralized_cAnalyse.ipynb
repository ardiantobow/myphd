{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- starting point of Episode 0 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 0], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 0], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['agent']], 0]\n",
      "next state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "state for agent 0: [[0, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[0, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 0], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 0], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 hit an obstacle! Next state: [212.5, 62.5, 237.5, 87.5]\n",
      "state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['obstacle']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['obstacle']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 3], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 3], False, [['agent']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 2], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 2], False, [['agent']], 0]\n",
      "next state for agent 1: [[6, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['agent']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['agent']], 0]\n",
      "next state for agent 1: [[7, 5], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 5], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['agent']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06c7730>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06e8e50>, <__main__.Case object at 0x7359c06e8f70>, <__main__.Case object at 0x7359c06e9030>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e91b0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06e9420>, <__main__.Case object at 0x7359c06e9510>, <__main__.Case object at 0x7359c06e95d0>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06e9840>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06e9ab0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e9c60>, <__main__.Case object at 0x7359c06e9d20>, <__main__.Case object at 0x7359c06e9de0>, <__main__.Case object at 0x7359c06e9ea0>, <__main__.Case object at 0x7359c06e9f90>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06ea170>, <__main__.Case object at 0x7359c06ea290>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06ea1d0>, <__main__.Case object at 0x7359c06ea4a0>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06ea650>, <__main__.Case object at 0x7359c06ea710>, <__main__.Case object at 0x7359c06ea7d0>, <__main__.Case object at 0x7359c06ea8c0>, <__main__.Case object at 0x7359c06ea980>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eab00>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06d4a30>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06e8cd0>, <__main__.Case object at 0x7359c06e8f10>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e8fd0>, <__main__.Case object at 0x7359c06e91e0>, <__main__.Case object at 0x7359c06e92d0>, <__main__.Case object at 0x7359c06e93c0>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06e9480>, <__main__.Case object at 0x7359c06e9570>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06e97b0>, <__main__.Case object at 0x7359c06e96f0>, <__main__.Case object at 0x7359c06e98a0>, <__main__.Case object at 0x7359c06e9960>, <__main__.Case object at 0x7359c06e9a20>, <__main__.Case object at 0x7359c06e9b10>, <__main__.Case object at 0x7359c06e9bd0>, <__main__.Case object at 0x7359c06e9cc0>, <__main__.Case object at 0x7359c06e9d80>, <__main__.Case object at 0x7359c06e9e40>, <__main__.Case object at 0x7359c06e9f00>, <__main__.Case object at 0x7359c06e9ff0>, <__main__.Case object at 0x7359c06ea0e0>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06ea2c0>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06ea500>, <__main__.Case object at 0x7359c06ea5f0>, <__main__.Case object at 0x7359c06ea6b0>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06ea920>, <__main__.Case object at 0x7359c06ea9e0>, <__main__.Case object at 0x7359c06eaaa0>]\n",
      "agent1 comm temp case base: []\n",
      "Episode succeeded, case (5, 4) is empty. Temporary case base stored to the case base: ((5, 4), 2, 0.5)\n",
      "Episode succeeded, case (6, 4) is empty. Temporary case base stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 5) is empty. Temporary case base stored to the case base: ((7, 5), 1, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) is empty. Temporary case base stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 4, 0.5)\n",
      "Episode succeeded, case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 3) is empty. Temporary case base stored to the case base: ((8, 3), 1, 0.5)\n",
      "Episode succeeded, case (8, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) is empty. Temporary case base stored to the case base: ((9, 2), 3, 0.5)\n",
      "Episode succeeded, case (9, 3) is empty. Temporary case base stored to the case base: ((9, 3), 1, 0.5)\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 4, 0.5)\n",
      "Episode succeeded, case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) is empty. Temporary case base stored to the case base: ((7, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 0.5, time steps: 36\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 0.5, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 0.5, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "Episode: 0, Total Steps: 44, Total Rewards: [-114, 57], Status Episode: False\n",
      "------------------------------------------End of episode 0 loop--------------------\n",
      "----- starting point of Episode 1 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 0.5, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.5, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 0.5, 3)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 1), 2, 0.5, 14)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.5, 14)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 1), 2, 0.5, 14)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 2), 3, 0.5, 17)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.5, 17)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 2), 3, 0.5, 17)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((8, 2), 3, 0.5, 21)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.5, 21)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((8, 2), 3, 0.5, 21)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((8, 1), 4, 0.5, 13)]\n",
      "comm next state for agent 0: ((8, 1), 4, 0.5, 13)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((8, 1), 4, 0.5, 13)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.5, 14)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.5, 14)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.5, 14)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((9, 2), 3, 0.5, 17)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.5, 17)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((9, 2), 3, 0.5, 17)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((9, 2), 3, 0.5, 17)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.5, 17)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((9, 2), 3, 0.5, 17)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((8, 2), 3, 0.5, 21)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.5, 21)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((8, 2), 3, 0.5, 21)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((7, 2), 2, 0.5, 28)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.5, 28)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((7, 2), 2, 0.5, 28)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((7, 3), 2, 0.5, 33)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.5, 33)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((7, 3), 2, 0.5, 33)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((7, 4), 3, 0.5, 37)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.5, 37)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((7, 4), 3, 0.5, 37)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((6, 4), 3, 0.5, 42)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.5, 42)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((6, 4), 3, 0.5, 42)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((5, 4), 2, 0.5, 43)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.5, 43)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 1 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((5, 4), 2, 0.5, 43)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 hit an obstacle! Next state: [62.5, 162.5, 87.5, 187.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 3], False, [['obstacle']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06e3c70>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06e8f70>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e9420>, <__main__.Case object at 0x7359c06e9840>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06e9fc0>, <__main__.Case object at 0x7359c06ea3b0>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06e8f40>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06e9b10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359d22379d0>, <__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e9030>, <__main__.Case object at 0x7359c06e9240>, <__main__.Case object at 0x7359c06e95d0>, <__main__.Case object at 0x7359c06e99f0>, <__main__.Case object at 0x7359c06e9c60>, <__main__.Case object at 0x7359c06e9ea0>, <__main__.Case object at 0x7359c06ea170>, <__main__.Case object at 0x7359c06ea1d0>, <__main__.Case object at 0x7359c06ea650>, <__main__.Case object at 0x7359c06ea8c0>]\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 4) is empty. Temporary case base stored to the case base: ((5, 4), 2, 0.5)\n",
      "Integrated case process. comm case (6, 4) is empty. Temporary case base stored to the case base: ((6, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 0.5)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 0.5)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 0.5)\n",
      "Integrated case process. comm case (9, 2) is empty. Temporary case base stored to the case base: ((9, 2), 3, 0.5)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.5)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 2, 0.5)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 4, 0.5)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.5)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.5)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06e8e50>, <__main__.Case object at 0x7359c06e91b0>, <__main__.Case object at 0x7359c06e9540>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06e9780>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06ea410>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06e9960>, <__main__.Case object at 0x7359c06e9c00>, <__main__.Case object at 0x7359c06ea0e0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.6, time steps: 43\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.6, time steps: 42\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 0.7, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.6, time steps: 33\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 0.7, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.6, time steps: 28\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 0.7, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 0.7, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 0.7, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.6, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 0.7, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.6, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 0.7, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (5, 5) is empty. Temporary case base stored to the case base: ((5, 5), 0, 0.5)\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 4), 2, 0.5, 23)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 4), 3, 0.5, 23)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 4), 3, 0.5, 23)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 3), 2, 0.5, 23)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 2), 2, 0.5, 23)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 23\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 23\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 23\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 0.7, time steps: 36\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 23\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.7, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 23\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 0.7, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.7, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 0.7, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.6, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 0.7, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.6, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 0.7, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.5, time steps: 22\n",
      "Episode: 1, Total Steps: 23, Total Rewards: [-122, 84], Status Episode: False\n",
      "------------------------------------------End of episode 1 loop--------------------\n",
      "----- starting point of Episode 2 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 0.6, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.6, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 2 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 0.6, 3)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((9, 1), 2, 0.6, 14)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.6, 14)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 2 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((9, 1), 2, 0.6, 14)]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], ((9, 2), 3, 0.6, 17)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.6, 17)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 2 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 2], False, [['agent']], ((9, 2), 3, 0.6, 17)]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], ((8, 2), 3, 0.6, 21)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.6, 21)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 2 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 2], False, [['agent']], ((8, 2), 3, 0.6, 21)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((7, 2), 2, 0.5, 23)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.5, 23)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 2 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((7, 2), 2, 0.5, 23)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((7, 3), 2, 0.5, 23)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.5, 23)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['agent']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 2 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [112.5, 112.5, 137.5, 137.5]\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((7, 3), 2, 0.5, 23)]\n",
      "next state for agent 0: [[2, 2], False, [['obstacle']], ((7, 4), 3, 0.5, 23)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.5, 23)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 2 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['obstacle']], ((7, 4), 3, 0.5, 23)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((7, 4), 3, 0.5, 23)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.5, 23)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 2 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((7, 4), 3, 0.5, 23)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((7, 4), 3, 0.5, 23)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.5, 23)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06e9420>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e9de0>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06ea9b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e9fc0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eab00>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.6)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.6)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06e95d0>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06e9150>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e9b10>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 0.8999999999999999, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 0.8999999999999999, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 0.8999999999999999, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 0.8999999999999999, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.7, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 0.8999999999999999, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.7, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 0.8999999999999999, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.8, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 0.8999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.7, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 4), 2, 0.5, 10)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 4), 3, 0.5, 10)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 4), 3, 0.5, 10)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 3), 2, 0.5, 10)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 2), 2, 0.5, 10)\n",
      "Episode succeeded, updated case base with fewer steps: ((8, 2), 3, 0.5, 10)\n",
      "Episode succeeded, updated case base with fewer steps: ((9, 2), 3, 0.5, 10)\n",
      "Episode succeeded, updated case base with fewer steps: ((9, 1), 2, 0.5, 10)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 0.8999999999999999, time steps: 36\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.8999999999999999, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 0.8999999999999999, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.8999999999999999, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 0.8999999999999999, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 0.8999999999999999, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.8, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 0.8999999999999999, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.7, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "Episode: 2, Total Steps: 10, Total Rewards: [-107, 91], Status Episode: False\n",
      "------------------------------------------End of episode 2 loop--------------------\n",
      "----- starting point of Episode 3 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 0.7, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.7, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 0.7, 3)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 1), 2, 0.5, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.5, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 1), 2, 0.5, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((9, 2), 3, 0.5, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.5, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((9, 2), 3, 0.5, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((8, 2), 3, 0.5, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.5, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((8, 2), 3, 0.5, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((7, 2), 2, 0.5, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.5, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((7, 2), 2, 0.5, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((7, 3), 2, 0.5, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.5, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((7, 3), 2, 0.5, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((7, 4), 3, 0.5, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.5, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((7, 4), 3, 0.5, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((6, 4), 3, 0.5, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.5, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((6, 4), 3, 0.5, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "next state for agent 0: [[1, 1], False, [['agent']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['agent']], ((5, 5), 0, 0.7, 22)]\n",
      "next state for agent 0: [[1, 1], False, [['agent']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['agent']], ((5, 5), 0, 0.7, 22)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 3 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [112.5, 112.5, 137.5, 137.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 0.7, 22)]\n",
      "next state for agent 0: [[2, 2], False, [['obstacle']], ((5, 5), 0, 0.7, 22)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 22)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06c7730>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06e9de0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06e90c0>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06e9870>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06bd750>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06e9840>, <__main__.Case object at 0x7359c06e8d00>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06e9c00>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06ea410>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06e9540>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) is empty. Temporary case base stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.5)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.5)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.7)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06e9b10>, <__main__.Case object at 0x7359c06ea3b0>, <__main__.Case object at 0x7359c06e9420>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06e95d0>, <__main__.Case object at 0x7359c06eb250>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06eaf80>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06e8e50>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.6, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.6, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.6, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.6, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.6, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.6, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.6, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.6, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1.0, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.7999999999999999, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 0.7999999999999999, time steps: 22\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 5), 0, 0.5, 19)\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.6, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.6, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 36\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.6, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.6, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1.0, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.7999999999999999, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.5, time steps: 19\n",
      "Episode: 3, Total Steps: 19, Total Rewards: [-118, 92], Status Episode: False\n",
      "------------------------------------------End of episode 3 loop--------------------\n",
      "----- starting point of Episode 4 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 0.7999999999999999, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.7999999999999999, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 0.7999999999999999, 3)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 1), 2, 0.6, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.6, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 1), 2, 0.6, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 2), 3, 0.6, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.6, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 2), 3, 0.6, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((8, 2), 3, 0.6, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.6, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((8, 2), 3, 0.6, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((7, 2), 2, 0.6, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.6, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((7, 2), 2, 0.6, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((7, 3), 2, 0.6, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.6, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((7, 3), 2, 0.6, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((7, 4), 3, 0.6, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.6, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((7, 4), 3, 0.6, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((6, 4), 3, 0.6, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.6, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((6, 4), 3, 0.6, 10)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((5, 4), 2, 0.6, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.6, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((5, 4), 2, 0.6, 10)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 0.5, 19)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.5, 19)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 0.5, 19)]\n",
      "next state for agent 0: [[1, 2], False, [['agent']], ((5, 5), 0, 0.5, 19)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.5, 19)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 4 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [62.5, 162.5, 87.5, 187.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 2], False, [['agent']], ((5, 5), 0, 0.5, 19)]\n",
      "next state for agent 0: [[1, 3], False, [['obstacle']], ((5, 5), 0, 0.5, 19)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.5, 19)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06e8d90>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb1c0>, <__main__.Case object at 0x7359c06e9d80>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06eb130>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06e8a90>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06eaef0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.5)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.5)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.5)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.6)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.6)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.6)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.6)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.6)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.6)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.7999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c06e0370>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e9a20>, <__main__.Case object at 0x7359c06eb070>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06e9780>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06e90c0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.7, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.7, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.7, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.7, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.7, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.7, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.7, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.7, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.8999999999999999, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 0.6, time steps: 19\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 5), 0, 0.5, 12)\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.7, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.7, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 36\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.7, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.7, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.7, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.7, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.8999999999999999, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.5, time steps: 12\n",
      "Episode: 4, Total Steps: 12, Total Rewards: [-111, 92], Status Episode: False\n",
      "------------------------------------------End of episode 4 loop--------------------\n",
      "----- starting point of Episode 5 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 0], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((9, 0), 2, 0.8999999999999999, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.8999999999999999, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((9, 0), 2, 0.8999999999999999, 3)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 0.7, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 0.7, 10)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((9, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [112.5, 112.5, 137.5, 137.5]\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((9, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['obstacle']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['obstacle']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 5], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 5], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 6], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 6], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 6], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 6], False, [['agent']], 0]\n",
      "next state for agent 1: [[7, 6], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 6], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 5], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 5], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 5 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 0.7, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06e8a90>, <__main__.Case object at 0x7359c06e8d90>, <__main__.Case object at 0x7359c06eb1c0>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e9780>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06eacb0>, <__main__.Case object at 0x7359c06eac50>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06e9ba0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06e9c00>, <__main__.Case object at 0x7359c06e8e80>, <__main__.Case object at 0x7359c06e8d00>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06e9de0>, <__main__.Case object at 0x7359c06eada0>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06eb6d0>, <__main__.Case object at 0x7359c06ea5c0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.7)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06e0370>, <__main__.Case object at 0x7359c06eaef0>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06e9d80>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06e8f40>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06ead70>, <__main__.Case object at 0x7359c06ead40>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06eae30>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.7999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.7999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.7999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.7999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.7999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.9999999999999999, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 0.7, time steps: 12\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 5), 1, 0.5, 17)\n",
      "Episode succeeded, case (7, 6) is empty. Temporary case base stored to the case base: ((7, 6), 1, 0.5)\n",
      "Episode succeeded, case (6, 6) is empty. Temporary case base stored to the case base: ((6, 6), 4, 0.5)\n",
      "Episode succeeded, case (6, 6) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 5) is empty. Temporary case base stored to the case base: ((6, 5), 2, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.7999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.7999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.7999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.7999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.7999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.9999999999999999, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 0.5, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 0.5, time steps: 9\n",
      "Episode: 5, Total Steps: 17, Total Rewards: [-104, 84], Status Episode: False\n",
      "------------------------------------------End of episode 5 loop--------------------\n",
      "----- starting point of Episode 6 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 0.9999999999999999, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.9999999999999999, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 0.9999999999999999, 3)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 1), 2, 0.7999999999999999, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.7999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 1), 2, 0.7999999999999999, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 6 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 2), 3, 0.7999999999999999, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.7999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['agent']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 2), 3, 0.7999999999999999, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((8, 2), 3, 0.7999999999999999, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((8, 2), 3, 0.7999999999999999, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((7, 2), 2, 0.7999999999999999, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.7999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((7, 2), 2, 0.7999999999999999, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((7, 3), 2, 0.7999999999999999, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.7999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((7, 3), 2, 0.7999999999999999, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((7, 4), 3, 0.7999999999999999, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.7999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((7, 4), 3, 0.7999999999999999, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 6 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((6, 3), 2, 1, 30)]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((6, 3), 2, 1, 30)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((6, 4), 3, 0.7999999999999999, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.7999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((6, 4), 3, 0.7999999999999999, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((5, 4), 2, 0.7999999999999999, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.7999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((5, 4), 2, 0.7999999999999999, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 6 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['agent']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[3, 2], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 6 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [112.5, 112.5, 137.5, 137.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 2], False, [['empty']], ((5, 5), 0, 0.7, 12)]\n",
      "next state for agent 0: [[2, 2], False, [['obstacle']], ((5, 5), 0, 0.7, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06e0370>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06e9c00>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06e9de0>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06eab00>, <__main__.Case object at 0x7359c06e9a20>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06e9f00>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06ea3b0>, <__main__.Case object at 0x7359c06e95d0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06eb970>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06ebcd0>, <__main__.Case object at 0x7359c06ebdf0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06eb0d0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06e9fc0>, <__main__.Case object at 0x7359c06eb1c0>, <__main__.Case object at 0x7359c06e9780>, <__main__.Case object at 0x7359c06eac50>, <__main__.Case object at 0x7359c06eaef0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06eae90>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06e9b10>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06eb0a0>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eb2e0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06eba00>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06ebeb0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (6, 3) is empty. Temporary case base stored to the case base: ((6, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.9999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06c7730>, <__main__.Case object at 0x7359c06e3c70>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06e8e80>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06eada0>, <__main__.Case object at 0x7359c06eb6d0>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06eb4f0>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06ea020>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06eb250>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06eb190>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06eb9d0>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06ebfa0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.8999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.8999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 0.7, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.8999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.8999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.8999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 0.7, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 0.7, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.8999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.8999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 0.7, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.8999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.8999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.8999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 0.7, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 0.7, time steps: 9\n",
      "Episode: 6, Total Steps: 35, Total Rewards: [-134, 89], Status Episode: False\n",
      "------------------------------------------End of episode 6 loop--------------------\n",
      "----- starting point of Episode 7 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 0.8999999999999999, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.8999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 0.8999999999999999, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['agent']], ((9, 2), 3, 0.8999999999999999, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.8999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['agent']], ((9, 2), 3, 0.8999999999999999, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((8, 2), 3, 0.8999999999999999, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.8999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((8, 2), 3, 0.8999999999999999, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((7, 2), 2, 0.8999999999999999, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.8999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((7, 2), 2, 0.8999999999999999, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((7, 3), 2, 0.8999999999999999, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.8999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((7, 3), 2, 0.8999999999999999, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((7, 4), 3, 0.8999999999999999, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.8999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((7, 4), 3, 0.8999999999999999, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((6, 4), 3, 0.8999999999999999, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.8999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((6, 4), 3, 0.8999999999999999, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((5, 4), 2, 0.8999999999999999, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.8999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((5, 4), 2, 0.8999999999999999, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 7 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 7 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [212.5, 62.5, 237.5, 87.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "next state for agent 0: [[4, 1], False, [['obstacle']], ((5, 5), 0, 0.7999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.7999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06e0370>, <__main__.Case object at 0x7359c06ebeb0>, <__main__.Case object at 0x7359c06e9840>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e9780>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06eb0a0>, <__main__.Case object at 0x7359c06eb940>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06eacb0>, <__main__.Case object at 0x7359c06e9d80>, <__main__.Case object at 0x7359c06eb490>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06c7730>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06eac20>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06e9de0>, <__main__.Case object at 0x7359c06eab00>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06ea950>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06eac50>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06e9b10>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e8d90>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06eadd0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.9999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.9999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 0.8999999999999999, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.9999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.9999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.9999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.9999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.9999999999999999, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 0.8999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.9999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.9999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 0.8999999999999999, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.9999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.9999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.9999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.9999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.9999999999999999, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 0.8999999999999999, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "Episode: 7, Total Steps: 19, Total Rewards: [-118, 92], Status Episode: False\n",
      "------------------------------------------End of episode 7 loop--------------------\n",
      "----- starting point of Episode 8 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 0], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 8 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((9, 1), 2, 0.9999999999999999, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.9999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((9, 1), 2, 0.9999999999999999, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((9, 2), 3, 0.9999999999999999, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.9999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((9, 2), 3, 0.9999999999999999, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((8, 2), 3, 0.9999999999999999, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.9999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((8, 2), 3, 0.9999999999999999, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((7, 2), 2, 0.9999999999999999, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.9999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((7, 2), 2, 0.9999999999999999, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((7, 3), 2, 0.9999999999999999, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.9999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((7, 3), 2, 0.9999999999999999, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((7, 4), 3, 0.9999999999999999, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.9999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((7, 4), 3, 0.9999999999999999, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((6, 4), 3, 0.9999999999999999, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.9999999999999999, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((6, 4), 3, 0.9999999999999999, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 8 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[0, 5], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 5], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[1, 5], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 8 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 5], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 5], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 5], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[2, 6], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 6], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[2, 5], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 5], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[1, 5], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 8 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [62.5, 212.5, 87.5, 237.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 5], False, [['empty']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "next state for agent 0: [[1, 4], False, [['obstacle']], ((5, 5), 0, 0.8999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.8999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06c7730>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06e9870>, <__main__.Case object at 0x7359c06eac20>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06eab00>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06e9780>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eb940>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e9d80>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06ea410>, <__main__.Case object at 0x7359c06e8d90>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06ea6b0>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06e8a60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06e9c00>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06e9f00>, <__main__.Case object at 0x7359c06eaef0>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06e94b0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06e9840>, <__main__.Case object at 0x7359c06ebeb0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06eb490>, <__main__.Case object at 0x7359c06eac50>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06eaa10>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06e8c70>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 8, Total Steps: 23, Total Rewards: [-122, 91], Status Episode: False\n",
      "------------------------------------------End of episode 8 loop--------------------\n",
      "----- starting point of Episode 9 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 9 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 9 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 1], False, [['agent']], ((5, 5), 0, 0.9999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.9999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['agent']], ((5, 5), 0, 0.9999999999999999, 12)]\n",
      "next state for agent 0: [[3, 2], False, [['empty']], ((5, 5), 0, 0.9999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.9999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 2], False, [['empty']], ((5, 5), 0, 0.9999999999999999, 12)]\n",
      "next state for agent 0: [[4, 2], False, [['empty']], ((5, 5), 0, 0.9999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.9999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 9 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [212.5, 62.5, 237.5, 87.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 2], False, [['empty']], ((5, 5), 0, 0.9999999999999999, 12)]\n",
      "next state for agent 0: [[4, 1], False, [['obstacle']], ((5, 5), 0, 0.9999999999999999, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 0.9999999999999999, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e3c70>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eae60>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06ebf10>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06eb1c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06bd750>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb0d0>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e9a20>, <__main__.Case object at 0x7359c06e9780>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e9660>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.9999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.9999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.9999999999999999)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 0.9999999999999999)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06e9c00>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06e9f00>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06eb400>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 9, Total Steps: 15, Total Rewards: [-114, 92], Status Episode: False\n",
      "------------------------------------------End of episode 9 loop--------------------\n",
      "----- starting point of Episode 10 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 10 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 2], False, [['agent']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 2], False, [['agent']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 10 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 10 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 4], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 10 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 4], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 4], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 10 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [62.5, 212.5, 87.5, 237.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 4], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 4], False, [['obstacle']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06c7730>, <__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06eb1c0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06ea410>, <__main__.Case object at 0x7359c06eb7f0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06eacb0>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06eb340>, <__main__.Case object at 0x7359c06ebac0>, <__main__.Case object at 0x7359c06ebd00>, <__main__.Case object at 0x7359c06eb6d0>, <__main__.Case object at 0x7359c06cc070>, <__main__.Case object at 0x7359c06cc100>, <__main__.Case object at 0x7359c06cc220>, <__main__.Case object at 0x7359c06cc2b0>, <__main__.Case object at 0x7359c06cc400>, <__main__.Case object at 0x7359c06cc580>, <__main__.Case object at 0x7359c06cc520>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd750>, <__main__.Case object at 0x7359c06e0370>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06eab00>, <__main__.Case object at 0x7359c06e9960>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06e9870>, <__main__.Case object at 0x7359c06eb940>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06e9f00>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06eba30>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06eaa10>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06e9de0>, <__main__.Case object at 0x7359c06ebfa0>, <__main__.Case object at 0x7359c06e8d90>, <__main__.Case object at 0x7359c06e8f70>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e95d0>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06ebbe0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06e8b80>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06cc310>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06cc490>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06e9a20>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06ebf10>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06ebeb0>, <__main__.Case object at 0x7359c06eb0a0>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06eb250>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06cc0d0>, <__main__.Case object at 0x7359c06cc1f0>, <__main__.Case object at 0x7359c06cc190>, <__main__.Case object at 0x7359c06cc3d0>, <__main__.Case object at 0x7359c06cc370>, <__main__.Case object at 0x7359c06cc5e0>, <__main__.Case object at 0x7359c06cc6d0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 10, Total Steps: 40, Total Rewards: [-139, 91], Status Episode: False\n",
      "------------------------------------------End of episode 10 loop--------------------\n",
      "----- starting point of Episode 11 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[8, 0], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 11 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((8, 0), 2, 1, 12)]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 0], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((8, 0), 2, 1, 12)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 0: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 11 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['agent']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[5, 0], False, [['agent']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[5, 0], False, [['agent']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[5, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 11 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[5, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 11 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [262.5, 112.5, 287.5, 137.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 2], False, [['obstacle']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06e9c00>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e9de0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06ea6b0>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06e9120>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c7730>, <__main__.Case object at 0x7359c06bd750>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06eba30>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06e8d90>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e96c0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06e9e70>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eb9d0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06eb550>, <__main__.Case object at 0x7359c06ebbe0>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06eb010>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 11, Total Steps: 16, Total Rewards: [-115, 89], Status Episode: False\n",
      "------------------------------------------End of episode 11 loop--------------------\n",
      "----- starting point of Episode 12 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 12 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 12 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 12 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [112.5, 112.5, 137.5, 137.5]\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['obstacle']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 12 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['obstacle']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 12 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['agent']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 12 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 12 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 12 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 12 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 12 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 12 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 2], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06e3c70>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06eb520>, <__main__.Case object at 0x7359c06eba30>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06e9f00>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06ebd90>, <__main__.Case object at 0x7359c06ea470>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06e9e70>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e9960>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06e9ae0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 12, Total Steps: 12, Total Rewards: [-103, 89], Status Episode: False\n",
      "------------------------------------------End of episode 12 loop--------------------\n",
      "----- starting point of Episode 13 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 13 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 13 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 13 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 13 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['agent']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 13 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 1], False, [['agent']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 13 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 5], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 hit an obstacle! Next state: [462.5, 262.5, 487.5, 287.5]\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 5], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['obstacle']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['obstacle']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 2], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 2], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 2], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 2], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[3, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 48 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 49 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 50 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 51 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 52 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 53 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 54 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 55 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 2], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 56 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 2], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 57 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 58 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 3], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 3], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 59 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 3], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 3], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 60 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 3], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 61 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 62 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 63 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 64 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 65 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 66 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 67 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 68 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 69 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 70 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 71 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 72 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[3, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 2], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 73 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[3, 2], False, [['agent']], 0]\n",
      "next state for agent 0: [[3, 3], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 74 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[3, 3], False, [['empty']], 0]\n",
      "next state for agent 0: [[4, 3], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 75 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[4, 3], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 3], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 76 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[3, 3], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 3], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 13 in steps 77 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 hit an obstacle! Next state: [112.5, 112.5, 137.5, 137.5]\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 3], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 2], False, [['obstacle']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "next state for agent 1: [[9, 5], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06bd750>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06e9d80>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06e95d0>, <__main__.Case object at 0x7359c06e9f00>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06e8e50>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06eb970>, <__main__.Case object at 0x7359c06ebee0>, <__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06ebbe0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06eb9d0>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06eb7f0>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06eb490>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06e8e80>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06ea530>, <__main__.Case object at 0x7359c06fc160>, <__main__.Case object at 0x7359c06fc220>, <__main__.Case object at 0x7359c06fc2e0>, <__main__.Case object at 0x7359c06fc3a0>, <__main__.Case object at 0x7359c06fc460>, <__main__.Case object at 0x7359c06fc520>, <__main__.Case object at 0x7359c06fc5e0>, <__main__.Case object at 0x7359c06fc640>, <__main__.Case object at 0x7359c06fc790>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06fc970>, <__main__.Case object at 0x7359c06fc8b0>, <__main__.Case object at 0x7359c06fcb50>, <__main__.Case object at 0x7359c06fcc10>, <__main__.Case object at 0x7359c06fccd0>, <__main__.Case object at 0x7359c06fcd90>, <__main__.Case object at 0x7359c06fce50>, <__main__.Case object at 0x7359c06fcf10>, <__main__.Case object at 0x7359c06fcfd0>, <__main__.Case object at 0x7359c06fd090>, <__main__.Case object at 0x7359c06fd150>, <__main__.Case object at 0x7359c06fd210>, <__main__.Case object at 0x7359c06fd2d0>, <__main__.Case object at 0x7359c06fd390>, <__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06fd540>, <__main__.Case object at 0x7359c06fd5d0>, <__main__.Case object at 0x7359c06fd690>, <__main__.Case object at 0x7359c06fd720>, <__main__.Case object at 0x7359c06fd810>, <__main__.Case object at 0x7359c06fd930>, <__main__.Case object at 0x7359c06fd9c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ea7a0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb520>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06e9960>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ebac0>, <__main__.Case object at 0x7359c06e9a20>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06ebf10>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eb550>, <__main__.Case object at 0x7359c06eb940>, <__main__.Case object at 0x7359c06eb2e0>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06ea410>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06eb250>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06ebeb0>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06ebcd0>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06fc040>, <__main__.Case object at 0x7359c06fc100>, <__main__.Case object at 0x7359c06fc1c0>, <__main__.Case object at 0x7359c06fc280>, <__main__.Case object at 0x7359c06fc340>, <__main__.Case object at 0x7359c06fc400>, <__main__.Case object at 0x7359c06fc4c0>, <__main__.Case object at 0x7359c06fc6a0>, <__main__.Case object at 0x7359c06fc670>, <__main__.Case object at 0x7359c06fc730>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06fc9d0>, <__main__.Case object at 0x7359c06fca90>, <__main__.Case object at 0x7359c06fc7f0>, <__main__.Case object at 0x7359c06fcac0>, <__main__.Case object at 0x7359c06fcbb0>, <__main__.Case object at 0x7359c06fcc70>, <__main__.Case object at 0x7359c06fcd30>, <__main__.Case object at 0x7359c06fcdf0>, <__main__.Case object at 0x7359c06fceb0>, <__main__.Case object at 0x7359c06fcf70>, <__main__.Case object at 0x7359c06fd030>, <__main__.Case object at 0x7359c06fd0f0>, <__main__.Case object at 0x7359c06fd1b0>, <__main__.Case object at 0x7359c06fd270>, <__main__.Case object at 0x7359c06fd330>, <__main__.Case object at 0x7359c06fd4e0>, <__main__.Case object at 0x7359c06fd480>, <__main__.Case object at 0x7359c06fd570>, <__main__.Case object at 0x7359c06fd750>, <__main__.Case object at 0x7359c06fd840>, <__main__.Case object at 0x7359c06fd7e0>, <__main__.Case object at 0x7359c06fd9f0>, <__main__.Case object at 0x7359c06fd990>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 13, Total Steps: 78, Total Rewards: [-177, -108], Status Episode: False\n",
      "------------------------------------------End of episode 13 loop--------------------\n",
      "----- starting point of Episode 14 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 2], False, [['agent']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[0, 2], False, [['agent']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 5], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 5], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 5], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 5], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 6], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 6], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 5], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 5], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 4], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 4], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 4], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 4], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 2], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 2], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 14 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['agent']], 0]\n",
      "next state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 14 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [112.5, 112.5, 137.5, 137.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 2], False, [['obstacle']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e3c70>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06eb0d0>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06eac20>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06e8d00>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06eaef0>, <__main__.Case object at 0x7359c06eb250>, <__main__.Case object at 0x7359c06e9840>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06fdab0>, <__main__.Case object at 0x7359c06fc160>, <__main__.Case object at 0x7359c06fc3a0>, <__main__.Case object at 0x7359c06fc5e0>, <__main__.Case object at 0x7359c06fc850>, <__main__.Case object at 0x7359c06fcb50>, <__main__.Case object at 0x7359c06fcd90>, <__main__.Case object at 0x7359c06fcfd0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06ebd00>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06ebbe0>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06eb0a0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e8f70>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06eb940>, <__main__.Case object at 0x7359c06ea410>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06ebcd0>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06fc250>, <__main__.Case object at 0x7359c06fc490>, <__main__.Case object at 0x7359c06fc700>, <__main__.Case object at 0x7359c06fc940>, <__main__.Case object at 0x7359c06fcc40>, <__main__.Case object at 0x7359c06fce80>, <__main__.Case object at 0x7359c06fd0c0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06e95d0>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06e8e50>, <__main__.Case object at 0x7359c06eb970>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06eb490>, <__main__.Case object at 0x7359c06e8e80>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06e9960>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06eb3a0>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06fca30>, <__main__.Case object at 0x7359c06fc220>, <__main__.Case object at 0x7359c06fc460>, <__main__.Case object at 0x7359c06fc640>, <__main__.Case object at 0x7359c06fc970>, <__main__.Case object at 0x7359c06fcc10>, <__main__.Case object at 0x7359c06fce50>, <__main__.Case object at 0x7359c06fd090>, <__main__.Case object at 0x7359c06fd2d0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 14, Total Steps: 40, Total Rewards: [-139, 92], Status Episode: False\n",
      "------------------------------------------End of episode 14 loop--------------------\n",
      "----- starting point of Episode 15 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 15 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[4, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 15 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 0], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 15 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [212.5, 62.5, 237.5, 87.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 0], False, [['agent']], 0]\n",
      "next state for agent 0: [[4, 1], False, [['obstacle']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06bd750>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e90c0>, <__main__.Case object at 0x7359c06eb7f0>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06ebcd0>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06eab00>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06ebbe0>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06e8f70>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06ea410>, <__main__.Case object at 0x7359c06ea470>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06ea530>, <__main__.Case object at 0x7359c06e8d90>, <__main__.Case object at 0x7359c06ebac0>, <__main__.Case object at 0x7359c06eb2e0>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e9c90>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 15, Total Steps: 15, Total Rewards: [-114, 92], Status Episode: False\n",
      "------------------------------------------End of episode 15 loop--------------------\n",
      "----- starting point of Episode 16 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 2], False, [['agent']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 2], False, [['agent']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 2], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 3], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[0, 3], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 4], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[0, 4], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 5], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 5], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 5], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 5], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 5], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 5], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 6], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 16 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 6], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 7], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 7], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 7], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 7], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 6], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 6], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 6], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 6], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 6], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 6], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 6], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 6], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 6], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 6], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 7], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 7], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 8], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 8], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 8], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 8], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 8], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 8], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 8], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 8], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 9], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 9], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[4, 9], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 9], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[4, 9], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 9], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[4, 9], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 9], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[4, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 16 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 hit an obstacle! Next state: [262.5, 412.5, 287.5, 437.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 8], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 8], False, [['obstacle']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06bd750>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06e8d90>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06ea020>, <__main__.Case object at 0x7359c06e8e50>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06ebf10>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06eac20>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06eb490>, <__main__.Case object at 0x7359c06eb520>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06fd390>, <__main__.Case object at 0x7359c06fc0d0>, <__main__.Case object at 0x7359c06fc490>, <__main__.Case object at 0x7359c06fcb80>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06e3c70>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06e8f70>, <__main__.Case object at 0x7359c06ea410>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eab00>, <__main__.Case object at 0x7359c06ea530>, <__main__.Case object at 0x7359c06eb2e0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06ea6b0>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06eb0d0>, <__main__.Case object at 0x7359c06eae60>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06e9960>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06fc7c0>, <__main__.Case object at 0x7359c06b1de0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.7, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e9360>, <__main__.Case object at 0x7359c06eb0a0>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06eb940>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e9d80>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06e9a20>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06fd180>, <__main__.Case object at 0x7359c06fc700>, <__main__.Case object at 0x7359c06fcf40>, <__main__.Case object at 0x7359c06fc160>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 16, Total Steps: 34, Total Rewards: [-133, 92], Status Episode: False\n",
      "------------------------------------------End of episode 16 loop--------------------\n",
      "----- starting point of Episode 17 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 17 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 17 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[0, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 1], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 48 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 49 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[4, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 50 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[4, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 51 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[4, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 52 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 53 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 54 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 55 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 56 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 0], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 57 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 58 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 59 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 17 in steps 60 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 61 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 62 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 63 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 64 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 17 in steps 65 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 66 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 17 in steps 67 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06e3c70>, <__main__.Case object at 0x7359c06bd750>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06eab00>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06e9de0>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06e95d0>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06eb520>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06eac50>, <__main__.Case object at 0x7359c06e9f00>, <__main__.Case object at 0x7359c06eb550>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06fc5e0>, <__main__.Case object at 0x7359c06fc310>, <__main__.Case object at 0x7359c06fc550>, <__main__.Case object at 0x7359c06fc250>, <__main__.Case object at 0x7359c06fc4c0>, <__main__.Case object at 0x7359c06fc880>, <__main__.Case object at 0x7359c06fc820>, <__main__.Case object at 0x7359c06fcb20>, <__main__.Case object at 0x7359c06fcd30>, <__main__.Case object at 0x7359c06fd150>, <__main__.Case object at 0x7359c06fc8b0>, <__main__.Case object at 0x7359c06fc460>, <__main__.Case object at 0x7359c06fd000>, <__main__.Case object at 0x7359c06fc850>, <__main__.Case object at 0x7359c06fc1f0>, <__main__.Case object at 0x7359c06fd960>, <__main__.Case object at 0x7359c06fd720>, <__main__.Case object at 0x7359c06fd540>, <__main__.Case object at 0x7359c06fd060>, <__main__.Case object at 0x7359c06fd2a0>, <__main__.Case object at 0x7359c06fd510>, <__main__.Case object at 0x7359c06fd780>, <__main__.Case object at 0x7359c06fda20>, <__main__.Case object at 0x7359c06fe410>, <__main__.Case object at 0x7359c06fe260>, <__main__.Case object at 0x7359c06fe290>, <__main__.Case object at 0x7359c06fe140>, <__main__.Case object at 0x7359c06fdf90>, <__main__.Case object at 0x7359c06fdd80>, <__main__.Case object at 0x7359c06fdcf0>, <__main__.Case object at 0x7359c06fdc30>, <__main__.Case object at 0x7359c06fda80>, <__main__.Case object at 0x7359c06fe5f0>, <__main__.Case object at 0x7359c06fe7a0>, <__main__.Case object at 0x7359c06fe830>, <__main__.Case object at 0x7359c06fe8f0>, <__main__.Case object at 0x7359c06fea10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eb490>, <__main__.Case object at 0x7359c06eacb0>, <__main__.Case object at 0x7359c06eb0a0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06fd390>, <__main__.Case object at 0x7359c06fcb80>, <__main__.Case object at 0x7359c06fcf40>, <__main__.Case object at 0x7359c06fc5b0>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06fc6a0>, <__main__.Case object at 0x7359c06fcbb0>, <__main__.Case object at 0x7359c06fcdf0>, <__main__.Case object at 0x7359c06fccd0>, <__main__.Case object at 0x7359c06fc640>, <__main__.Case object at 0x7359c06fd240>, <__main__.Case object at 0x7359c06fc580>, <__main__.Case object at 0x7359c06fc1c0>, <__main__.Case object at 0x7359c06fc070>, <__main__.Case object at 0x7359c06fd810>, <__main__.Case object at 0x7359c06fd5d0>, <__main__.Case object at 0x7359c06fd300>, <__main__.Case object at 0x7359c06fd0f0>, <__main__.Case object at 0x7359c06fd330>, <__main__.Case object at 0x7359c06fd570>, <__main__.Case object at 0x7359c06fd7e0>, <__main__.Case object at 0x7359c06fe440>, <__main__.Case object at 0x7359c06fe3b0>, <__main__.Case object at 0x7359c06fe230>, <__main__.Case object at 0x7359c06e8bb0>, <__main__.Case object at 0x7359c06fe020>, <__main__.Case object at 0x7359c06fdea0>, <__main__.Case object at 0x7359c06fdc60>, <__main__.Case object at 0x7359c06fdba0>, <__main__.Case object at 0x7359c06fe530>, <__main__.Case object at 0x7359c06fe680>, <__main__.Case object at 0x7359c06fe890>, <__main__.Case object at 0x7359c06fe980>, <__main__.Case object at 0x7359c06feaa0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.6, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.6, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.6, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.6, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.7, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 0.8999999999999999, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) is empty. Temporary case base stored to the case base: ((7, 1), 4, 0.5)\n",
      "Episode succeeded, case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 4, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) is empty. Temporary case base stored to the case base: ((5, 0), 4, 0.5)\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 4, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 1, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 1, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 1) is empty. Temporary case base stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 1, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 1, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.6, time steps: 43\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.6, time steps: 42\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6, time steps: 37\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6, time steps: 33\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6, time steps: 28\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.6, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.6, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.7, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 0.8999999999999999, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.5, time steps: 58\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.5, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.5, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.5, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.5, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5, time steps: 45\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 0.5, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 0.5, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.5, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.5, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 0.5, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.5, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 0.5, time steps: 15\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06e8f70>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06ea530>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06ea3b0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06eb7f0>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06e9870>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06ebd00>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06eb340>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06fca60>, <__main__.Case object at 0x7359c06fca00>, <__main__.Case object at 0x7359c06fcd00>, <__main__.Case object at 0x7359c06fc940>, <__main__.Case object at 0x7359c06fc400>, <__main__.Case object at 0x7359c06fc730>, <__main__.Case object at 0x7359c06fc910>, <__main__.Case object at 0x7359c06fcac0>, <__main__.Case object at 0x7359c06fce20>, <__main__.Case object at 0x7359c06fd090>, <__main__.Case object at 0x7359c06fc790>, <__main__.Case object at 0x7359c06fc0a0>, <__main__.Case object at 0x7359c06fc3d0>, <__main__.Case object at 0x7359c06fc370>, <__main__.Case object at 0x7359c06fc040>, <__main__.Case object at 0x7359c06fd930>, <__main__.Case object at 0x7359c06fd600>, <__main__.Case object at 0x7359c06fd450>, <__main__.Case object at 0x7359c06fd120>, <__main__.Case object at 0x7359c06fd360>, <__main__.Case object at 0x7359c06fd5a0>, <__main__.Case object at 0x7359c06fd870>, <__main__.Case object at 0x7359c06fc9a0>, <__main__.Case object at 0x7359c06fe3e0>, <__main__.Case object at 0x7359c06fe2c0>, <__main__.Case object at 0x7359c06fe2f0>, <__main__.Case object at 0x7359c06fe050>, <__main__.Case object at 0x7359c06fdf30>, <__main__.Case object at 0x7359c06fddb0>, <__main__.Case object at 0x7359c06fde40>, <__main__.Case object at 0x7359c06fdbd0>, <__main__.Case object at 0x7359c06fdae0>, <__main__.Case object at 0x7359c06fe650>, <__main__.Case object at 0x7359c06fe770>, <__main__.Case object at 0x7359c06fe710>, <__main__.Case object at 0x7359c06fe950>, <__main__.Case object at 0x7359c06fea70>, <__main__.Case object at 0x7359c06feb90>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode: 17, Total Steps: 68, Total Rewards: [33, 92], Status Episode: True\n",
      "------------------------------------------End of episode 17 loop--------------------\n",
      "----- starting point of Episode 18 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.5, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.5, 17)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 45)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 45)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 45)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 47)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 47)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 47)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 48)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.5, 48)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 48)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 51)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.5, 51)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 51)]\n",
      "next state for agent 1: [[8, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 18 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[4, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 3], False, [['empty']], ((4, 0), 4, 0.5, 51)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.5, 51)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 18 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "state for agent 0: [[5, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((9, 3), 1, 1, 16)]\n",
      "comm next state for agent 0: ((9, 3), 1, 1, 16)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 3], False, [['empty']], ((4, 0), 4, 0.5, 51)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((5, 0), 4, 0.5, 53)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.5, 53)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((9, 3), 1, 1, 16)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((5, 0), 4, 0.5, 53)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 0.5, 53)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.5, 53)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 0.5, 53)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 4, 0.5, 56)]\n",
      "comm next state for agent 1: ((6, 0), 4, 0.5, 56)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 4, 0.5, 56)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((7, 0), 2, 0.5, 57)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.5, 57)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[7, 1], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((7, 0), 2, 0.5, 57)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((7, 1), 4, 0.5, 58)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 58)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[8, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((7, 1), 4, 0.5, 58)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((8, 1), 4, 0.6, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 0.6, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[9, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((8, 1), 4, 0.6, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((9, 1), 2, 0.6, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 2], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((9, 1), 2, 0.6, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 18 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.6, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06e8d00>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e90c0>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06eb7f0>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eaec0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06eacb0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eb9d0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06eb250>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.7, time steps: 43\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.7, time steps: 42\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.7, time steps: 33\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.7, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.7, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.7, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.7, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.8999999999999999, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 0.6, time steps: 58\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 0.6, time steps: 57\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 0.6, time steps: 56\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.6, time steps: 51\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.6, time steps: 48\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 45\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 0.7, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 0.7, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.7, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.7, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 0.7, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.7, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 0.7, time steps: 15\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 4), 2, 0.5, 22)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 4), 3, 0.5, 22)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 4), 3, 0.5, 22)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 3), 2, 0.5, 22)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 2), 2, 0.5, 22)\n",
      "Episode succeeded, case (8, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 1), 4, 0.5, 22)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 0), 2, 0.5, 22)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 0), 4, 0.5, 22)\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 0), 4, 0.5, 22)\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((4, 0), 4, 0.5, 22)\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((3, 0), 4, 0.5, 22)\n",
      "Episode succeeded, updated case base with fewer steps: ((2, 0), 4, 0.5, 22)\n",
      "Episode succeeded, updated case base with fewer steps: ((1, 0), 4, 0.5, 22)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 3) is empty. Temporary case base stored to the case base: ((9, 3), 1, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7, time steps: 21\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.7, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.7, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.7, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.8999999999999999, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 0.7, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 0.7, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.7, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 0.7, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.7, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 0.7, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06eab00>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06eb550>, <__main__.Case object at 0x7359c06ea410>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06eaa10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e3cd0>, <__main__.Case object at 0x7359c069e500>, <__main__.Case object at 0x7359c06eac20>, <__main__.Case object at 0x7359c06ea6b0>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06ea020>, <__main__.Case object at 0x7359c06eb940>, <__main__.Case object at 0x7359c06eaef0>, <__main__.Case object at 0x7359c06e9780>, <__main__.Case object at 0x7359c06eae60>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e8f70>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06eb340>, <__main__.Case object at 0x7359c06eab60>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 0.6)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 4, 0.5)\n",
      "Integrated case process. comm case (5, 0) is empty. Temporary case base stored to the case base: ((5, 0), 4, 0.5)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.5, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.5, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.5, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.5, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5, time steps: 17\n",
      "Episode: 18, Total Steps: 22, Total Rewards: [79, 86], Status Episode: True\n",
      "------------------------------------------End of episode 18 loop--------------------\n",
      "----- starting point of Episode 19 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.6, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.6, 17)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 22)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 22)]\n",
      "next state for agent 1: [[9, 2], False, [['agent']], ((2, 0), 4, 0.5, 22)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 22)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 19 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['agent']], ((2, 0), 4, 0.5, 22)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((3, 0), 4, 0.5, 22)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.5, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((3, 0), 4, 0.5, 22)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((4, 0), 4, 0.5, 22)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.5, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((4, 0), 4, 0.5, 22)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((5, 0), 4, 0.5, 22)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.5, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((5, 0), 4, 0.5, 22)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((6, 0), 4, 0.5, 22)]\n",
      "comm next state for agent 1: ((6, 0), 4, 0.5, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((6, 0), 4, 0.5, 22)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((7, 0), 2, 0.5, 22)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.5, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[7, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((7, 0), 2, 0.5, 22)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((7, 1), 4, 0.5, 22)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 22)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 19 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[8, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((7, 1), 4, 0.5, 22)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((8, 1), 4, 0.7, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 0.7, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[9, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((8, 1), 4, 0.7, 13)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[9, 2], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((9, 2), 3, 0.7, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((9, 2), 3, 0.7, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 19 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 0.7, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06eb9d0>, <__main__.Case object at 0x7359c06eb250>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06eb550>, <__main__.Case object at 0x7359c06e9870>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eb910>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.7999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.7999999999999999, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.7999999999999999, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 0.8999999999999999, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 0.8999999999999999, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.8999999999999999, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.8999999999999999, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 0.8999999999999999, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.8999999999999999, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 0.8999999999999999, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 4), 2, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 4), 3, 0.5, 20)\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 4), 3, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 3), 2, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 2), 2, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((8, 2), 3, 0.5, 20)\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 1), 4, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 0), 2, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 0), 4, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 0), 4, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((4, 0), 4, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((3, 0), 4, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((2, 0), 4, 0.5, 20)\n",
      "Episode succeeded, updated case base with fewer steps: ((1, 0), 4, 0.5, 20)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.7999999999999999, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.7999999999999999, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.7999999999999999, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5, time steps: 20\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 0.8999999999999999, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 0.8999999999999999, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.8999999999999999, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.8999999999999999, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 0.8999999999999999, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.8999999999999999, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 0.8999999999999999, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e90c0>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06eb7f0>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06fe230>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06ea530>, <__main__.Case object at 0x7359c06ebd00>, <__main__.Case object at 0x7359c06fdfc0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 0.7, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 0.7, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 0.7, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 0.7, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.7, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.7, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.7, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.7, time steps: 17\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 0.7)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 4, 0.5)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.6)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.7, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.7, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.7, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.7, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.7, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7, time steps: 17\n",
      "Episode: 19, Total Steps: 20, Total Rewards: [81, 89], Status Episode: True\n",
      "------------------------------------------End of episode 19 loop--------------------\n",
      "----- starting point of Episode 20 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.7, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.7, 17)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 20)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 20)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 20)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 20)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.5, 20)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((6, 0), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((7, 0), 2, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[7, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((7, 0), 2, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((7, 1), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 20 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 20 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.5, 20)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 20)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06eb2e0>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06ea0b0>, <__main__.Case object at 0x7359c06e8eb0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06eae30>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.8999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.8999999999999999, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.8999999999999999, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 4), 2, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 4), 3, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 4), 3, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 3), 2, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 2), 2, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((8, 2), 3, 0.5, 18)\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 1), 4, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 0), 2, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 0), 4, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 0), 4, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((4, 0), 4, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((3, 0), 4, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((2, 0), 4, 0.5, 18)\n",
      "Episode succeeded, updated case base with fewer steps: ((1, 0), 4, 0.5, 18)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.8999999999999999, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.8999999999999999, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.8999999999999999, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06eb9d0>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06eb400>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06eaa10>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06ea3b0>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06e90c0>, <__main__.Case object at 0x7359c06e9000>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 0.8999999999999999, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 0.8999999999999999, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 0.8999999999999999, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 0.8999999999999999, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.8999999999999999, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.8999999999999999, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.8999999999999999, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 17\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 4, 0.5)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.7)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.8999999999999999, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.8999999999999999, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.8999999999999999, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.8999999999999999, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.8999999999999999, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8999999999999999, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8999999999999999, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 17\n",
      "Episode: 20, Total Steps: 18, Total Rewards: [83, 92], Status Episode: True\n",
      "------------------------------------------End of episode 20 loop--------------------\n",
      "----- starting point of Episode 21 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.7999999999999999, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7999999999999999, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.7999999999999999, 17)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 18)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 18)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 18)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 18)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 18)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.5, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 18)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 18)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.5, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 18)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 0.5, 18)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.5, 18)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 0.5, 18)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 4, 0.5, 18)]\n",
      "comm next state for agent 1: ((6, 0), 4, 0.5, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 4, 0.5, 18)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((7, 0), 2, 0.5, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.5, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[7, 1], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((7, 0), 2, 0.5, 18)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((7, 1), 4, 0.5, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.5, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[8, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((7, 1), 4, 0.5, 18)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((8, 1), 4, 0.8999999999999999, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 0.8999999999999999, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[9, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((8, 1), 4, 0.8999999999999999, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 2], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 21 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 1), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06eb700>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06eb550>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb9d0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06e8a60>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 0.9999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 0.9999999999999999, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 0.9999999999999999, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.9999999999999999, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.9999999999999999, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.9999999999999999, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06ebd00>, <__main__.Case object at 0x7359c06eab00>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06e8e50>, <__main__.Case object at 0x7359c06fc1c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06e90c0>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06eb7f0>, <__main__.Case object at 0x7359c06eb2b0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.5)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 4, 0.5)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.7999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "Episode: 21, Total Steps: 19, Total Rewards: [82, 90], Status Episode: True\n",
      "------------------------------------------End of episode 21 loop--------------------\n",
      "----- starting point of Episode 22 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.8999999999999999, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.8999999999999999, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.8999999999999999, 17)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.6, 18)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.6, 18)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.6, 18)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.6, 18)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.6, 18)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.6, 18)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['agent']], ((3, 0), 4, 0.6, 18)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.6, 18)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 22 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['agent']], ((3, 0), 4, 0.6, 18)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 0.6, 18)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.6, 18)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 22 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 0.6, 18)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 0.6, 18)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 0.6, 18)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((6, 0), 4, 0.6, 18)]\n",
      "comm next state for agent 1: ((6, 0), 4, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((6, 0), 4, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 22 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 22 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 0.6, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.6, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e9150>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06ebd00>, <__main__.Case object at 0x7359c06e8f70>, <__main__.Case object at 0x7359c06fcfd0>, <__main__.Case object at 0x7359c06fe5c0>, <__main__.Case object at 0x7359c06fd9f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06fc160>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.8, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 3), 2, 0.5, 22)\n",
      "Episode succeeded, case (7, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.8, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5, time steps: 22\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eb940>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06ea530>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06fe0e0>, <__main__.Case object at 0x7359c06fe890>, <__main__.Case object at 0x7359c06fe980>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eaa10>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06e8e50>, <__main__.Case object at 0x7359c06fc070>, <__main__.Case object at 0x7359c06fe6e0>, <__main__.Case object at 0x7359c06fe380>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.6)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 4, 0.6)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.6)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.6)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.6)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.6)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.6)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.6)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "Episode: 22, Total Steps: 22, Total Rewards: [79, 91], Status Episode: True\n",
      "------------------------------------------End of episode 22 loop--------------------\n",
      "----- starting point of Episode 23 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.9999999999999999, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.9999999999999999, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.9999999999999999, 17)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.7, 18)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.7, 18)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.7, 18)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.7, 18)]\n",
      "next state for agent 1: [[8, 2], False, [['agent']], ((3, 0), 4, 0.7, 18)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.7, 18)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 23 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[4, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['agent']], ((3, 0), 4, 0.7, 18)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((4, 0), 4, 0.7, 18)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.7, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((8, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((4, 0), 4, 0.7, 18)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((5, 0), 4, 0.7, 18)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.7, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 2), 2, 1, 10)]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((5, 0), 4, 0.7, 18)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((6, 0), 4, 0.7, 18)]\n",
      "comm next state for agent 1: ((6, 0), 4, 0.7, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((7, 3), 2, 1, 10)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((6, 0), 4, 0.7, 18)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((7, 0), 2, 0.7, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.7, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[7, 1], False, [['empty']], ((7, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((7, 0), 2, 0.7, 18)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((7, 1), 4, 0.7, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.7, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[8, 1], False, [['empty']], ((6, 4), 3, 1, 10)]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((7, 1), 4, 0.7, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 1], False, [['empty']], ((5, 4), 2, 1, 10)]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 23 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eb7f0>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06ebd00>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06e9750>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06eb550>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06ea4d0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1.0, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 3), 2, 0.5, 18)\n",
      "Episode succeeded, case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1.0, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5, time steps: 14\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06e9870>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06e9600>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e9150>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06eafe0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.7)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.7)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 4, 0.7)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.7)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.7)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.7)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.7)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.7)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.9999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "Episode: 23, Total Steps: 18, Total Rewards: [83, 91], Status Episode: True\n",
      "------------------------------------------End of episode 23 loop--------------------\n",
      "----- starting point of Episode 24 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 24 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 17)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.7999999999999999, 18)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 24 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [112.5, 62.5, 137.5, 87.5]\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['obstacle']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.7999999999999999, 18)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 24 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['obstacle']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 34)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 24 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 34)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 24 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 34)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 24 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 34)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 24 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 34)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 24 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "next state for agent 0: [[2, 1], False, [['agent']], ((9, 2), 3, 1, 10)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 10)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((2, 1), 4, 1, 34)]\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 34)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06eb2e0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06eba60>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1.0, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 14\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1.0, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5, time steps: 14\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06eb550>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e9150>, <__main__.Case object at 0x7359c06e8a60>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06e8e50>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06eb940>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 10\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 4), 2, 0.5, 9)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 4), 3, 0.5, 9)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 4), 3, 0.5, 9)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 3), 2, 0.5, 9)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 2), 2, 0.5, 9)\n",
      "Episode succeeded, updated case base with fewer steps: ((8, 2), 3, 0.5, 9)\n",
      "Episode succeeded, updated case base with fewer steps: ((9, 2), 3, 0.5, 9)\n",
      "Episode succeeded, updated case base with fewer steps: ((9, 1), 2, 0.5, 9)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (2, 1) is empty. Temporary case base stored to the case base: ((2, 1), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.5, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.5, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "Episode: 24, Total Steps: 9, Total Rewards: [-102, 92], Status Episode: False\n",
      "------------------------------------------End of episode 24 loop--------------------\n",
      "----- starting point of Episode 25 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 0], False, [['agent']], ((0, 0), 4, 1, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 17)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 25 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], ((0, 0), 4, 1, 17)]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((1, 0), 4, 1, 18)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((1, 0), 4, 1, 18)]\n",
      "next state for agent 1: [[9, 0], False, [['empty']], ((2, 0), 4, 0.7999999999999999, 18)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7999999999999999, 18)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 25 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['empty']], ((2, 0), 4, 0.7999999999999999, 18)]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((3, 0), 4, 0.7999999999999999, 18)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.7999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((9, 1), 2, 0.5, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.5, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((3, 0), 4, 0.7999999999999999, 18)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((4, 0), 4, 0.7999999999999999, 18)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.7999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((9, 1), 2, 0.5, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((9, 2), 3, 0.5, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.5, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((4, 0), 4, 0.7999999999999999, 18)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((5, 0), 4, 0.7999999999999999, 18)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.7999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((9, 2), 3, 0.5, 9)]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((8, 2), 3, 0.5, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.5, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((5, 0), 4, 0.7999999999999999, 18)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((6, 0), 4, 0.7999999999999999, 18)]\n",
      "comm next state for agent 1: ((6, 0), 4, 0.7999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((8, 2), 3, 0.5, 9)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], ((7, 2), 2, 0.5, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.5, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((6, 0), 4, 0.7999999999999999, 18)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((7, 0), 2, 0.7999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.7999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[7, 1], False, [['empty']], ((7, 2), 2, 0.5, 9)]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], ((7, 3), 2, 0.5, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.5, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((7, 0), 2, 0.7999999999999999, 18)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((7, 1), 4, 0.7999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.7999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[8, 1], False, [['empty']], ((7, 3), 2, 0.5, 9)]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], ((7, 4), 3, 0.5, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.5, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((7, 1), 4, 0.7999999999999999, 18)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 1: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[9, 1], False, [['empty']], ((7, 4), 3, 0.5, 9)]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], ((6, 4), 3, 0.5, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.5, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((9, 1), 2, 1, 14)]\n",
      "comm next state for agent 1: ((9, 1), 2, 1, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[9, 2], False, [['empty']], ((6, 4), 3, 0.5, 9)]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 4), 2, 0.5, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.5, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((9, 1), 2, 1, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((9, 2), 3, 1, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 4), 2, 0.5, 9)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((9, 2), 3, 1, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 25 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((9, 2), 3, 1, 17)]\n",
      "comm next state for agent 1: ((9, 2), 3, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06eaa10>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06e8b50>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06c4ee0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.7, time steps: 14\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.5)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.5)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.5)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.7, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.7, time steps: 14\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06fd7e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06e9150>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06ebca0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.6, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.6, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.6, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.6, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "Episode: 25, Total Steps: 18, Total Rewards: [83, 89], Status Episode: True\n",
      "------------------------------------------End of episode 25 loop--------------------\n",
      "----- starting point of Episode 26 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.6, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.6, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 17)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 18)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.6, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.6, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.6, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 18)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.6, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 0.6, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.6, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 0.6, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 0.6, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.6, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 0.6, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 0.6, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.6, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 0.6, 9)]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((7, 4), 3, 0.6, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.6, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((6, 0), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((7, 4), 3, 0.6, 9)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], ((6, 4), 3, 0.6, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.6, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((7, 0), 2, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[7, 1], False, [['empty']], ((6, 4), 3, 0.6, 9)]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], ((5, 4), 2, 0.6, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.6, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((7, 0), 2, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 1], False, [['empty']], ((5, 4), 2, 0.6, 9)]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 26 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 1), 4, 0.8999999999999999, 18)]\n",
      "comm next state for agent 1: ((7, 1), 4, 0.8999999999999999, 18)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06ea2f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06e9150>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06eb580>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.8999999999999999, time steps: 14\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.6)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.6)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.6)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.6)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.6)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.6)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.6)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.6)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.8999999999999999, time steps: 14\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06e90c0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06fcbe0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06eb2e0>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06e94b0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06fcfa0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.7, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.7, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.7, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.7, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.7, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.7, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "Episode: 26, Total Steps: 18, Total Rewards: [83, 92], Status Episode: True\n",
      "------------------------------------------End of episode 26 loop--------------------\n",
      "----- starting point of Episode 27 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 17)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 17)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.7, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.7, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 17)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 18)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.7, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.7, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.7, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 18)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.9999999999999999, 18)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.9999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.7, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 0.7, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.9999999999999999, 18)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.9999999999999999, 18)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.9999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 0.7, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 0.7, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.7, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.9999999999999999, 18)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.9999999999999999, 18)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.9999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 0.7, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 0.7, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.7, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.9999999999999999, 18)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.9999999999999999, 18)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.9999999999999999, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 0.7, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 0.7, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.7, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.9999999999999999, 18)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 0.7, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 0.7, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.7, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 0.7, 9)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((5, 4), 2, 0.7, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.7, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((5, 4), 2, 0.7, 9)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 27 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.8999999999999999, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.8999999999999999, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06eb550>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06ea680>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06e9e10>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.9999999999999999, time steps: 14\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 4), 2, 0.5, 16)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 4), 3, 0.5, 16)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 4), 3, 0.5, 16)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 3), 2, 0.5, 16)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 0), 2, 0.5, 16)\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 0), 4, 0.5, 16)\n",
      "Episode succeeded, updated case base with fewer steps: ((4, 0), 4, 0.5, 16)\n",
      "Episode succeeded, updated case base with fewer steps: ((3, 0), 4, 0.5, 16)\n",
      "Episode succeeded, updated case base with fewer steps: ((2, 0), 4, 0.5, 16)\n",
      "Episode succeeded, updated case base with fewer steps: ((1, 0), 4, 0.5, 16)\n",
      "Episode succeeded, updated case base with fewer steps: ((0, 0), 4, 0.5, 16)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.7)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.7)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.7)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.7)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.7)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.7)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5, time steps: 16\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.9999999999999999, time steps: 14\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5, time steps: 7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06e8be0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06ebd60>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.7999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.7999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.7999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.7999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.7999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "Episode: 27, Total Steps: 16, Total Rewards: [85, 92], Status Episode: True\n",
      "------------------------------------------End of episode 27 loop--------------------\n",
      "----- starting point of Episode 28 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.5, 16)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.7999999999999999, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.7999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.5, 16)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 16)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.7999999999999999, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.7999999999999999, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.7999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 16)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 16)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.7999999999999999, 9)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((8, 2), 3, 0.7999999999999999, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7999999999999999, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 16)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((8, 2), 3, 0.7999999999999999, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 0.7999999999999999, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.7999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((3, 1), 1, 1, 40)]\n",
      "comm next state for agent 1: ((3, 1), 1, 1, 40)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 0.7999999999999999, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 0.7999999999999999, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.7999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((3, 1), 1, 1, 40)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((3, 0), 4, 0.5, 16)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 0.7999999999999999, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 4), 3, 0.7999999999999999, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.7999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((3, 0), 4, 0.5, 16)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((4, 0), 4, 0.5, 16)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 4), 3, 0.7999999999999999, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((6, 4), 3, 0.7999999999999999, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.7999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((4, 0), 4, 0.5, 16)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((5, 0), 4, 0.5, 16)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((6, 4), 3, 0.7999999999999999, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((5, 4), 2, 0.7999999999999999, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.7999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((5, 0), 4, 0.5, 16)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((6, 0), 2, 0.5, 16)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((5, 4), 2, 0.7999999999999999, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((6, 0), 2, 0.5, 16)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 0), 2, 0.5, 16)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 0), 2, 0.5, 16)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 0), 2, 0.5, 16)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.5, 16)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 28 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 0), 2, 0.5, 16)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 0), 2, 0.5, 16)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 0), 2, 0.5, 16)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 0), 2, 0.5, 16)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 28 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 0), 2, 0.5, 16)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 0), 2, 0.5, 16)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.5, 16)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06e8a60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06eb580>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.7, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 7\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 4), 2, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 4), 3, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 3), 2, 0.5, 14)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 0), 2, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 0), 4, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((4, 0), 4, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((3, 0), 4, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((3, 1), 1, 0.5, 14)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((2, 0), 4, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((1, 0), 4, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((0, 0), 4, 0.5, 14)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.7, time steps: 16\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6, time steps: 7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06ea950>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06bd7e0>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eaa10>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06ea320>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 1, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.8999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.8999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.8999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 28, Total Steps: 14, Total Rewards: [87, 92], Status Episode: True\n",
      "------------------------------------------End of episode 28 loop--------------------\n",
      "----- starting point of Episode 29 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.5, 14)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.8999999999999999, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.8999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.5, 14)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 14)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.8999999999999999, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.8999999999999999, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.8999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 14)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 14)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.8999999999999999, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 0.8999999999999999, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.8999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 14)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 14)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.5, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 0.8999999999999999, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 0.8999999999999999, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.8999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 14)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 14)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.5, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 0.8999999999999999, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 0.8999999999999999, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.8999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 14)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.5, 14)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.5, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 0.8999999999999999, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 0.8999999999999999, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.8999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.5, 14)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 0.5, 14)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.5, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 0.8999999999999999, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 0.8999999999999999, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.8999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 0.5, 14)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 0.6, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 0.6, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 0.8999999999999999, 9)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 4), 2, 0.8999999999999999, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.8999999999999999, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 0.6, 7)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 4), 2, 0.8999999999999999, 9)]\n",
      "next state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 29 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 29 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 29 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06e90c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eb010>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.7999999999999999, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.7, time steps: 7\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 4), 3, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 3), 2, 0.5, 14)\n",
      "Episode succeeded, updated case base with fewer steps: ((7, 2), 2, 0.5, 14)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.7, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 0.7, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6, time steps: 14\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.7, time steps: 7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06e8b20>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06ebc70>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.6)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.9999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.9999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.9999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.9999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.9999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 0.9999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 0.9999999999999999, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 29, Total Steps: 14, Total Rewards: [87, 92], Status Episode: True\n",
      "------------------------------------------End of episode 29 loop--------------------\n",
      "----- starting point of Episode 30 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.6, 14)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.9999999999999999, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 0.9999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.6, 14)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.6, 14)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 0.9999999999999999, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.9999999999999999, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 0.9999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.6, 14)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.6, 14)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 0.9999999999999999, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 0.9999999999999999, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.9999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.6, 14)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.6, 14)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 0.9999999999999999, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 0.9999999999999999, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.9999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.6, 14)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.6, 14)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 0.9999999999999999, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 0.9999999999999999, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.9999999999999999, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.6, 14)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 0.9999999999999999, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 0.9999999999999999, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.9999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 0.6, 14)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.6, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 0.9999999999999999, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 0.9999999999999999, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.9999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 0.6, 14)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 0.7, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 0.7, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 0.9999999999999999, 9)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((5, 4), 2, 0.9999999999999999, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 0.9999999999999999, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 0.7, 7)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 1, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((5, 4), 2, 0.9999999999999999, 9)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 1, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 30 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 14)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 14)]\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06eab30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06e90c0>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06ebc10>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.7999999999999999, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 0.8999999999999999, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.7999999999999999, time steps: 7\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 4), 2, 0.5, 12)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 4), 3, 0.5, 12)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 3), 2, 0.5, 12)\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 2), 2, 0.5, 12)\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((6, 0), 2, 0.5, 12)\n",
      "Episode succeeded, updated case base with fewer steps: ((5, 0), 4, 0.5, 12)\n",
      "Episode succeeded, updated case base with fewer steps: ((4, 0), 4, 0.5, 12)\n",
      "Episode succeeded, updated case base with fewer steps: ((3, 0), 4, 0.5, 12)\n",
      "Episode succeeded, updated case base with fewer steps: ((2, 0), 4, 0.5, 12)\n",
      "Episode succeeded, updated case base with fewer steps: ((1, 0), 4, 0.5, 12)\n",
      "Episode succeeded, updated case base with fewer steps: ((0, 0), 4, 0.5, 12)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.7, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.7, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.7, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 0.8999999999999999, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.7999999999999999, time steps: 7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06e9ed0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06eae00>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.7)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.6)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.6)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.6)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.6)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.6)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.6)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 30, Total Steps: 12, Total Rewards: [89, 92], Status Episode: True\n",
      "------------------------------------------End of episode 30 loop--------------------\n",
      "----- starting point of Episode 31 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.5, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.5, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.5, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.5, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.5, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.5, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.5, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.5, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 0.7999999999999999, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 0.7999999999999999, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 0.7999999999999999, 7)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 0.5, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 0.5, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.5, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.5, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.5, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 31 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.5, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.5, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.5, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9150>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06ebca0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.8999999999999999, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.8999999999999999, time steps: 7\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.8999999999999999, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.8999999999999999, time steps: 7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06eb880>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06ea080>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06eb640>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 31, Total Steps: 12, Total Rewards: [89, 92], Status Episode: True\n",
      "------------------------------------------End of episode 31 loop--------------------\n",
      "----- starting point of Episode 32 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.6, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.6, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.6, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.6, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.6, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.6, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['agent']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 0.6, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 0.6, 12)]\n",
      "next state for agent 1: [[8, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 32 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "state for agent 0: [[5, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((8, 3), 1, 1, 20)]\n",
      "comm next state for agent 0: ((8, 3), 1, 1, 20)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((5, 0), 4, 0.6, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((8, 3), 1, 1, 20)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((5, 0), 4, 0.6, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((6, 0), 2, 0.6, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((6, 0), 2, 0.6, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((6, 1), 2, 0.8999999999999999, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 0.8999999999999999, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((6, 1), 2, 0.8999999999999999, 7)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((6, 2), 2, 0.6, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((6, 2), 2, 0.6, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['agent']], ((6, 3), 2, 0.6, 12)]\n",
      "comm next state for agent 1: ((6, 3), 2, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['agent']], ((6, 3), 2, 0.6, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['agent']], ((6, 4), 3, 0.6, 12)]\n",
      "comm next state for agent 1: ((6, 4), 3, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 32 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['target']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['agent']], ((6, 4), 3, 0.6, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((5, 4), 2, 0.6, 12)]\n",
      "comm next state for agent 1: ((5, 4), 2, 0.6, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06ea830>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06e9ba0>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06ea800>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.9999999999999999, time steps: 7\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 3) is empty. Temporary case base stored to the case base: ((8, 3), 1, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.7, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.9999999999999999, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06e9150>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06e8a60>, <__main__.Case object at 0x7359c06eaec0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e03d0>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eace0>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e8e50>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((8, 3), 1, 0.5, 13)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.6)\n",
      "Integrated case process. comm case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.6)\n",
      "Integrated case process. comm case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.6)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.6)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.6)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.6)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.6)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.6)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.6)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.6)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 0.5, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 32, Total Steps: 13, Total Rewards: [88, 88], Status Episode: True\n",
      "------------------------------------------End of episode 32 loop--------------------\n",
      "----- starting point of Episode 33 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.7, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.7, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.7, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.7, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.7, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.7, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.7, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.7, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.7, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.7, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.7, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['agent']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.7, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['agent']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 0.7, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.7, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 0.7, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((6, 0), 2, 0.7, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.7, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((6, 0), 2, 0.7, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((6, 1), 2, 0.9999999999999999, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 0.9999999999999999, 7)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 33 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((6, 1), 2, 0.9999999999999999, 7)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 1), 2, 0.9999999999999999, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 0.9999999999999999, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 1), 2, 0.9999999999999999, 7)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 1), 2, 0.9999999999999999, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 0.9999999999999999, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 1), 2, 0.9999999999999999, 7)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 1), 2, 0.9999999999999999, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 0.9999999999999999, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 33 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 1), 2, 0.9999999999999999, 7)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 1), 2, 0.9999999999999999, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 0.9999999999999999, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06ebfd0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eb5e0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06e9150>, <__main__.Case object at 0x7359c06e8d60>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06ea5c0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 0.7, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.7)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.7)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.7)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.7)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.7)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.7)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.7)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 0.7, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 33, Total Steps: 13, Total Rewards: [88, 92], Status Episode: True\n",
      "------------------------------------------End of episode 33 loop--------------------\n",
      "----- starting point of Episode 34 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.7999999999999999, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 34 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 34 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.7999999999999999, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 0.7999999999999999, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.7999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06e88b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06e9c90>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06eaec0>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06e9750>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06eb2b0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 0.8999999999999999, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.7999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 0.8999999999999999, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 34, Total Steps: 12, Total Rewards: [89, 92], Status Episode: True\n",
      "------------------------------------------End of episode 34 loop--------------------\n",
      "----- starting point of Episode 35 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.8999999999999999, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.8999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 0.8999999999999999, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.8999999999999999, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.8999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 0.8999999999999999, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.8999999999999999, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.8999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 0.8999999999999999, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['agent']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 0.8999999999999999, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.8999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 0.8999999999999999, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 0.8999999999999999, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.8999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[7, 0], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 0.8999999999999999, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[7, 0], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[7, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 35 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[8, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[9, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 1], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[9, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[8, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[7, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 35 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 35 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], 0]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((7, 0), 2, 1, 18)]\n",
      "comm next state for agent 1: ((7, 0), 2, 1, 18)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06ebf40>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb5b0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e9150>, <__main__.Case object at 0x7359c06fd570>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c50c0>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06e88b0>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06e8b50>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06ead10>, <__main__.Case object at 0x7359c06e9ae0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.9999999999999999, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06ebd60>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06fd6c0>, <__main__.Case object at 0x7359c06fd990>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06eb2e0>, <__main__.Case object at 0x7359c06e9870>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06fd0f0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 35, Total Steps: 19, Total Rewards: [82, 92], Status Episode: True\n",
      "------------------------------------------End of episode 35 loop--------------------\n",
      "----- starting point of Episode 36 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 0], False, [['agent']], ((0, 0), 4, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 0.9999999999999999, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], ((0, 0), 4, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((1, 0), 4, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 0.9999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((1, 0), 4, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((2, 0), 4, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.9999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((2, 0), 4, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 1], False, [['empty']], ((2, 0), 4, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 0.9999999999999999, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 0: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 1], False, [['empty']], ((2, 0), 4, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((3, 0), 4, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 0.9999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((3, 0), 4, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((4, 0), 4, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 0.9999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((4, 0), 4, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((5, 0), 4, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 0.9999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((5, 0), 4, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[7, 1], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 2], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((7, 1), 2, 1, 8)]\n",
      "comm next state for agent 0: ((7, 1), 2, 1, 8)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 1], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((6, 2), 2, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 0.9999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((7, 1), 2, 1, 8)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((6, 2), 2, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((6, 3), 2, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((6, 3), 2, 0.9999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((6, 3), 2, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((6, 4), 3, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((6, 4), 3, 0.9999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['target']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((6, 4), 3, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 4), 2, 0.9999999999999999, 12)]\n",
      "comm next state for agent 1: ((5, 4), 2, 0.9999999999999999, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "Agent 0 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 5], True, [['target']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 4), 2, 0.9999999999999999, 12)]\n",
      "next state for agent 1: [[6, 5], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 5], False, [['empty']], 0]\n",
      "next state for agent 1: [[6, 6], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "comm next state for agent 1: ((5, 5), 0, 1, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "Agent 0 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 6], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "next state for agent 1: [[7, 6], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "Agent 0 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 6], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 5], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "comm next state for agent 1: ((5, 5), 0, 1, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "Agent 0 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 5], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "comm next state for agent 1: ((5, 5), 0, 1, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "comm next state for agent 1: ((5, 5), 0, 1, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "comm next state for agent 1: ((5, 5), 0, 1, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 36 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: True\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 22)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 22)]\n",
      "comm next state for agent 1: ((5, 5), 0, 1, 22)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06ea680>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e90c0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06fd0f0>, <__main__.Case object at 0x7359c06fc880>, <__main__.Case object at 0x7359c06fc340>, <__main__.Case object at 0x7359c06fe680>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06ea5c0>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06fd6c0>, <__main__.Case object at 0x7359c06fc0d0>, <__main__.Case object at 0x7359c06fe230>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode succeeded, case (5, 5) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (7, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06eaa70>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06e9870>, <__main__.Case object at 0x7359c06e99c0>, <__main__.Case object at 0x7359c06ea260>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06eb850>, <__main__.Case object at 0x7359c06eb670>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06e8c70>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06fd570>, <__main__.Case object at 0x7359c06fcee0>, <__main__.Case object at 0x7359c06fdfc0>, <__main__.Case object at 0x7359c06fe9e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06eb430>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06fc5e0>, <__main__.Case object at 0x7359c06fd180>, <__main__.Case object at 0x7359c06fc6a0>, <__main__.Case object at 0x7359c06fe0b0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 6) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 6) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.9999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 36, Total Steps: 22, Total Rewards: [87, 79], Status Episode: True\n",
      "------------------------------------------End of episode 36 loop--------------------\n",
      "----- starting point of Episode 37 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((6, 2), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[6, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 37 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['empty']], ((5, 5), 0, 1, 12)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 2), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eae30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06eaa40>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eabf0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06eb2e0>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06e92a0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 37, Total Steps: 12, Total Rewards: [89, 92], Status Episode: True\n",
      "------------------------------------------End of episode 37 loop--------------------\n",
      "----- starting point of Episode 38 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 1], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "state for agent 0: [[2, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((8, 1), 4, 1, 13)]\n",
      "comm next state for agent 0: ((8, 1), 4, 1, 13)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 1], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((8, 1), 4, 1, 13)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 1], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 2], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 2], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 3], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 2), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[6, 3], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 4], False, [['agent']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 2), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['empty']], ((6, 3), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "state for agent 0: [[6, 4], False, [['agent']], ((6, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 4], False, [['agent']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['empty']], ((6, 3), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['target']], ((6, 4), 3, 1, 12)]\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 38 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "Agent 0 reached the target! Next state: [262.5, 262.5, 287.5, 287.5], Target: [262.5, 262.5, 287.5, 287.5]\n",
      "Agent 1 is locked. Done status: True, win status: True\n",
      "state for agent 0: [[5, 4], False, [['agent']], ((5, 4), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 5], True, [['agent']], ((5, 5), 0, 1, 12)]\n",
      "comm next state for agent 0: ((5, 5), 0, 1, 12)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 5], True, [['target']], ((6, 4), 3, 1, 12)]\n",
      "next state for agent 1: [[5, 5], True, [['agent']], ((6, 4), 3, 1, 12)]\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06eba60>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06eb280>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06e9e10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06ea2f0>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06ea1a0>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06ebe80>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode succeeded, case (5, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 3) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 2) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 1) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (4, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (3, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (2, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (1, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (0, 0) for agent 0 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (5, 5) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 5), 0, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 1), 4, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06eafb0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06ea470>, <__main__.Case object at 0x7359c06ea440>, <__main__.Case object at 0x7359c06eb7c0>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06eb310>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06ebfd0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode succeeded, case (5, 5) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (5, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (6, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 4) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 3) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (7, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (8, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 2) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, updated case base with fewer steps: ((8, 1), 4, 0.5, 12)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not updated as it has more or equal steps.\n",
      "Episode succeeded, case (9, 0) for agent 1 is not updated as it has more or equal steps.\n",
      "Integrated case process. comm case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 1)\n",
      "Integrated case process. comm case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 38, Total Steps: 12, Total Rewards: [89, 90], Status Episode: True\n",
      "------------------------------------------End of episode 38 loop--------------------\n",
      "----- starting point of Episode 39 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 39 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 39 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 39 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 39 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[4, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 39 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 39 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 39 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 39 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 39 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06ebf70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eb730>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06eb370>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06eb1f0>, <__main__.Case object at 0x7359c06e8d60>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eb4c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06eaf50>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06ea320>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode: 39, Total Steps: 10, Total Rewards: [-106, -109], Status Episode: False\n",
      "------------------------------------------End of episode 39 loop--------------------\n",
      "----- starting point of Episode 40 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 1], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((0, 1), 4, 1, 21)]\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 21)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 1], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[2, 1], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((0, 1), 4, 1, 21)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((1, 1), 4, 1, 26)]\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 26)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "state for agent 0: [[2, 1], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((1, 1), 4, 1, 26)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 34)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 1], False, [['empty']], 0]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((2, 1), 4, 1, 34)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((3, 1), 1, 1, 14)]\n",
      "comm next state for agent 1: ((3, 1), 1, 1, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((3, 1), 1, 1, 14)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 1], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[5, 1], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 2], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['obstacle']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[5, 2], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 1], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[5, 1], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 40 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((5, 4), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "next state for agent 1: [[5, 4], False, [['agent']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06ea7a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06ea740>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eb8e0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06ea4d0>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06eb2b0>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06eb2e0>, <__main__.Case object at 0x7359c06ea950>, <__main__.Case object at 0x7359c06ea9b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06eb4c0>, <__main__.Case object at 0x7359c06ebc10>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e9720>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 1, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 1)\n",
      "Integrated case process. comm case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 4, 1)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 40, Total Steps: 13, Total Rewards: [-112, -107], Status Episode: False\n",
      "------------------------------------------End of episode 40 loop--------------------\n",
      "----- starting point of Episode 41 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 41 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 41 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 41 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 41 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 41 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 41 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 41 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['agent']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['agent']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06eb760>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06e9810>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ea590>, <__main__.Case object at 0x7359c06ea3e0>, <__main__.Case object at 0x7359c06ea320>, <__main__.Case object at 0x7359c06eb580>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e9ed0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 41, Total Steps: 9, Total Rewards: [-106, -108], Status Episode: False\n",
      "------------------------------------------End of episode 41 loop--------------------\n",
      "----- starting point of Episode 42 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 42 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 42 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 42 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 1], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 42 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 1], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((3, 1), 1, 1, 14)]\n",
      "comm next state for agent 1: ((3, 1), 1, 1, 14)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 42 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((3, 1), 1, 1, 14)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 42 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['agent']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['agent']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06ea7a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb3d0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06ea830>, <__main__.Case object at 0x7359c06e92a0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06e9930>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 1, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 42, Total Steps: 9, Total Rewards: [-108, -108], Status Episode: False\n",
      "------------------------------------------End of episode 42 loop--------------------\n",
      "----- starting point of Episode 43 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 43 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 43 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 43 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 43 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 43 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 43 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 43 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 43 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 43 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06ebaf0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06ebbb0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06ebe80>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06ea7a0>, <__main__.Case object at 0x7359c06e9660>, <__main__.Case object at 0x7359c06eb400>, <__main__.Case object at 0x7359c06eb130>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ebdc0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06eb5e0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 43, Total Steps: 10, Total Rewards: [-106, -109], Status Episode: False\n",
      "------------------------------------------End of episode 43 loop--------------------\n",
      "----- starting point of Episode 44 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 44 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 44 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 44 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 44 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 44 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 44 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 44 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06eaa40>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06e9120>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eb580>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eadd0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 44, Total Steps: 8, Total Rewards: [-107, -107], Status Episode: False\n",
      "------------------------------------------End of episode 44 loop--------------------\n",
      "----- starting point of Episode 45 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 45 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 45 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 45 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 45 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 45 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 45 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 45 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06ebaf0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06eb790>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eb310>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06ebfd0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 45, Total Steps: 8, Total Rewards: [-107, -107], Status Episode: False\n",
      "------------------------------------------End of episode 45 loop--------------------\n",
      "----- starting point of Episode 46 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 46 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 46 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 46 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 46 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 46 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 46 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 46 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06e9930>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eb3d0>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06eb820>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06ebf70>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06e8b20>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 46, Total Steps: 8, Total Rewards: [-107, -107], Status Episode: False\n",
      "------------------------------------------End of episode 46 loop--------------------\n",
      "----- starting point of Episode 47 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 47 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 47 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 47 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 47 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 47 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 3], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 47 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((6, 3), 2, 1, 30)]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 3], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 47 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((6, 3), 2, 1, 30)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((6, 3), 2, 1, 30)]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e8c10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06ebbb0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 1)\n",
      "Integrated case process. comm case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eb010>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06eb5e0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 47, Total Steps: 8, Total Rewards: [-106, -107], Status Episode: False\n",
      "------------------------------------------End of episode 47 loop--------------------\n",
      "----- starting point of Episode 48 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 48 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 48 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 48 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 48 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 48 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 48 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 48 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06ebaf0>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e9810>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ebb20>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06ea350>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eb760>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 48, Total Steps: 8, Total Rewards: [-106, -107], Status Episode: False\n",
      "------------------------------------------End of episode 48 loop--------------------\n",
      "----- starting point of Episode 49 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 49 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 49 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 49 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 49 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 49 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 49 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 49 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06eaa40>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06ebfd0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06e96c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eab60>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 49, Total Steps: 8, Total Rewards: [-106, -107], Status Episode: False\n",
      "------------------------------------------End of episode 49 loop--------------------\n",
      "----- starting point of Episode 50 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 50 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 50 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 50 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 50 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 50 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 50 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 50 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06ebf70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e8c10>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06eb580>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06eb880>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 50, Total Steps: 8, Total Rewards: [-107, -107], Status Episode: False\n",
      "------------------------------------------End of episode 50 loop--------------------\n",
      "----- starting point of Episode 51 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 51 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 51 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 51 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 51 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 51 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 51 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 51 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06e9630>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06e8ca0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06ea800>, <__main__.Case object at 0x7359c06eb130>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06e9810>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 51, Total Steps: 8, Total Rewards: [-106, -107], Status Episode: False\n",
      "------------------------------------------End of episode 51 loop--------------------\n",
      "----- starting point of Episode 52 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 52 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 52 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 52 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 52 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 52 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 52 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 52 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06ebfd0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06ebb20>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06eb580>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06ea8f0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06eb760>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 52, Total Steps: 8, Total Rewards: [-106, -107], Status Episode: False\n",
      "------------------------------------------End of episode 52 loop--------------------\n",
      "----- starting point of Episode 53 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 53 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[1, 0], False, [['agent']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 53 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[1, 0], False, [['agent']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 53 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[2, 0], False, [['agent']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 53 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[2, 0], False, [['agent']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 53 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 53 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 53 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 53 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "Agent 1 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((6, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((5, 4), 2, 1, 9)]\n",
      "comm next state for agent 0: ((5, 4), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[5, 4], False, [['obstacle']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['agent']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06b1e10>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06eb820>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06ebb50>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06b1e70>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06e9720>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06eb700>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 2, 1)\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06eab60>, <__main__.Case object at 0x7359c06eb8e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06ea860>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 53, Total Steps: 9, Total Rewards: [-108, -107], Status Episode: False\n",
      "------------------------------------------End of episode 53 loop--------------------\n",
      "----- starting point of Episode 54 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 54 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 54 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 54 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 54 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 54 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 54 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 54 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e9630>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06e92a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06c4ee0>, <__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06eb730>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e8be0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eb8b0>, <__main__.Case object at 0x7359c06e9a50>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06ebc70>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06eb760>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eb310>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 54, Total Steps: 8, Total Rewards: [-106, -107], Status Episode: False\n",
      "------------------------------------------End of episode 54 loop--------------------\n",
      "----- starting point of Episode 55 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 55 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], 0]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 55 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 55 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 55 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 55 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 55 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 55 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06e9ae0>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06eae30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06c5120>, <__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e9120>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06ea9b0>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06eb310>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06e9ed0>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06e9c90>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ea770>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 55, Total Steps: 8, Total Rewards: [-106, -107], Status Episode: False\n",
      "------------------------------------------End of episode 55 loop--------------------\n",
      "----- starting point of Episode 56 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 56 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 56 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 56 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 56 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 56 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 56 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 56 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06e9b70>, <__main__.Case object at 0x7359c06e8b20>, <__main__.Case object at 0x7359c06e8c10>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06e9720>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06b1e40>, <__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06e3a90>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06e96c0>, <__main__.Case object at 0x7359c06eb700>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06e9930>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06eb880>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06eb5e0>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06ebca0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06bfdf0>, <__main__.Case object at 0x7359c06ebf70>, <__main__.Case object at 0x7359c06eaa40>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eb580>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 56, Total Steps: 8, Total Rewards: [-106, -107], Status Episode: False\n",
      "------------------------------------------End of episode 56 loop--------------------\n",
      "----- starting point of Episode 57 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 57 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[6, 0], False, [['empty']], 0]\n",
      "next state for agent 0: [[6, 0], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "state for agent 0: [[6, 0], False, [['agent']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], 0]\n",
      "next state for agent 1: [[8, 3], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 57 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['obstacle']], 0]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 3], False, [['empty']], ((6, 0), 2, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 57 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 is locked. Done status: True, win status: False\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "next state for agent 0: [[6, 1], False, [['agent']], 0]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((6, 1), 2, 1, 7)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 1), 2, 1, 7)]\n",
      "comm next state for agent 1: ((6, 1), 2, 1, 7)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e0190>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06eadd0>, <__main__.Case object at 0x7359c06e9900>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06e9000>, <__main__.Case object at 0x7359c06ebfd0>, <__main__.Case object at 0x7359c06eb8e0>, <__main__.Case object at 0x7359c06eb010>, <__main__.Case object at 0x7359c06eb160>, <__main__.Case object at 0x7359c06eae00>, <__main__.Case object at 0x7359c06e9870>, <__main__.Case object at 0x7359c06e8a60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c06d70a0>, <__main__.Case object at 0x7359c069d060>, <__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06eb100>, <__main__.Case object at 0x7359c06e8c10>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06e9c90>, <__main__.Case object at 0x7359c06eae30>, <__main__.Case object at 0x7359c06eba90>, <__main__.Case object at 0x7359c06ea350>, <__main__.Case object at 0x7359c06ebb20>, <__main__.Case object at 0x7359c06ea8f0>, <__main__.Case object at 0x7359c06e9810>, <__main__.Case object at 0x7359c06ea860>, <__main__.Case object at 0x7359c06eabf0>, <__main__.Case object at 0x7359c06eab30>, <__main__.Case object at 0x7359c06e8e50>, <__main__.Case object at 0x7359c06e9600>, <__main__.Case object at 0x7359c06eb670>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06ea9b0>, <__main__.Case object at 0x7359c06e8eb0>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06e9750>, <__main__.Case object at 0x7359c06e9a50>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06ebbb0>, <__main__.Case object at 0x7359c06eb460>, <__main__.Case object at 0x7359c06e99c0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 57, Total Steps: 14, Total Rewards: [-107, -113], Status Episode: False\n",
      "------------------------------------------End of episode 57 loop--------------------\n",
      "----- starting point of Episode 58 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[0, 0], False, [['agent']], []]\n",
      "next state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 3)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 0], False, [['agent']], []]\n",
      "next state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 58 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[1, 0], False, [['empty']], ((9, 0), 2, 1, 3)]\n",
      "next state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "comm next state for agent 0: ((9, 1), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 1], False, [['empty']], ((0, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 58 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[2, 0], False, [['empty']], ((9, 1), 2, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((9, 2), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[9, 2], False, [['empty']], ((1, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 58 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[3, 0], False, [['empty']], ((9, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[3, 0], False, [['agent']], ((8, 2), 3, 1, 9)]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 9)\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "state for agent 1: [[8, 2], False, [['empty']], ((2, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 58 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[3, 0], False, [['agent']], ((8, 2), 3, 1, 9)]\n",
      "next state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 2], False, [['empty']], 0]\n",
      "next state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 58 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "state for agent 0: [[4, 0], False, [['empty']], ((7, 2), 2, 1, 9)]\n",
      "next state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 3], False, [['empty']], ((3, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((4, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 58 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "state for agent 0: [[5, 0], False, [['empty']], ((7, 3), 2, 1, 9)]\n",
      "next state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[7, 4], False, [['empty']], ((4, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "comm next state for agent 1: ((5, 0), 4, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "----- starting point of Episode 58 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "Agent 0 hit an obstacle! Next state: [312.5, 62.5, 337.5, 87.5]\n",
      "Agent 1 hit an obstacle! Next state: [262.5, 212.5, 287.5, 237.5]\n",
      "state for agent 0: [[6, 0], False, [['empty']], ((7, 4), 3, 1, 9)]\n",
      "next state for agent 0: [[6, 1], False, [['obstacle']], ((6, 4), 3, 1, 9)]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 9)\n",
      "action type of agent: 0: using solution from case base, no learning\n",
      "state for agent 1: [[6, 4], False, [['empty']], ((5, 0), 4, 1, 12)]\n",
      "next state for agent 1: [[5, 4], False, [['obstacle']], ((6, 0), 2, 1, 12)]\n",
      "comm next state for agent 1: ((6, 0), 2, 1, 12)\n",
      "action type of agent: 1: using solution from case base, no learning\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7359c06e29e0>, <__main__.Case object at 0x7359c06ebc40>, <__main__.Case object at 0x7359c06e9930>, <__main__.Case object at 0x7359c06ebdf0>, <__main__.Case object at 0x7359c06eb910>, <__main__.Case object at 0x7359c06eb790>, <__main__.Case object at 0x7359c06eb640>, <__main__.Case object at 0x7359c06eaa40>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7359c069e8c0>, <__main__.Case object at 0x7359c06b1de0>, <__main__.Case object at 0x7359c06e3ca0>, <__main__.Case object at 0x7359c06e9e10>, <__main__.Case object at 0x7359c06e92a0>, <__main__.Case object at 0x7359c06e9450>, <__main__.Case object at 0x7359c06e8ca0>, <__main__.Case object at 0x7359c06e9000>]\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 2), 3, 1)\n",
      "Integrated case process. comm case (9, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 1)\n",
      "Integrated case process. comm case (9, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 22\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 18\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 14\n",
      "cases content after RETAIN, problem: (3, 2), solution: 1, tv: 1, time steps: 38\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 1, time steps: 15\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 7\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 20\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7359c06bd570>, <__main__.Case object at 0x7359c06ebca0>, <__main__.Case object at 0x7359c06e9d50>, <__main__.Case object at 0x7359c06ea770>, <__main__.Case object at 0x7359c06eb130>, <__main__.Case object at 0x7359c06eafe0>, <__main__.Case object at 0x7359c06e8be0>, <__main__.Case object at 0x7359c06eb010>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7359c06bd7b0>, <__main__.Case object at 0x7359c06ebd30>, <__main__.Case object at 0x7359c06ebe20>, <__main__.Case object at 0x7359c06e97e0>, <__main__.Case object at 0x7359c06e8fa0>, <__main__.Case object at 0x7359c06ebb50>, <__main__.Case object at 0x7359c06eb5e0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "case content after REVISE for agent 1, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (5, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 0), 4, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 5), solution: 1, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (6, 2), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1, time steps: 25\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 3), solution: 1, tv: 1, time steps: 13\n",
      "cases content after RETAIN, problem: (9, 2), solution: 3, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 1, time steps: 16\n",
      "cases content after RETAIN, problem: (9, 1), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (8, 1), solution: 4, tv: 0.5, time steps: 12\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 1), solution: 2, tv: 1, time steps: 8\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1, time steps: 3\n",
      "cases content after RETAIN, problem: (5, 5), solution: 0, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (7, 6), solution: 1, tv: 1, time steps: 12\n",
      "cases content after RETAIN, problem: (6, 6), solution: 4, tv: 1, time steps: 11\n",
      "cases content after RETAIN, problem: (6, 5), solution: 2, tv: 1, time steps: 9\n",
      "cases content after RETAIN, problem: (7, 0), solution: 2, tv: 1, time steps: 57\n",
      "cases content after RETAIN, problem: (6, 0), solution: 4, tv: 1, time steps: 56\n",
      "cases content after RETAIN, problem: (5, 0), solution: 4, tv: 1, time steps: 53\n",
      "cases content after RETAIN, problem: (4, 0), solution: 4, tv: 1, time steps: 51\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1, time steps: 48\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1, time steps: 47\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1, time steps: 45\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1, time steps: 17\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1, time steps: 34\n",
      "cases content after RETAIN, problem: (3, 1), solution: 1, tv: 1, time steps: 40\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1, time steps: 26\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1, time steps: 21\n",
      "Episode: 58, Total Steps: 8, Total Rewards: [-107, -107], Status Episode: False\n",
      "------------------------------------------End of episode 58 loop--------------------\n",
      "Success rate: 35.59322033898305%\n",
      "Data saved to experiment_results/avg_rewards/avg_rewards_20241007_033511.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to experiment_results/total_steps/total_steps_20241007_033512.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to experiment_results/avg_cases/avg_cases_20241007_033512.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import json\n",
    "import psutil\n",
    "import pynvml\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from environment_ma_sensory_vector_dynamic import Env\n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, num_actions, env, alpha, gamma, epsilon):\n",
    "        self.env = env\n",
    "        self.num_actions = num_actions\n",
    "        self.learning_rate = alpha\n",
    "        self.discount_factor = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_tables = [defaultdict(lambda: [0.0] * num_actions) for _ in range(env.num_agents)]\n",
    "\n",
    "    @staticmethod\n",
    "    def arg_max(state_action):\n",
    "        max_index_list = []\n",
    "        max_value = state_action[0]\n",
    "        for index, value in enumerate(state_action):\n",
    "            if value > max_value:\n",
    "                max_index_list.clear()\n",
    "                max_value = value\n",
    "                max_index_list.append(index)\n",
    "            elif value == max_value:\n",
    "                max_index_list.append(index)\n",
    "        return random.choice(max_index_list)\n",
    "\n",
    "    def choose_action(self, agent_idx, state):\n",
    "        state = tuple(state)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            state_action = self.q_tables[agent_idx][state]\n",
    "            action = self.arg_max(state_action)\n",
    "        return action\n",
    "\n",
    "    def learn(self, agent_idx, state, action, reward, next_state, case_base=None):\n",
    "        state = tuple(state)\n",
    "        next_state = tuple(next_state)\n",
    "        current_q = self.q_tables[agent_idx][state][action]\n",
    "        max_next_q = max(self.q_tables[agent_idx][next_state])\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)\n",
    "        self.q_tables[agent_idx][state][action] = new_q\n",
    "\n",
    "\n",
    "class Case:\n",
    "    INCREMENT_SUCCESS = 0.1\n",
    "    DECREMENT_UNSUCCESS = -0.4\n",
    "    DECREMENT_SUCCESS_NO_CASE = -0.2\n",
    "\n",
    "    def __init__(self, problem, solution, trust_value=0.5, total_time_steps=0):\n",
    "        self.problem = ast.literal_eval(problem) if isinstance(problem, str) else problem\n",
    "        self.solution = solution\n",
    "        self.trust_value = trust_value\n",
    "        self.total_time_steps = total_time_steps  # New attribute for total time steps\n",
    "\n",
    "    @staticmethod\n",
    "    def sim_q(state1, state2):\n",
    "        state1 = np.atleast_1d(state1)\n",
    "        state2 = np.atleast_1d(state2)\n",
    "        CNDMaxDist = 6\n",
    "        v = state1.size\n",
    "        DistQ = np.sum([Case.dist_q(Objic, Objip) for Objic, Objip in zip(state1, state2)])\n",
    "        similarity = (CNDMaxDist * v - DistQ) / (CNDMaxDist * v)\n",
    "        return similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def dist_q(X1, X2):\n",
    "        return np.min(np.abs(X1 - X2))\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(state, case_base, threshold=0.1):\n",
    "        state = ast.literal_eval(state) if isinstance(state, str) else state\n",
    "        for case in case_base:\n",
    "            if state == case.problem: \n",
    "                return case\n",
    "\n",
    "    @staticmethod\n",
    "    def reuse(agent_idx, c, own_temp_case_base, comm_temp_case_base, source='own'):\n",
    "        \"\"\"Reuse step for adding cases to temporary case bases.\"\"\"\n",
    "        if source == 'own':\n",
    "            own_temp_case_base.append(c)\n",
    "        elif source == 'comm':\n",
    "            comm_temp_case_base.append(c)\n",
    "\n",
    "    @staticmethod\n",
    "    def revise(agent_idx, case_base, temporary_case_base, successful_episodes, total_steps):\n",
    "        for case in case_base:\n",
    "            if any((case.problem, case.solution) == (temp_case.problem, temp_case.solution) for temp_case in temporary_case_base):\n",
    "                if successful_episodes:\n",
    "                    case.trust_value += Case.INCREMENT_SUCCESS\n",
    "                else:\n",
    "                    case.trust_value -= Case.DECREMENT_UNSUCCESS\n",
    "            else:\n",
    "                if successful_episodes:\n",
    "                    case.trust_value -= Case.DECREMENT_SUCCESS_NO_CASE\n",
    "            \n",
    "            case.trust_value = max(0, min(case.trust_value, 1))\n",
    "            print(f\"case content after REVISE for agent {agent_idx}, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}, time steps: {case.total_time_steps}\")\n",
    "\n",
    "    @staticmethod\n",
    "    \n",
    "    @staticmethod\n",
    "    def retain(agent_idx, case_base, own_temp_case_base, comm_temp_case_base, successful_episodes, total_steps, threshold=0.49):\n",
    "        if successful_episodes:\n",
    "            for temp_case in reversed(own_temp_case_base):\n",
    "                state = tuple(np.atleast_1d(temp_case.problem))\n",
    "\n",
    "                existing_case = next((case for case in case_base if tuple(np.atleast_1d(case.problem)) == state), None)\n",
    "                \n",
    "                if existing_case is None:\n",
    "                    case_base.append(temp_case)\n",
    "                    print(f\"Episode succeeded, case {temp_case.problem} is empty. Temporary case base stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value}\")\n",
    "                else:\n",
    "                    if total_steps < existing_case.total_time_steps:\n",
    "                        # Update the case in the case base if the new case has fewer total steps\n",
    "                        existing_case.solution = temp_case.solution\n",
    "                        existing_case.trust_value = max(0, temp_case.trust_value)\n",
    "                        existing_case.total_time_steps = total_steps\n",
    "                        print(f\"Episode succeeded, updated case base with fewer steps: {temp_case.problem, temp_case.solution, temp_case.trust_value, total_steps}\")\n",
    "                    else:\n",
    "                        print(f\"Episode succeeded, case {temp_case.problem} for agent {agent_idx} is not updated as it has more or equal steps.\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Episode not succeeded, temporary case base from own experience is not stored to the case base\")\n",
    "\n",
    "        case_base_dict = {tuple(np.atleast_1d(case.problem)): case for case in case_base}\n",
    "\n",
    "        for temp_comm_case in reversed(comm_temp_case_base):\n",
    "            state_comm = tuple(np.atleast_1d(temp_comm_case.problem))\n",
    "            existing_case = case_base_dict.get(state_comm)\n",
    "\n",
    "            if existing_case is None:\n",
    "                case_base.append(temp_comm_case)\n",
    "                case_base_dict[state_comm] = temp_comm_case\n",
    "                print(f\"Integrated case process. comm case {temp_comm_case.problem} is empty. Temporary case base stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")\n",
    "            else:\n",
    "                print(f\"Integrated case process. comm case {temp_comm_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")\n",
    "\n",
    "        # Remove cases with trust values below the threshold\n",
    "        case_base[:] = [case for case in case_base if case.trust_value >= threshold]\n",
    "\n",
    "        for case in case_base:\n",
    "            print(f\"cases content after RETAIN, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}, time steps: {case.total_time_steps}\")\n",
    "\n",
    "        return case_base\n",
    "\n",
    "    \n",
    "\n",
    "class QCBRL:\n",
    "    def __init__(self, num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render):\n",
    "        self.num_actions = num_actions\n",
    "        self.env = env\n",
    "        self.episodes = episodes\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.render = render\n",
    "        self.epsilon_decay = epsilon_decay  \n",
    "        self.epsilon_min = epsilon_min  \n",
    "\n",
    "        self.problem_solvers = [ProblemSolver(num_actions, self.env, alpha, gamma, epsilon) for _ in range(self.env.num_agents)]\n",
    "        self.case_bases = [[] for _ in range(self.env.num_agents)]  # Individual case bases for each agent\n",
    "        self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for own experiences\n",
    "        self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for communication experiences\n",
    "        self.successful_episodes = [0] * self.env.num_agents\n",
    "        self.rewards_per_episode = [[] for _ in range(self.env.num_agents)]  \n",
    "        self.total_successful_episodes = 0 \n",
    "        self.action_type = [0] * self.env.num_agents\n",
    "        self.cases_per_episode = [[] for _ in range(self.env.num_agents)]\n",
    "\n",
    "    def run(self):\n",
    "        rewards = []\n",
    "        memory_usage = []\n",
    "        gpu_memory_usage = []\n",
    "        num_successful_episodes = 0\n",
    "        total_steps_list = []\n",
    "        success_steps = []\n",
    "\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "        for episode in range(episodes):\n",
    "            states = self.env.reset()\n",
    "            episode_reward = [0] * self.env.num_agents\n",
    "            total_steps = 0 \n",
    "            self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            success_count = [0] * self.env.num_agents\n",
    "            dones = [False] * self.env.num_agents\n",
    "            win_states = [False] * self.env.num_agents\n",
    "            successful_episodes = False\n",
    "\n",
    "            while not(all(dones)):\n",
    "                print(f\"----- starting point of Episode {episode} in steps {total_steps} loop -----\")\n",
    "                \n",
    "                actions = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    # print(f\"state before take action: {state}\")\n",
    "                    action = self.take_action(agent_idx, state)\n",
    "                    actions.append(action)\n",
    "\n",
    "                # print(f\"actions pass to the environment\")\n",
    "                next_states, rewards, dones = self.env.step(actions)\n",
    "\n",
    "                win_states = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    action = actions[agent_idx]\n",
    "                    reward = rewards[agent_idx]\n",
    "                    next_state = next_states[agent_idx]\n",
    "\n",
    "                    physical_state = tuple(state[0])\n",
    "                    win_state = state[1]\n",
    "                    comm_state = state[2]  # Communication state containing messages from other agents\n",
    "\n",
    "                    physical_next_state = tuple(next_state[0])\n",
    "                    win_next_state = next_state[1]\n",
    "                    sensory_next_state = next_state[2]\n",
    "                    comm_next_state = tuple(next_state[3]) if next_state[3] != 0 else next_state[3]\n",
    "\n",
    "                    physical_action = action[0]\n",
    "                    comm_action = action[1]\n",
    "\n",
    "                    # Process messages received from other agents\n",
    "                    print(f\"state for agent {agent_idx}: {state}\")\n",
    "                    print(f\"next state for agent {agent_idx}: {next_state}\")\n",
    "                    print(f\"comm next state for agent {agent_idx}: {comm_next_state}\")\n",
    "                    # print(f\"comm next state content: {comm_next_state[0]}\")\n",
    "                    \n",
    "                    # if all(element is None for element in comm_next_state):\n",
    "                    # if (comm_next_state == [None]) or (comm_next_state is None):\n",
    "                    if (comm_next_state == 0):\n",
    "                        pass\n",
    "                    else:\n",
    "                        comm_case = Case(problem=comm_next_state[0], solution=comm_next_state[1], trust_value=comm_next_state[2], total_time_steps=comm_next_state[3])\n",
    "                        Case.reuse(agent_idx, comm_case, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='comm')\n",
    "\n",
    "                    # print(f\"state agent {agent_idx} before update: {physical_state}\")\n",
    "                    # print(f\"win state agent {agent_idx} before update: {win_next_state}\")\n",
    "                    # print(f\"action agent {agent_idx} before update: {physical_action}\")\n",
    "                    # print(f\"reward agent {agent_idx} before update: {reward}\")\n",
    "                    # print(f\"next state agent {agent_idx} before update: {physical_next_state}\")\n",
    "\n",
    "                    c = Case(physical_state, physical_action, total_time_steps=total_steps)\n",
    "                    Case.reuse(agent_idx, c, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='own')\n",
    "\n",
    "                    # if self.action_type[agent_idx] == 0:\n",
    "                    #     if not env.locked[agent_idx]:\n",
    "                    #         print(f\"action type of agent: {agent_idx}: problem solver, agent learned\")\n",
    "                    #         self.problem_solvers[agent_idx].learn(agent_idx, physical_state, physical_action, reward, physical_next_state, self.case_bases[agent_idx])\n",
    "                    #     else:\n",
    "                    #         print(f\"action type of agent: {agent_idx}: using problem solver but locked, no learning\")\n",
    "                    if self.action_type[agent_idx] == 0:\n",
    "                        print(f\"action type of agent: {agent_idx}: problem solver, agent learned\")\n",
    "                        self.problem_solvers[agent_idx].learn(agent_idx, physical_state, physical_action, reward, physical_next_state, self.case_bases[agent_idx])\n",
    "                    else:\n",
    "                        print(f\"action type of agent: {agent_idx}: using solution from case base, no learning\")\n",
    "\n",
    "                    if (win_next_state): \n",
    "                        success_count[agent_idx] += 1\n",
    "                        # print(f\"agent{agent_idx} hit !!!!!\")\n",
    "                    # else:\n",
    "                    #     print(f\"agent{agent_idx} not hit !!!!!\")\n",
    "\n",
    "                    episode_reward[agent_idx] += reward\n",
    "                    win_states.append(win_next_state)  \n",
    "\n",
    "                states = next_states\n",
    "                total_steps += 1\n",
    "\n",
    "                self.env.render()\n",
    "                \n",
    "            if all(win_states):\n",
    "                self.total_successful_episodes += 1\n",
    "                success_steps.append(total_steps)\n",
    "                successful_episodes = True\n",
    "                \n",
    "\n",
    "            \n",
    "            for agent_idx in range(self.env.num_agents):\n",
    "                print(f\"win status of agent {agent_idx}  before update the case base: {win_states[agent_idx]}\")\n",
    "                self.rewards_per_episode[agent_idx].append(episode_reward[agent_idx])\n",
    "                self.cases_per_episode[agent_idx].append(len(self.case_bases[agent_idx]))\n",
    "\n",
    "                print(f\"agent{agent_idx} own temp case base: {self.own_temp_case_bases[agent_idx]}\")\n",
    "                print(f\"agent{agent_idx} comm temp case base: {self.comm_temp_case_bases[agent_idx]}\")\n",
    "                \n",
    "                \n",
    "                Case.revise(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], win_states[agent_idx], total_steps = total_steps)\n",
    "                self.case_bases[agent_idx] = Case.retain(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], win_states[agent_idx], total_steps = total_steps)\n",
    "               \n",
    "                \n",
    "            self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "            \n",
    "            memory_usage.append(psutil.virtual_memory().percent)\n",
    "            gpu_memory_usage.append(pynvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**2)\n",
    "\n",
    "            print(f\"Episode: {episode}, Total Steps: {total_steps}, Total Rewards: {episode_reward}, Status Episode: {successful_episodes}\")\n",
    "            print(f\"------------------------------------------End of episode {episode} loop--------------------\")\n",
    "\n",
    "        # self.save_case_base_temporary()  # Save temporary case base after training\n",
    "        # self.save_case_base()  # Save case base after training\n",
    "\n",
    "        success_rate = self.total_successful_episodes / episodes * 100\n",
    "\n",
    "        return self.rewards_per_episode, success_rate, memory_usage, gpu_memory_usage, success_steps,  self.cases_per_episode\n",
    "\n",
    "    def take_action(self, agent_idx, state):\n",
    "        # print(f\"state detected in take action function: {state}\")\n",
    "        physical_state = tuple(state[0])\n",
    "        win_state = state[1]\n",
    "        comm_state = state[2]\n",
    "        # similar_solution = None\n",
    "\n",
    "        # if np.random.rand() < 0.01:\n",
    "        if np.random.rand() < self.epsilon:\n",
    "        # if np.random.rand() < 0:\n",
    "            # physical_action = np.random.choice(self.num_actions)\n",
    "            # comm_action = 0\n",
    "\n",
    "            physical_action = self.problem_solvers[agent_idx].choose_action(agent_idx, physical_state)\n",
    "            comm_action = 0  # No communication action if using problem solver action\n",
    "            self.action_type[agent_idx] = 0\n",
    "            print(f\"Physical Action for Agent {agent_idx} from problem solver: {physical_action}\")\n",
    "\n",
    "        else:\n",
    "            similar_solution = Case.retrieve(physical_state, self.case_bases[agent_idx])\n",
    "            if similar_solution is not None:\n",
    "                physical_action = similar_solution.solution\n",
    "                comm_action = (similar_solution.problem, similar_solution.solution, similar_solution.trust_value, similar_solution.total_time_steps)\n",
    "                self.action_type[agent_idx] = 1\n",
    "                # print(f\"Problem detected as a similiar soulution in case base: {similar_solution.problem}\")\n",
    "                print(f\"Physical Action for Agent {agent_idx} from case base: {physical_action}\")\n",
    "                # print(f\"Communication Action for Agent {agent_idx} from case base: {comm_action}\")\n",
    "                # print(f\"Trust value detected as a similiar solution in case base: {similar_solution.trust_value}\")\n",
    "            else:\n",
    "                physical_action = self.problem_solvers[agent_idx].choose_action(agent_idx, physical_state)\n",
    "                comm_action = 0  # No communication action if using problem solver action\n",
    "                self.action_type[agent_idx] = 0\n",
    "                print(f\"Physical Action for Agent {agent_idx} from problem solver: {physical_action}\")\n",
    "\n",
    "        # print(f\"physical action returned from the take action: {physical_action}\")\n",
    "        # print(f\"comm action returned from the take action: {comm_action}\")\n",
    "\n",
    "        return (physical_action, comm_action)\n",
    "\n",
    "    def case_exists_in_case_base(self, case, case_base):\n",
    "        \"\"\"Check if a case exists in the given case base.\"\"\"\n",
    "        return any(existing_case.problem == case.problem and existing_case.solution == case.solution for existing_case in case_base)\n",
    "        \n",
    "    \n",
    "    def save_case_base_temporary(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_temporary_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": int(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps)} for case in self.own_temp_case_bases[agent_idx] + self.comm_temp_case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Temporary case base for Agent {agent_idx} saved successfully.\")\n",
    "\n",
    "    def save_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": int(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps)} for case in self.case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Case base for Agent {agent_idx} saved successfully.\")\n",
    "        \n",
    "    def load_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            try:\n",
    "                with open(filename, 'r') as file:\n",
    "                    case_base_data = json.load(file)\n",
    "                    self.case_bases[agent_idx] = [Case(np.array(case[\"problem\"]), case[\"solution\"], case[\"trust_value\"], case[\"total_time_steps\"]) for case in case_base_data]\n",
    "                    print(f\"Case base for Agent {agent_idx} loaded successfully.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Case base file for Agent {agent_idx} not found. Starting with an empty case base.\")\n",
    "\n",
    "    def display_success_rate(self, success_rate):\n",
    "        print(f\"Success rate: {success_rate}%\")\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    @staticmethod\n",
    "    def save_data_to_csv(data, filename_prefix):\n",
    "        # Get the current date and time in the format 'YYYYMMDD_HHMMSS'\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Define root directory and subdirectory paths\n",
    "        root_folder = 'experiment_results'\n",
    "        subfolders = {\n",
    "            'avg_rewards': os.path.join(root_folder, 'avg_rewards'),\n",
    "            'total_steps': os.path.join(root_folder, 'total_steps'),\n",
    "            'avg_cases': os.path.join(root_folder, 'avg_cases')\n",
    "        }\n",
    "\n",
    "        # Create subfolder if it doesn't exist\n",
    "        if filename_prefix in subfolders:\n",
    "            os.makedirs(subfolders[filename_prefix], exist_ok=True)\n",
    "            # Create the full filename with the timestamp in the appropriate subfolder\n",
    "            filename = os.path.join(subfolders[filename_prefix], f\"{filename_prefix}_{timestamp}.csv\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid filename prefix. It must be one of 'avg_rewards', 'total_steps', or 'avg_cases'.\")\n",
    "\n",
    "        # Save data to CSV file\n",
    "        with open(filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Write data to CSV file based on its format\n",
    "            if filename_prefix == 'avg_rewards':\n",
    "                # Write header\n",
    "                header = ['eps'] + [f'agent_{i}_reward' for i in range(len(data))]\n",
    "                writer.writerow(header)\n",
    "                # Write rows\n",
    "                for i in range(len(next(iter(data.values())))):  # Assuming all agents have equal length data\n",
    "                    row = [i] + [data[f'Agent_{agent_idx}'][i] for agent_idx in range(len(data))]\n",
    "                    writer.writerow(row)\n",
    "            elif filename_prefix == 'total_steps':\n",
    "                # Write header\n",
    "                writer.writerow(['eps', 'total_steps'])\n",
    "                # Write rows\n",
    "                for i, total_steps in enumerate(data['total_steps']):\n",
    "                    writer.writerow([i, total_steps])\n",
    "            elif filename_prefix == 'avg_cases':\n",
    "                # Write header with increment and decrement values\n",
    "                header = ['inc_success', 'dec_unsuccess', 'dec_success_nocase', 'eps'] + [f'total_case_agent_{agent_idx}' for agent_idx in range(len(data))]\n",
    "                writer.writerow(header)\n",
    "                inc_success = Case.INCREMENT_SUCCESS\n",
    "                dec_unsuccess = Case.DECREMENT_UNSUCCESS\n",
    "                dec_success_nocase = Case.DECREMENT_SUCCESS_NO_CASE\n",
    "                # Write rows\n",
    "                for i in range(len(next(iter(data.values())))):  # Assuming all agents have equal length data\n",
    "                    row = [inc_success, dec_unsuccess, dec_success_nocase, i] + [data[f'Agent_{agent_idx}'][i] for agent_idx in range(len(data))]\n",
    "                    writer.writerow(row)\n",
    "\n",
    "        print(f\"Data saved to {filename}\")\n",
    "\n",
    "    def plot_rewards(self, rewards, window=1):\n",
    "        avg_rewards = {}\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            # Calculate the moving average of rewards over the specified window size\n",
    "            moving_avg_rewards = [np.mean(rewards[agent_idx][i:i + window]) for i in range(0, len(rewards[agent_idx]), window)]\n",
    "            avg_rewards[f'Agent_{agent_idx}'] = moving_avg_rewards\n",
    "            \n",
    "            # Plot the moving average rewards\n",
    "            plt.plot(moving_avg_rewards, label=f'Agent {agent_idx}')\n",
    "\n",
    "        # Save data to CSV with a unique timestamp\n",
    "        self.save_data_to_csv(avg_rewards, 'avg_rewards')\n",
    "\n",
    "        plt.xlabel(f'Episode (Averaged over every {window} episodes)')\n",
    "        plt.ylabel('Average Total Reward')\n",
    "        plt.title('Average Rewards over Episodes')\n",
    "        plt.legend()\n",
    "        plt.ylim(-400, 400)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_total_steps(self, total_steps_list):\n",
    "        total_steps_data = {'total_steps': total_steps_list}\n",
    "\n",
    "        # Save data to CSV with a unique timestamp\n",
    "        self.save_data_to_csv(total_steps_data, 'total_steps')\n",
    "\n",
    "        # Plot total steps for successful episodes\n",
    "        plt.plot(total_steps_list)\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Steps')\n",
    "        plt.title('Total Steps for Successful Episodes over Episodes')\n",
    "        plt.ylim(top=500)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_average_cases(self, num_cases_per_episode_agents, window=1):\n",
    "        avg_num_cases_per_episode_agents = [\n",
    "            [np.mean(num_cases_per_episode_agents[agent_idx][i:i + window]) for i in range(0, len(num_cases_per_episode_agents[agent_idx]), window)]\n",
    "            for agent_idx in range(self.env.num_agents)\n",
    "        ]\n",
    "\n",
    "        # Prepare data for CSV\n",
    "        avg_cases_data = {}\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            avg_cases_data[f'Agent_{agent_idx}'] = avg_num_cases_per_episode_agents[agent_idx]\n",
    "\n",
    "        # Save data to CSV with a unique timestamp\n",
    "        self.save_data_to_csv(avg_cases_data, 'avg_cases')\n",
    "\n",
    "        # Plot the average number of cases stored in case base for each agent\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            plt.plot(range(0, len(num_cases_per_episode_agents[agent_idx]), window), avg_num_cases_per_episode_agents[agent_idx], label=f'Average Number of Cases Stored (Agent {agent_idx})', marker='o')\n",
    "\n",
    "        plt.xlabel(f'Episode (Averaged over every {window} episodes)')\n",
    "        plt.ylabel('Average Count')\n",
    "        plt.title('Average Number of Cases Stored in Case Base Over Episodes for Each Agent')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "        # Adding the original incremental and decremental values as additional labels below the graph\n",
    "        plt.figtext(0.1, -0.1, \"+0.1 if (successful_episodes and case exists)\", fontsize=10, color='green')\n",
    "        plt.figtext(0.1, -0.15, \"-0.4 if (not successful_episodes and case exists)\", fontsize=10, color='red')\n",
    "        plt.figtext(0.1, -0.2, \"-0.2 if (successful_episodes and case does not exist)\", fontsize=10, color='orange')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_resources(self, memory_usage, gpu_memory_usage):\n",
    "        plt.plot(memory_usage, label='Memory (%)')\n",
    "        plt.plot(gpu_memory_usage, label='GPU Memory (MB)')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Resource Usage')\n",
    "        plt.title('Resource Usage over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_agents = 2\n",
    "    num_obstacles = 10\n",
    "    obstacles_random_steps = 20\n",
    "    is_agent_silent = False\n",
    "    episodes=59\n",
    "    max_steps=400\n",
    "    alpha=0.1\n",
    "    gamma=0.9\n",
    "    epsilon=0.1\n",
    "    epsilon_decay = 0.995  \n",
    "    epsilon_min = 0.01  \n",
    "    render = True\n",
    "    sensory_size = 0 #it must be odd, if event will be converted to one level odd number above\n",
    "    gpixels=50\n",
    "    gheight=10\n",
    "    gwidth=10\n",
    "    is_sensor_active = True\n",
    "    window=1\n",
    "\n",
    "    env = Env(num_agents=num_agents, num_obstacles=num_obstacles, obstacles_random_steps = obstacles_random_steps, is_agent_silent=is_agent_silent, sensory_size=sensory_size, gpixels=gpixels, gheight=gheight, gwidth=gwidth, is_sensor_active=is_sensor_active)\n",
    "    \n",
    "    num_actions = len(env.action_space)\n",
    "    \n",
    "    agent = QCBRL(num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render)\n",
    "    rewards, success_rate, memory_usage, gpu_memory_usage, total_step_list, cases_per_episode = agent.run()\n",
    "\n",
    "    agent.display_success_rate(success_rate)\n",
    "    agent.plot_rewards(rewards, window=window)\n",
    "    agent.plot_total_steps(total_step_list)\n",
    "    agent.plot_resources(memory_usage, gpu_memory_usage)\n",
    "    agent.plot_average_cases(cases_per_episode, window=window)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
