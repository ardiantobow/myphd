{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- starting point of Episode 0 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 48 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 49 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 50 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 51 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 52 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 53 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 54 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 55 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 56 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 57 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 58 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 59 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 60 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 61 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 62 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 63 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 64 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 65 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 66 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 67 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 68 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 69 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 70 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 71 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 72 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 73 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 74 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 75 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 76 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 77 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 78 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 79 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 80 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 81 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 82 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 83 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 84 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 85 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 86 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 87 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 88 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 89 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 90 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 91 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 92 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 93 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 94 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 95 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 96 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 97 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 98 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e3870e440>, <__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e3875de70>, <__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e3875dd50>, <__main__.Case object at 0x730e38775150>, <__main__.Case object at 0x730e387766e0>, <__main__.Case object at 0x730e38776800>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38776a10>, <__main__.Case object at 0x730e38776ad0>, <__main__.Case object at 0x730e38776bf0>, <__main__.Case object at 0x730e38776c80>, <__main__.Case object at 0x730e38776d10>, <__main__.Case object at 0x730e38776e00>, <__main__.Case object at 0x730e38776f50>, <__main__.Case object at 0x730e38776fe0>, <__main__.Case object at 0x730e387770a0>, <__main__.Case object at 0x730e387771c0>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e38777370>, <__main__.Case object at 0x730e38777400>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e38777670>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e38777820>, <__main__.Case object at 0x730e387778b0>, <__main__.Case object at 0x730e387779d0>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38777af0>, <__main__.Case object at 0x730e38777c10>, <__main__.Case object at 0x730e38777d00>, <__main__.Case object at 0x730e38777ca0>, <__main__.Case object at 0x730e38777e20>, <__main__.Case object at 0x730e38777f40>, <__main__.Case object at 0x730e38776c20>, <__main__.Case object at 0x730e387564d0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e387772e0>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38780580>, <__main__.Case object at 0x730e387776a0>, <__main__.Case object at 0x730e38780730>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38777a00>, <__main__.Case object at 0x730e38780a30>, <__main__.Case object at 0x730e38780ac0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38777d30>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38780dc0>, <__main__.Case object at 0x730e38780e80>, <__main__.Case object at 0x730e38780fa0>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e387812a0>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38781480>, <__main__.Case object at 0x730e387815a0>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38781780>, <__main__.Case object at 0x730e387818a0>, <__main__.Case object at 0x730e38781930>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38782080>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38782230>, <__main__.Case object at 0x730e387822c0>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e38782560>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38782740>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38782a70>, <__main__.Case object at 0x730e38782b60>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38782c80>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e38748370>, <__main__.Case object at 0x730e3874bca0>, <__main__.Case object at 0x730e3875dc30>, <__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3876a920>, <__main__.Case object at 0x730e387763e0>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38776530>, <__main__.Case object at 0x730e38776680>, <__main__.Case object at 0x730e38776740>, <__main__.Case object at 0x730e38776830>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38776590>, <__main__.Case object at 0x730e38776a70>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e387762f0>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e38776ec0>, <__main__.Case object at 0x730e38776ef0>, <__main__.Case object at 0x730e38777070>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38777340>, <__main__.Case object at 0x730e387773a0>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e38777580>, <__main__.Case object at 0x730e38777640>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e38777910>, <__main__.Case object at 0x730e38777970>, <__main__.Case object at 0x730e387765c0>, <__main__.Case object at 0x730e38777b50>, <__main__.Case object at 0x730e38777c40>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38777e80>, <__main__.Case object at 0x730e38777f70>, <__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e38780160>, <__main__.Case object at 0x730e38780220>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38780340>, <__main__.Case object at 0x730e38780100>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e387805e0>, <__main__.Case object at 0x730e38780640>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38780be0>, <__main__.Case object at 0x730e38780c40>, <__main__.Case object at 0x730e387809a0>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e38780ee0>, <__main__.Case object at 0x730e38780f40>, <__main__.Case object at 0x730e38780ca0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38781240>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38781540>, <__main__.Case object at 0x730e387803d0>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38781840>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38781ae0>, <__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e387809d0>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38780fd0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38782680>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e387827d0>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38782aa0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387818d0>, <__main__.Case object at 0x730e38782ce0>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 0, Total Steps: 99, Total Rewards: [-36, -108], Status Episode: False\n",
      "------------------------------------------End of episode 0 loop--------------------\n",
      "----- starting point of Episode 1 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e3873cbb0>, <__main__.Case object at 0x730e387564d0>, <__main__.Case object at 0x730e3874ab30>, <__main__.Case object at 0x730e387697b0>, <__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e387765f0>, <__main__.Case object at 0x730e38776770>, <__main__.Case object at 0x730e38776aa0>, <__main__.Case object at 0x730e38776bf0>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e38776e90>, <__main__.Case object at 0x730e387771c0>, <__main__.Case object at 0x730e38777040>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e387776d0>, <__main__.Case object at 0x730e387779d0>, <__main__.Case object at 0x730e38777ac0>, <__main__.Case object at 0x730e38777d00>, <__main__.Case object at 0x730e38777eb0>, <__main__.Case object at 0x730e3873f1c0>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38776530>, <__main__.Case object at 0x730e38776740>, <__main__.Case object at 0x730e3876a920>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e38777070>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e38777340>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e387777f0>, <__main__.Case object at 0x730e38776ad0>, <__main__.Case object at 0x730e38777b50>, <__main__.Case object at 0x730e38777cd0>, <__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e3876ab00>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e3874bca0>, <__main__.Case object at 0x730e3875c970>, <__main__.Case object at 0x730e387682e0>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e387766b0>, <__main__.Case object at 0x730e38776950>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38776c50>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e38776fb0>, <__main__.Case object at 0x730e38776a10>, <__main__.Case object at 0x730e38777370>, <__main__.Case object at 0x730e387775b0>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e38777880>, <__main__.Case object at 0x730e38777af0>, <__main__.Case object at 0x730e38777d60>, <__main__.Case object at 0x730e38777f40>, <__main__.Case object at 0x730e387776a0>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38776680>, <__main__.Case object at 0x730e38776830>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38777a00>, <__main__.Case object at 0x730e387762f0>, <__main__.Case object at 0x730e38776ec0>, <__main__.Case object at 0x730e38776ef0>, <__main__.Case object at 0x730e38776590>, <__main__.Case object at 0x730e387773a0>, <__main__.Case object at 0x730e38777580>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e38777970>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38777d90>, <__main__.Case object at 0x730e38777e50>, <__main__.Case object at 0x730e38777220>]\n",
      "agent1 comm temp case base: []\n",
      "Episode succeeded, case (5, 4) is empty. Temporary case base stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 0, 0.5)\n",
      "Episode succeeded, case (6, 4) is empty. Temporary case base stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 5) is empty. Temporary case base stored to the case base: ((6, 5), 1, 0.5)\n",
      "Episode succeeded, case (7, 5) is empty. Temporary case base stored to the case base: ((7, 5), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 2, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 4, 0.5)\n",
      "Episode succeeded, case (6, 3) is empty. Temporary case base stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (5, 3) is empty. Temporary case base stored to the case base: ((5, 3), 1, 0.5)\n",
      "Episode succeeded, case (5, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 3), 0, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 4, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 0, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 1, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 4, 0.5)\n",
      "Episode succeeded, case (5, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 3), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 3, 0.5)\n",
      "Episode succeeded, case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 3, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 4, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 1, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 0, 0.5)\n",
      "Episode succeeded, case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 1, 0.5)\n",
      "Episode succeeded, case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 0, 0.5)\n",
      "Episode succeeded, case (7, 1) is empty. Temporary case base stored to the case base: ((7, 1), 4, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 1, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 5), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 5), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 4), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 3), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 3), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 2), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "Episode: 1, Total Steps: 38, Total Rewards: [-17, 13], Status Episode: False\n",
      "------------------------------------------End of episode 1 loop--------------------\n",
      "----- starting point of Episode 2 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.5, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 0.5, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 0.5, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 0.5, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 0.5, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 0.5, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.5, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 0.5, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 0.5, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.5, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 2 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.5, 35)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e38748550>, <__main__.Case object at 0x730e3876a920>, <__main__.Case object at 0x730e387766e0>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e38777820>, <__main__.Case object at 0x730e38777ca0>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38777190>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38755000>, <__main__.Case object at 0x730e3870e440>, <__main__.Case object at 0x730e3875de70>, <__main__.Case object at 0x730e387697b0>, <__main__.Case object at 0x730e38776c80>, <__main__.Case object at 0x730e387764d0>, <__main__.Case object at 0x730e38777670>, <__main__.Case object at 0x730e38777b80>, <__main__.Case object at 0x730e38776530>, <__main__.Case object at 0x730e38776a40>, <__main__.Case object at 0x730e38777070>]\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (6, 4) is empty. Temporary case base stored to the case base: ((6, 4), 3, 0.5)\n",
      "Integrated case process. comm case (6, 3) is empty. Temporary case base stored to the case base: ((6, 3), 2, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 0.5)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 0.5)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 0.5)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 0.5)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 0.5)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 0.5)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 0.5)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e3873cbb0>, <__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e387682e0>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e38776e90>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e387768c0>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e38777340>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 5), solution: 1, tv: 0.09999999999999998, time steps: 34\n",
      "case content after REVISE for agent 1, problem: (7, 5), solution: 3, tv: 0.09999999999999998, time steps: 33\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 2, tv: 0.09999999999999998, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 0.6, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.09999999999999998, time steps: 28\n",
      "case content after REVISE for agent 1, problem: (5, 3), solution: 1, tv: 0.09999999999999998, time steps: 27\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 3, tv: 0.09999999999999998, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 3, tv: 0.09999999999999998, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (7, 1), solution: 4, tv: 0.09999999999999998, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "Episode: 2, Total Steps: 11, Total Rewards: [-19, 40], Status Episode: False\n",
      "------------------------------------------End of episode 2 loop--------------------\n",
      "----- starting point of Episode 3 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.6, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 0.6, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 0.6, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 0.6, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 0.6, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 0.6, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 3 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38748550>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e38776d40>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38777d60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e387564d0>, <__main__.Case object at 0x730e38776fe0>, <__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e38777610>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e387768c0>, <__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e38777e20>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e3876a920>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e38776aa0>, <__main__.Case object at 0x730e38777ac0>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e38776e90>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e38776680>, <__main__.Case object at 0x730e387776a0>, <__main__.Case object at 0x730e387763b0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.7, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 0.7, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.7, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 0.7, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 0.7, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 0.7, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 0.7, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.7, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.7\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.7\n",
      "Episode: 3, Total Steps: 11, Total Rewards: [-16, 40], Status Episode: False\n",
      "------------------------------------------End of episode 3 loop--------------------\n",
      "----- starting point of Episode 4 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.7, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 0.7, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 0.7, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 0.7, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 0.7, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 0.7, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.7, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 0.7, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 0.7, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.7, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 0.7, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387564d0>, <__main__.Case object at 0x730e387682e0>, <__main__.Case object at 0x730e38777e20>, <__main__.Case object at 0x730e38777610>, <__main__.Case object at 0x730e38776d40>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38776a40>, <__main__.Case object at 0x730e387776d0>, <__main__.Case object at 0x730e38776470>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e38777a30>, <__main__.Case object at 0x730e38776bc0>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38776ef0>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e38777a90>, <__main__.Case object at 0x730e38777f70>, <__main__.Case object at 0x730e38776f50>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e387812a0>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38780dc0>, <__main__.Case object at 0x730e38777ac0>, <__main__.Case object at 0x730e38780a30>, <__main__.Case object at 0x730e38780850>, <__main__.Case object at 0x730e38780730>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e38780400>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e38781930>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38777a00>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38782560>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38782890>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e38748550>, <__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e38777820>, <__main__.Case object at 0x730e387769b0>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e38748370>, <__main__.Case object at 0x730e38776710>, <__main__.Case object at 0x730e38777580>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (5, 4) is empty. Temporary case base stored to the case base: ((5, 4), 3, 0.7)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e387766e0>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e387768c0>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e38777d60>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38777af0>, <__main__.Case object at 0x730e38776e30>, <__main__.Case object at 0x730e38777730>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38777b50>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e387767d0>, <__main__.Case object at 0x730e38781210>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e387815a0>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38780610>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38780b50>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38782110>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38781e10>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38782920>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 0.7999999999999999, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 0.7999999999999999, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.7999999999999999, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 0.7999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 0.7999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 0.7999999999999999, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 0.7999999999999999, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.7999999999999999, time steps: 1\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "Episode: 4, Total Steps: 48, Total Rewards: [-57, 40], Status Episode: False\n",
      "------------------------------------------End of episode 4 loop--------------------\n",
      "----- starting point of Episode 5 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.7999999999999999, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 0.7999999999999999, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 0.7999999999999999, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 0.7999999999999999, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 0.7999999999999999, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 0.7999999999999999, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.7999999999999999, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 0.7999999999999999, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 0.7999999999999999, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.7999999999999999, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 0.7999999999999999, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 48 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 49 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 50 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 51 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 52 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 53 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 54 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 55 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 56 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 57 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 58 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 59 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 60 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 61 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 62 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e3873cbb0>, <__main__.Case object at 0x730e387769b0>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e387776d0>, <__main__.Case object at 0x730e38777a30>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e387775b0>, <__main__.Case object at 0x730e38776ef0>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e38776e30>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e38777b50>, <__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781000>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38780700>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38782230>, <__main__.Case object at 0x730e38782740>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38780f70>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38782b60>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e38782980>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38781ed0>, <__main__.Case object at 0x730e38783610>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e387830a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e387682e0>, <__main__.Case object at 0x730e38748370>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e38777610>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e38776a40>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e38777970>, <__main__.Case object at 0x730e38777cd0>, <__main__.Case object at 0x730e38777370>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e38777d60>, <__main__.Case object at 0x730e38777af0>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e38777c40>, <__main__.Case object at 0x730e38777490>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38782b90>, <__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38777d00>, <__main__.Case object at 0x730e38780a30>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38781450>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e38781780>, <__main__.Case object at 0x730e387771c0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e387805e0>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e38780220>, <__main__.Case object at 0x730e38782c80>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e387828f0>, <__main__.Case object at 0x730e38782b30>, <__main__.Case object at 0x730e38783820>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38783580>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e387832e0>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38783100>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38777340>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38776470>, <__main__.Case object at 0x730e38776bc0>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e38776f80>, <__main__.Case object at 0x730e38777ac0>, <__main__.Case object at 0x730e38776f20>, <__main__.Case object at 0x730e387762f0>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38777730>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e387812a0>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38780730>, <__main__.Case object at 0x730e38780250>, <__main__.Case object at 0x730e38781930>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38781480>, <__main__.Case object at 0x730e38780e80>, <__main__.Case object at 0x730e387815a0>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38782080>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38780ca0>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38780be0>, <__main__.Case object at 0x730e38780970>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e387820b0>, <__main__.Case object at 0x730e387822f0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38782a40>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e387835b0>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e387833a0>, <__main__.Case object at 0x730e38783250>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38783040>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 0.8999999999999999, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 0.8999999999999999, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.8999999999999999, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 0.8999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 0.8999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 0.8999999999999999, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 0.8999999999999999, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.8999999999999999, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "Episode: 5, Total Steps: 63, Total Rewards: [-72, 40], Status Episode: False\n",
      "------------------------------------------End of episode 5 loop--------------------\n",
      "----- starting point of Episode 6 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.8999999999999999, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 0.8999999999999999, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 0.8999999999999999, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 0.8999999999999999, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 0.8999999999999999, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 0.8999999999999999, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.8999999999999999, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 0.8999999999999999, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 0.8999999999999999, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.8999999999999999, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 0.8999999999999999, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e38776a40>, <__main__.Case object at 0x730e38777970>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e387779a0>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e387769b0>, <__main__.Case object at 0x730e38777f10>, <__main__.Case object at 0x730e38776f50>, <__main__.Case object at 0x730e38776650>, <__main__.Case object at 0x730e38777880>, <__main__.Case object at 0x730e38777e20>, <__main__.Case object at 0x730e38777e50>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e387768c0>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38780f40>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38780220>, <__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387828f0>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e387832e0>, <__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38780640>, <__main__.Case object at 0x730e387813f0>, <__main__.Case object at 0x730e38781540>, <__main__.Case object at 0x730e387809d0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e387827d0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38783220>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e387682e0>, <__main__.Case object at 0x730e38777f70>, <__main__.Case object at 0x730e387766e0>, <__main__.Case object at 0x730e387777f0>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38776710>, <__main__.Case object at 0x730e387778b0>, <__main__.Case object at 0x730e38776fe0>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e38777b50>, <__main__.Case object at 0x730e38776560>, <__main__.Case object at 0x730e387765f0>, <__main__.Case object at 0x730e38777a90>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38776aa0>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38777370>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38783820>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38777d30>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e387811b0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38782aa0>, <__main__.Case object at 0x730e38780a30>, <__main__.Case object at 0x730e38783370>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38748370>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e38777610>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e38776e90>, <__main__.Case object at 0x730e38775150>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38777130>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e38776680>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e38777430>, <__main__.Case object at 0x730e38776ec0>, <__main__.Case object at 0x730e38777a00>, <__main__.Case object at 0x730e38776b00>, <__main__.Case object at 0x730e387832b0>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38782c80>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38782b30>, <__main__.Case object at 0x730e38783580>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e38780100>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38781ed0>, <__main__.Case object at 0x730e38783430>, <__main__.Case object at 0x730e38783130>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 0.9999999999999999, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 0.9999999999999999, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.9999999999999999, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 0.9999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 0.9999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 0.9999999999999999, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 0.9999999999999999, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.9999999999999999, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.7, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7\n",
      "Episode: 6, Total Steps: 47, Total Rewards: [-56, 40], Status Episode: False\n",
      "------------------------------------------End of episode 6 loop--------------------\n",
      "----- starting point of Episode 7 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.9999999999999999, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 0.9999999999999999, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 0.9999999999999999, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 0.9999999999999999, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 0.9999999999999999, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 0.9999999999999999, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.9999999999999999, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 0.9999999999999999, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 0.9999999999999999, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 0.9999999999999999, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 0.9999999999999999, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38748370>, <__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e38777c40>, <__main__.Case object at 0x730e38777820>, <__main__.Case object at 0x730e38776560>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38777a30>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38776f50>, <__main__.Case object at 0x730e38777e20>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e387778e0>, <__main__.Case object at 0x730e38777d00>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e38776b00>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38780400>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38783820>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38783760>, <__main__.Case object at 0x730e38781900>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e3876a920>, <__main__.Case object at 0x730e38776fe0>, <__main__.Case object at 0x730e38777b50>, <__main__.Case object at 0x730e38777a90>, <__main__.Case object at 0x730e38776aa0>, <__main__.Case object at 0x730e38777970>, <__main__.Case object at 0x730e387779a0>, <__main__.Case object at 0x730e38777f10>, <__main__.Case object at 0x730e38777880>, <__main__.Case object at 0x730e38777b20>, <__main__.Case object at 0x730e38776830>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e387776d0>, <__main__.Case object at 0x730e38777430>, <__main__.Case object at 0x730e38777a00>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38780dc0>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38780a30>, <__main__.Case object at 0x730e38777550>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38748550>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e387771c0>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e387765f0>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38777d30>, <__main__.Case object at 0x730e38776d40>, <__main__.Case object at 0x730e387769b0>, <__main__.Case object at 0x730e38776650>, <__main__.Case object at 0x730e38777e50>, <__main__.Case object at 0x730e38777610>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e38777ca0>, <__main__.Case object at 0x730e38776ef0>, <__main__.Case object at 0x730e38776f80>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38783370>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38781c60>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38782aa0>, <__main__.Case object at 0x730e38782b90>, <__main__.Case object at 0x730e38780490>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.7999999999999999, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7999999999999999\n",
      "Episode: 7, Total Steps: 29, Total Rewards: [-38, 40], Status Episode: False\n",
      "------------------------------------------End of episode 7 loop--------------------\n",
      "----- starting point of Episode 8 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 8 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38748550>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38777730>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e387772e0>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e38776710>, <__main__.Case object at 0x730e38777a30>, <__main__.Case object at 0x730e38777e20>, <__main__.Case object at 0x730e38777d00>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e38776bf0>, <__main__.Case object at 0x730e38776a40>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e38780f40>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e387820e0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387564d0>, <__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e38777340>, <__main__.Case object at 0x730e38777c70>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38776ad0>, <__main__.Case object at 0x730e38776560>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38776f50>, <__main__.Case object at 0x730e387778e0>, <__main__.Case object at 0x730e38777f40>, <__main__.Case object at 0x730e387778b0>, <__main__.Case object at 0x730e38777370>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38777ca0>, <__main__.Case object at 0x730e38776f80>, <__main__.Case object at 0x730e38775150>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e38780a30>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38777f10>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e38777880>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e38776ec0>, <__main__.Case object at 0x730e387766e0>, <__main__.Case object at 0x730e387767d0>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e387771c0>, <__main__.Case object at 0x730e38777ac0>, <__main__.Case object at 0x730e38777490>, <__main__.Case object at 0x730e38776f20>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38780400>, <__main__.Case object at 0x730e38783820>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38782c20>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.8999999999999999, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.8999999999999999\n",
      "Episode: 8, Total Steps: 25, Total Rewards: [-34, 40], Status Episode: False\n",
      "------------------------------------------End of episode 8 loop--------------------\n",
      "----- starting point of Episode 9 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 9 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38748550>, <__main__.Case object at 0x730e3873cbb0>, <__main__.Case object at 0x730e38777340>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38776560>, <__main__.Case object at 0x730e38777f40>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e38777a00>, <__main__.Case object at 0x730e38777c40>, <__main__.Case object at 0x730e38776410>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38777610>, <__main__.Case object at 0x730e38777b20>, <__main__.Case object at 0x730e38777820>, <__main__.Case object at 0x730e38776e90>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38783640>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38780400>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38781540>, <__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38782aa0>, <__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38783520>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e38780c70>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38782230>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e38780160>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e38748370>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38776bc0>, <__main__.Case object at 0x730e38777370>, <__main__.Case object at 0x730e38776f80>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e38777cd0>, <__main__.Case object at 0x730e38777d60>, <__main__.Case object at 0x730e38777f70>, <__main__.Case object at 0x730e387779a0>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38776e30>, <__main__.Case object at 0x730e38777490>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e38777d30>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387564d0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38777af0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38780640>, <__main__.Case object at 0x730e387772e0>, <__main__.Case object at 0x730e38783820>, <__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e38782b90>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e387809d0>, <__main__.Case object at 0x730e38783760>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38776380>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38780f40>, <__main__.Case object at 0x730e38783610>, <__main__.Case object at 0x730e38781570>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e38777c70>, <__main__.Case object at 0x730e38776ad0>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e387778b0>, <__main__.Case object at 0x730e38777ca0>, <__main__.Case object at 0x730e38777b50>, <__main__.Case object at 0x730e38777970>, <__main__.Case object at 0x730e38776470>, <__main__.Case object at 0x730e38776680>, <__main__.Case object at 0x730e387769b0>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e387776d0>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e387768c0>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38783370>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e387828f0>, <__main__.Case object at 0x730e387829e0>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38781360>, <__main__.Case object at 0x730e38782b30>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e38781000>, <__main__.Case object at 0x730e38780f70>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38782980>, <__main__.Case object at 0x730e38780fd0>, <__main__.Case object at 0x730e387800a0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.9999999999999999, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.9999999999999999\n",
      "Episode: 9, Total Steps: 48, Total Rewards: [-57, 40], Status Episode: False\n",
      "------------------------------------------End of episode 9 loop--------------------\n",
      "----- starting point of Episode 10 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 10 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38748550>, <__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38777370>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38777a90>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e387772e0>, <__main__.Case object at 0x730e38777340>, <__main__.Case object at 0x730e38776ef0>, <__main__.Case object at 0x730e38777a30>, <__main__.Case object at 0x730e38777130>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38775150>, <__main__.Case object at 0x730e38777e20>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e38783760>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38783040>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387564d0>, <__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e38776710>, <__main__.Case object at 0x730e38776a40>, <__main__.Case object at 0x730e387767d0>, <__main__.Case object at 0x730e38777d30>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e387765f0>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e38776830>, <__main__.Case object at 0x730e38776d40>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e387776d0>, <__main__.Case object at 0x730e387768c0>, <__main__.Case object at 0x730e38777880>, <__main__.Case object at 0x730e38780610>, <__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38783820>, <__main__.Case object at 0x730e387809d0>, <__main__.Case object at 0x730e38777cd0>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38776560>, <__main__.Case object at 0x730e38780e20>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38776f80>, <__main__.Case object at 0x730e38777d60>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e38776f20>, <__main__.Case object at 0x730e38776380>, <__main__.Case object at 0x730e38777f40>, <__main__.Case object at 0x730e38777730>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e38776ec0>, <__main__.Case object at 0x730e38777c70>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e38776bf0>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e38783280>, <__main__.Case object at 0x730e38783700>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 10, Total Steps: 30, Total Rewards: [-39, 40], Status Episode: False\n",
      "------------------------------------------End of episode 10 loop--------------------\n",
      "----- starting point of Episode 11 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 11 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e3873cbb0>, <__main__.Case object at 0x730e38777d00>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e38777820>, <__main__.Case object at 0x730e38777970>, <__main__.Case object at 0x730e387771c0>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e38777f40>, <__main__.Case object at 0x730e38776ec0>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38748550>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38780a30>, <__main__.Case object at 0x730e38781ea0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e3876a920>, <__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e38777490>, <__main__.Case object at 0x730e38776410>, <__main__.Case object at 0x730e38777e50>, <__main__.Case object at 0x730e38776680>, <__main__.Case object at 0x730e38777cd0>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38777f10>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e387778b0>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38777d60>, <__main__.Case object at 0x730e38776380>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e38776470>, <__main__.Case object at 0x730e38777ac0>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e38780610>, <__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e387777f0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e38776b00>, <__main__.Case object at 0x730e387779a0>, <__main__.Case object at 0x730e387778e0>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e38777b50>, <__main__.Case object at 0x730e387762f0>, <__main__.Case object at 0x730e38777370>, <__main__.Case object at 0x730e387772e0>, <__main__.Case object at 0x730e38777a00>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e387769b0>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e38776f20>, <__main__.Case object at 0x730e38777730>, <__main__.Case object at 0x730e38777c70>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38780400>, <__main__.Case object at 0x730e38780640>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38783760>, <__main__.Case object at 0x730e38780f40>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38783280>, <__main__.Case object at 0x730e38782740>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38781ed0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 11, Total Steps: 33, Total Rewards: [-42, 40], Status Episode: False\n",
      "------------------------------------------End of episode 11 loop--------------------\n",
      "----- starting point of Episode 12 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 12 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e38776410>, <__main__.Case object at 0x730e38777cd0>, <__main__.Case object at 0x730e38777490>, <__main__.Case object at 0x730e38776e30>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e38777d00>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e387766e0>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e38777c40>, <__main__.Case object at 0x730e38776aa0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e38776680>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38776f80>, <__main__.Case object at 0x730e38776e90>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38777af0>, <__main__.Case object at 0x730e387779a0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387682e0>, <__main__.Case object at 0x730e38776bf0>, <__main__.Case object at 0x730e38777e50>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38777f10>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38777a30>, <__main__.Case object at 0x730e38777a90>, <__main__.Case object at 0x730e38776ad0>, <__main__.Case object at 0x730e387774c0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 12, Total Steps: 13, Total Rewards: [-22, 40], Status Episode: False\n",
      "------------------------------------------End of episode 12 loop--------------------\n",
      "----- starting point of Episode 13 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 13 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e387779a0>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38776e90>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38776d40>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e387765f0>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e387768c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e38776680>, <__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e38776a40>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e38777850>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e38748370>, <__main__.Case object at 0x730e387777f0>, <__main__.Case object at 0x730e38776f80>, <__main__.Case object at 0x730e38777880>, <__main__.Case object at 0x730e38777af0>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e38776ef0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "Episode: 13, Total Steps: 11, Total Rewards: [-17, 40], Status Episode: False\n",
      "------------------------------------------End of episode 13 loop--------------------\n",
      "----- starting point of Episode 14 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 14 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e3873cbb0>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38776d40>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38776830>, <__main__.Case object at 0x730e38776410>, <__main__.Case object at 0x730e38777c40>, <__main__.Case object at 0x730e38776710>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e38775150>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387564d0>, <__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e38777e20>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38776ef0>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e387765f0>, <__main__.Case object at 0x730e3876a920>, <__main__.Case object at 0x730e38777d30>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e387772e0>, <__main__.Case object at 0x730e38776f50>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e387778e0>, <__main__.Case object at 0x730e38776a40>, <__main__.Case object at 0x730e38776aa0>, <__main__.Case object at 0x730e38776e90>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e387768c0>, <__main__.Case object at 0x730e38777880>, <__main__.Case object at 0x730e38776e30>, <__main__.Case object at 0x730e38777e50>, <__main__.Case object at 0x730e38776560>, <__main__.Case object at 0x730e38777130>, <__main__.Case object at 0x730e38775120>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.7, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7\n",
      "Episode: 14, Total Steps: 14, Total Rewards: [-23, 40], Status Episode: False\n",
      "------------------------------------------End of episode 14 loop--------------------\n",
      "----- starting point of Episode 15 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 15 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e38776f50>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e38777490>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e38776d40>, <__main__.Case object at 0x730e38776830>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e38776ec0>, <__main__.Case object at 0x730e387777f0>, <__main__.Case object at 0x730e38777130>, <__main__.Case object at 0x730e38776470>, <__main__.Case object at 0x730e38777970>, <__main__.Case object at 0x730e38776e30>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38781b40>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e387771c0>, <__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38776410>, <__main__.Case object at 0x730e38776bf0>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38777b20>, <__main__.Case object at 0x730e38777af0>, <__main__.Case object at 0x730e38776560>, <__main__.Case object at 0x730e387778b0>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e38777c70>, <__main__.Case object at 0x730e38777ca0>, <__main__.Case object at 0x730e38781ed0>, <__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38777ac0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387682e0>, <__main__.Case object at 0x730e38748370>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38776380>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e387772e0>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e387762f0>, <__main__.Case object at 0x730e38775150>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e387776d0>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e38776fe0>, <__main__.Case object at 0x730e38777f40>, <__main__.Case object at 0x730e38776b00>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e38781c00>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.7999999999999999, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7999999999999999\n",
      "Episode: 15, Total Steps: 25, Total Rewards: [-34, 40], Status Episode: False\n",
      "------------------------------------------End of episode 15 loop--------------------\n",
      "----- starting point of Episode 16 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 16 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387682e0>, <__main__.Case object at 0x730e3873cbb0>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e38776410>, <__main__.Case object at 0x730e38777af0>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38776f50>, <__main__.Case object at 0x730e38777490>, <__main__.Case object at 0x730e38776830>, <__main__.Case object at 0x730e38776ec0>, <__main__.Case object at 0x730e38776470>, <__main__.Case object at 0x730e38776e30>, <__main__.Case object at 0x730e387772e0>, <__main__.Case object at 0x730e387762f0>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e38777100>, <__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38781600>, <__main__.Case object at 0x730e38780640>, <__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e387806d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e38776bf0>, <__main__.Case object at 0x730e38777ac0>, <__main__.Case object at 0x730e387778b0>, <__main__.Case object at 0x730e38777c70>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e38777130>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e38777f70>, <__main__.Case object at 0x730e38776fe0>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38777340>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38783760>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38783610>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38777f40>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e387836d0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e38776ef0>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38776a40>, <__main__.Case object at 0x730e38776560>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e387779a0>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e387777f0>, <__main__.Case object at 0x730e38777970>, <__main__.Case object at 0x730e387765f0>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38775150>, <__main__.Case object at 0x730e387776d0>, <__main__.Case object at 0x730e38776b00>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38780f40>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38780400>, <__main__.Case object at 0x730e38780a30>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e38781540>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e387818d0>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38781fc0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.8999999999999999, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.8999999999999999\n",
      "Episode: 16, Total Steps: 41, Total Rewards: [-50, 40], Status Episode: False\n",
      "------------------------------------------End of episode 16 loop--------------------\n",
      "----- starting point of Episode 17 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 17 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3873f1f0>, <__main__.Case object at 0x730e38777cd0>, <__main__.Case object at 0x730e38777a30>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e38776980>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38777820>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38776bc0>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e387766e0>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38780850>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38780eb0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3870f880>, <__main__.Case object at 0x730e3876a920>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e38777e50>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38777b20>, <__main__.Case object at 0x730e38777610>, <__main__.Case object at 0x730e38776f20>, <__main__.Case object at 0x730e38777730>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e38777c40>, <__main__.Case object at 0x730e38777ca0>, <__main__.Case object at 0x730e38776aa0>, <__main__.Case object at 0x730e38775150>, <__main__.Case object at 0x730e38776b00>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e38783610>, <__main__.Case object at 0x730e387768c0>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38782020>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e38748370>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38777e20>, <__main__.Case object at 0x730e38777d60>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38777f70>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38776d40>, <__main__.Case object at 0x730e38777a90>, <__main__.Case object at 0x730e387778e0>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e38777f10>, <__main__.Case object at 0x730e387767d0>, <__main__.Case object at 0x730e38777430>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e387813f0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38783220>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.9999999999999999, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.9999999999999999\n",
      "Episode: 17, Total Steps: 28, Total Rewards: [-37, 40], Status Episode: False\n",
      "------------------------------------------End of episode 17 loop--------------------\n",
      "----- starting point of Episode 18 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 18 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e3873cbb0>, <__main__.Case object at 0x730e38777e50>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e38777730>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e38776aa0>, <__main__.Case object at 0x730e387768c0>, <__main__.Case object at 0x730e387768f0>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e387778e0>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e387834c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e387564d0>, <__main__.Case object at 0x730e3873efb0>, <__main__.Case object at 0x730e38777610>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e38777ca0>, <__main__.Case object at 0x730e38776b00>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38777820>, <__main__.Case object at 0x730e38777010>, <__main__.Case object at 0x730e38776890>, <__main__.Case object at 0x730e38777d60>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e38777a90>, <__main__.Case object at 0x730e38777f10>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e38776ef0>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e3876a920>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38781570>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.5, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.5, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.5, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.5, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.5, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.5, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e38776da0>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38777b20>, <__main__.Case object at 0x730e38777c40>, <__main__.Case object at 0x730e38775150>, <__main__.Case object at 0x730e38777ac0>, <__main__.Case object at 0x730e38776fe0>, <__main__.Case object at 0x730e38776b30>, <__main__.Case object at 0x730e38776bc0>, <__main__.Case object at 0x730e387766e0>, <__main__.Case object at 0x730e38776ce0>, <__main__.Case object at 0x730e38777f70>, <__main__.Case object at 0x730e38776d40>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e38777fa0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e38780d90>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 18, Total Steps: 23, Total Rewards: [-32, 40], Status Episode: False\n",
      "------------------------------------------End of episode 18 loop--------------------\n",
      "----- starting point of Episode 19 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 48 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 49 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 50 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 51 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 52 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 53 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 54 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 55 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 56 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 57 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 58 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 59 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 60 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 61 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 62 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 63 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 64 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 19 in steps 65 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387682e0>, <__main__.Case object at 0x730e38748550>, <__main__.Case object at 0x730e38777610>, <__main__.Case object at 0x730e38776b00>, <__main__.Case object at 0x730e387771f0>, <__main__.Case object at 0x730e38777d60>, <__main__.Case object at 0x730e38777f10>, <__main__.Case object at 0x730e38776b60>, <__main__.Case object at 0x730e38776cb0>, <__main__.Case object at 0x730e38777850>, <__main__.Case object at 0x730e38777760>, <__main__.Case object at 0x730e387778e0>, <__main__.Case object at 0x730e38776bf0>, <__main__.Case object at 0x730e387779a0>, <__main__.Case object at 0x730e38777d30>, <__main__.Case object at 0x730e387775b0>, <__main__.Case object at 0x730e387777f0>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38780640>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38780f40>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e387829e0>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38782110>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38783550>, <__main__.Case object at 0x730e38783310>, <__main__.Case object at 0x730e38783f70>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38783cd0>, <__main__.Case object at 0x730e38783ca0>, <__main__.Case object at 0x730e38783af0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e3875de10>, <__main__.Case object at 0x730e3873cbb0>, <__main__.Case object at 0x730e387697e0>, <__main__.Case object at 0x730e38777ca0>, <__main__.Case object at 0x730e38777820>, <__main__.Case object at 0x730e38777c70>, <__main__.Case object at 0x730e38777a90>, <__main__.Case object at 0x730e38777e50>, <__main__.Case object at 0x730e38776aa0>, <__main__.Case object at 0x730e38777370>, <__main__.Case object at 0x730e38777550>, <__main__.Case object at 0x730e38776500>, <__main__.Case object at 0x730e38776680>, <__main__.Case object at 0x730e387778b0>, <__main__.Case object at 0x730e387774c0>, <__main__.Case object at 0x730e38777790>, <__main__.Case object at 0x730e38777be0>, <__main__.Case object at 0x730e3870e1d0>, <__main__.Case object at 0x730e387772e0>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e3875de40>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38777dc0>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e387776d0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38776920>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38776440>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38781210>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781d80>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.6, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.09999999999999998, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.09999999999999998, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.09999999999999998, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.09999999999999998, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.09999999999999998, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.09999999999999998, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.09999999999999998, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.7999999999999999, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.09999999999999998, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) is empty. Temporary case base stored to the case base: ((3, 3), 1, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 0, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) is empty. Temporary case base stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 0, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 0, 0.5)\n",
      "Episode succeeded, case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 3), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387695a0>, <__main__.Case object at 0x730e3874ab60>, <__main__.Case object at 0x730e38777940>, <__main__.Case object at 0x730e387763b0>, <__main__.Case object at 0x730e38777190>, <__main__.Case object at 0x730e387772b0>, <__main__.Case object at 0x730e38775120>, <__main__.Case object at 0x730e38777730>, <__main__.Case object at 0x730e38777a30>, <__main__.Case object at 0x730e38776b90>, <__main__.Case object at 0x730e38777a60>, <__main__.Case object at 0x730e387773d0>, <__main__.Case object at 0x730e38777b20>, <__main__.Case object at 0x730e38776dd0>, <__main__.Case object at 0x730e38776e30>, <__main__.Case object at 0x730e38776380>, <__main__.Case object at 0x730e38777d00>, <__main__.Case object at 0x730e38780700>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e38783820>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38783280>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e387813f0>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38780850>, <__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e38782b60>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e38782c80>, <__main__.Case object at 0x730e38782740>, <__main__.Case object at 0x730e387809d0>, <__main__.Case object at 0x730e38781f90>, <__main__.Case object at 0x730e38782aa0>, <__main__.Case object at 0x730e38780580>, <__main__.Case object at 0x730e38780250>, <__main__.Case object at 0x730e387818a0>, <__main__.Case object at 0x730e38781ae0>, <__main__.Case object at 0x730e38780fd0>, <__main__.Case object at 0x730e38780100>, <__main__.Case object at 0x730e38782b30>, <__main__.Case object at 0x730e38781450>, <__main__.Case object at 0x730e387832e0>, <__main__.Case object at 0x730e38780ac0>, <__main__.Case object at 0x730e38782560>, <__main__.Case object at 0x730e38780e80>, <__main__.Case object at 0x730e387815a0>, <__main__.Case object at 0x730e38781e10>, <__main__.Case object at 0x730e38780c40>, <__main__.Case object at 0x730e38780970>, <__main__.Case object at 0x730e387820b0>, <__main__.Case object at 0x730e38782680>, <__main__.Case object at 0x730e38783790>, <__main__.Case object at 0x730e38783460>, <__main__.Case object at 0x730e38783f10>, <__main__.Case object at 0x730e38783f40>, <__main__.Case object at 0x730e38783dc0>, <__main__.Case object at 0x730e38783d00>, <__main__.Case object at 0x730e38783b80>, <__main__.Case object at 0x730e38783a90>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 19, Total Steps: 66, Total Rewards: [-15, 40], Status Episode: True\n",
      "------------------------------------------End of episode 19 loop--------------------\n",
      "----- starting point of Episode 20 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 0)\n",
      "----- starting point of Episode 20 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 1)\n",
      "----- starting point of Episode 20 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 35)\n",
      "----- starting point of Episode 20 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.5, 37)\n",
      "----- starting point of Episode 20 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.5, 53)\n",
      "----- starting point of Episode 20 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.5, 59)\n",
      "----- starting point of Episode 20 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 0.5, 60)\n",
      "----- starting point of Episode 20 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 0.5, 61)\n",
      "----- starting point of Episode 20 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 0.6, 29)\n",
      "----- starting point of Episode 20 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 0.6, 30)\n",
      "----- starting point of Episode 20 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.6, 35)\n",
      "----- starting point of Episode 20 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.6, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38783c10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38783d90>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.7, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.7, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.7, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.8999999999999999, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 1, tv: 0.09999999999999998, time steps: 56\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.09999999999999998, time steps: 52\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.09999999999999998, time steps: 51\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.09999999999999998, time steps: 50\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38780d00>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38783a90>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38781570>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 0.5)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 0.5)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "Episode: 20, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 20 loop--------------------\n",
      "----- starting point of Episode 21 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 0)\n",
      "----- starting point of Episode 21 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.6, 1)\n",
      "----- starting point of Episode 21 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 35)\n",
      "----- starting point of Episode 21 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.6, 37)\n",
      "----- starting point of Episode 21 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.6, 53)\n",
      "----- starting point of Episode 21 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.6, 59)\n",
      "----- starting point of Episode 21 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 0.6, 60)\n",
      "----- starting point of Episode 21 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 0.6, 61)\n",
      "----- starting point of Episode 21 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 0.7, 29)\n",
      "----- starting point of Episode 21 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 0.7, 30)\n",
      "----- starting point of Episode 21 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.7, 35)\n",
      "----- starting point of Episode 21 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.7, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e387821a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38781990>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.7999999999999999, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.7999999999999999, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.7999999999999999, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 0.9999999999999999, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 0.7, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 0.7, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.7, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.7, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38781210>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38781de0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38780be0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e387816c0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.09999999999999998, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.09999999999999998, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.09999999999999998, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.09999999999999998, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.09999999999999998, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.09999999999999998, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.09999999999999998, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.09999999999999998, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 21, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 21 loop--------------------\n",
      "----- starting point of Episode 22 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7, 0)\n",
      "----- starting point of Episode 22 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7, 1)\n",
      "----- starting point of Episode 22 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7, 35)\n",
      "----- starting point of Episode 22 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.7, 37)\n",
      "----- starting point of Episode 22 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.7, 53)\n",
      "----- starting point of Episode 22 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.7, 59)\n",
      "----- starting point of Episode 22 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 0.7, 60)\n",
      "----- starting point of Episode 22 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 0.7, 61)\n",
      "----- starting point of Episode 22 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 0.7999999999999999, 29)\n",
      "----- starting point of Episode 22 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 0.7999999999999999, 30)\n",
      "----- starting point of Episode 22 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.7999999999999999, 35)\n",
      "----- starting point of Episode 22 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.7999999999999999, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38782470>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38781e40>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.8999999999999999, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.8999999999999999, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.8999999999999999, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 0.7999999999999999, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 0.7999999999999999, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.7999999999999999, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.7999999999999999, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.7999999999999999, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7999999999999999, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7999999999999999, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38780b80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e387824d0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 0.7)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 0.7)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 0.7)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 0.7)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 0.7)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.7)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.7)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.7)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "Episode: 22, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 22 loop--------------------\n",
      "----- starting point of Episode 23 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7999999999999999, 0)\n",
      "----- starting point of Episode 23 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7999999999999999, 1)\n",
      "----- starting point of Episode 23 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7999999999999999, 35)\n",
      "----- starting point of Episode 23 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.7999999999999999, 37)\n",
      "----- starting point of Episode 23 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.7999999999999999, 53)\n",
      "----- starting point of Episode 23 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.7999999999999999, 59)\n",
      "----- starting point of Episode 23 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 0.7999999999999999, 60)\n",
      "----- starting point of Episode 23 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 0.7999999999999999, 61)\n",
      "----- starting point of Episode 23 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 0.8999999999999999, 29)\n",
      "----- starting point of Episode 23 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 0.8999999999999999, 30)\n",
      "----- starting point of Episode 23 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.8999999999999999, 35)\n",
      "----- starting point of Episode 23 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.8999999999999999, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e38783220>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38780be0>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38781fc0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 0.9999999999999999, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 0.9999999999999999, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 0.9999999999999999, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 0.8999999999999999, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 0.8999999999999999, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.8999999999999999, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.8999999999999999, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.8999999999999999, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.8999999999999999, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.8999999999999999, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38781210>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e387807c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38782140>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.29999999999999993, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.29999999999999993, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.29999999999999993, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.29999999999999993, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.29999999999999993, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.29999999999999993, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.29999999999999993, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.29999999999999993, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 23, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 23 loop--------------------\n",
      "----- starting point of Episode 24 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.8999999999999999, 0)\n",
      "----- starting point of Episode 24 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.8999999999999999, 1)\n",
      "----- starting point of Episode 24 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.8999999999999999, 35)\n",
      "----- starting point of Episode 24 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.8999999999999999, 37)\n",
      "----- starting point of Episode 24 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.8999999999999999, 53)\n",
      "----- starting point of Episode 24 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.8999999999999999, 59)\n",
      "----- starting point of Episode 24 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 0.8999999999999999, 60)\n",
      "----- starting point of Episode 24 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 0.8999999999999999, 61)\n",
      "----- starting point of Episode 24 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 0.9999999999999999, 29)\n",
      "----- starting point of Episode 24 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 0.9999999999999999, 30)\n",
      "----- starting point of Episode 24 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.9999999999999999, 35)\n",
      "----- starting point of Episode 24 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 0.9999999999999999, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38780910>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e387810c0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 0.9999999999999999, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 0.9999999999999999, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.9999999999999999, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.9999999999999999, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.9999999999999999, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.9999999999999999, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.9999999999999999, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38782bc0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38780040>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "Episode: 24, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 24 loop--------------------\n",
      "----- starting point of Episode 25 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.9999999999999999, 0)\n",
      "----- starting point of Episode 25 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.9999999999999999, 1)\n",
      "----- starting point of Episode 25 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.9999999999999999, 35)\n",
      "----- starting point of Episode 25 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.9999999999999999, 37)\n",
      "----- starting point of Episode 25 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.9999999999999999, 53)\n",
      "----- starting point of Episode 25 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.9999999999999999, 59)\n",
      "----- starting point of Episode 25 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 0.9999999999999999, 60)\n",
      "----- starting point of Episode 25 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 0.9999999999999999, 61)\n",
      "----- starting point of Episode 25 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 25 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 25 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 25 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38783a90>, <__main__.Case object at 0x730e38781750>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38783490>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38781210>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38781c90>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38782c20>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.4999999999999999, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.4999999999999999, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.4999999999999999, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.4999999999999999, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.4999999999999999, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.4999999999999999, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.4999999999999999, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.4999999999999999, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.4999999999999999\n",
      "Episode: 25, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 25 loop--------------------\n",
      "----- starting point of Episode 26 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 26 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 26 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 26 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 26 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 26 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 26 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 26 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 26 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 26 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 26 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 26 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387824d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e387820e0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38782ce0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38782800>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.09999999999999987, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.09999999999999987, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.09999999999999987, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.09999999999999987, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.09999999999999987, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.09999999999999987, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.09999999999999987, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.09999999999999987, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 26, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 26 loop--------------------\n",
      "----- starting point of Episode 27 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 27 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 27 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 27 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 27 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 27 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 27 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 27 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 27 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 27 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 27 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 27 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387824a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38783a90>, <__main__.Case object at 0x730e387823b0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e387806d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38781210>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38782890>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 27, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 27 loop--------------------\n",
      "----- starting point of Episode 28 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 28 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 28 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 28 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 28 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 28 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 28 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 28 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 28 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 28 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 28 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 28 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387831c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38780460>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387819c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38780be0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 28, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 28 loop--------------------\n",
      "----- starting point of Episode 29 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 29 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 29 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 29 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 29 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 29 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 29 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 29 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 29 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 29 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 29 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 29 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780be0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38782c20>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38782fe0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38780880>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38783d90>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 29, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 29 loop--------------------\n",
      "----- starting point of Episode 30 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 30 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 30 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 30 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 30 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 30 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 30 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 30 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 30 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 30 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 30 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 30 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387807f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38781c30>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38783220>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38782f20>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 30, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 30 loop--------------------\n",
      "----- starting point of Episode 31 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 31 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 31 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 31 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 31 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 31 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 31 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 31 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 31 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 31 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 31 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 31 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38782bc0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38781a20>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38782ce0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38780d90>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 31, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 31 loop--------------------\n",
      "----- starting point of Episode 32 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 32 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 32 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 32 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 32 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 32 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 32 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 32 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 32 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 32 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 32 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 32 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38783670>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38780d30>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e38781f60>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38783730>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 32, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 32 loop--------------------\n",
      "----- starting point of Episode 33 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 33 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 33 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 33 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 33 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 33 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 33 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 33 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 33 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 33 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 33 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 33 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e387808b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38781750>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e387824d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38781d50>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 33, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 33 loop--------------------\n",
      "----- starting point of Episode 34 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 34 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 34 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 34 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 34 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 34 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 34 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 34 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 34 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 34 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 34 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 34 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e387802b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38782290>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e387823e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e387824a0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 34, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 34 loop--------------------\n",
      "----- starting point of Episode 35 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 35 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 35 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 35 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 35 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 35 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 35 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 35 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 35 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 35 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 35 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 35 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38783a90>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38780d90>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38782050>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38782200>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781210>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38780940>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 35, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 35 loop--------------------\n",
      "----- starting point of Episode 36 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 36 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 36 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 36 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 36 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 36 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 36 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 36 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 36 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 36 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 36 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 36 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38780490>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e387831c0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38781ea0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e38780eb0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 36, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 36 loop--------------------\n",
      "----- starting point of Episode 37 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 37 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 37 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 37 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 37 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 37 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 37 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 37 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 37 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 37 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 37 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 37 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38782320>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e387815d0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38781f60>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38781210>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387807f0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 37, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 37 loop--------------------\n",
      "----- starting point of Episode 38 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 38 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 38 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 38 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 38 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 38 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 38 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 38 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 38 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 38 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 38 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 38 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387824a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38780bb0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387831f0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38781db0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 38, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 38 loop--------------------\n",
      "----- starting point of Episode 39 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 39 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 39 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 39 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 39 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 39 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 39 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 39 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 39 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 39 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 39 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 39 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38780310>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e387808e0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38781570>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38781090>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 39, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 39 loop--------------------\n",
      "----- starting point of Episode 40 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 40 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 40 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 40 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 40 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 40 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 40 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 40 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 40 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 40 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 40 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 40 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38780550>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38782b00>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38782200>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e387808b0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 40, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 40 loop--------------------\n",
      "----- starting point of Episode 41 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 41 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 41 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 41 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 41 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 41 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 41 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 41 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 41 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 41 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 41 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 41 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387807f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38781ba0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38780f10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38783e50>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 41, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 41 loop--------------------\n",
      "----- starting point of Episode 42 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 42 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 42 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 42 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 42 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 42 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 42 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 42 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 42 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 42 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 42 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 42 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38782260>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38783490>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e387833d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e387806d0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 42, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 42 loop--------------------\n",
      "----- starting point of Episode 43 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 43 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 43 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 43 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 43 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 43 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 43 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 43 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 43 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 43 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 43 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 43 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38780460>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38783a90>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e387814e0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e387831f0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38780490>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 43, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 43 loop--------------------\n",
      "----- starting point of Episode 44 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 44 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 44 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 44 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 44 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 44 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 44 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 44 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 44 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 44 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 44 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 44 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387808b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38781de0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e387828c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38783670>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 44, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 44 loop--------------------\n",
      "----- starting point of Episode 45 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 45 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 45 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 45 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 45 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 45 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 45 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 45 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 45 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 45 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 45 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 45 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38781fc0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38780130>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38782890>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38783a90>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38783220>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 45, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 45 loop--------------------\n",
      "----- starting point of Episode 46 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 46 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 46 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 46 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 46 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 46 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 46 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 46 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 46 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 46 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 46 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 46 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38782140>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781f00>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e387823e0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38780310>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e387814b0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 46, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 46 loop--------------------\n",
      "----- starting point of Episode 47 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 47 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 47 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 47 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 47 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 47 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 47 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 47 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 47 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 47 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 47 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 47 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38780490>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38781e70>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e387817b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38780e50>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 47, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 47 loop--------------------\n",
      "----- starting point of Episode 48 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 48 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 48 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 48 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 48 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 48 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 48 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 48 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 48 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 48 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 48 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 48 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e387824d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38780550>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e387820e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38782410>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 48, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 48 loop--------------------\n",
      "----- starting point of Episode 49 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 49 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 49 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 49 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 49 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 49 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 49 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 49 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 49 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 49 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 49 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 49 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387833d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38780370>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38782260>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38783d90>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 49, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 49 loop--------------------\n",
      "----- starting point of Episode 50 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 50 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 50 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 50 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 50 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 50 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 50 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 50 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 50 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 50 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 50 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 50 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387814b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38783040>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38782440>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38783400>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 50, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 50 loop--------------------\n",
      "----- starting point of Episode 51 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 51 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 51 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 51 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 51 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 51 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 51 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 51 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 51 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 51 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 51 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 51 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e387805b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38781120>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e387808e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38782290>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 51, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 51 loop--------------------\n",
      "----- starting point of Episode 52 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 52 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 52 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 52 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 52 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 52 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 52 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 52 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 52 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 52 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 52 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 52 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38782890>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38781210>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387801c0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38780df0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38780820>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 52, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 52 loop--------------------\n",
      "----- starting point of Episode 53 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 53 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 53 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 53 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 53 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 53 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 53 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 53 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 53 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 53 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 53 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 53 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38783d90>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38780880>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387827a0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780af0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 53, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 53 loop--------------------\n",
      "----- starting point of Episode 54 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 54 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 54 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 54 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 54 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 54 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 54 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 54 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 54 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 54 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 54 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 54 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e387815d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38782140>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38780d60>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e387836d0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 54, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 54 loop--------------------\n",
      "----- starting point of Episode 55 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 55 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 55 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 55 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 55 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 55 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 55 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 55 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 55 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 55 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 55 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 55 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38781b70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38780eb0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38783160>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387824d0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 55, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 55 loop--------------------\n",
      "----- starting point of Episode 56 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 56 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 56 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 56 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 56 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 56 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 56 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 56 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 56 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 56 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 56 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 56 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38780820>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38781e40>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e387811e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38782cb0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 56, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 56 loop--------------------\n",
      "----- starting point of Episode 57 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 57 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 57 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 57 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 57 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 57 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 57 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 57 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 57 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 57 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 57 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 57 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38780a60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38781c90>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38780130>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38783d30>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 57, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 57 loop--------------------\n",
      "----- starting point of Episode 58 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 58 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 58 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 58 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 58 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 58 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 58 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 58 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 58 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 58 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 58 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 58 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38782fe0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38782fb0>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e387802b0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387813c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e387805b0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 58, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 58 loop--------------------\n",
      "----- starting point of Episode 59 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 59 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 59 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 59 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 59 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 59 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 59 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 59 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 59 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 59 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 59 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 59 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38780b20>, <__main__.Case object at 0x730e38783a90>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e387824d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38783190>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38783ac0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38782ad0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 59, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 59 loop--------------------\n",
      "----- starting point of Episode 60 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 60 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 60 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 60 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 60 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 60 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 60 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 60 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 60 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 60 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 60 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 60 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38780c10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e387819c0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38780550>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38782140>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e387807c0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 60, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 60 loop--------------------\n",
      "----- starting point of Episode 61 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 61 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 61 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 61 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 61 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 61 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 61 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 61 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 61 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 61 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 61 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 61 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387801f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387839d0>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38782260>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e387815d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38782320>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 61, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 61 loop--------------------\n",
      "----- starting point of Episode 62 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 62 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 62 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 62 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 62 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 62 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 62 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 62 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 62 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 62 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 62 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 62 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e387805b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e387810c0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e387817e0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38780940>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38783a90>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e387827a0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 62, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 62 loop--------------------\n",
      "----- starting point of Episode 63 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 63 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 63 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 63 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 63 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 63 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 63 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 63 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 63 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 63 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 63 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 63 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e387800d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387802e0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38781750>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38781120>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e387823e0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 63, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 63 loop--------------------\n",
      "----- starting point of Episode 64 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 64 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 64 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 64 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 64 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 64 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 64 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 64 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 64 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 64 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 64 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 64 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782950>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38781960>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e387811e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38781a80>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e38780a60>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 64, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 64 loop--------------------\n",
      "----- starting point of Episode 65 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 65 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 65 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 65 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 65 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 65 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 65 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 65 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 65 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 65 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 65 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 65 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38782320>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e387807f0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38783400>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38782bc0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38781db0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38780490>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 65, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 65 loop--------------------\n",
      "----- starting point of Episode 66 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 66 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 66 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 66 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 66 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 66 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 66 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 66 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 66 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 66 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 66 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 66 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38780370>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38782fe0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e387824d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387823b0>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e38783040>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38781fc0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38780e50>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 66, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 66 loop--------------------\n",
      "----- starting point of Episode 67 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 67 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 67 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 67 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 67 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 67 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 67 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 67 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 67 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 67 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 67 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 67 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38783d90>, <__main__.Case object at 0x730e387830d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e387815d0>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38780550>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e387816c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38781060>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 67, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 67 loop--------------------\n",
      "----- starting point of Episode 68 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 68 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 68 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 68 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 68 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 68 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 68 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 68 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 2), 2, 1, 29)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 68 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 3), 2, 1, 30)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 68 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "----- starting point of Episode 68 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "----- starting point of Episode 68 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38783130>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38780a60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38780af0>, <__main__.Case object at 0x730e38781ba0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38780430>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38782710>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38781090>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "Integrated case process. comm case (6, 1) is empty. Temporary case base stored to the case base: ((6, 1), 2, 1)\n",
      "Integrated case process. comm case (6, 0) is empty. Temporary case base stored to the case base: ((6, 0), 2, 1)\n",
      "Integrated case process. comm case (7, 0) is empty. Temporary case base stored to the case base: ((7, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 1, 1)\n",
      "Integrated case process. comm case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 3, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e387836d0>, <__main__.Case object at 0x730e38781ff0>, <__main__.Case object at 0x730e38782890>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38780460>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38782050>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (6, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 1), 2, 0.5)\n",
      "Episode succeeded, case (6, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 0), 2, 0.5)\n",
      "Episode succeeded, case (7, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 68, Total Steps: 12, Total Rewards: [39, 40], Status Episode: True\n",
      "------------------------------------------End of episode 68 loop--------------------\n",
      "----- starting point of Episode 69 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 1, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 69 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 1, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 69 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 1, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 69 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 1, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 69 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 1, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 69 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 1, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 69 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 69 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 69 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 69 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 69 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 69 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e387801c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38783fd0>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e387801f0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38780310>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e387805b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38783ee0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38781e70>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 69, Total Steps: 12, Total Rewards: [39, -15], Status Episode: False\n",
      "------------------------------------------End of episode 69 loop--------------------\n",
      "----- starting point of Episode 70 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 2, 0.6, 1)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 70 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 1), 3, 0.6, 2)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 70 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 1, 0.6, 6)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 70 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 3, 0.6, 7)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 70 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 0), 3, 0.6, 9)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 70 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 0), 2, 0.6, 11)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 70 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 70 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 70 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 70 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 70 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 70 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((6, 1), 2, 0.6, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38781c30>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38780820>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38782c20>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e387813c0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38783a90>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38781120>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38783670>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (6, 1), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (6, 0), solution: 2, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (7, 0), solution: 3, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 1, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 3, tv: 0.19999999999999996, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 70, Total Steps: 12, Total Rewards: [39, -15], Status Episode: False\n",
      "------------------------------------------End of episode 70 loop--------------------\n",
      "----- starting point of Episode 71 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((6, 3), 2, 1, 30)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((6, 4), 3, 1, 35)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((5, 4), 3, 1, 37)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 71 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e387836a0>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38783df0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e387821a0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e387829e0>, <__main__.Case object at 0x730e38780f70>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38781a80>]\n",
      "agent0 comm temp case base: []\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 4, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38783580>, <__main__.Case object at 0x730e387800a0>, <__main__.Case object at 0x730e38782590>, <__main__.Case object at 0x730e38782440>, <__main__.Case object at 0x730e38782950>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e387808b0>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38780040>, <__main__.Case object at 0x730e387824d0>, <__main__.Case object at 0x730e387807c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38782470>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38781e40>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 0.6, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 0, 0.5)\n",
      "Episode succeeded, case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 0, 0.5)\n",
      "Episode succeeded, case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 0.5)\n",
      "Episode succeeded, case (9, 1) is empty. Temporary case base stored to the case base: ((9, 1), 1, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 0, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 4, 0.5)\n",
      "Episode succeeded, case (9, 2) is empty. Temporary case base stored to the case base: ((9, 2), 1, 0.5)\n",
      "Episode succeeded, case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 4, 0.5)\n",
      "Episode succeeded, case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 0, 0.5)\n",
      "Episode succeeded, case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 4, 0.5)\n",
      "Episode succeeded, case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 0, 0.5)\n",
      "Episode succeeded, case (9, 3) is empty. Temporary case base stored to the case base: ((9, 3), 1, 0.5)\n",
      "Episode succeeded, case (9, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 2), 2, 0.5)\n",
      "Episode succeeded, case (9, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 1), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 0, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 0, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 1, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 4, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 4, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 2), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 3), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 71, Total Steps: 29, Total Rewards: [39, 22], Status Episode: True\n",
      "------------------------------------------End of episode 71 loop--------------------\n",
      "----- starting point of Episode 72 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 0.5, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 72 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 0.5, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 72 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 0.5, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 72 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.5, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 72 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.5, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 72 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.5, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 72 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.5, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 72 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 72 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 72 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 72 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 72 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e38780670>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38783430>, <__main__.Case object at 0x730e38782650>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e38783bb0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38780df0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 4, tv: 0.09999999999999998, time steps: 28\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 0.5)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 0.5)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 0.5)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 0.5)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 0.5)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 0.5)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38782050>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38781d50>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (6, 3), solution: 2, tv: 0.19999999999999996, time steps: 30\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.7, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.6, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (9, 1), solution: 1, tv: 0.09999999999999998, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (9, 2), solution: 1, tv: 0.09999999999999998, time steps: 14\n",
      "case content after REVISE for agent 1, problem: (9, 3), solution: 1, tv: 0.09999999999999998, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 72, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 72 loop--------------------\n",
      "----- starting point of Episode 73 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 0.6, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 73 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 0.6, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 73 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 0.6, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 73 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.6, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 73 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.6, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 73 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.6, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 73 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.6, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 73 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 73 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 73 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 73 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 73 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e387833d0>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38780c70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e387829e0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e387813f0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.09999999999999998, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.09999999999999998, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.09999999999999998, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.09999999999999998, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.09999999999999998, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.09999999999999998, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.09999999999999998, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.7)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e387805b0>, <__main__.Case object at 0x730e38780f70>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e38781b10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e387805e0>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38780850>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.7999999999999999, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.7, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.7, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.7, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 0.7, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 0.7, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 73, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 73 loop--------------------\n",
      "----- starting point of Episode 74 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 0.7, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 74 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 0.7, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 74 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 0.7, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 74 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 74 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.7, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 74 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.7, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 74 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.7, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 74 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 74 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 74 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 74 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 74 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38783220>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387834f0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38781c60>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781ab0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.29999999999999993, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 0.7)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 0.7)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 0.7)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 0.7)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 0.7)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 0.7)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 0.7)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38783760>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38782cb0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38780bb0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.8999999999999999, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.7999999999999999, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.7999999999999999, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.7999999999999999, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.7999999999999999, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 0.7999999999999999, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 0.7999999999999999, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 74, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 74 loop--------------------\n",
      "----- starting point of Episode 75 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 0.7999999999999999, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 75 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 0.7999999999999999, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 75 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 0.7999999999999999, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 75 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.7999999999999999, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 75 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.7999999999999999, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 75 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.7999999999999999, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 75 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.7999999999999999, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 75 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 75 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 75 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 75 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 75 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999999, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e387806a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e38781c60>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e38781720>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.29999999999999993, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.29999999999999993, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.29999999999999993, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.29999999999999993, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.29999999999999993, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.29999999999999993, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.29999999999999993, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38782bf0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38782b60>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e387805e0>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e387826b0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.9999999999999999, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.8999999999999999, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.8999999999999999, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.8999999999999999, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.8999999999999999, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 0.8999999999999999, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 0.8999999999999999, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 75, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 75 loop--------------------\n",
      "----- starting point of Episode 76 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 0.8999999999999999, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 76 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 0.8999999999999999, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 76 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 0.8999999999999999, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 76 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.8999999999999999, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 76 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.8999999999999999, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 76 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.8999999999999999, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 76 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.8999999999999999, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 76 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 76 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 76 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 76 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 76 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999999, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38783760>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38782770>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781c60>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38781810>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.4999999999999999, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38783280>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e38781e40>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38780e50>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38783520>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e38780460>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 0.9999999999999999, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 0.9999999999999999, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 0.9999999999999999, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 0.9999999999999999, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 0.9999999999999999, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 0.9999999999999999, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 76, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 76 loop--------------------\n",
      "----- starting point of Episode 77 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 0.9999999999999999, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 77 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 0.9999999999999999, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 77 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 0.9999999999999999, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 77 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 0.9999999999999999, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 77 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 0.9999999999999999, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 77 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 0.9999999999999999, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 77 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 0.9999999999999999, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 77 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 77 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 77 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 77 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 77 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e387834f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e387829e0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.09999999999999987, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.4999999999999999, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.4999999999999999, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.4999999999999999, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.4999999999999999, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.4999999999999999, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.4999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.4999999999999999, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.4999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38781270>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387807c0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 77, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 77 loop--------------------\n",
      "----- starting point of Episode 78 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 78 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 78 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 78 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 78 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 78 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 78 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 78 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 78 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 78 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 78 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 78 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38783760>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38782ad0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38781db0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38780850>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.09999999999999987, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.09999999999999987, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.09999999999999987, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.09999999999999987, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.09999999999999987, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.09999999999999987, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.09999999999999987, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e38783af0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780160>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e38783190>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38783c40>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 78, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 78 loop--------------------\n",
      "----- starting point of Episode 79 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 79 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 79 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 79 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 79 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 79 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 79 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 79 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 79 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 79 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 79 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 79 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38780190>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38780700>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387826b0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e38781870>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38783af0>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e387829e0>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e387828c0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 79, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 79 loop--------------------\n",
      "----- starting point of Episode 80 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 80 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 80 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 80 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 80 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 80 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 80 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 80 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 80 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 80 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 80 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 80 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e387830d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781c00>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.6, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38780b80>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e387805e0>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e387831f0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e38780160>, <__main__.Case object at 0x730e38783760>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38781c60>, <__main__.Case object at 0x730e38781120>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 80, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 80 loop--------------------\n",
      "----- starting point of Episode 81 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 81 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 81 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 81 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 81 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 81 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 81 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 81 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 81 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 81 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 81 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 81 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38783520>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38782290>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e387829e0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38780460>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.19999999999999996, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.19999999999999996, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.19999999999999996, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.19999999999999996, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.19999999999999996, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38780700>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38780130>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e387823e0>, <__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e387831c0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 81, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 81 loop--------------------\n",
      "----- starting point of Episode 82 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 82 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 82 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 82 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 82 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 82 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 82 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 82 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 82 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 82 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 82 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 82 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e387829b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38783c40>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38781c60>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e387805e0>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38781d20>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e38781330>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 82, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 82 loop--------------------\n",
      "----- starting point of Episode 83 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 83 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 83 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 83 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 83 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 83 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 83 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 83 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 83 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 83 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 83 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 83 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38780700>, <__main__.Case object at 0x730e387829e0>, <__main__.Case object at 0x730e38782b60>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38783520>, <__main__.Case object at 0x730e38783a60>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38782020>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e387801f0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.6, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e387831c0>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e387802b0>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38780940>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38780c10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38783cd0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38782350>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38781ab0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 83, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 83 loop--------------------\n",
      "----- starting point of Episode 84 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 84 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 84 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 84 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 84 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 84 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 84 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 84 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 84 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 84 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 84 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 84 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780790>, <__main__.Case object at 0x730e38781db0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38781c60>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38783190>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.19999999999999996, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.19999999999999996, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.19999999999999996, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.19999999999999996, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.19999999999999996, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38781b70>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e38783cd0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38782fe0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 84, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 84 loop--------------------\n",
      "----- starting point of Episode 85 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 85 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 85 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 85 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 85 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 85 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 85 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 85 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 85 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 85 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 85 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 85 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38783520>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38781ed0>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38780700>, <__main__.Case object at 0x730e38780520>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387829e0>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e387831c0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38783a60>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38782f20>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38782b60>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38781510>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 85, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 85 loop--------------------\n",
      "----- starting point of Episode 86 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 86 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 86 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 86 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 86 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 86 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 86 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 86 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 86 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 86 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 86 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 86 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e387823e0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38781ed0>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38782cb0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.6, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38780550>, <__main__.Case object at 0x730e387816f0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38783cd0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38782260>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 86, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 86 loop--------------------\n",
      "----- starting point of Episode 87 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 87 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 87 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 87 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 87 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 87 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 87 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 87 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 87 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 87 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 87 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 87 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38783a60>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38781120>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38780550>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.19999999999999996, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.19999999999999996, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.19999999999999996, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.19999999999999996, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.19999999999999996, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38781a50>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38783af0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e387825c0>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e38783700>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 87, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 87 loop--------------------\n",
      "----- starting point of Episode 88 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 88 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 88 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 88 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 88 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 88 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 88 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 88 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 88 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 88 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 88 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 88 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e387801f0>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e38783ca0>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38781a20>, <__main__.Case object at 0x730e387820e0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782d70>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38781ed0>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38783520>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e387819f0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38780a00>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38783af0>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38781d50>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38783670>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 88, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 88 loop--------------------\n",
      "----- starting point of Episode 89 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 89 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 89 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 89 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 89 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 89 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 89 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 89 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 89 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 89 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 89 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 89 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781e70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38783ca0>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38780190>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.6, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38781420>, <__main__.Case object at 0x730e387806d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38783430>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38782bf0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 89, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 89 loop--------------------\n",
      "----- starting point of Episode 90 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 90 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 90 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 90 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 90 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 90 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 90 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 90 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 90 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 90 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 90 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 90 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38780e50>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38782170>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38782620>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38781570>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e38781420>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.19999999999999996, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.19999999999999996, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.19999999999999996, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.19999999999999996, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.19999999999999996, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38780880>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38780f10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e387829e0>, <__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38780850>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 90, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 90 loop--------------------\n",
      "----- starting point of Episode 91 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 91 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 91 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 91 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 91 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 91 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 91 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 91 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 91 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 91 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 91 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 91 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780850>, <__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38783b50>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e387803a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38783ca0>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e387819c0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e38781510>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e38783430>, <__main__.Case object at 0x730e38782bc0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e387806a0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38781c60>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 91, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 91 loop--------------------\n",
      "----- starting point of Episode 92 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 92 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 92 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 92 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 92 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 92 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 92 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 92 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 92 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 92 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 92 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 92 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38781ea0>, <__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e387825c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38780cd0>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38783b50>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38783730>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.6, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e38780850>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38780a90>, <__main__.Case object at 0x730e38783cd0>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38781cf0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38781810>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38781ed0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 92, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 92 loop--------------------\n",
      "----- starting point of Episode 93 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 93 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 93 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 93 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 93 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 93 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 93 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 93 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 93 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 93 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 93 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 93 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781ed0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e387802e0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e387816f0>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38780a60>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38781150>, <__main__.Case object at 0x730e38781d50>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.19999999999999996, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.19999999999999996, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.19999999999999996, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.19999999999999996, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.19999999999999996, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783a60>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38783160>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e38782020>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e38783520>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38783430>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38782b00>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781270>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 93, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 93 loop--------------------\n",
      "----- starting point of Episode 94 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 94 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 94 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 94 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 94 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 94 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 94 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 94 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 94 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 94 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 94 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 94 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e38781870>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e38783b50>, <__main__.Case object at 0x730e38783700>, <__main__.Case object at 0x730e387820e0>, <__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e38781ed0>, <__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38780850>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38781390>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e387811e0>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38780070>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38782020>, <__main__.Case object at 0x730e38780760>, <__main__.Case object at 0x730e38782b60>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38783cd0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38782d10>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 94, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 94 loop--------------------\n",
      "----- starting point of Episode 95 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 95 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 95 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 95 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 95 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 95 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 95 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 95 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 95 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 95 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 95 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 95 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e38781e70>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38783610>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38781660>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38783a60>, <__main__.Case object at 0x730e38780670>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38783c10>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.6, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38781f60>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38783ca0>, <__main__.Case object at 0x730e38781c00>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38783520>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38783490>, <__main__.Case object at 0x730e38781de0>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38781030>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 95, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 95 loop--------------------\n",
      "----- starting point of Episode 96 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 96 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 96 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 96 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 96 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 96 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 96 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 96 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 96 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 96 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 96 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 96 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38780e20>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38780850>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38781630>, <__main__.Case object at 0x730e38781570>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e387808e0>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38783a60>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e38781f30>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e387812d0>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e387831f0>, <__main__.Case object at 0x730e38781c60>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.19999999999999996, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.19999999999999996, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.19999999999999996, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.19999999999999996, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.19999999999999996, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e38781b10>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38780d30>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38782050>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e387813c0>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38780520>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38781120>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38781b40>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 96, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 96 loop--------------------\n",
      "----- starting point of Episode 97 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 97 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 97 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 97 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 97 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 97 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 97 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 97 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 97 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 97 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 97 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 97 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e38780070>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38781ab0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38781b70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387806d0>, <__main__.Case object at 0x730e38782530>, <__main__.Case object at 0x730e38780190>, <__main__.Case object at 0x730e387803a0>, <__main__.Case object at 0x730e38780130>, <__main__.Case object at 0x730e38780c10>, <__main__.Case object at 0x730e38781030>, <__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38781270>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 47\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (7, 4) is empty. Temporary case base stored to the case base: ((7, 4), 3, 1)\n",
      "Integrated case process. comm case (7, 3) is empty. Temporary case base stored to the case base: ((7, 3), 2, 1)\n",
      "Integrated case process. comm case (7, 2) is empty. Temporary case base stored to the case base: ((7, 2), 2, 1)\n",
      "Integrated case process. comm case (8, 2) is empty. Temporary case base stored to the case base: ((8, 2), 3, 1)\n",
      "Integrated case process. comm case (8, 1) is empty. Temporary case base stored to the case base: ((8, 1), 2, 1)\n",
      "Integrated case process. comm case (8, 0) is empty. Temporary case base stored to the case base: ((8, 0), 2, 1)\n",
      "Integrated case process. comm case (9, 0) is empty. Temporary case base stored to the case base: ((9, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38782410>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e38783610>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e38783520>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e387828c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e38780d30>, <__main__.Case object at 0x730e387821d0>, <__main__.Case object at 0x730e387810f0>, <__main__.Case object at 0x730e38782ce0>, <__main__.Case object at 0x730e38782290>, <__main__.Case object at 0x730e38782170>, <__main__.Case object at 0x730e38780bb0>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38783ca0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.19999999999999996, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.19999999999999996, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (6, 2) is empty. Temporary case base stored to the case base: ((6, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 97, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 97 loop--------------------\n",
      "----- starting point of Episode 98 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 98 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 98 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 98 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 98 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 98 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 98 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 98 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 98 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 98 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 98 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 98 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38780f10>, <__main__.Case object at 0x730e38783e50>, <__main__.Case object at 0x730e38783730>, <__main__.Case object at 0x730e38780d90>, <__main__.Case object at 0x730e38780d00>, <__main__.Case object at 0x730e38781c00>, <__main__.Case object at 0x730e38782ad0>, <__main__.Case object at 0x730e38782260>, <__main__.Case object at 0x730e38782b60>, <__main__.Case object at 0x730e387830a0>, <__main__.Case object at 0x730e38780a60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387830d0>, <__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38783d30>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e387827a0>, <__main__.Case object at 0x730e387814b0>, <__main__.Case object at 0x730e387829b0>, <__main__.Case object at 0x730e38780910>, <__main__.Case object at 0x730e38781c90>, <__main__.Case object at 0x730e38780df0>, <__main__.Case object at 0x730e38783430>, <__main__.Case object at 0x730e387816f0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 47\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.6, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.6, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781690>, <__main__.Case object at 0x730e38780850>, <__main__.Case object at 0x730e38781b40>, <__main__.Case object at 0x730e38782cb0>, <__main__.Case object at 0x730e38781300>, <__main__.Case object at 0x730e387800d0>, <__main__.Case object at 0x730e38782830>, <__main__.Case object at 0x730e38781870>, <__main__.Case object at 0x730e38781990>, <__main__.Case object at 0x730e38783cd0>, <__main__.Case object at 0x730e38780490>, <__main__.Case object at 0x730e387826b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387828c0>, <__main__.Case object at 0x730e38781060>, <__main__.Case object at 0x730e38783c40>, <__main__.Case object at 0x730e387802e0>, <__main__.Case object at 0x730e38782320>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38781720>, <__main__.Case object at 0x730e38783e20>, <__main__.Case object at 0x730e38782fe0>, <__main__.Case object at 0x730e38782f20>, <__main__.Case object at 0x730e387805e0>, <__main__.Case object at 0x730e38783ac0>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "Integrated case process. comm case (5, 2) is empty. Temporary case base stored to the case base: ((5, 2), 4, 1)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 4, 1)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "Episode: 98, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 98 loop--------------------\n",
      "----- starting point of Episode 99 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((9, 0), 3, 1, 18)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0)\n",
      "----- starting point of Episode 99 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 0), 2, 1, 19)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1)\n",
      "----- starting point of Episode 99 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 1), 2, 1, 20)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 35)\n",
      "----- starting point of Episode 99 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((8, 2), 3, 1, 21)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 37)\n",
      "----- starting point of Episode 99 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 2), 2, 1, 22)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 53)\n",
      "----- starting point of Episode 99 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 3), 2, 1, 24)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 59)\n",
      "----- starting point of Episode 99 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((7, 4), 3, 1, 26)\n",
      "comm next state for agent 1: ((4, 2), 4, 1, 60)\n",
      "----- starting point of Episode 99 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((6, 4), 3, 1, 35)\n",
      "comm next state for agent 1: ((5, 2), 4, 1, 61)\n",
      "----- starting point of Episode 99 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((5, 4), 3, 1, 37)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 99 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 99 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "----- starting point of Episode 99 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 47)\n",
      "comm next state for agent 1: ((6, 2), 2, 1, 29)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x730e38783ac0>, <__main__.Case object at 0x730e38782bf0>, <__main__.Case object at 0x730e38783610>, <__main__.Case object at 0x730e387807c0>, <__main__.Case object at 0x730e387814e0>, <__main__.Case object at 0x730e38780d60>, <__main__.Case object at 0x730e38782770>, <__main__.Case object at 0x730e38781d80>, <__main__.Case object at 0x730e38781270>, <__main__.Case object at 0x730e387801c0>, <__main__.Case object at 0x730e38782800>, <__main__.Case object at 0x730e387820e0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x730e387810c0>, <__main__.Case object at 0x730e38781cf0>, <__main__.Case object at 0x730e38782c20>, <__main__.Case object at 0x730e38782d10>, <__main__.Case object at 0x730e38780280>, <__main__.Case object at 0x730e38781330>, <__main__.Case object at 0x730e38783220>, <__main__.Case object at 0x730e38783340>, <__main__.Case object at 0x730e38782200>, <__main__.Case object at 0x730e38783c10>, <__main__.Case object at 0x730e387834c0>, <__main__.Case object at 0x730e38780cd0>]\n",
      "case content after REVISE for agent 0, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (6, 3), solution: 2, tv: 1, time steps: 30\n",
      "case content after REVISE for agent 0, problem: (6, 2), solution: 2, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (5, 2), solution: 4, tv: 1, time steps: 61\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 4, tv: 1, time steps: 60\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 59\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 53\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (7, 4), solution: 3, tv: 0.19999999999999996, time steps: 26\n",
      "case content after REVISE for agent 0, problem: (7, 3), solution: 2, tv: 0.19999999999999996, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (7, 2), solution: 2, tv: 0.19999999999999996, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (8, 2), solution: 3, tv: 0.19999999999999996, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (8, 1), solution: 2, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (8, 0), solution: 2, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (9, 0), solution: 3, tv: 0.19999999999999996, time steps: 18\n",
      "Episode succeeded, case (5, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 3), 2, 0.5)\n",
      "Episode succeeded, case (6, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((6, 2), 2, 0.5)\n",
      "Episode succeeded, case (5, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((5, 2), 4, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (6, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x730e38781180>, <__main__.Case object at 0x730e38781b70>, <__main__.Case object at 0x730e38780460>, <__main__.Case object at 0x730e387824a0>, <__main__.Case object at 0x730e38780eb0>, <__main__.Case object at 0x730e38781090>, <__main__.Case object at 0x730e38783670>, <__main__.Case object at 0x730e38780a00>, <__main__.Case object at 0x730e387819c0>, <__main__.Case object at 0x730e387835e0>, <__main__.Case object at 0x730e38781660>, <__main__.Case object at 0x730e387823e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x730e387826b0>, <__main__.Case object at 0x730e387817b0>, <__main__.Case object at 0x730e38781960>, <__main__.Case object at 0x730e387806a0>, <__main__.Case object at 0x730e38781cc0>, <__main__.Case object at 0x730e38783b50>, <__main__.Case object at 0x730e38781d20>, <__main__.Case object at 0x730e38781900>, <__main__.Case object at 0x730e387816c0>, <__main__.Case object at 0x730e38780370>, <__main__.Case object at 0x730e387804c0>, <__main__.Case object at 0x730e38781a80>]\n",
      "case content after REVISE for agent 1, problem: (5, 4), solution: 3, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (6, 4), solution: 3, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 47\n",
      "case content after REVISE for agent 1, problem: (7, 4), solution: 3, tv: 1, time steps: 26\n",
      "case content after REVISE for agent 1, problem: (7, 3), solution: 2, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (7, 2), solution: 2, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (8, 2), solution: 3, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (8, 1), solution: 2, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (8, 0), solution: 2, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (9, 0), solution: 3, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (6, 2), solution: 2, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 59\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 53\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "case content after REVISE for agent 1, problem: (5, 2), solution: 4, tv: 0.6, time steps: 61\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 4, tv: 0.6, time steps: 60\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (5, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((5, 4), 3, 0.5)\n",
      "Episode succeeded, case (6, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((6, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 4), 3, 0.5)\n",
      "Episode succeeded, case (7, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 3), 2, 0.5)\n",
      "Episode succeeded, case (7, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((7, 2), 2, 0.5)\n",
      "Episode succeeded, case (8, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 2), 3, 0.5)\n",
      "Episode succeeded, case (8, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 1), 2, 0.5)\n",
      "Episode succeeded, case (8, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((8, 0), 2, 0.5)\n",
      "Episode succeeded, case (9, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((9, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (5, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (6, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (7, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (7, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (7, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (8, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (8, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (9, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (5, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 4, tv: 0.6\n",
      "Episode: 99, Total Steps: 12, Total Rewards: [39, 42], Status Episode: True\n",
      "------------------------------------------End of episode 99 loop--------------------\n",
      "Success rate: 79.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbCklEQVR4nO3dd1gUV9sG8HuXsjQBAWmKioAFNWqwIcaGArbYEqOiYo8GG3aTWKMSjdG8RqPRRIivGnuJJlGxl9hrrFFjF2wICAgs7Pn+8GU+1wVlYVlwvH/XxZXsmTNnzjyg3E5VCCEEiIiIiGRKWdQTICIiIipMDDtEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7REREJGsMO0REJImOjoZCocDNmzeNul2FQoHJkycbdZv07mDYoXdG9l/i2V+mpqYoXbo0evXqhXv37hX19N4a5cuXR5s2bXJcduLECSgUCkRHRxt3Uu+ovXv3av1Mv/q1atWqop4iUbFgWtQTIDK2qVOnwtPTE2lpaThy5Aiio6Nx8OBBnD9/HhYWFkU9PSK9DR06FHXq1NFp9/f313usHj16oEuXLlCpVIaYGlGxwLBD75yWLVuidu3aAIB+/frByckJM2fOxG+//YbOnTsX8ezyR6PRICMjg2FNhlJSUmBtbf3aPh988AE++ugjg2zPxMQEJiYmBhmLqLjgaSx6533wwQcAgOvXr2u1X758GR999BEcHBxgYWGB2rVr47ffftPqo1arMWXKFPj4+MDCwgKOjo5o2LAhYmJitPrt3r0bH3zwAaytrWFvb4927drh0qVLWn169eqF8uXL68xv8uTJUCgUWm0KhQKDBw/GihUrULVqVahUKmzbtg0AcO/ePfTt2xfu7u5QqVTw9PTEoEGDkJGRIa2fkJCA4cOHw8PDAyqVCt7e3pg5cyY0Go1+xcuDuLg49O7dG2XKlIFKpYKbmxvatWundU3I5s2b0bp1a2nOXl5e+Oqrr5CVlaUz3oIFC1ChQgVYWlqibt26OHDgAJo0aYImTZpo9UtPT8ekSZPg7e0NlUoFDw8PjBkzBunp6Xma99q1a+Hn5wdLS0s4OTmhe/fuWqc7Z8+eDYVCgVu3bumsO378eJibm+Pp06dS29GjRxESEgI7OztYWVmhcePGOHTokNZ62d/rixcvolu3bihZsiQaNmyYp/m+ycs/M5UqVYKFhQX8/Pywf/9+rX45XbNz4sQJBAcHw8nJCZaWlvD09ESfPn201ktJScHIkSOln6lKlSph9uzZEEJo9UtPT0dERARKlSqFEiVK4MMPP8Tdu3dznPO9e/fQp08fuLi4QKVSoWrVqli6dKlOv++//x5Vq1aFlZUVSpYsidq1a2PlypX5rBTJEY/s0Dsv+y/1kiVLSm0XLlxAQEAASpcujXHjxsHa2hpr1qxB+/btsX79enTo0AHAi19OkZGR6NevH+rWrYukpCScOHECp06dQosWLQAAO3fuRMuWLVGhQgVMnjwZz58/x/fff4+AgACcOnUqx4CTF7t378aaNWswePBgODk5oXz58rh//z7q1q2LhIQEDBgwAJUrV8a9e/ewbt06pKamwtzcHKmpqWjcuDHu3buHTz/9FGXLlsVff/2F8ePHIzY2Ft99911ByqmjU6dOuHDhAoYMGYLy5cvj4cOHiImJwe3bt6V9j46Oho2NDUaMGAEbGxvs3r0bEydORFJSEr755htprIULF2Lw4MH44IMPEBERgZs3b6J9+/YoWbIkypQpI/XTaDT48MMPcfDgQQwYMABVqlTB33//jblz5+Kff/7Bpk2bXjvn6Oho9O7dG3Xq1EFkZCQePHiA//znPzh06BBOnz4Ne3t7dO7cGWPGjMGaNWswevRorfXXrFmDoKAg6Wdq9+7daNmyJfz8/DBp0iQolUpERUWhWbNmOHDgAOrWrau1/scffwwfHx/MmDFDJyzk5NmzZ3j8+LFOu6Ojo1ZQ3rdvH1avXo2hQ4dCpVLhhx9+QEhICI4dO4Zq1arlOPbDhw8RFBSEUqVKYdy4cbC3t8fNmzexYcMGqY8QAh9++CH27NmDvn37ombNmti+fTtGjx6Ne/fuYe7cuVLffv36Yfny5ejWrRsaNGiA3bt3o3Xr1jrbffDgAerXry+FtFKlSuHPP/9E3759kZSUhOHDhwMAlixZgqFDh+Kjjz7CsGHDkJaWhnPnzuHo0aPo1q3bG2tH7whB9I6IiooSAMTOnTvFo0ePxJ07d8S6detEqVKlhEqlEnfu3JH6BgYGiurVq4u0tDSpTaPRiAYNGggfHx+prUaNGqJ169av3W7NmjWFs7OzePLkidR29uxZoVQqRc+ePaW2sLAwUa5cOZ31J02aJF79owpAKJVKceHCBa32nj17CqVSKY4fP64zjkajEUII8dVXXwlra2vxzz//aC0fN26cMDExEbdv337t/pQrVy7XfT5+/LgAIKKiooQQQjx9+lQAEN98881rx0xNTdVp+/TTT4WVlZX0PUhPTxeOjo6iTp06Qq1WS/2io6MFANG4cWOp7b///a9QKpXiwIEDWmMuWrRIABCHDh3KdS4ZGRnC2dlZVKtWTTx//lxq37p1qwAgJk6cKLX5+/sLPz8/rfWPHTsmAIhly5YJIV7U3cfHRwQHB0vfg+x99vT0FC1atJDasr/XXbt2zXV+L9uzZ48AkOtXbGys1De77cSJE1LbrVu3hIWFhejQoYPUlv3n5MaNG0IIITZu3CgA5PgzlW3Tpk0CgJg2bZpW+0cffSQUCoW4du2aEEKIM2fOCADis88+0+rXrVs3AUBMmjRJauvbt69wc3MTjx8/1urbpUsXYWdnJ/3MtGvXTlStWjUP1aJ3GU9j0TunefPmKFWqFDw8PPDRRx/B2toav/32m3RkID4+Hrt370bnzp2lfzE/fvwYT548QXBwMK5evSqdzrC3t8eFCxdw9erVHLcVGxuLM2fOoFevXnBwcJDa33vvPbRo0QJ//PFHvvejcePG8PX1lT5rNBps2rQJbdu2la5Jeln2v/DXrl2LDz74ACVLlpT27fHjx2jevDmysrJ0TmsUhKWlJczNzbF3716tUzo59cuWXfMPPvgAqampuHz5MoAXp1KePHmC/v37w9T0/w9Kh4aGah2Vy97HKlWqoHLlylr72KxZMwDAnj17cp3LiRMn8PDhQ3z22Wda10C1bt0alStXxu+//y61ffLJJzh58qTWKdDVq1dDpVKhXbt2AIAzZ87g6tWr6NatG548eSLNJSUlBYGBgdi/f7/O6cOBAwfmOr+cTJw4ETExMTpfL//MAS8uWPbz85M+ly1bFu3atcP27dtzPGUIvPgZB4CtW7dCrVbn2OePP/6AiYkJhg4dqtU+cuRICCHw559/Sv0A6PTLPkqTTQiB9evXo23bthBCaH0Pg4ODkZiYiFOnTknzu3v3Lo4fP/6aCtG7jqex6J2zYMECVKxYEYmJiVi6dCn279+vdefJtWvXIITAhAkTMGHChBzHePjwIUqXLo2pU6eiXbt2qFixIqpVq4aQkBD06NED7733HgBI13NUqlRJZ4wqVapg+/bteboANSeenp5anx89eoSkpKRcT0dku3r1Ks6dO4dSpUrlum8FlR2sVCoVZs6ciZEjR8LFxQX169dHmzZt0LNnT7i6ukr9L1y4gC+//BK7d+9GUlKS1liJiYkA/r+W3t7eWstNTU11TgVevXoVly5dytc+vu57VrlyZRw8eFD6/PHHH2PEiBFYvXo1Pv/8cwghsHbtWrRs2RK2trbSXAAgLCws120mJiZqBbZXv7dvUr16dTRv3vyN/Xx8fHTaKlasiNTUVDx69Ejre5KtcePG6NSpE6ZMmYK5c+eiSZMmaN++Pbp16yb9ubl16xbc3d1RokQJrXWrVKkiLc/+r1KphJeXl1a/V2v96NEjJCQkYPHixVi8eHGO+5L9PRw7dix27tyJunXrwtvbG0FBQejWrRsCAgLeWA96dzDs0Dunbt260pGP9u3bo2HDhujWrRuuXLkCGxsb6V/Zo0aNQnBwcI5jZP/CbdSoEa5fv47Nmzdjx44d+OmnnzB37lwsWrQI/fr102ter16EnC23f3G/fDREHxqNBi1atMCYMWNyXF6xYsXXrm9hYYHnz5/nuCw1NVXqk2348OFo27YtNm3ahO3bt2PChAmIjIzE7t27UatWLSQkJKBx48awtbXF1KlT4eXlBQsLC5w6dQpjx47N10XTGo0G1atXx5w5c3Jc7uHhofeYOXF3d8cHH3yANWvW4PPPP8eRI0dw+/ZtzJw5U2suAPDNN9+gZs2aOY5jY2Oj9Tm/39vCoFAosG7dOhw5cgRbtmzB9u3b0adPH3z77bc4cuSIztwNIbtm3bt3zzUkZv+DokqVKrhy5Qq2bt2Kbdu2Yf369fjhhx8wceJETJkyxeBzo7cTww6900xMTBAZGYmmTZti/vz5GDduHCpUqAAAMDMzy9O/lh0cHNC7d2/07t0bycnJaNSoESZPnox+/fqhXLlyAIArV67orHf58mU4OTlJR3VKliyJhIQEnX453e2Tk1KlSsHW1hbnz59/bT8vLy8kJyfnad9yUq5cOVy8eDHHZdn7mb3fL29z5MiRGDlyJK5evYqaNWvi22+/xfLly7F37148efIEGzZsQKNGjaR1bty4obNd4MWRt6ZNm0rtmZmZuHnzpvTLL3t7Z8+eRWBgYK4h8nX7l70v2ae9Xt6/V/ftk08+wWeffYYrV65g9erVsLKyQtu2bbXmAgC2trb5rrmh5HS69Z9//oGVlVWuR8Gy1a9fH/Xr18f06dOxcuVKhIaGYtWqVdLP+c6dO/Hs2TOtozvZpyCza1auXDloNBpcv35d62jOq38+su/UysrKylPNrK2t8cknn+CTTz5BRkYGOnbsiOnTp2P8+PF8HAMB4K3nRGjSpAnq1q2L7777DmlpaXB2dkaTJk3w448/IjY2Vqf/o0ePpP9/8uSJ1jIbGxt4e3tLtze7ubmhZs2a+OWXX7SCzPnz57Fjxw60atVKavPy8kJiYiLOnTsntcXGxmLjxo152g+lUon27dtjy5YtOHHihM5y8b+7ejp37ozDhw9j+/btOn0SEhKQmZn52u20atUKd+/e1bmjKT09HT/99BOcnZ3x/vvvA3hxpCctLU2rn5eXF0qUKCHVKPuZLuKlu44yMjLwww8/aK1Xu3ZtODo6YsmSJVpzXLFihc71QJ07d8a9e/ewZMkSnfk/f/4cKSkpue5f7dq14ezsjEWLFmndpv7nn3/i0qVLOncOderUCSYmJvj111+xdu1atGnTRuu0pJ+fH7y8vDB79mwkJyfrbO/ln6fCdvjwYelaFwC4c+cONm/ejKCgoFyfrfP06VOdO8Kyj1Bl16dVq1bIysrC/PnztfrNnTsXCoUCLVu2BADpv/PmzdPq9+odgCYmJujUqRPWr1+fY3h/3Z9Bc3Nz+Pr6QgiR6zVG9O7hkR0iAKNHj8bHH3+M6OhoDBw4EAsWLEDDhg1RvXp19O/fHxUqVMCDBw9w+PBh3L17F2fPngUA+Pr6okmTJvDz84ODgwNOnDiBdevWYfDgwdLY33zzDVq2bAl/f3/07dtXuvXczs5O611AXbp0wdixY9GhQwcMHToUqampWLhwISpWrKj1C+p1ZsyYgR07dqBx48bSLdexsbFYu3YtDh48CHt7e4wePRq//fYb2rRpg169esHPzw8pKSn4+++/sW7dOty8eRNOTk65bmPAgAFYunQpPv74Y/Tp0we1atXCkydPsHr1apw/fx7Lli2Dubk5gBdHDQIDA9G5c2f4+vrC1NQUGzduxIMHD9ClSxcAQIMGDVCyZEmEhYVh6NChUCgU+O9//6vzC9bc3ByTJ0/GkCFD0KxZM3Tu3Bk3b95EdHQ0vLy8tI7g9OjRA2vWrMHAgQOxZ88eBAQEICsrC5cvX8aaNWuwffv2HC/iBl4c0Zs5cyZ69+6Nxo0bo2vXrtKt5+XLl0dERIRWf2dnZzRt2hRz5szBs2fP8Mknn2gtVyqV+Omnn9CyZUtUrVoVvXv3RunSpXHv3j3s2bMHtra22LJlS56+v7k5cOCATqgEXpzqefmIV7Vq1RAcHKx16zmA157u+eWXX/DDDz+gQ4cO8PLywrNnz7BkyRLY2tpKYb1t27Zo2rQpvvjiC9y8eRM1atTAjh07sHnzZgwfPlw6ulWzZk107doVP/zwAxITE9GgQQPs2rUL165d09nu119/jT179qBevXro378/fH19ER8fj1OnTmHnzp2Ij48HAAQFBcHV1RUBAQFwcXHBpUuXMH/+fLRu3VrnGiJ6hxXVbWBExpZ9S21Ot9BmZWUJLy8v4eXlJTIzM4UQQly/fl307NlTuLq6CjMzM1G6dGnRpk0bsW7dOmm9adOmibp16wp7e3thaWkpKleuLKZPny4yMjK0xt+5c6cICAgQlpaWwtbWVrRt21ZcvHhRZx47duwQ1apVE+bm5qJSpUpi+fLlud56Hh4enuN+3rp1S/Ts2VO6pb5ChQoiPDxcpKenS32ePXsmxo8fL7y9vYW5ublwcnISDRo0ELNnz9aZe06ePn0qIiIihKenpzAzMxO2traiadOm4s8//9Tq9/jxYxEeHi4qV64srK2thZ2dnahXr55Ys2aNVr9Dhw6J+vXrC0tLS+Hu7i7GjBkjtm/fLgCIPXv2aPWdN2+eKFeunFCpVKJu3bri0KFDws/PT4SEhGj1y8jIEDNnzhRVq1YVKpVKlCxZUvj5+YkpU6aIxMTEN+7j6tWrRa1atYRKpRIODg4iNDRU3L17N8e+S5YsEQBEiRIltG5Xf9np06dFx44dhaOjo1CpVKJcuXKic+fOYteuXVKf7O/1o0eP3jg/Id586/nLt3Jn/8wsX75c+Pj4CJVKJWrVqqVT31dvPT916pTo2rWrKFu2rFCpVMLZ2Vm0adNG6xZ2IV78TEVERAh3d3dhZmYmfHx8xDfffKN1u70QQjx//lwMHTpUODo6Cmtra9G2bVtx584dnfkKIcSDBw9EeHi48PDwEGZmZsLV1VUEBgaKxYsXS31+/PFH0ahRI6muXl5eYvTo0Xn6HtO7QyFEHp5YRURUTGk0GpQqVQodO3bM8bQVvaBQKBAeHq5zqonoXcBrdojorZGWlqZzemvZsmWIj4/XeV0EEVE2XrNDRG+NI0eOICIiAh9//DEcHR1x6tQp/Pzzz6hWrRo+/vjjop4eERVTDDtE9NYoX748PDw8MG/ePMTHx8PBwQE9e/bE119/LV0UTUT0Kl6zQ0RERLLGa3aIiIhI1hh2iIiISNZ4zQ5e3Lp6//59lChRQu9HyxMREVHREELg2bNncHd3h1KZ+/Ebhh0A9+/fN9iLAYmIiMi47ty5gzJlyuS6nGEHkB4pfufOHdja2hpsXLVajR07diAoKAhmZmYGG5d0sdbGw1obD2ttXKy38Riq1klJSfDw8Hjjq0EYdgDp1JWtra3Bw46VlRVsbW35B6eQsdbGw1obD2ttXKy38Ri61m+6BIUXKBMREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkazxRaCFRQggIwUmWelARgog+FK5QqVWs9bGwlobD2ttXKx34TKzAt7wws7CUqRhJzIyEhs2bMDly5dhaWmJBg0aYObMmahUqZLUp0mTJti3b5/Wep9++ikWLVokfb59+zYGDRqEPXv2wMbGBmFhYYiMjISpaRHunjoVZt+UQxsAOFd003hXmAGstZGw1sbDWhsX613IPr8PmFsXyaaLNOzs27cP4eHhqFOnDjIzM/H5558jKCgIFy9ehLX1/xekf//+mDp1qvTZyspK+v+srCy0bt0arq6u+OuvvxAbG4uePXvCzMwMM2bMMOr+EBERUfFTpGFn27ZtWp+jo6Ph7OyMkydPolGjRlK7lZUVXF1dcxxjx44duHjxInbu3AkXFxfUrFkTX331FcaOHYvJkyfD3Ny8UPchV2ZWUI++he3bdyA4OAhmZjwkWpjUajVrbSSstfGw1sbFehcyM6s39ykkxeqancTERACAg4ODVvuKFSuwfPlyuLq6om3btpgwYYJ0dOfw4cOoXr06XFxcpP7BwcEYNGgQLly4gFq1ahlvB16mUADm1sgyUb04bMc/OIVLoWatjYW1Nh7W2rhYb9kqNmFHo9Fg+PDhCAgIQLVq1aT2bt26oVy5cnB3d8e5c+cwduxYXLlyBRs2bAAAxMXFaQUdANLnuLi4HLeVnp6O9PR06XNSUhKAF6lerVYbbJ+yxzLkmJQz1tp4WGvjYa2Ni/U2HkPVOq/rF5uwEx4ejvPnz+PgwYNa7QMGDJD+v3r16nBzc0NgYCCuX78OLy+vfG0rMjISU6ZM0WnfsWOH1vVAhhITE2PwMSlnrLXxsNbGw1obF+ttPAWtdWpqap76FYuwM3jwYGzduhX79+9HmTJlXtu3Xr16AIBr167By8sLrq6uOHbsmFafBw8eAECu1/mMHz8eI0aMkD4nJSXBw8MDQUFBsLW1LciuaFGr1YiJiUGLFi14/reQsdbGw1obD2ttXKy38Riq1tlnZt6kSMOOEAJDhgzBxo0bsXfvXnh6er5xnTNnzgAA3NzcAAD+/v6YPn06Hj58CGdnZwAvkqKtrS18fX1zHEOlUkGlUum0m5mZFcoPeGGNS7pYa+NhrY2HtTYu1tt4ClrrvK5bpGEnPDwcK1euxObNm1GiRAnpGhs7OztYWlri+vXrWLlyJVq1agVHR0ecO3cOERERaNSoEd577z0AQFBQEHx9fdGjRw/MmjULcXFx+PLLLxEeHp5joCEiIqJ3S5G+LmLhwoVITExEkyZN4ObmJn2tXr0aAGBubo6dO3ciKCgIlStXxsiRI9GpUyds2bJFGsPExARbt26FiYkJ/P390b17d/Ts2VPruTxERET07iry01iv4+HhofP05JyUK1cOf/zxh6GmRURERDLCF4ESERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrBVp2ImMjESdOnVQokQJODs7o3379rhy5YpWn7S0NISHh8PR0RE2Njbo1KkTHjx4oNXn9u3baN26NaysrODs7IzRo0cjMzPTmLtCRERExVSRhp19+/YhPDwcR44cQUxMDNRqNYKCgpCSkiL1iYiIwJYtW7B27Vrs27cP9+/fR8eOHaXlWVlZaN26NTIyMvDXX3/hl19+QXR0NCZOnFgUu0RERETFjGlRbnzbtm1an6Ojo+Hs7IyTJ0+iUaNGSExMxM8//4yVK1eiWbNmAICoqChUqVIFR44cQf369bFjxw5cvHgRO3fuhIuLC2rWrImvvvoKY8eOxeTJk2Fubl4Uu0ZERETFRJGGnVclJiYCABwcHAAAJ0+ehFqtRvPmzaU+lStXRtmyZXH48GHUr18fhw8fRvXq1eHi4iL1CQ4OxqBBg3DhwgXUqlVLZzvp6elIT0+XPiclJQEA1Go11Gq1wfYneyxDjkk5Y62Nh7U2HtbauFhv4zFUrfO6frEJOxqNBsOHD0dAQACqVasGAIiLi4O5uTns7e21+rq4uCAuLk7q83LQyV6evSwnkZGRmDJlik77jh07YGVlVdBd0RETE2PwMSlnrLXxsNbGw1obF+ttPAWtdWpqap76FZuwEx4ejvPnz+PgwYOFvq3x48djxIgR0uekpCR4eHggKCgItra2BtuOWq1GTEwMWrRoATMzM4ONS7pYa+NhrY2HtTYu1tt4DFXr7DMzb1Isws7gwYOxdetW7N+/H2XKlJHaXV1dkZGRgYSEBK2jOw8ePICrq6vU59ixY1rjZd+tld3nVSqVCiqVSqfdzMysUH7AC2tc0sVaGw9rbTystXGx3sZT0Frndd0ivRtLCIHBgwdj48aN2L17Nzw9PbWW+/n5wczMDLt27ZLarly5gtu3b8Pf3x8A4O/vj7///hsPHz6U+sTExMDW1ha+vr7G2REiIiIqtor0yE54eDhWrlyJzZs3o0SJEtI1NnZ2drC0tISdnR369u2LESNGwMHBAba2thgyZAj8/f1Rv359AEBQUBB8fX3Ro0cPzJo1C3Fxcfjyyy8RHh6e49EbIiIiercUadhZuHAhAKBJkyZa7VFRUejVqxcAYO7cuVAqlejUqRPS09MRHByMH374QeprYmKCrVu3YtCgQfD394e1tTXCwsIwdepUY+0GERERFWNFGnaEEG/sY2FhgQULFmDBggW59ilXrhz++OMPQ06NiIiIZILvxiIiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWctX2MnMzMTOnTvx448/4tmzZwCA+/fvIzk52aCTIyIiIiooU31XuHXrFkJCQnD79m2kp6ejRYsWKFGiBGbOnIn09HQsWrSoMOZJRERElC96H9kZNmwYateujadPn8LS0lJq79ChA3bt2mXQyREREREVlN5Hdg4cOIC//voL5ubmWu3ly5fHvXv3DDYxIiIiIkPQ+8iORqNBVlaWTvvdu3dRokQJg0yKiIiIyFD0DjtBQUH47rvvpM8KhQLJycmYNGkSWrVqZci5ERERERWY3qexvv32WwQHB8PX1xdpaWno1q0brl69CicnJ/z666+FMUciIiKifNM77JQpUwZnz57FqlWrcO7cOSQnJ6Nv374IDQ3VumCZiIiIqDjQO+wAgKmpKbp3727ouRAREREZnN5h57fffsuxXaFQwMLCAt7e3vD09CzwxIiIiIgMQe+w0759eygUCgghtNqz2xQKBRo2bIhNmzahZMmSBpsoERERUX7ofTdWTEwM6tSpg5iYGCQmJiIxMRExMTGoV68etm7div379+PJkycYNWpUYcyXiIiISC96H9kZNmwYFi9ejAYNGkhtgYGBsLCwwIABA3DhwgV899136NOnj0EnSkRERJQfeh/ZuX79OmxtbXXabW1t8e+//wIAfHx88Pjx44LPjoiIiKiA9A47fn5+GD16NB49eiS1PXr0CGPGjEGdOnUAAFevXoWHh4fhZklERESUT3qfxvr555/Rrl07lClTRgo0d+7cQYUKFbB582YAQHJyMr788kvDzpSIiIgoH/QOO5UqVcLFixexY8cO/PPPP1JbixYtoFS+OFDUvn17g06SiIiIKL/y9VBBpVKJkJAQhISEGHo+RERERAaVr7CTkpKCffv24fbt28jIyNBaNnToUINMjIiIiMgQ9A47p0+fRqtWrZCamoqUlBQ4ODjg8ePHsLKygrOzM8MOERERFSt6340VERGBtm3b4unTp7C0tMSRI0dw69Yt+Pn5Yfbs2YUxRyIiIqJ80zvsnDlzBiNHjoRSqYSJiQnS09Ph4eGBWbNm4fPPPy+MORIRERHlm95hx8zMTLrrytnZGbdv3wYA2NnZ4c6dO3qNtX//frRt2xbu7u5QKBTYtGmT1vJevXpBoVBofb16UXR8fDxCQ0Nha2sLe3t79O3bF8nJyfruFhEREcmU3tfs1KpVC8ePH4ePjw8aN26MiRMn4vHjx/jvf/+LatWq6TVWSkoKatSogT59+qBjx4459gkJCUFUVJT0WaVSaS0PDQ1FbGwsYmJioFar0bt3bwwYMAArV67Ud9eIiIhIhvQOOzNmzMCzZ88AANOnT0fPnj0xaNAg+Pj4YOnSpXqN1bJlS7Rs2fK1fVQqFVxdXXNcdunSJWzbtg3Hjx9H7dq1AQDff/89WrVqhdmzZ8Pd3V2v+RAREZH86B12skMF8OI01rZt2ww6oVft3bsXzs7OKFmyJJo1a4Zp06bB0dERAHD48GHY29trzal58+ZQKpU4evQoOnToUKhzIyIiouJP77Dz/PlzCCFgZWUFALh16xY2btwIX19fBAUFGXRyISEh6NixIzw9PXH9+nV8/vnnaNmyJQ4fPgwTExPExcXB2dlZax1TU1M4ODggLi4u13HT09ORnp4ufU5KSgIAqNVqqNVqg80/eyxDjkk5Y62Nh7U2HtbauFhv4zFUrfO6vt5hp127dujYsSMGDhyIhIQE1K1bF+bm5nj8+DHmzJmDQYMG6T3Z3HTp0kX6/+rVq+O9996Dl5cX9u7di8DAwHyPGxkZiSlTpui079ixQwpxhhQTE2PwMSlnrLXxsNbGw1obF+ttPAWtdWpqap766R12Tp06hblz5wIA1q1bB1dXV5w+fRrr16/HxIkTDRp2XlWhQgU4OTnh2rVrCAwMhKurKx4+fKjVJzMzE/Hx8ble5wMA48ePx4gRI6TPSUlJ8PDwQFBQEGxtbQ02X7VajZiYGLRo0QJmZmYGG5d0sdbGw1obD2ttXKy38Riq1tlnZt5E77CTmpqKEiVKAHhxJKRjx45QKpWoX78+bt26pe9werl79y6ePHkCNzc3AIC/vz8SEhJw8uRJ+Pn5AQB2794NjUaDevXq5TqOSqXSuasLeHFbfWH8gBfWuKSLtTYe1tp4WGvjYr2Np6C1zuu6eocdb29vbNq0CR06dMD27dsREREBAHj48KHeR0WSk5Nx7do16fONGzdw5swZODg4wMHBAVOmTEGnTp3g6uqK69evY8yYMfD29kZwcDAAoEqVKggJCUH//v2xaNEiqNVqDB48GF26dOGdWEREL9FoNDrvMiRtarUapqamSEtLQ1ZWVlFPR9byWmszMzOYmJgUeHt6h52JEyeiW7duiIiIQGBgIPz9/QG8OMpTq1YtvcY6ceIEmjZtKn3OPrUUFhaGhQsX4ty5c/jll1+QkJAAd3d3BAUF4auvvtI6KrNixQoMHjwYgYGBUCqV6NSpE+bNm6fvbhERyVZGRgZu3LgBjUZT1FMp1oQQcHV1xZ07d6BQKIp6OrKmT63t7e3h6upaoO+J3mHno48+QsOGDREbG4saNWpI7YGBgXrf6t2kSRMIIXJdvn379jeO4eDgwAcIEhHlQgiB2NhYmJiYwMPDQ3oCPunSaDRITk6GjY0N61TI8lJrIQRSU1Ola3OzL2HJD73DDgC4urrqXABct27dfE+CiIgKR2ZmJlJTU+Hu7l4od5vKSfapPgsLC4adQpbXWltaWgJ4camMs7Nzvk9p5Tns1KpVK8dDSHZ2dqhYsSKGDx+OKlWq5GsSRERUOLKvhzA3Ny/imRDlT3ZIV6vVhR922rdvn2N7QkICTp06hZo1a2L37t0ICAjI10SIiKjw8BoUelsZ4mc3z2Fn0qRJr13+xRdfYOLEidi1a1eBJ0VERERkKAY7KdmtWzf8/fffhhqOiIjonXPlyhW4urpKL9zOj4sXL6JMmTJISUkx4MzebgYLOyYmJrytkYiIDKJXr15QKBQYOHCgzrLw8HAoFAr06tXL+BMrZOPHj8eQIUOkh/fevHkTjRo1grW1NRo1aoSbN29q9W/Tpg3Wr1+v1ebr64v69etjzpw5xpp2sWewsLNhwwb4+voaajgiInrHeXh4YNWqVXj+/LnUlpaWhpUrV6Js2bJFOLPcCSGQmZmZr3Vv376NrVu3aoW4kSNHonTp0jhz5gzc3NwwatQoadnq1aul58u9qnfv3li4cGG+5yI3eQ478+bNy/Hrq6++Qvv27TFp0iRMnDixMOdKRETvkPfffx8eHh7YsGGD1LZhwwaULVtW5yG2Go0GkZGR8PT0hKWlJWrUqIF169ZJy/fu3QuFQoHt27ejVq1asLS0RLNmzfDw4UP8+eefqFKlCuzt7dGvXz+tl0ump6dj6NChcHZ2hoWFBRo2bIjjx4/rjPvnn3/Cz88PKpUKy5cvh1KpxIkTJ7Tm+N1336FcuXK5ngVZs2YNatSogdKlS0ttly5dQlhYGHx8fNCrVy9cunQJwIubg7788kssWLAgx7FatGiB+Ph47Nu3701lfifk+QLl7Jd/vsrW1haVKlXC/v37pacpExFR8SSEwHN10bwKwdLMRO87a/r06YOoqCiEhoYCAJYuXYrevXtj7969Wv0iIyOxfPlyLFq0CD4+Pti/fz+6d++OUqVKoXHjxlK/yZMnY/78+bCyskLnzp3RuXNnqFQqrFy5EklJSejYsSPmz5+PcePGAQDGjBmD9evX45dffkG5cuUwa9YsBAcH49q1a3BwcJDGHTduHGbPno0KFSqgZMmSaN68OaKiolC7dm2pT1RUFHr16pXrc2UOHDig1R8AatSogZ07dyIoKAg7duzAe++9BwAYPXo0wsPD4eHhkeNY5ubmqFmzJg4cOIDAwMA8Vlu+8hx2bty4UZjzICIiI3iuzoLvxDc/nb4wXJwaDCtz/Z5l2717d4wfP1560fShQ4ewatUqrbCTnp6OGTNmYOfOndI/uitUqICDBw/ixx9/1Ao706ZNkx6R0rdvX4wfPx7Xr19HhQoVoNFo8OGHH2LPnj0YN24cUlJSsHDhQkRHR6Nly5YAgCVLliAmJgY///wzRo8eLY07depUtGjRQvrcr18/DBw4EHPmzIFKpcKpU6fw999/Y/Pmzbnu661bt3TCzuzZs/Hpp5+ifPnyeO+99/Djjz9i//79OHPmDGbOnInOnTvjxIkTCAoKwrx587Sep+Tu7l7oL+h+W+TrCcpERETGUKpUKbRu3RrR0dEQQqB169ZwcnLS6nPt2jWkpqZqhQ3gxTvBXj3dlX1kBABcXFxgZWWFChUqSG3Ozs44e/YsAOD69etQq9Vaz48zMzND3bp1pdNJ2V4NKe3bt0d4eDg2btyILl26IDo6Gk2bNkX58uVz3dfnz5/DwsJCq6106dLYunWr9Dk9PR3BwcH45ZdfMG3aNJQoUQJXrlxBSEgIfvzxRwwZMkTqa2lpqXVK7l3GsENE9A6xNDPBxanBRbbt/OjTpw8GDx4MADleo5KcnAwA+P3337WudwGg9eJo4EVYyaZQKLQ+Z7fl585ia2trrc/m5ubo2bMnoqKi0LFjR6xcuRL/+c9/XjuGk5MTnj59+to+M2bMQFBQEPz8/NC/f39MmzYNZmZm6NixI3bv3q0VduLj4+Hl5aX3vsgRww4R0TtEoVDofSqpqIWEhCAjIwMKhQLBwbpBzdfXFyqVCrdv39Y6ZVVQXl5eMDc3x6FDh1CuXDkAL15ZcPz4cQwfPvyN6/fr1w/VqlXDDz/8gMzMTHTs2PG1/WvVqoWLFy/muvzSpUtYuXIlzpw5A+DFq0DUarU0r+xXg2Q7f/48PvroozfO813wdv3EExHRO8fExEQ6bZTTu5FKlCiBUaNGISIiAhqNBg0bNkRiYiIOHToEW1tbhIWF5Wu71tbWGDRoEEaPHg0HBweULVsWs2bNQmpqKvr27fvG9atUqYL69etj7Nix6NOnj/RSy9wEBwejX79+yMrK0tlPIQQGDBiAuXPnSkeRAgICsGTJElSsWBHLli1D165dpf43b97EvXv30Lx583zsufzwta5ERFTs2drawtbWNtflX331FSZMmIDIyEhUqVIFISEh+P333+Hp6Vmg7X799dfo1KkTevTogffffx/Xrl3D9u3bUbJkyTyt37dvX2RkZKBPnz5v7NuyZUuYmppi586dOssWL14MFxcXtGnTRmqbPHky0tLSUK9ePXh7eyM8PFxa9uuvvyIoKEg6IvXOE/mwf/9+ERoaKurXry/u3r0rhBBi2bJl4sCBA/kZrsglJiYKACIxMdGg42ZkZIhNmzaJjIwMg45Lulhr42GtjccQtX7+/Lm4ePGieP78uQFnJk9ZWVni6dOnIisry2BjTp06VVSvXj3P/efPny+CgoIKtM309HRRtmxZcfDgwQKNU5j0qfXrfobz+vtb7yM769evR3BwMCwtLXH69Gmkp6cDABITEzFjxgwDRzEiIqK3T3JyMs6fP4/58+drXTT8Jp9++ikaNWpUoHdj3b59G59//rnWXWTvOr3DzrRp07Bo0SIsWbJE6yr2gIAAnDp1yqCTIyIiehsNHjwYfn5+aNKkSZ5OYWUzNTXFF198Ib0bKz+8vb3x6aef5nt9OdL7AuUrV66gUaNGOu12dnZISEgwxJyIiIjeatHR0YiOji7qadD/6H1kx9XVFdeuXdNpP3jwoNaDmYiIiIiKA73DTv/+/TFs2DAcPXoUCoUC9+/fx4oVKzBq1CgMGjSoMOZIRERElG96n8YaN24cNBoNAgMDkZqaikaNGkGlUmHUqFF6XYRFREREZAx6hx2FQoEvvvgCo0ePxrVr15CcnAxfX1/Y2NgUxvyIiIiICkTvsJOYmIisrCw4ODjA19dXao+Pj4epqelrH/pEREREZGx6X7PTpUsXrFq1Sqd9zZo16NKli0EmRURERGQoeoedo0ePomnTpjrtTZo0wdGjRw0yKSIiIio6EyZMwIABAwp1G0+ePIGrqyvu3r1bqNsB8hF20tPTkZmZqdOuVqvx/Plzg0yKiIgoLi4Ow4YNg7e3NywsLODi4oKAgAAsXLgQqampUr/y5ctDoVBAoVDA2toa77//PtauXSst79WrF9q3b68z/t69e6FQKF77jLjscY8cOaLVnp6eDkdHRygUCuzdu7egu1qsxMXF4T//+Q+++OILqa1Xr15QKBQYOHCgTv/w8HAoFAr06tVLp3/2l6OjI0JCQnDu3Dmpj6OjI3r06IFJkyYV6v4A+Qg7devWxeLFi3XaFy1aBD8/P4NMioiI3m3//vsvatWqhR07dmDGjBk4ffo0Dh8+jDFjxmDr1q06L8ucOnUqYmNjcfr0adSpUweffPIJ/vrrL4PMxcPDA1FRUVptGzduLNY35mRkZOR73Z9++gkNGjTQeYmoh4cHVq1apXVgIy0tDStXrkTZsmV1xgkJCUFsbCxiY2Oxa9cumJqaar3IFHgRilasWIH4+Ph8zzcv8vW6iJ9++gmNGjXClClTMGXKFDRq1AhLly7lu7GIiMggPvvsM5iamuLEiRPo3LkzqlSpggoVKqBdu3b4/fff0bZtW63+JUqUgKurKypWrIgFCxbA0tISW7ZsMchcwsLCdH7JL126FGFhYTp979y5g86dO8Pe3h4ODg5o164dbt68KS3PPso0Y8YMuLi4wN7eHlOnTkVmZiZGjx4NBwcHlClTRidc/f3332jWrBksLS3h6OiIAQMGIDk5WWfc6dOnw93dHZUqVcLUqVNRrVo1nTnWrFkTEyZMyHV/V61apVNfAHj//ffh4eGBDRs2SG0bNmxA2bJlUatWLZ3+KpUKrq6ucHV1Rc2aNTFu3DjcuXMHjx49kvpUrVoV7u7u2LhxY67zMQS9w05AQACOHDkCDw8PrFmzBlu2bIG3tzfOnTuHDz74oDDmSEREhiIEkJFSNF9C5GmKT548wY4dOxAeHg5ra+sc+ygUilzXNzU1hZmZWYGObrzMz88P5cuXx/r16wG8eNHm/v370aNHD61+arUawcHBKFGiBA4cOIBDhw7BxsYGISEhWnPZvXs37t+/j/3792POnDmYNGkS2rRpg5IlS+Lo0aMYOHAgPv30U+lalpSUFAQHB6NkyZI4fvw41q5di507d2Lw4MFa29+1axeuXLmCmJgYbN26FX369MGlS5dw/Phxqc/p06dx7tw59O7dO8d9jY+Px8WLF1G7du0cl/fp00criC1dujTXsV6WnJyM5cuXw9vbG46OjlrL6tatiwMHDrxxjILQ69ZztVqNTz/9FBMmTMCKFSsKa05ERFRY1KnADPei2fbn9wHznMPLy65duwYhBCpVqqTV7uTkhLS0NAAvrhOZOXOmzroZGRn49ttvkZiYiGbNmhlm3njxS37p0qXo3r07oqOj0apVK5QqVUqrz+rVq6HRaPDTTz9JYSwqKgr29vbYu3cvgoKCAAAODg6YN28elEolKlWqhFmzZiE1NRWff/45AGD8+PH4+uuvcfDgQXTp0gUrV65EWloali1bJoW/+fPno23btpg5cyZcXFwAANbW1vjpp59gbm4uzSk4OBhRUVGoU6eONJ/GjRvn+nqn27dvQwgBd/ecf0a6d++O8ePH49atWwCAQ4cOYdWqVTlet7R161bpVF9KSgrc3NywdetWKJVKaDQaqZ+7uztOnz79muoXnF5HdszMzKRkS0REZEzHjh3DmTNnULVqVaSnp2stGzt2LGxsbGBlZYWZM2fi66+/RuvWrQ227e7du+Pw4cP4999/ER0dneObzM+ePYtr166hRIkSsLGxgY2NDRwcHJCWlobr169L/apWrQql8v9//bq4uKB69erSZxMTEzg6OuLhw4cAgEuXLqFGjRpaR7kCAgKg0Whw5coVqa169epaQQd48YqnX3/9FWlpacjIyMDKlStf+xb27FN1FhYWOS4vVaoUWrdujejoaERFRaF169ZwcnLKsW/Tpk1x5swZnDlzBseOHUNwcDBatmwpBaVslpaWWhecFwa9HyrYvn17bNq0CREREYUxHyIiKkxmVi+OsBTVtvPA29sbCoVC6xc5AOlohKWlpc46o0ePRq9evWBjYwMXFxet01y2trY6v2ABICEhASYmJrmeKnuZo6Mj2rRpg759+yItLQ0tW7bEs2fPtPokJyfDz88vxzMfLx8FMjMz01qmUChybHv56Ede5LQfbdu2hUqlwsaNG2Fubg61Wo2PPvoo1zGyg8vTp091jlxl69Onj3QKbcGCBa+dj7e3t/T5p59+gp2dHZYsWYKpU6dK7fHx8bluy1D0Djs+Pj6YOnUqDh06BD8/P53iDh061GCTIyIiA1Mo8nQqqSg5OjqiRYsWmD9/PoYMGZKnMOLk5KT1i/VllSpVwqpVq5Ceng6VSiW1nzp1Cp6enjpBIzd9+vRBq1atMHbsWJiYmOgsf//997F69Wo4Ozsb9G0CVapUQXR0NFJSUqRaHDp0SDoN9jqmpqYICwtDVFQUzM3N0aVLlxzDYjYvLy/Y2tri4sWLqFixYo59sq9BUigUCA4OzvN+KBQKKJVKncfUnD9/Hk2aNMnzOPmhd9j5+eefYW9vj5MnT+LkyZNayxQKBcMOEREV2A8//ICAgADUrl0bkydPxnvvvQelUonjx4/j8uXLej3qJDQ0FFOnTkXPnj0xZswY2NnZYf/+/fjuu+8wa9asPI8TEhKCR48e5RpkQkND8c0336Bdu3aYOnUqypQpg1u3bmHDhg0YM2YMypQpk+dtvTrupEmTEBYWhsmTJ+PRo0cYMmQIevToIV2v8zr9+vVDlSpVALwISa+jVCrRvHlzHDx4MMdnEwEvTrNdunRJ+v/cpKenIy4uDsCLI0Xz589HcnKy1p1eqampOHnyZKHfza132Llx40ZhzIOIiEji5eWF06dPY8aMGRg/fjzu3r0LlUoFX19fjBo1Cp999lmex7K3t8eBAwcwbtw4fPjhh0hMTIS3tzfmzJmDvn375nkchUKR6/UpAGBlZYX9+/dj7Nix6NixI549e4bSpUsjMDCwQEd6rKyssH37dgwbNgx16tSBlZUVOnXqhDlz5uRpfR8fHzRo0ADx8fGoV6/eG/v369cP/fv3x6xZs7SuLXpZXvZn27ZtcHNzA/Di0QCVK1fG2rVr0aRJE+kU3ebNm1G2bNlCv5tbIUQe7wWUsaSkJNjZ2SExMdGghx7VajX++OMPtGrVKs+HSSl/WGvjYa2NxxC1TktLw40bN+Dp6ZnrRaf0gkajQVJSEmxtbXP9Jf82EkLAx8cHn332GUaMGJGn/vXq1UNERAS6du1aKHPKrnVISAiGDh2Kbt265dr3dT/Def39rfeRndddxQ28uOeeiIiIit6jR4+watUqxMXF5el5OMCLI1iLFy/G33//Xahze/LkCTp06FBogepleoedp0+fan1Wq9U4f/48EhISDPpMAyIiIioYZ2dnODk5YfHixShZsmSe16tZsyZq1qxZeBPDiwvRR48e/doHRBqK3mEnp0c6azQaDBo0CF5eXgaZFBERERUcr1R5wSAnJZVKJUaMGIG5c+caYjgiIiIigzHYFVjXr19HZmamoYYjIiID4r/w6W1liJ9dvU9jvXoltxACsbGx+P3333N8AywRERWd7OegZGRkvPZhckTFVfarJApy96feYefVl3UplUqUKlUK33777Rvv1CIiIuMyNTWFlZUVHj16BDMzM1ndUm1oGo0GGRkZSEtLY50KWV5qLYRAamoqHj58CHt7+9c+wPBN9A47e/bsyffGiIjIuBQKBdzc3HDjxo0c3w9F/08IgefPn8PS0tIodwi9y/Sptb29PVxdXQu0Pb3DTrZHjx5JL2mrVKlSob/Ei4iI8sfc3Bw+Pj7IyMgo6qkUa2q1Gvv370ejRo34wMxCltdam5mZFeiITja9w05KSgqGDBmCZcuWSY97NjExQc+ePfH999/Dyipvb7UlIiLjUSqVfILyG5iYmCAzMxMWFhYMO4XM2LXW+6TkiBEjsG/fPmzZsgUJCQlISEjA5s2bsW/fPowcObIw5khERESUb3of2Vm/fj3WrVun9Tr2Vq1awdLSEp07d8bChQsNOT8iIiKiAtH7yE5qamqOr5R3dnaWbg8jIiIiKi70Djv+/v6YNGkS0tLSpLbnz59jypQp8Pf3N+jkiIiIiApK79NY//nPfxAcHIwyZcqgRo0aAICzZ8/CwsIC27dvN/gEiYiIiApC77BTrVo1XL16FStWrMDly5cBAF27dkVoaCifzklERETFTr6es2NlZYX+/fsbei5EREREBqf3NTu//PILfv/9d+nzmDFjYG9vjwYNGvDpnERERFTs6B12ZsyYIZ2uOnz4MObPn49Zs2bByckJERERBp8gERERUUHofRrrzp078Pb2BgBs2rQJH330EQYMGICAgACtZ+8QERERFQd6H9mxsbHBkydPAAA7duxAixYtAAAWFhZ4/vy5YWdHREREVEB6h50WLVqgX79+6NevH/755x+0atUKAHDhwgWUL19er7H279+Ptm3bwt3dHQqFAps2bdJaLoTAxIkT4ebmBktLSzRv3hxXr17V6hMfH4/Q0FDY2trC3t4effv2RXJysr67RURERDKld9hZsGAB/P398ejRI6xfvx6Ojo4AgJMnT6Jr1656jZWSkoIaNWpgwYIFOS6fNWsW5s2bh0WLFuHo0aOwtrZGcHCw1gMNQ0NDceHCBcTExGDr1q3Yv38/BgwYoO9uERERkUzpfc2Ovb095s+fr9M+ZcoUvTfesmVLtGzZMsdlQgh89913+PLLL9GuXTsAwLJly+Di4oJNmzahS5cuuHTpErZt24bjx4+jdu3aAIDvv/8erVq1wuzZs+Hu7q73nIiIiEhe8vWcnQMHDuDHH3/Ev//+i7Vr16J06dL473//C09PTzRs2NAgE7tx4wbi4uLQvHlzqc3Ozg716tXD4cOH0aVLFxw+fBj29vZS0AGA5s2bQ6lU4ujRo+jQoUOOY6enpyM9PV36nJSUBABQq9VQq9UGmX/2eC//lwoPa208rLXxsNbGxXobj6Fqndf18/XW8x49eiA0NBSnTp2SQkNiYiJmzJiBP/74Q98hcxQXFwcAOi8ddXFxkZbFxcXB2dlZa7mpqSkcHBykPjmJjIzM8UjUjh07YGVlVdCp64iJiTH4mJQz1tp4WGvjYa2Ni/U2noLWOq8vINc77EybNg2LFi1Cz549sWrVKqk9ICAA06ZN03e4IjF+/HiMGDFC+pyUlAQPDw8EBQXB1tbWYNtRq9WIiYlBixYtYGZmZrBxSRdrbTystfGw1sbFehuPoWqdfWbmTfQOO1euXEGjRo102u3s7JCQkKDvcLlydXUFADx48ABubm5S+4MHD1CzZk2pz8OHD7XWy8zMRHx8vLR+TlQqFVQqlU67mZlZofyAF9a4pIu1Nh7W2nhYa+NivY2noLXO67p6343l6uqKa9eu6bQfPHgQFSpU0He4XHl6esLV1RW7du2S2pKSknD06FH4+/sDAPz9/ZGQkICTJ09KfXbv3g2NRoN69eoZbC5ERET09tL7yE7//v0xbNgwLF26FAqFAvfv38fhw4cxatQoTJgwQa+xkpOTtYLTjRs3cObMGTg4OKBs2bIYPnw4pk2bBh8fH3h6emLChAlwd3dH+/btAQBVqlRBSEgI+vfvj0WLFkGtVmPw4MHo0qUL78QiIiIiAPkIO+PGjYNGo0FgYCBSU1PRqFEjqFQqjBo1CkOGDNFrrBMnTqBp06bS5+zraMLCwhAdHY0xY8YgJSUFAwYMQEJCAho2bIht27bBwsJCWmfFihUYPHgwAgMDoVQq0alTJ8ybN0/f3SIiIiKZ0jvsKBQKfPHFFxg9ejSuXbuG5ORk+Pr6wsbGBs+fP5deEpoXTZo0gRDitduaOnUqpk6dmmsfBwcHrFy5Uq99ICIioneH3tfsZDM3N4evry/q1q0LMzMzzJkzB56enoacGxEREVGB5TnspKenY/z48ahduzYaNGggvccqKioKnp6emDt3LiIiIgprnkRERET5kufTWBMnTsSPP/6I5s2b46+//sLHH3+M3r1748iRI5gzZw4+/vhjmJiYFOZciYiIiPSW57Czdu1aLFu2DB9++CHOnz+P9957D5mZmTh79iwUCkVhzpGIiIgo3/J8Guvu3bvw8/MDAFSrVg0qlQoREREMOkRERFSs5TnsZGVlwdzcXPpsamoKGxubQpkUERERkaHk+TSWEAK9evWSXrOQlpaGgQMHwtraWqvfhg0bDDtDIiIiogLIc9gJCwvT+ty9e3eDT4aIiIjI0PIcdqKiogpzHkRERESFIt8PFSQiIiJ6GzDsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsFeuwM3nyZCgUCq2vypUrS8vT0tIQHh4OR0dH2NjYoFOnTnjw4EERzpiIiIiKm2IddgCgatWqiI2Nlb4OHjwoLYuIiMCWLVuwdu1a7Nu3D/fv30fHjh2LcLZERERU3JgW9QTexNTUFK6urjrtiYmJ+Pnnn7Fy5Uo0a9YMABAVFYUqVargyJEjqF+/vrGnSkRERMVQsQ87V69ehbu7OywsLODv74/IyEiULVsWJ0+ehFqtRvPmzaW+lStXRtmyZXH48OHXhp309HSkp6dLn5OSkgAAarUaarXaYHPPHsuQY1LOWGvjYa2Nh7U2LtbbeAxV67yurxBCiAJtqRD9+eefSE5ORqVKlRAbG4spU6bg3r17OH/+PLZs2YLevXtrhRYAqFu3Lpo2bYqZM2fmOu7kyZMxZcoUnfaVK1fCysrK4PtBREREhpeamopu3bohMTERtra2ufYr1mHnVQkJCShXrhzmzJkDS0vLfIednI7seHh44PHjx68tlr7UajViYmLQokULmJmZGWxc0sVaGw9rbTystXGx3sZjqFonJSXBycnpjWGn2J/Gepm9vT0qVqyIa9euoUWLFsjIyEBCQgLs7e2lPg8ePMjxGp+XqVQqqFQqnXYzM7NC+QEvrHFJF2ttPKy18bDWxsV6G09Ba53XdYv93VgvS05OxvXr1+Hm5gY/Pz+YmZlh165d0vIrV67g9u3b8Pf3L8JZEhERUXFSrI/sjBo1Cm3btkW5cuVw//59TJo0CSYmJujatSvs7OzQt29fjBgxAg4ODrC1tcWQIUPg7+/PO7GIiIhIUqzDzt27d9G1a1c8efIEpUqVQsOGDXHkyBGUKlUKADB37lwolUp06tQJ6enpCA4Oxg8//FDEsyYiIqLipFiHnVWrVr12uYWFBRYsWIAFCxYYaUZERET0tnmrrtkhIiIi0hfDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREcmaaVFPQM5+/zsORx4ooD5zH1YW5lCZKmFuqoSJQqHdUQGoTJVQmZr8fx+lIudBKUeZmZmITwfuJTyHqam6qKcja6y18RTHWgsBZGkE0jM1SM/MQkamBhmZmjyta2aqlP6uMzdVwlSpwKt/HeZ3TumZWf+bkwbpag2UCkBlZgJzEyVUZkqYmyjfuC1D1VsIIFMjXsxJrUFGlgbqLI3O3/Mv5v1SHbM0L+ZraiLN2cRANcrTHPPyfVRAa44q0xfHTLLrnp6ZhYwsDSB0V61VtiQszU0MvCd5oxBC5DCld0tSUhLs7OyQmJgIW1tbg43bbPYe/Ps41WDjERERva12j2yMCqVsAABqtRp//PEHWrVqBTMzs3yPmdff3zyyU4j8KzjCMisZdg5OUGcJZPzvXx2aV/KlRuB/y16k+zS1bh96M01WFpQmRfOvhncNa208xbHWZiYvjkyo/vdlloejJkIA6qwXfwdm/12ozsrbEaE3USggHTHJPiIigP8dadAg439HffLCUPU2f7lGZiYwUSqko2DZR6GUCoV0lEdlqoSpiRLqrP+vT5o6C1mawvtd8Ooc83KkTZP9ffzf0aB0dRYA7aNoZiZK5HRywsyk6K6cYdgpRJPbVsEff9xAq1a1C5Rc6c3+/18Jwax1IWOtjYe1Ni7WW754gTIRERHJGsMOERERyRrDDhEREckaww4RERHJmmzCzoIFC1C+fHlYWFigXr16OHbsWFFPiYiIiIoBWYSd1atXY8SIEZg0aRJOnTqFGjVqIDg4GA8fPizqqREREVERk0XYmTNnDvr374/evXvD19cXixYtgpWVFZYuXVrUUyMiIqIi9tY/ZycjIwMnT57E+PHjpTalUonmzZvj8OHDOa6Tnp6O9PR06XNSUhKAF89YUKsN90j27LEMOSbljLU2HtbaeFhr42K9jcdQtc7r+m992Hn8+DGysrLg4uKi1e7i4oLLly/nuE5kZCSmTJmi075jxw5YWVkZfI4xMTEGH5NyxlobD2ttPKy1cbHexlPQWqem5u2VTG992MmP8ePHY8SIEdLnpKQkeHh4ICgoyKDvxlKr1YiJiUGLFi34NM5CxlobD2ttPKy1cbHexmOoWmefmXmTtz7sODk5wcTEBA8ePNBqf/DgAVxdXXNcR6VSQaVS6bSbmZkVyg94YY1Lulhr42GtjYe1Ni7W23gKWuu8rvvWX6Bsbm4OPz8/7Nq1S2rTaDTYtWsX/P39i3BmREREVBy89Ud2AGDEiBEICwtD7dq1UbduXXz33XdISUlB7969i3pqREREVMRkEXY++eQTPHr0CBMnTkRcXBxq1qyJbdu26Vy0TERERO8eWYQdABg8eDAGDx6cr3WFEADyfqFTXqnVaqSmpiIpKYnnfwsZa208rLXxsNbGxXobj6Fqnf17O/v3eG5kE3YK4tmzZwAADw+PIp4JERER6evZs2ews7PLdblCvCkOvQM0Gg3u37+PEiVKQKFQGGzc7Fva79y5Y9Bb2kkXa208rLXxsNbGxXobj6FqLYTAs2fP4O7uDqUy93uueGQHL564XKZMmUIb39bWln9wjIS1Nh7W2nhYa+NivY3HELV+3RGdbG/9redEREREr8OwQ0RERLLGsFOIVCoVJk2alOPTmsmwWGvjYa2Nh7U2LtbbeIxda16gTERERLLGIztEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7hWjBggUoX748LCwsUK9ePRw7dqyop/TWi4yMRJ06dVCiRAk4Ozujffv2uHLlilaftLQ0hIeHw9HRETY2NujUqRMePHhQRDOWh6+//hoKhQLDhw+X2lhnw7p37x66d+8OR0dHWFpaonr16jhx4oS0XAiBiRMnws3NDZaWlmjevDmuXr1ahDN+O2VlZWHChAnw9PSEpaUlvLy88NVXX2m9W4m1zp/9+/ejbdu2cHd3h0KhwKZNm7SW56Wu8fHxCA0Nha2tLezt7dG3b18kJycXfHKCCsWqVauEubm5WLp0qbhw4YLo37+/sLe3Fw8ePCjqqb3VgoODRVRUlDh//rw4c+aMaNWqlShbtqxITk6W+gwcOFB4eHiIXbt2iRMnToj69euLBg0aFOGs327Hjh0T5cuXF++9954YNmyY1M46G058fLwoV66c6NWrlzh69Kj4999/xfbt28W1a9ekPl9//bWws7MTmzZtEmfPnhUffvih8PT0FM+fPy/Cmb99pk+fLhwdHcXWrVvFjRs3xNq1a4WNjY34z3/+I/VhrfPnjz/+EF988YXYsGGDACA2btyotTwvdQ0JCRE1atQQR44cEQcOHBDe3t6ia9euBZ4bw04hqVu3rggPD5c+Z2VlCXd3dxEZGVmEs5Kfhw8fCgBi3759QgghEhIShJmZmVi7dq3U59KlSwKAOHz4cFFN86317Nkz4ePjI2JiYkTjxo2lsMM6G9bYsWNFw4YNc12u0WiEq6ur+Oabb6S2hIQEoVKpxK+//mqMKcpG69atRZ8+fbTaOnbsKEJDQ4UQrLWhvBp28lLXixcvCgDi+PHjUp8///xTKBQKce/evQLNh6exCkFGRgZOnjyJ5s2bS21KpRLNmzfH4cOHi3Bm8pOYmAgAcHBwAACcPHkSarVaq/aVK1dG2bJlWft8CA8PR+vWrbXqCbDOhvbbb7+hdu3a+Pjjj+Hs7IxatWphyZIl0vIbN24gLi5Oq952dnaoV68e662nBg0aYNeuXfjnn38AAGfPnsXBgwfRsmVLAKx1YclLXQ8fPgx7e3vUrl1b6tO8eXMolUocPXq0QNvni0ALwePHj5GVlQUXFxetdhcXF1y+fLmIZiU/Go0Gw4cPR0BAAKpVqwYAiIuLg7m5Oezt7bX6uri4IC4urghm+fZatWoVTp06hePHj+ssY50N699//8XChQsxYsQIfP755zh+/DiGDh0Kc3NzhIWFSTXN6e8U1ls/48aNQ1JSEipXrgwTExNkZWVh+vTpCA0NBQDWupDkpa5xcXFwdnbWWm5qagoHB4cC155hh95a4eHhOH/+PA4ePFjUU5GdO3fuYNiwYYiJiYGFhUVRT0f2NBoNateujRkzZgAAatWqhfPnz2PRokUICwsr4tnJy5o1a7BixQqsXLkSVatWxZkzZzB8+HC4u7uz1jLG01iFwMnJCSYmJjp3pjx48ACurq5FNCt5GTx4MLZu3Yo9e/agTJkyUrurqysyMjKQkJCg1Z+118/Jkyfx8OFDvP/++zA1NYWpqSn27duHefPmwdTUFC4uLqyzAbm5ucHX11errUqVKrh9+zYASDXl3ykFN3r0aIwbNw5dunRB9erV0aNHD0RERCAyMhIAa11Y8lJXV1dXPHz4UGt5ZmYm4uPjC1x7hp1CYG5uDj8/P+zatUtq02g02LVrF/z9/YtwZm8/IQQGDx6MjRs3Yvfu3fD09NRa7ufnBzMzM63aX7lyBbdv32bt9RAYGIi///4bZ86ckb5q166N0NBQ6f9ZZ8MJCAjQeYTCP//8g3LlygEAPD094erqqlXvpKQkHD16lPXWU2pqKpRK7V99JiYm0Gg0AFjrwpKXuvr7+yMhIQEnT56U+uzevRsajQb16tUr2AQKdHkz5WrVqlVCpVKJ6OhocfHiRTFgwABhb28v4uLiinpqb7VBgwYJOzs7sXfvXhEbGyt9paamSn0GDhwoypYtK3bv3i1OnDgh/P39hb+/fxHOWh5evhtLCNbZkI4dOyZMTU3F9OnTxdWrV8WKFSuElZWVWL58udTn66+/Fvb29mLz5s3i3Llzol27drwdOh/CwsJE6dKlpVvPN2zYIJycnMSYMWOkPqx1/jx79kycPn1anD59WgAQc+bMEadPnxa3bt0SQuStriEhIaJWrVri6NGj4uDBg8LHx4e3nhd333//vShbtqwwNzcXdevWFUeOHCnqKb31AOT4FRUVJfV5/vy5+Oyzz0TJkiWFlZWV6NChg4iNjS26ScvEq2GHdTasLVu2iGrVqgmVSiUqV64sFi9erLVco9GICRMmCBcXF6FSqURgYKC4cuVKEc327ZWUlCSGDRsmypYtKywsLESFChXEF198IdLT06U+rHX+7NmzJ8e/n8PCwoQQeavrkydPRNeuXYWNjY2wtbUVvXv3Fs+ePSvw3BRCvPTYSCIiIiKZ4TU7REREJGsMO0RERCRrDDtEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7REREJGsMO0T01rp58yYUCgXOnDlTaNvo1asX2rdvX2jjE1HhY9ghoiLTq1cvKBQKna+QkJA8re/h4YHY2FhUq1atkGdKRG8z06KeABG920JCQhAVFaXVplKp8rSuiYkJ30RNRG/EIztEVKRUKhVcXV21vkqWLAkAUCgUWLhwIVq2bAlLS0tUqFAB69atk9Z99TTW06dPERoailKlSsHS0hI+Pj5aQervv/9Gs2bNYGlpCUdHRwwYMADJycnS8qysLIwYMQL29vZwdHTEmDFj8OobdTQaDSIjI+Hp6QlLS0vUqFFDa05EVPww7BBRsTZhwgR06tQJZ8+eRWhoKLp06YJLly7l2vfixYv4888/cenSJSxcuBBOTk4AgJSUFAQHB6NkyZI4fvw41q5di507d2Lw4MHS+t9++y2io6OxdOlSHDx4EPHx8di4caPWNiIjI7Fs2TIsWrQIFy5cQEREBLp37459+/YVXhGIqGAK/CpRIqJ8CgsLEyYmJsLa2lrra/r06UKIF2+5HzhwoNY69erVE4MGDRJCCHHjxg0BQJw+fVoIIUTbtm1F7969c9zW4sWLRcmSJUVycrLU9vvvvwulUini4uKEEEK4ubmJWbNmScvVarUoU6aMaNeunRBCiLS0NGFlZSX++usvrbH79u0runbtmv9CEFGh4jU7RFSkmjZtioULF2q1OTg4SP/v7++vtczf3z/Xu68GDRqETp064dSpUwgKCkL79u3RoEEDAMClS5dQo0YNWFtbS/0DAgKg0Whw5coVWFhYIDY2FvXq1ZOWm5qaonbt2tKprGvXriE1NRUtWrTQ2m5GRgZq1aql/84TkVEw7BBRkbK2toa3t7dBxmrZsiVu3bqFP/74AzExMQgMDER4eDhmz55tkPGzr+/5/fffUbp0aa1leb2omoiMj9fsEFGxduTIEZ3PVapUybV/qVKlEBYWhuXLl+O7777D4sWLAQBVqlTB2bNnkZKSIvU9dOgQlEolKlWqBDs7O7i5ueHo0aPS8szMTJw8eVL67OvrC5VKhdu3b8Pb21vry8PDw1C7TEQGxiM7RFSk0tPTERcXp9VmamoqXVi8du1a1K5dGw0bNsSKFStw7Ngx/PzzzzmONXHiRPj5+aFq1apIT0/H1q1bpWAUGhqKSZMmISwsDJMnT8ajR48wZMgQ9OjRAy4uLgCAYcOG4euvv4aPjw8qV66MOXPmICEhQRq/RIkSGDVqFCIiIqDRaNCwYUMkJibi0KFDsLW1RVhYWCFUiIgKimGHiIrUtm3b4ObmptVWqVIlXL58GQAwZcoUrFq1Cp999hnc3Nzw66+/wtfXN8exzM3NMX78eNy8eROWlpb44IMPsGrVKgCAlZUVtm/fjmHDhqFOnTqwsrJCp06dMGfOHGn9kSNHIjY2FmFhYVAqlejTpw86dOiAxMREqc9XX32FUqVKITIyEv/++y/s7e3x/vvv4/PPPzd0aYjIQBRCvPIQCSKiYkKhUGDjxo18XQMRFQiv2SEiIiJZY9ghIiIiWeM1O0RUbPEsOxEZAo/sEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrDHsEBERkawx7BAREZGsMewQERGRrP0fNh2R0sW/dOcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import json\n",
    "import psutil\n",
    "import pynvml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from environment_ma_reward_distance_dynamic_notrandom import Env\n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, num_actions, env, alpha, gamma, epsilon):\n",
    "        self.env = env\n",
    "        self.num_actions = num_actions\n",
    "        self.learning_rate = alpha\n",
    "        self.discount_factor = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_tables = [defaultdict(lambda: [0.0] * num_actions) for _ in range(env.num_agents)]\n",
    "\n",
    "    @staticmethod\n",
    "    def arg_max(state_action):\n",
    "        max_index_list = []\n",
    "        max_value = state_action[0]\n",
    "        for index, value in enumerate(state_action):\n",
    "            if value > max_value:\n",
    "                max_index_list.clear()\n",
    "                max_value = value\n",
    "                max_index_list.append(index)\n",
    "            elif value == max_value:\n",
    "                max_index_list.append(index)\n",
    "        return random.choice(max_index_list)\n",
    "\n",
    "    def choose_action(self, agent_idx, state):\n",
    "        state = tuple(state)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            state_action = self.q_tables[agent_idx][state]\n",
    "            action = self.arg_max(state_action)\n",
    "        return action\n",
    "\n",
    "    def learn(self, agent_idx, state, action, reward, next_state):\n",
    "        state = tuple(state)\n",
    "        next_state = tuple(next_state)\n",
    "        current_q = self.q_tables[agent_idx][state][action]\n",
    "        max_next_q = max(self.q_tables[agent_idx][next_state])\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)\n",
    "        self.q_tables[agent_idx][state][action] = new_q\n",
    "\n",
    "\n",
    "class Case:\n",
    "\n",
    "    def __init__(self, problem, solution, trust_value=0.5, total_time_steps=0):\n",
    "        self.problem = ast.literal_eval(problem) if isinstance(problem, str) else problem\n",
    "        self.solution = solution\n",
    "        self.trust_value = trust_value\n",
    "        self.total_time_steps = total_time_steps  # New attribute for total time steps\n",
    "\n",
    "    @staticmethod\n",
    "    def sim_q(state1, state2):\n",
    "        state1 = np.atleast_1d(state1)\n",
    "        state2 = np.atleast_1d(state2)\n",
    "        CNDMaxDist = 6\n",
    "        v = state1.size\n",
    "        DistQ = np.sum([Case.dist_q(Objic, Objip) for Objic, Objip in zip(state1, state2)])\n",
    "        similarity = (CNDMaxDist * v - DistQ) / (CNDMaxDist * v)\n",
    "        return similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def dist_q(X1, X2):\n",
    "        return np.min(np.abs(X1 - X2))\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(state, case_base, threshold=0.1):\n",
    "        state = ast.literal_eval(state) if isinstance(state, str) else state\n",
    "        for case in case_base:\n",
    "            if state == case.problem: \n",
    "                return case\n",
    "\n",
    "    @staticmethod\n",
    "    def reuse(agent_idx, c, own_temp_case_base, comm_temp_case_base, source='own'):\n",
    "        \"\"\"Reuse step for adding cases to temporary case bases.\"\"\"\n",
    "        if source == 'own':\n",
    "            own_temp_case_base.append(c)\n",
    "        elif source == 'comm':\n",
    "            comm_temp_case_base.append(c)\n",
    "\n",
    "    @staticmethod\n",
    "    def revise(agent_idx, case_base, temporary_case_base, successful_episodes):\n",
    "        for case in case_base:\n",
    "            if any((case.problem, case.solution) == (temp_case.problem, temp_case.solution) for temp_case in temporary_case_base):\n",
    "                if successful_episodes:\n",
    "                    case.trust_value += 0.1\n",
    "                else:\n",
    "                    case.trust_value -= 0.4\n",
    "            else:\n",
    "                if successful_episodes:\n",
    "                    case.trust_value -= 0.4\n",
    "            \n",
    "            case.trust_value = max(0, min(case.trust_value, 1))\n",
    "            print(f\"case content after REVISE for agent {agent_idx}, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}, time steps: {case.total_time_steps}\")\n",
    "\n",
    "    @staticmethod\n",
    "    \n",
    "    def retain(agent_idx, case_base, own_temp_case_base, comm_temp_case_base, successful_episodes, threshold=0.49):\n",
    "\n",
    "        if successful_episodes:\n",
    "            for temp_case in reversed(own_temp_case_base):\n",
    "                state = tuple(np.atleast_1d(temp_case.problem))\n",
    "    \n",
    "                if not any(tuple(np.atleast_1d(case.problem)) == state for case in case_base):\n",
    "                    case_base.append(temp_case)\n",
    "                    # Case.added_states.add(state)\n",
    "                    print(f\"Episode succeeded, case {temp_case.problem} is empty. Temporary case base stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value}\")         \n",
    "                else:\n",
    "                    print(f\"Episode succeeded, case {temp_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value}\")    \n",
    "        else:\n",
    "            print(f\"Episode not succeeded, temporary case base from own experience is not stored to the case base\")\n",
    "        \n",
    "\n",
    "        case_base_dict = {tuple(np.atleast_1d(case.problem)): case for case in case_base}\n",
    "\n",
    "        for temp_comm_case in reversed(comm_temp_case_base):\n",
    "            state_comm = tuple(np.atleast_1d(temp_comm_case.problem))\n",
    "            \n",
    "            existing_case = case_base_dict.get(state_comm) \n",
    "\n",
    "            if existing_case is None:\n",
    "                case_base.append(temp_comm_case)\n",
    "                case_base_dict[state_comm] = temp_comm_case \n",
    "                print(f\"Integrated case process. comm case {temp_comm_case.problem} is empty. Temporary case base stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")         \n",
    "            # elif existing_case.trust_value < temp_comm_case.trust_value:\n",
    "            #     existing_case.solution = temp_comm_case.solution\n",
    "            #     existing_case.trust_value = max(0, temp_comm_case.trust_value)\n",
    "            #     print(f\"Integrated case process. Similar comm case for agent {agent_idx} is found. Updated case base with higher trust value: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")\n",
    "            # else:\n",
    "            #     print(f\"Integrated case process. comm case {temp_comm_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")   \n",
    "\n",
    "\n",
    "        case_base[:] = [case for case in case_base if case.trust_value >= threshold]\n",
    "\n",
    "        for case in case_base:\n",
    "            print(f\"cases content after RETAIN, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}\")\n",
    "\n",
    "        return case_base\n",
    "    \n",
    "\n",
    "class QCBRL:\n",
    "    def __init__(self, num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render):\n",
    "        self.num_actions = num_actions\n",
    "        self.env = env\n",
    "        self.episodes = episodes\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.render = render\n",
    "        self.epsilon_decay = epsilon_decay  \n",
    "        self.epsilon_min = epsilon_min  \n",
    "\n",
    "        self.problem_solvers = [ProblemSolver(num_actions, self.env, alpha, gamma, epsilon) for _ in range(self.env.num_agents)]\n",
    "        self.case_bases = [[] for _ in range(self.env.num_agents)]  # Individual case bases for each agent\n",
    "        self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for own experiences\n",
    "        self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for communication experiences\n",
    "        self.successful_episodes = [0] * self.env.num_agents\n",
    "        self.rewards_per_episode = [[] for _ in range(self.env.num_agents)]  \n",
    "        self.total_successful_episodes = 0 \n",
    "        self.action_type = 0\n",
    "\n",
    "    def run(self):\n",
    "        rewards = []\n",
    "        memory_usage = []\n",
    "        gpu_memory_usage = []\n",
    "        num_successful_episodes = 0\n",
    "        total_steps_list = []\n",
    "        success_steps = []\n",
    "\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "        for episode in range(episodes):\n",
    "            states = self.env.reset()\n",
    "            episode_reward = [0] * self.env.num_agents\n",
    "            total_steps = 0 \n",
    "            self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            success_count = [0] * self.env.num_agents\n",
    "            dones = [False] * self.env.num_agents\n",
    "            win_states = [False] * self.env.num_agents\n",
    "            successful_episodes = False\n",
    "\n",
    "            while not(all(dones)):\n",
    "                print(f\"----- starting point of Episode {episode} in steps {total_steps} loop -----\")\n",
    "                \n",
    "                actions = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    # print(f\"state before take action: {state}\")\n",
    "                    action = self.take_action(agent_idx, state)\n",
    "                    actions.append(action)\n",
    "\n",
    "                # print(f\"actions pass to the environment\")\n",
    "                next_states, rewards, dones = self.env.step(actions)\n",
    "\n",
    "                win_states = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    action = actions[agent_idx]\n",
    "                    reward = rewards[agent_idx]\n",
    "                    next_state = next_states[agent_idx]\n",
    "\n",
    "                    physical_state = tuple(state[0])\n",
    "                    win_state = state[1]\n",
    "                    comm_state = state[2]  # Communication state containing messages from other agents\n",
    "\n",
    "                    physical_next_state = tuple(next_state[0])\n",
    "                    win_next_state = next_state[1]\n",
    "                    comm_next_state = tuple(next_state[2]) if next_state[2] != 0 else next_state[2]\n",
    "\n",
    "                    physical_action = action[0]\n",
    "                    comm_action = action[1]\n",
    "\n",
    "                    # Process messages received from other agents\n",
    "                    print(f\"comm next state for agent {agent_idx}: {comm_next_state}\")\n",
    "                    # print(f\"comm next state content: {comm_next_state[0]}\")\n",
    "                    \n",
    "                    # if all(element is None for element in comm_next_state):\n",
    "                    # if (comm_next_state == [None]) or (comm_next_state is None):\n",
    "                    if (comm_next_state == 0):\n",
    "                        pass\n",
    "                    else:\n",
    "                        comm_case = Case(problem=comm_next_state[0], solution=comm_next_state[1], trust_value=comm_next_state[2], total_time_steps=comm_next_state[3])\n",
    "                        Case.reuse(agent_idx, comm_case, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='comm')\n",
    "\n",
    "                    # print(f\"state agent {agent_idx} before update: {physical_state}\")\n",
    "                    # print(f\"win state agent {agent_idx} before update: {win_next_state}\")\n",
    "                    # print(f\"action agent {agent_idx} before update: {physical_action}\")\n",
    "                    # print(f\"reward agent {agent_idx} before update: {reward}\")\n",
    "                    # print(f\"next state agent {agent_idx} before update: {physical_next_state}\")\n",
    "\n",
    "                    c = Case(physical_state, physical_action, total_time_steps=total_steps)\n",
    "                    Case.reuse(agent_idx, c, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='own')\n",
    "\n",
    "                    if self.action_type == 0:\n",
    "                        print(f\"action type of agent: {agent_idx}: problem solver, agent learned\")\n",
    "                        self.problem_solvers[agent_idx].learn(agent_idx, physical_state, physical_action, reward, physical_next_state)\n",
    "\n",
    "                    if (win_next_state): \n",
    "                        success_count[agent_idx] += 1\n",
    "                        # print(f\"agent{agent_idx} hit !!!!!\")\n",
    "                    # else:\n",
    "                    #     print(f\"agent{agent_idx} not hit !!!!!\")\n",
    "\n",
    "                    episode_reward[agent_idx] += reward\n",
    "                    win_states.append(win_next_state)  \n",
    "\n",
    "                states = next_states\n",
    "                total_steps += 1\n",
    "\n",
    "                self.env.render()\n",
    "                \n",
    "            if self.env.win_flag:\n",
    "                self.total_successful_episodes += 1\n",
    "                success_steps.append(total_steps)\n",
    "                successful_episodes = True\n",
    "                \n",
    "\n",
    "            \n",
    "            for agent_idx in range(self.env.num_agents):\n",
    "                print(f\"win status of agent {agent_idx}  before update the case base: {win_states[agent_idx]}\")\n",
    "                self.rewards_per_episode[agent_idx].append(episode_reward[agent_idx])\n",
    "\n",
    "                print(f\"agent{agent_idx} own temp case base: {self.own_temp_case_bases[agent_idx]}\")\n",
    "                print(f\"agent{agent_idx} comm temp case base: {self.comm_temp_case_bases[agent_idx]}\")\n",
    "                \n",
    "                \n",
    "                Case.revise(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], win_states[agent_idx])\n",
    "                self.case_bases[agent_idx] = Case.retain(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], win_states[agent_idx])\n",
    "               \n",
    "                \n",
    "            self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "            \n",
    "            memory_usage.append(psutil.virtual_memory().percent)\n",
    "            gpu_memory_usage.append(pynvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**2)\n",
    "\n",
    "            print(f\"Episode: {episode}, Total Steps: {total_steps}, Total Rewards: {episode_reward}, Status Episode: {successful_episodes}\")\n",
    "            print(f\"------------------------------------------End of episode {episode} loop--------------------\")\n",
    "\n",
    "        # self.save_case_base_temporary()  # Save temporary case base after training\n",
    "        # self.save_case_base()  # Save case base after training\n",
    "\n",
    "        success_rate = self.total_successful_episodes / episodes * 100\n",
    "\n",
    "        return self.rewards_per_episode, success_rate, memory_usage, gpu_memory_usage, success_steps\n",
    "\n",
    "    def take_action(self, agent_idx, state):\n",
    "        # print(f\"state detected in take action function: {state}\")\n",
    "        physical_state = tuple(state[0])\n",
    "        win_state = state[1]\n",
    "        comm_state = state[2]\n",
    "\n",
    "        similar_solution = Case.retrieve(physical_state, self.case_bases[agent_idx])\n",
    "        if similar_solution is not None:\n",
    "            physical_action = similar_solution.solution\n",
    "            comm_action = (similar_solution.problem, similar_solution.solution, similar_solution.trust_value, similar_solution.total_time_steps)\n",
    "            self.action_type = 1\n",
    "            # print(f\"Problem detected as a similiar soulution in case base: {similar_solution.problem}\")\n",
    "            print(f\"Physical Action for Agent {agent_idx} from case base: {physical_action}\")\n",
    "            # print(f\"Communication Action for Agent {agent_idx} from case base: {comm_action}\")\n",
    "            # print(f\"Trust value detected as a similiar solution in case base: {similar_solution.trust_value}\")\n",
    "        else:\n",
    "            physical_action = self.problem_solvers[agent_idx].choose_action(agent_idx, physical_state)\n",
    "            comm_action = 0  # No communication action if using problem solver action\n",
    "            self.action_type = 0\n",
    "            print(f\"Physical Action for Agent {agent_idx} from problem solver: {physical_action}\")\n",
    "\n",
    "        # print(f\"physical action returned from the take action: {physical_action}\")\n",
    "        # print(f\"comm action returned from the take action: {comm_action}\")\n",
    "\n",
    "        return (physical_action, comm_action)\n",
    "\n",
    "    def case_exists_in_case_base(self, case, case_base):\n",
    "        \"\"\"Check if a case exists in the given case base.\"\"\"\n",
    "        return any(existing_case.problem == case.problem and existing_case.solution == case.solution for existing_case in case_base)\n",
    "        \n",
    "    \n",
    "    def save_case_base_temporary(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_temporary_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": int(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps)} for case in self.own_temp_case_bases[agent_idx] + self.comm_temp_case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Temporary case base for Agent {agent_idx} saved successfully.\")\n",
    "\n",
    "    def save_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": int(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps)} for case in self.case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Case base for Agent {agent_idx} saved successfully.\")\n",
    "        \n",
    "    def load_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            try:\n",
    "                with open(filename, 'r') as file:\n",
    "                    case_base_data = json.load(file)\n",
    "                    self.case_bases[agent_idx] = [Case(np.array(case[\"problem\"]), case[\"solution\"], case[\"trust_value\"], case[\"total_time_steps\"]) for case in case_base_data]\n",
    "                    print(f\"Case base for Agent {agent_idx} loaded successfully.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Case base file for Agent {agent_idx} not found. Starting with an empty case base.\")\n",
    "\n",
    "    def display_success_rate(self, success_rate):\n",
    "        print(f\"Success rate: {success_rate}%\")\n",
    "\n",
    "\n",
    "    def plot_rewards(self, rewards):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            plt.plot([reward for reward in rewards[agent_idx]], label=f'Agent {agent_idx}')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.title('Rewards over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_total_steps(self, total_steps_list):\n",
    "        plt.plot(total_steps_list)\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Steps')\n",
    "        plt.title('Total Steps for Successful Episodes over Episodes')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_resources(self, memory_usage, gpu_memory_usage):\n",
    "        plt.plot(memory_usage, label='Memory (%)')\n",
    "        plt.plot(gpu_memory_usage, label='GPU Memory (MB)')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Resource Usage')\n",
    "        plt.title('Resource Usage over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_agents = 2\n",
    "    num_obstacles = 6\n",
    "    obstacles_random_steps = 35\n",
    "    is_agent_silent = False\n",
    "    episodes=100\n",
    "    max_steps=1000\n",
    "    alpha=0.1\n",
    "    gamma=0.9\n",
    "    epsilon=0.2\n",
    "    epsilon_decay = 0.995  \n",
    "    epsilon_min = 0.01  \n",
    "    render = True\n",
    "\n",
    "    env = Env(num_agents=num_agents, num_obstacles=num_obstacles, obstacles_random_steps = obstacles_random_steps, is_agent_silent=is_agent_silent)\n",
    "    \n",
    "    num_actions = len(env.action_space)\n",
    "    \n",
    "    agent = QCBRL(num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render)\n",
    "    rewards, success_rate, memory_usage, gpu_memory_usage, total_step_list = agent.run()\n",
    "\n",
    "    agent.display_success_rate(success_rate)\n",
    "    agent.plot_rewards(rewards)\n",
    "    agent.plot_total_steps(total_step_list)\n",
    "    agent.plot_resources(memory_usage, gpu_memory_usage)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
