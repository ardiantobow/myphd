{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- starting point of Episode 0 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010c9e70>, <__main__.Case object at 0x7f4c010ca9e0>, <__main__.Case object at 0x7f4c010cb2b0>, <__main__.Case object at 0x7f4c010cbdc0>, <__main__.Case object at 0x7f4c010cbe50>, <__main__.Case object at 0x7f4c010d9330>, <__main__.Case object at 0x7f4c010d9cf0>, <__main__.Case object at 0x7f4c010da650>, <__main__.Case object at 0x7f4c010db070>, <__main__.Case object at 0x7f4c010dbbe0>, <__main__.Case object at 0x7f4c010dbc40>, <__main__.Case object at 0x7f4c010e0f40>, <__main__.Case object at 0x7f4c010e1a50>, <__main__.Case object at 0x7f4c010e2500>, <__main__.Case object at 0x7f4c010e2ec0>, <__main__.Case object at 0x7f4c010e3910>, <__main__.Case object at 0x7f4c010e39a0>, <__main__.Case object at 0x7f4c010ece20>, <__main__.Case object at 0x7f4c010ed7e0>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010c8520>, <__main__.Case object at 0x7f4c010c8a60>, <__main__.Case object at 0x7f4c010c9960>, <__main__.Case object at 0x7f4c010ca380>, <__main__.Case object at 0x7f4c010cada0>, <__main__.Case object at 0x7f4c010cbcd0>, <__main__.Case object at 0x7f4c010d8760>, <__main__.Case object at 0x7f4c010d91b0>, <__main__.Case object at 0x7f4c010d9c00>, <__main__.Case object at 0x7f4c010da140>, <__main__.Case object at 0x7f4c010dab60>, <__main__.Case object at 0x7f4c010db580>, <__main__.Case object at 0x7f4c010e04f0>, <__main__.Case object at 0x7f4c010e0a30>, <__main__.Case object at 0x7f4c010e1960>, <__main__.Case object at 0x7f4c010e1ea0>, <__main__.Case object at 0x7f4c010e2dd0>, <__main__.Case object at 0x7f4c010e3820>, <__main__.Case object at 0x7f4c010e3d60>, <__main__.Case object at 0x7f4c010ec7c0>, <__main__.Case object at 0x7f4c010ed6f0>, <__main__.Case object at 0x7f4c010ee140>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 0, Total Steps: 22, Total Rewards: [-31, -11], Status Episode: False\n",
      "------------------------------------------End of episode 0 loop--------------------\n",
      "----- starting point of Episode 1 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c010fd6f0>, <__main__.Case object at 0x7f4c010fe110>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c011049d0>, <__main__.Case object at 0x7f4c011053f0>, <__main__.Case object at 0x7f4c01105f90>, <__main__.Case object at 0x7f4c01106950>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c011078b0>, <__main__.Case object at 0x7f4c011079a0>, <__main__.Case object at 0x7f4c01105e40>, <__main__.Case object at 0x7f4c01107a00>, <__main__.Case object at 0x7f4c01107c40>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107c70>]\n",
      "agent0 comm temp case base: []\n",
      "Episode succeeded, case (3, 4) is empty. Temporary case base stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (2, 4) is empty. Temporary case base stored to the case base: ((2, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 3, 0.5)\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) is empty. Temporary case base stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) is empty. Temporary case base stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 0, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 0, 0.5)\n",
      "Episode succeeded, case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 0, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 3, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 0, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 4), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 1, tv: 0.5\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010ffa60>, <__main__.Case object at 0x7f4c011044c0>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01106860>, <__main__.Case object at 0x7f4c01106da0>, <__main__.Case object at 0x7f4c011077c0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107b50>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107eb0>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 1, Total Steps: 22, Total Rewards: [29, -12], Status Episode: False\n",
      "------------------------------------------End of episode 1 loop--------------------\n",
      "----- starting point of Episode 2 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 4)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 0), 2, 0.5, 7)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 1), 2, 0.5, 8)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.5, 9)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 2), 4, 0.5, 11)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 2), 4, 0.5, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 2), 2, 0.5, 15)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 3), 3, 0.5, 16)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 3), 2, 0.5, 17)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 4), 4, 0.5, 21)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010e0130>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c01110280>, <__main__.Case object at 0x7f4c01107d60>, <__main__.Case object at 0x7f4c011102b0>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01110c10>, <__main__.Case object at 0x7f4c01110be0>]\n",
      "agent0 comm temp case base: []\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (2, 4), solution: 4, tv: 0.09999999999999998, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 0.6, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 1, tv: 0.09999999999999998, time steps: 3\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010efeb0>, <__main__.Case object at 0x7f4c010fd6f0>, <__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c01107790>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01107820>, <__main__.Case object at 0x7f4c01107ac0>, <__main__.Case object at 0x7f4c01107fa0>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01110040>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c011102e0>, <__main__.Case object at 0x7f4c011103a0>, <__main__.Case object at 0x7f4c01110460>, <__main__.Case object at 0x7f4c01110520>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c011106a0>, <__main__.Case object at 0x7f4c01110760>, <__main__.Case object at 0x7f4c01110820>, <__main__.Case object at 0x7f4c011108e0>, <__main__.Case object at 0x7f4c011109a0>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c01110b50>, <__main__.Case object at 0x7f4c01110c40>, <__main__.Case object at 0x7f4c01110d30>, <__main__.Case object at 0x7f4c01110df0>, <__main__.Case object at 0x7f4c01110ee0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c010ee140>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c01107bb0>, <__main__.Case object at 0x7f4c01107a00>, <__main__.Case object at 0x7f4c01104ac0>, <__main__.Case object at 0x7f4c01106980>, <__main__.Case object at 0x7f4c01107400>, <__main__.Case object at 0x7f4c01107b80>]\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (3, 4) is empty. Temporary case base stored to the case base: ((3, 4), 4, 0.5)\n",
      "Integrated case process. comm case (3, 3) is empty. Temporary case base stored to the case base: ((3, 3), 2, 0.5)\n",
      "Integrated case process. comm case (4, 3) is empty. Temporary case base stored to the case base: ((4, 3), 3, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 2, 0.5)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 4, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 0.5)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 0.5)\n",
      "Integrated case process. comm case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 2, 0.5)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "Episode: 2, Total Steps: 31, Total Rewards: [41, -40], Status Episode: False\n",
      "------------------------------------------End of episode 2 loop--------------------\n",
      "----- starting point of Episode 3 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 4)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 0), 2, 0.6, 7)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 1), 2, 0.6, 8)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 9)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 2), 4, 0.6, 11)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 2), 4, 0.6, 12)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 2), 2, 0.6, 15)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 3), 3, 0.6, 16)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 3), 2, 0.6, 17)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.5, 11)\n",
      "comm next state for agent 1: ((3, 4), 4, 0.6, 21)\n",
      "----- starting point of Episode 3 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.5, 11)\n",
      "comm next state for agent 1: ((4, 4), 0, 0.5, 30)\n",
      "----- starting point of Episode 3 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.5, 11)\n",
      "comm next state for agent 1: ((4, 4), 0, 0.5, 30)\n",
      "----- starting point of Episode 3 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.5, 11)\n",
      "comm next state for agent 1: ((4, 4), 0, 0.5, 30)\n",
      "----- starting point of Episode 3 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.5, 11)\n",
      "comm next state for agent 1: ((4, 4), 0, 0.5, 30)\n",
      "----- starting point of Episode 3 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.5, 11)\n",
      "comm next state for agent 1: ((4, 4), 0, 0.5, 30)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010e0130>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c011102b0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c011100a0>, <__main__.Case object at 0x7f4c01110070>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01110250>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c01110d60>, <__main__.Case object at 0x7f4c01110130>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.7, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 0.7, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 0.7, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 0.7, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.7, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 0.7, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.7, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 30\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c01105030>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01107d90>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c011077c0>, <__main__.Case object at 0x7f4c01107ac0>, <__main__.Case object at 0x7f4c011100d0>, <__main__.Case object at 0x7f4c01110310>, <__main__.Case object at 0x7f4c01110700>, <__main__.Case object at 0x7f4c01110910>, <__main__.Case object at 0x7f4c01110e20>, <__main__.Case object at 0x7f4c011101f0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010ef460>, <__main__.Case object at 0x7f4c010fe110>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c011049d0>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107d60>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01110370>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110850>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c011103a0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 0.6, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.09999999999999998, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.09999999999999998, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.09999999999999998, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.09999999999999998, time steps: 4\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) is empty. Temporary case base stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 0, 0.5)\n",
      "Episode succeeded, case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 1, 0.5)\n",
      "Episode succeeded, case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 1, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.6)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.6)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.6)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.6)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.6)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.6)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 0.6)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 0.6)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 0.6)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "Episode: 3, Total Steps: 15, Total Rewards: [41, 36], Status Episode: True\n",
      "------------------------------------------End of episode 3 loop--------------------\n",
      "----- starting point of Episode 4 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.5, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7, 4)\n",
      "----- starting point of Episode 4 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.5, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.7, 7)\n",
      "----- starting point of Episode 4 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 0.5, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 0.7, 8)\n",
      "----- starting point of Episode 4 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 0.5, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.7, 9)\n",
      "----- starting point of Episode 4 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.6, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.7, 11)\n",
      "----- starting point of Episode 4 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 0.6, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.7, 12)\n",
      "----- starting point of Episode 4 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 0.6, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 0.7, 15)\n",
      "----- starting point of Episode 4 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 0.6, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 0.7, 16)\n",
      "----- starting point of Episode 4 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 0.6, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 0.7, 17)\n",
      "----- starting point of Episode 4 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 0.6, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 0.7, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01110400>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010e0130>, <__main__.Case object at 0x7f4c010ef460>, <__main__.Case object at 0x7f4c010fd6f0>, <__main__.Case object at 0x7f4c010ffa60>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c01110ee0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.7999999999999999, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 0.7999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 0.7999999999999999, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 0.7999999999999999, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.7999999999999999, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 0.7999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.7999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 30\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.6)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.6)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.6)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.6)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.6)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.6)\n",
      "Integrated case process. comm case (2, 1) is empty. Temporary case base stored to the case base: ((2, 1), 2, 0.5)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 3, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c011101f0>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c011100a0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01110490>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01110970>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 0.7, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 0.7, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 0.7, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 0.7, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.7, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.09999999999999998, time steps: 30\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.7)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.7)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.7)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.7)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.7)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.7)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 0.7)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 0.7)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 0.7)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 0.7)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "Episode: 4, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 4 loop--------------------\n",
      "----- starting point of Episode 5 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.6, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7999999999999999, 4)\n",
      "----- starting point of Episode 5 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.6, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.7999999999999999, 7)\n",
      "----- starting point of Episode 5 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 0.6, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 0.7999999999999999, 8)\n",
      "----- starting point of Episode 5 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 0.6, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.7999999999999999, 9)\n",
      "----- starting point of Episode 5 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.7, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.7999999999999999, 11)\n",
      "----- starting point of Episode 5 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 0.7, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.7999999999999999, 12)\n",
      "----- starting point of Episode 5 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 0.7, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 0.7999999999999999, 15)\n",
      "----- starting point of Episode 5 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 0.7, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 0.7999999999999999, 16)\n",
      "----- starting point of Episode 5 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 0.7, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 0.7999999999999999, 17)\n",
      "----- starting point of Episode 5 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 0.7, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 0.7999999999999999, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110a60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c01110d90>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.8999999999999999, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 0.8999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 0.8999999999999999, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 0.8999999999999999, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.8999999999999999, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 0.8999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.8999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.09999999999999998, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.09999999999999998, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.09999999999999998, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.09999999999999998, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.7)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.7)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.7)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.7)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.7)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.7)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 0.6)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 0.6)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 0.6)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c01110850>, <__main__.Case object at 0x7f4c01110370>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c01110d30>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01110070>, <__main__.Case object at 0x7f4c01110490>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c011101f0>, <__main__.Case object at 0x7f4c01110cd0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 0.7999999999999999, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 0.7999999999999999, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 0.7999999999999999, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 0.7999999999999999, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.7999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.29999999999999993, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.29999999999999993, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.29999999999999993, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.29999999999999993, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 0.7, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 0.7, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.7, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.7, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 0.7999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7\n",
      "Episode: 5, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 5 loop--------------------\n",
      "----- starting point of Episode 6 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.7, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.8999999999999999, 4)\n",
      "----- starting point of Episode 6 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.7, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.8999999999999999, 7)\n",
      "----- starting point of Episode 6 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 0.7, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 0.8999999999999999, 8)\n",
      "----- starting point of Episode 6 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 0.7, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.8999999999999999, 9)\n",
      "----- starting point of Episode 6 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.7999999999999999, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.8999999999999999, 11)\n",
      "----- starting point of Episode 6 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 0.7999999999999999, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.8999999999999999, 12)\n",
      "----- starting point of Episode 6 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 0.7999999999999999, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 0.8999999999999999, 15)\n",
      "----- starting point of Episode 6 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 0.7999999999999999, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 0.8999999999999999, 16)\n",
      "----- starting point of Episode 6 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 0.7999999999999999, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 0.8999999999999999, 17)\n",
      "----- starting point of Episode 6 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 0.7999999999999999, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 0.8999999999999999, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c01110070>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c01110850>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01110580>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.9999999999999999, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 0.9999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 0.9999999999999999, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 0.9999999999999999, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.9999999999999999, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 0.9999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.9999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.7999999999999999)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 0.7)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 0.7)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 0.7)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.7)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c01110ee0>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c01110250>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01110df0>, <__main__.Case object at 0x7f4c01110b20>, <__main__.Case object at 0x7f4c011101f0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01110370>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 0.8999999999999999, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 0.8999999999999999, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 0.8999999999999999, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 0.8999999999999999, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.8999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.3999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.3999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.3999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.3999999999999999, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 0.7999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 0.7999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.7999999999999999, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.7999999999999999, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7999999999999999\n",
      "Episode: 6, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 6 loop--------------------\n",
      "----- starting point of Episode 7 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.7999999999999999, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.9999999999999999, 4)\n",
      "----- starting point of Episode 7 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.7999999999999999, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.9999999999999999, 7)\n",
      "----- starting point of Episode 7 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 0.7999999999999999, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 0.9999999999999999, 8)\n",
      "----- starting point of Episode 7 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 0.7999999999999999, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.9999999999999999, 9)\n",
      "----- starting point of Episode 7 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.8999999999999999, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.9999999999999999, 11)\n",
      "----- starting point of Episode 7 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 0.8999999999999999, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 0.9999999999999999, 12)\n",
      "----- starting point of Episode 7 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 0.8999999999999999, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 0.9999999999999999, 15)\n",
      "----- starting point of Episode 7 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 0.8999999999999999, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 0.9999999999999999, 16)\n",
      "----- starting point of Episode 7 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 0.8999999999999999, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 0.9999999999999999, 17)\n",
      "----- starting point of Episode 7 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 0.8999999999999999, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 0.9999999999999999, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110df0>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c01110850>, <__main__.Case object at 0x7f4c01110ee0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01110a30>, <__main__.Case object at 0x7f4c011101f0>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c01110670>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.29999999999999993, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.29999999999999993, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.29999999999999993, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.29999999999999993, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.7999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c011100d0>, <__main__.Case object at 0x7f4c01110d60>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c01110400>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01110c40>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110dc0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 0.9999999999999999, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 0.9999999999999999, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 0.9999999999999999, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 0.9999999999999999, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.9999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.4999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.4999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.4999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.4999999999999999, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 0.8999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 0.8999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.8999999999999999, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.8999999999999999, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 0.9999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8999999999999999\n",
      "Episode: 7, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 7 loop--------------------\n",
      "----- starting point of Episode 8 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.8999999999999999, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 8 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.8999999999999999, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 8 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 0.8999999999999999, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 8 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 0.8999999999999999, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 8 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.9999999999999999, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 8 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 0.9999999999999999, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 8 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 0.9999999999999999, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 8 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 0.9999999999999999, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 8 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 0.9999999999999999, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 8 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 0.9999999999999999, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01110a30>, <__main__.Case object at 0x7f4c01110c40>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110ee0>, <__main__.Case object at 0x7f4c01110d60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c011100d0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.3999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.3999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.3999999999999999, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.3999999999999999, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.9999999999999999)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01110550>, <__main__.Case object at 0x7f4c01111870>, <__main__.Case object at 0x7f4c011100a0>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c011103d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c011107c0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.5999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.5999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.5999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.5999999999999999, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 0.9999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 0.9999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.9999999999999999, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.9999999999999999, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9999999999999999\n",
      "Episode: 8, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 8 loop--------------------\n",
      "----- starting point of Episode 9 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.9999999999999999, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 9 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.9999999999999999, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 9 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 0.9999999999999999, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 9 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 0.9999999999999999, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 9 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 9 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 9 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 9 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 9 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 9 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c01110a30>, <__main__.Case object at 0x7f4c01110d60>, <__main__.Case object at 0x7f4c011100a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c01111870>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.4999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.4999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.4999999999999999, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.4999999999999999, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.9999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c011107f0>, <__main__.Case object at 0x7f4c01110d30>, <__main__.Case object at 0x7f4c011101f0>, <__main__.Case object at 0x7f4c01110550>, <__main__.Case object at 0x7f4c01110070>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01110d90>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c011101c0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 9, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 9 loop--------------------\n",
      "----- starting point of Episode 10 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 10 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 10 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 10 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 10 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 10 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 10 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 10 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 10 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 10 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c01110d90>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c011100a0>, <__main__.Case object at 0x7f4c01110d30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c011107f0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.5999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.5999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.5999999999999999, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.5999999999999999, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c01110250>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110df0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c01110490>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110a30>, <__main__.Case object at 0x7f4c011101f0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 10, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 10 loop--------------------\n",
      "----- starting point of Episode 11 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 11 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 11 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 11 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 11 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 11 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 11 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 11 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 11 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 11 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c01110d30>, <__main__.Case object at 0x7f4c01110250>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c011108b0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01110cd0>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110400>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01110c40>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c01110b20>, <__main__.Case object at 0x7f4c01110a30>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c01110220>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 11, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 11 loop--------------------\n",
      "----- starting point of Episode 12 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 12 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 12 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 12 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 12 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 12 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 12 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 12 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 12 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 12 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c01110250>, <__main__.Case object at 0x7f4c01110400>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01110550>, <__main__.Case object at 0x7f4c01110a30>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c011104c0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01110370>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c01110cd0>, <__main__.Case object at 0x7f4c011105e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c011100d0>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c01110160>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 12, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 12 loop--------------------\n",
      "----- starting point of Episode 13 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 13 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 13 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 13 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 13 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 13 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 13 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 13 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 13 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 13 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01110550>, <__main__.Case object at 0x7f4c011100d0>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c01110400>, <__main__.Case object at 0x7f4c011103d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c01110a60>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c01110850>, <__main__.Case object at 0x7f4c01110070>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110370>, <__main__.Case object at 0x7f4c01110d90>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01111870>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c01110b80>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 13, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 13 loop--------------------\n",
      "----- starting point of Episode 14 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 14 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 14 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 14 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 14 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 14 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 14 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 14 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 14 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 14 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01111870>, <__main__.Case object at 0x7f4c01110550>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c01110070>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c01110850>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110ee0>, <__main__.Case object at 0x7f4c01110df0>, <__main__.Case object at 0x7f4c01110a30>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c01110580>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c011107f0>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c011105b0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 14, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 14 loop--------------------\n",
      "----- starting point of Episode 15 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 15 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 15 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 15 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 15 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 15 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 15 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 15 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 15 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 15 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c011107f0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110070>, <__main__.Case object at 0x7f4c01110df0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01110cd0>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c01110ee0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c01110d60>, <__main__.Case object at 0x7f4c01110c40>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110670>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c01110490>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c01110550>, <__main__.Case object at 0x7f4c01110a30>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 15, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 15 loop--------------------\n",
      "----- starting point of Episode 16 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 16 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 16 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 16 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 16 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 16 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 16 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 16 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 16 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 16 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c01110cd0>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01110df0>, <__main__.Case object at 0x7f4c01110c40>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01110370>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c01110d60>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c011101f0>, <__main__.Case object at 0x7f4c011100a0>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c011100d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110b20>, <__main__.Case object at 0x7f4c01110550>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110190>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 16, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 16 loop--------------------\n",
      "----- starting point of Episode 17 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 17 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 17 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 17 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 17 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 17 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 17 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 17 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 17 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 17 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01110370>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110cd0>, <__main__.Case object at 0x7f4c01110c40>, <__main__.Case object at 0x7f4c011105e0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c01110550>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c011100a0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01110d30>, <__main__.Case object at 0x7f4c01110d90>, <__main__.Case object at 0x7f4c01110100>, <__main__.Case object at 0x7f4c011101f0>, <__main__.Case object at 0x7f4c01111870>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01110a90>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 17, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 17 loop--------------------\n",
      "----- starting point of Episode 18 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 18 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 18 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 18 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 18 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 18 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 18 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 18 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 18 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 18 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c01110370>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c01110d90>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01110d30>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110250>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c011107f0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01110850>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01110cd0>, <__main__.Case object at 0x7f4c01110100>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 18, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 18 loop--------------------\n",
      "----- starting point of Episode 19 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 4)\n",
      "----- starting point of Episode 19 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 7)\n",
      "----- starting point of Episode 19 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 1, 8)\n",
      "----- starting point of Episode 19 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 19 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 19 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 19 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 19 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 19 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "----- starting point of Episode 19 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 9)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110850>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c01110d90>, <__main__.Case object at 0x7f4c01110130>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c01110250>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c01110ee0>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01110cd0>, <__main__.Case object at 0x7f4c01110370>, <__main__.Case object at 0x7f4c01110580>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c01110220>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 19, Total Steps: 10, Total Rewards: [-12, 41], Status Episode: False\n",
      "------------------------------------------End of episode 19 loop--------------------\n",
      "----- starting point of Episode 20 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 4)\n",
      "----- starting point of Episode 20 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.6, 7)\n",
      "----- starting point of Episode 20 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 2, 0.6, 8)\n",
      "----- starting point of Episode 20 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 9)\n",
      "----- starting point of Episode 20 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 9)\n",
      "----- starting point of Episode 20 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 9)\n",
      "----- starting point of Episode 20 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 9)\n",
      "----- starting point of Episode 20 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 9)\n",
      "----- starting point of Episode 20 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 9)\n",
      "----- starting point of Episode 20 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 9)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110130>, <__main__.Case object at 0x7f4c01110cd0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c01110ee0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110d60>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c01110880>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110850>, <__main__.Case object at 0x7f4c01110a90>, <__main__.Case object at 0x7f4c01110370>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.6)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.6)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.6)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.6)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.6)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.6)\n",
      "Integrated case process. comm case (1, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.6)\n",
      "Integrated case process. comm case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.6)\n",
      "Integrated case process. comm case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.6)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 20, Total Steps: 10, Total Rewards: [-12, 41], Status Episode: False\n",
      "------------------------------------------End of episode 20 loop--------------------\n",
      "----- starting point of Episode 21 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 21 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 21 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010ffbb0>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c011101c0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01110400>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c01111510>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c01111600>, <__main__.Case object at 0x7f4c01111390>, <__main__.Case object at 0x7f4c011102e0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01110a00>, <__main__.Case object at 0x7f4c01110c70>, <__main__.Case object at 0x7f4c011108e0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010fd330>, <__main__.Case object at 0x7f4c010ee530>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 3, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 1, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 0, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c01110a30>, <__main__.Case object at 0x7f4c01110c40>, <__main__.Case object at 0x7f4c01110b80>, <__main__.Case object at 0x7f4c01110850>, <__main__.Case object at 0x7f4c01110df0>, <__main__.Case object at 0x7f4c011107f0>, <__main__.Case object at 0x7f4c01110d90>, <__main__.Case object at 0x7f4c01110250>, <__main__.Case object at 0x7f4c01111870>, <__main__.Case object at 0x7f4c01111750>, <__main__.Case object at 0x7f4c011115a0>, <__main__.Case object at 0x7f4c01111540>, <__main__.Case object at 0x7f4c011114b0>, <__main__.Case object at 0x7f4c01111450>, <__main__.Case object at 0x7f4c011113c0>, <__main__.Case object at 0x7f4c01111240>, <__main__.Case object at 0x7f4c01110e20>, <__main__.Case object at 0x7f4c01110910>, <__main__.Case object at 0x7f4c01110520>, <__main__.Case object at 0x7f4c01110b50>, <__main__.Case object at 0x7f4c01110b20>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 2, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 2, tv: 0.5\n",
      "Episode: 21, Total Steps: 28, Total Rewards: [23, 41], Status Episode: True\n",
      "------------------------------------------End of episode 21 loop--------------------\n",
      "----- starting point of Episode 22 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 0.5, 17)\n",
      "----- starting point of Episode 22 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 0.5, 18)\n",
      "----- starting point of Episode 22 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.5, 20)\n",
      "----- starting point of Episode 22 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 22 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 22 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 22 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 22 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 22 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 22 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110400>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110af0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c011114e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c010ffbb0>, <__main__.Case object at 0x7f4c010fd7e0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c01111570>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 2, tv: 0.09999999999999998, time steps: 27\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 4, 0.5)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.5\n",
      "Episode: 22, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 22 loop--------------------\n",
      "----- starting point of Episode 23 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 0.6, 17)\n",
      "----- starting point of Episode 23 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 0.6, 18)\n",
      "----- starting point of Episode 23 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.6, 20)\n",
      "----- starting point of Episode 23 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 23 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 23 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 23 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 23 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 23 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 23 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c011100d0>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01111a20>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c011116f0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01110dc0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.7, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.7, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01111a80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c010fdd50>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110b50>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.09999999999999998, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.09999999999999998, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.09999999999999998, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 0.6)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 0.6)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 23, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 23 loop--------------------\n",
      "----- starting point of Episode 24 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 0.7, 17)\n",
      "----- starting point of Episode 24 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 0.7, 18)\n",
      "----- starting point of Episode 24 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.7, 20)\n",
      "----- starting point of Episode 24 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 24 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 24 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 24 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 24 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 24 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 24 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010ee140>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c011114e0>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c01110790>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c01111360>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.7999999999999999, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.7999999999999999, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.7999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c011116f0>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110670>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01110b50>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c011108b0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 0.7)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 0.7)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 0.7)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.7\n",
      "Episode: 24, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 24 loop--------------------\n",
      "----- starting point of Episode 25 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 0.7999999999999999, 17)\n",
      "----- starting point of Episode 25 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 0.7999999999999999, 18)\n",
      "----- starting point of Episode 25 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.7999999999999999, 20)\n",
      "----- starting point of Episode 25 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 25 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 25 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 25 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 25 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 25 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 25 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01111a80>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c011116f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c01111360>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c011105b0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.8999999999999999, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.8999999999999999, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c011100d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c01111a20>, <__main__.Case object at 0x7f4c01110880>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.29999999999999993, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.29999999999999993, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.29999999999999993, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 0.7999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.7999999999999999\n",
      "Episode: 25, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 25 loop--------------------\n",
      "----- starting point of Episode 26 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 0.8999999999999999, 17)\n",
      "----- starting point of Episode 26 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 0.8999999999999999, 18)\n",
      "----- starting point of Episode 26 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.8999999999999999, 20)\n",
      "----- starting point of Episode 26 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 26 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 26 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 26 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 26 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 26 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 26 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110dc0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c01110160>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.9999999999999999, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.9999999999999999, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.9999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01111360>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c01110b50>, <__main__.Case object at 0x7f4c011114e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01111600>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c011107c0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.3999999999999999, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.3999999999999999, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.3999999999999999, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.8999999999999999\n",
      "Episode: 26, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 26 loop--------------------\n",
      "----- starting point of Episode 27 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 0.9999999999999999, 17)\n",
      "----- starting point of Episode 27 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 0.9999999999999999, 18)\n",
      "----- starting point of Episode 27 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.9999999999999999, 20)\n",
      "----- starting point of Episode 27 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 27 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 27 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 27 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 27 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 27 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 27 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c011100d0>, <__main__.Case object at 0x7f4c01110a60>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01111360>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010fdd50>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c010ee140>, <__main__.Case object at 0x7f4c01111570>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01111600>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c01111a80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c011116f0>, <__main__.Case object at 0x7f4c011105e0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.4999999999999999, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.4999999999999999, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.4999999999999999, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 0.9999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 0.9999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.9999999999999999\n",
      "Episode: 27, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 27 loop--------------------\n",
      "----- starting point of Episode 28 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 28 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 28 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 28 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 28 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 28 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 28 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 28 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 28 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 28 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c011114e0>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c011116c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01111420>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c011108b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01110670>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.5999999999999999, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.5999999999999999, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.5999999999999999, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 28, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 28 loop--------------------\n",
      "----- starting point of Episode 29 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 29 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 29 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 29 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 29 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 29 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 29 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 29 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 29 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 29 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01111a80>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110160>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01111420>, <__main__.Case object at 0x7f4c010ee140>, <__main__.Case object at 0x7f4c01110400>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01111360>, <__main__.Case object at 0x7f4c011100d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fdd50>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110b50>, <__main__.Case object at 0x7f4c011103d0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 29, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 29 loop--------------------\n",
      "----- starting point of Episode 30 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 30 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 30 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 30 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 30 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 30 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 30 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 30 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 30 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 30 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c011116f0>, <__main__.Case object at 0x7f4c01111570>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c01110400>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c011107c0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c01111420>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c011114e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c011116c0>, <__main__.Case object at 0x7f4c01110af0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 30, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 30 loop--------------------\n",
      "----- starting point of Episode 31 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 31 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 31 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 31 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 31 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 31 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 31 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 31 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 31 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 31 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c011100d0>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01111420>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01107700>, <__main__.Case object at 0x7f4c01111360>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01110400>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c01111a80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01111a20>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110940>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 31, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 31 loop--------------------\n",
      "----- starting point of Episode 32 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 32 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 32 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 32 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 32 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 32 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 32 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 32 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 32 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 32 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c011114e0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01110400>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01111360>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c011105e0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01111a20>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c011108b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c01110580>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 32, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 32 loop--------------------\n",
      "----- starting point of Episode 33 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 33 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 33 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 33 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 33 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 33 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 33 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 33 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 33 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 33 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01111a80>, <__main__.Case object at 0x7f4c011116f0>, <__main__.Case object at 0x7f4c011116c0>, <__main__.Case object at 0x7f4c011107c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c01110670>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01111360>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c011100d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c01111600>, <__main__.Case object at 0x7f4c01111420>, <__main__.Case object at 0x7f4c01111a20>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 33, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 33 loop--------------------\n",
      "----- starting point of Episode 34 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 34 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 34 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 34 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 34 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 34 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 34 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 34 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 34 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 34 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01111360>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c011103d0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01111600>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c011114e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01111a20>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01110400>, <__main__.Case object at 0x7f4c01110970>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 34, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 34 loop--------------------\n",
      "----- starting point of Episode 35 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 35 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 35 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 35 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 35 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 35 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 35 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 35 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 35 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 35 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c011100d0>, <__main__.Case object at 0x7f4c01110220>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c011104c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c01107d00>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c01110af0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c01111a80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01111600>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 35, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 35 loop--------------------\n",
      "----- starting point of Episode 36 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 36 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 36 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 36 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 36 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 36 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 36 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 36 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 36 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 36 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c01107700>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c011114e0>, <__main__.Case object at 0x7f4c011116c0>, <__main__.Case object at 0x7f4c01111420>, <__main__.Case object at 0x7f4c01110670>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c01110940>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c011103d0>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c01111a20>, <__main__.Case object at 0x7f4c011108b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01111600>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01111360>, <__main__.Case object at 0x7f4c01110880>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 36, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 36 loop--------------------\n",
      "----- starting point of Episode 37 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 37 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 37 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 37 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 37 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 37 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 37 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 37 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 37 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 37 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c01111a80>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c01110400>, <__main__.Case object at 0x7f4c011103d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01110580>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110970>, <__main__.Case object at 0x7f4c011100d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c011116f0>, <__main__.Case object at 0x7f4c011104c0>, <__main__.Case object at 0x7f4c01110dc0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 37, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 37 loop--------------------\n",
      "----- starting point of Episode 38 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 38 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 38 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 38 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 38 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 38 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 38 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "----- starting point of Episode 38 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((4, 3), 3, 1, 16)\n",
      "----- starting point of Episode 38 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 38 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c011108b0>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110af0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01110580>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01111a20>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c011116f0>, <__main__.Case object at 0x7f4c01111600>, <__main__.Case object at 0x7f4c011114e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01110dc0>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c01110790>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 1), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 38, Total Steps: 10, Total Rewards: [141, 141], Status Episode: True\n",
      "------------------------------------------End of episode 38 loop--------------------\n",
      "----- starting point of Episode 39 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17)\n",
      "----- starting point of Episode 39 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 1, 18)\n",
      "----- starting point of Episode 39 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 20)\n",
      "----- starting point of Episode 39 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 39 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 39 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 39 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c011100d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01105e10>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 2), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01110580>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01110790>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((4, 2), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((3, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 1)\n",
      "Integrated case process. comm case (0, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 1)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 39, Total Steps: 7, Total Rewards: [-16, -16], Status Episode: False\n",
      "------------------------------------------End of episode 39 loop--------------------\n",
      "----- starting point of Episode 40 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.6, 3)\n",
      "comm next state for agent 1: ((0, 0), 2, 0.6, 17)\n",
      "----- starting point of Episode 40 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.6, 5)\n",
      "comm next state for agent 1: ((0, 1), 4, 0.6, 18)\n",
      "----- starting point of Episode 40 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 0.6, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.6, 20)\n",
      "----- starting point of Episode 40 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 40 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 40 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 1, 12)\n",
      "comm next state for agent 1: ((3, 2), 4, 1, 12)\n",
      "----- starting point of Episode 40 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 1, 15)\n",
      "comm next state for agent 1: ((4, 2), 2, 1, 15)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01107700>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c011116c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c01107850>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 4, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 2), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.6)\n",
      "Integrated case process. comm case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.6)\n",
      "Integrated case process. comm case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01107eb0>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c011100d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01110400>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 0.19999999999999996, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.19999999999999996, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((4, 2), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((3, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((2, 2), 4, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.6)\n",
      "Integrated case process. comm case (0, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.6)\n",
      "Integrated case process. comm case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 40, Total Steps: 7, Total Rewards: [-16, -16], Status Episode: False\n",
      "------------------------------------------End of episode 40 loop--------------------\n",
      "----- starting point of Episode 41 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010fcdc0>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107f10>, <__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c01107f40>, <__main__.Case object at 0x7f4c01107d90>, <__main__.Case object at 0x7f4c011077c0>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c01111ae0>]\n",
      "agent0 comm temp case base: []\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c011044c0>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c011116c0>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01110af0>, <__main__.Case object at 0x7f4c011116f0>, <__main__.Case object at 0x7f4c01111930>, <__main__.Case object at 0x7f4c01110f10>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 41, Total Steps: 19, Total Rewards: [-13, -28], Status Episode: False\n",
      "------------------------------------------End of episode 41 loop--------------------\n",
      "----- starting point of Episode 42 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 5)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 4, 0.6, 12)\n",
      "comm next state for agent 1: ((3, 1), 3, 1, 7)\n",
      "----- starting point of Episode 42 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 2, 0.6, 15)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 42 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 42 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 42 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 3), 3, 1, 16)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c011077c0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c011116c0>, <__main__.Case object at 0x7f4c01111930>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01107fa0>, <__main__.Case object at 0x7f4c01110af0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 3, 1)\n",
      "Integrated case process. comm case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 2, 0.6)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 4, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c010fdd50>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01105e10>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01111300>, <__main__.Case object at 0x7f4c01110790>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c011116f0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c01107be0>, <__main__.Case object at 0x7f4c01107f70>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01111600>, <__main__.Case object at 0x7f4c01110e20>, <__main__.Case object at 0x7f4c01110a30>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 2, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 3, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "Episode: 42, Total Steps: 14, Total Rewards: [-23, -20], Status Episode: False\n",
      "------------------------------------------End of episode 42 loop--------------------\n",
      "----- starting point of Episode 43 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 43 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 43 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 43 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.6, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 43 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.6, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 43 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((2, 1), 2, 0.6, 8)\n",
      "----- starting point of Episode 43 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 1), 2, 0.6, 8)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 43 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 1), 2, 0.6, 8)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 43 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 1), 2, 0.6, 8)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c011107c0>, <__main__.Case object at 0x7f4c01110790>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c011054e0>, <__main__.Case object at 0x7f4c01110520>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 1, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 2, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 4, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 3\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 2), 4, 0.6)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.6)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010ff190>, <__main__.Case object at 0x7f4c010fdd50>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c01107d90>, <__main__.Case object at 0x7f4c01107cd0>, <__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c01107c40>, <__main__.Case object at 0x7f4c011116f0>, <__main__.Case object at 0x7f4c01110e20>, <__main__.Case object at 0x7f4c01111600>, <__main__.Case object at 0x7f4c01110700>, <__main__.Case object at 0x7f4c011114b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c01110f10>, <__main__.Case object at 0x7f4c01111930>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c01110e80>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 3, tv: 0.19999999999999996, time steps: 16\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.7, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.19999999999999996, time steps: 20\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 3, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 1, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 0, 0.5)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.6)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.6)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.6)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "Episode: 43, Total Steps: 15, Total Rewards: [-24, 39], Status Episode: False\n",
      "------------------------------------------End of episode 43 loop--------------------\n",
      "----- starting point of Episode 44 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.5, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.7, 11)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.5, 9)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 44 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 14)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01107880>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c011077c0>, <__main__.Case object at 0x7f4c01107a00>, <__main__.Case object at 0x7f4c01107940>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c01110f10>, <__main__.Case object at 0x7f4c01110940>, <__main__.Case object at 0x7f4c01110160>, <__main__.Case object at 0x7f4c011113f0>, <__main__.Case object at 0x7f4c011109a0>, <__main__.Case object at 0x7f4c01110850>, <__main__.Case object at 0x7f4c011118d0>, <__main__.Case object at 0x7f4c01110190>, <__main__.Case object at 0x7f4c01111480>, <__main__.Case object at 0x7f4c01110cd0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c011054e0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c011073a0>, <__main__.Case object at 0x7f4c011064a0>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c01110520>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01110880>, <__main__.Case object at 0x7f4c011105e0>, <__main__.Case object at 0x7f4c01110910>, <__main__.Case object at 0x7f4c01111420>, <__main__.Case object at 0x7f4c01110370>, <__main__.Case object at 0x7f4c01110670>, <__main__.Case object at 0x7f4c01111720>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 0.6, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.7, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 3\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 0, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 1, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 1, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 3, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 3, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 3, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.7)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. comm case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c01104ac0>, <__main__.Case object at 0x7f4c01107790>, <__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c010fdd50>, <__main__.Case object at 0x7f4c01111930>, <__main__.Case object at 0x7f4c01111570>, <__main__.Case object at 0x7f4c011116c0>, <__main__.Case object at 0x7f4c01110b50>, <__main__.Case object at 0x7f4c01110070>, <__main__.Case object at 0x7f4c01111330>, <__main__.Case object at 0x7f4c01111a20>, <__main__.Case object at 0x7f4c01110550>, <__main__.Case object at 0x7f4c01110df0>, <__main__.Case object at 0x7f4c01110ee0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.7999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.6, time steps: 14\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.6, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.6, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "Episode: 44, Total Steps: 20, Total Rewards: [31, 43], Status Episode: True\n",
      "------------------------------------------End of episode 44 loop--------------------\n",
      "----- starting point of Episode 45 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.6, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 11)\n",
      "----- starting point of Episode 45 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.5, 12)\n",
      "----- starting point of Episode 45 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.5, 13)\n",
      "----- starting point of Episode 45 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 45 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.7999999999999999, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.7, 11)\n",
      "----- starting point of Episode 45 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.6, 9)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.5, 17)\n",
      "----- starting point of Episode 45 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 45 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c01107fa0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c011044c0>, <__main__.Case object at 0x7f4c01106980>, <__main__.Case object at 0x7f4c010fd330>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010c9540>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01104ac0>, <__main__.Case object at 0x7f4c01107790>, <__main__.Case object at 0x7f4c010fce20>, <__main__.Case object at 0x7f4c010fd7e0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 3, tv: 0.19999999999999996, time steps: 16\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.7999999999999999, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.6, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.6, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.6, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.09999999999999998, time steps: 14\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.6)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c011054e0>, <__main__.Case object at 0x7f4c011073a0>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107940>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c01110400>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010ee530>, <__main__.Case object at 0x7f4c01107d90>, <__main__.Case object at 0x7f4c011040a0>, <__main__.Case object at 0x7f4c011078b0>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c010ffbb0>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c01110ee0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.8999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 14\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.7, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.7, time steps: 2\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.7)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. comm case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "Episode: 45, Total Steps: 8, Total Rewards: [143, 143], Status Episode: True\n",
      "------------------------------------------End of episode 45 loop--------------------\n",
      "----- starting point of Episode 46 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.7, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 11)\n",
      "----- starting point of Episode 46 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.6, 12)\n",
      "----- starting point of Episode 46 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.6, 13)\n",
      "----- starting point of Episode 46 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 46 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.8999999999999999, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.7999999999999999, 11)\n",
      "----- starting point of Episode 46 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7, 9)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.6, 17)\n",
      "----- starting point of Episode 46 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 46 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c010fd330>, <__main__.Case object at 0x7f4c010fdd50>, <__main__.Case object at 0x7f4c01104ac0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c01107a60>, <__main__.Case object at 0x7f4c01110520>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01107a00>, <__main__.Case object at 0x7f4c01107940>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.8999999999999999, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.7, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.7, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.7, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 11\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.7)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.7)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c011079a0>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c011073a0>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c01110df0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010fff70>, <__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107df0>, <__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c011054e0>, <__main__.Case object at 0x7f4c011106d0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.9999999999999999, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.7999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.7999999999999999, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.09999999999999998, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.09999999999999998, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.09999999999999998, time steps: 11\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.6)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.7999999999999999)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 0.6)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 0.6)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 0.6)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 46, Total Steps: 8, Total Rewards: [143, 143], Status Episode: True\n",
      "------------------------------------------End of episode 46 loop--------------------\n",
      "----- starting point of Episode 47 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.7999999999999999, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7, 11)\n",
      "----- starting point of Episode 47 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.7, 12)\n",
      "----- starting point of Episode 47 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.7, 13)\n",
      "----- starting point of Episode 47 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 47 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 0.9999999999999999, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.8999999999999999, 11)\n",
      "----- starting point of Episode 47 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7999999999999999, 9)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7, 17)\n",
      "----- starting point of Episode 47 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 47 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c011078e0>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c011104f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010cb3a0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010fd7e0>, <__main__.Case object at 0x7f4c01104ac0>, <__main__.Case object at 0x7f4c01107a60>, <__main__.Case object at 0x7f4c01104ee0>, <__main__.Case object at 0x7f4c01107fd0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.9999999999999999, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.29999999999999993, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.7999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.7999999999999999, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.7999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 11\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.7999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c010fdd50>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c011078b0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c011105b0>, <__main__.Case object at 0x7f4c01110520>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010fd330>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107940>, <__main__.Case object at 0x7f4c01104610>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c010eefb0>, <__main__.Case object at 0x7f4c01110400>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.8999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.8999999999999999, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.19999999999999996, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.19999999999999996, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 11\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.7)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 0.7)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 0.7)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 0.7)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "Episode: 47, Total Steps: 8, Total Rewards: [143, 143], Status Episode: True\n",
      "------------------------------------------End of episode 47 loop--------------------\n",
      "----- starting point of Episode 48 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.8999999999999999, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7999999999999999, 11)\n",
      "----- starting point of Episode 48 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.7999999999999999, 12)\n",
      "----- starting point of Episode 48 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.7999999999999999, 13)\n",
      "----- starting point of Episode 48 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 48 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.9999999999999999, 11)\n",
      "----- starting point of Episode 48 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.8999999999999999, 9)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7999999999999999, 17)\n",
      "----- starting point of Episode 48 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 48 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c010ff6a0>, <__main__.Case object at 0x7f4c011072b0>, <__main__.Case object at 0x7f4c01107940>, <__main__.Case object at 0x7f4c01107760>, <__main__.Case object at 0x7f4c01107c10>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c011101f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010c9540>, <__main__.Case object at 0x7f4c010fc7c0>, <__main__.Case object at 0x7f4c010fdd50>, <__main__.Case object at 0x7f4c010fe200>, <__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01106980>, <__main__.Case object at 0x7f4c013ff790>, <__main__.Case object at 0x7f4c011078b0>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.3999999999999999, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.8999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.8999999999999999, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.8999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 11\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c010fd1e0>, <__main__.Case object at 0x7f4c010fe770>, <__main__.Case object at 0x7f4c011054e0>, <__main__.Case object at 0x7f4c011044c0>, <__main__.Case object at 0x7f4c011077f0>, <__main__.Case object at 0x7f4c01107e20>, <__main__.Case object at 0x7f4c01110520>, <__main__.Case object at 0x7f4c011106a0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c010fd7e0>, <__main__.Case object at 0x7f4c010ff640>, <__main__.Case object at 0x7f4c01107a00>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107850>, <__main__.Case object at 0x7f4c01107dc0>, <__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c011104f0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.9999999999999999, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.9999999999999999, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.29999999999999993, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.29999999999999993, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.29999999999999993, time steps: 11\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.7999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 0.7999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 0.7999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999\n",
      "Episode: 48, Total Steps: 8, Total Rewards: [143, 143], Status Episode: True\n",
      "------------------------------------------End of episode 48 loop--------------------\n",
      "----- starting point of Episode 49 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.9999999999999999, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.8999999999999999, 11)\n",
      "----- starting point of Episode 49 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.8999999999999999, 12)\n",
      "----- starting point of Episode 49 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 3, 1, 7)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.8999999999999999, 13)\n",
      "----- starting point of Episode 49 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 2, 1, 8)\n",
      "comm next state for agent 1: ((2, 1), 2, 1, 8)\n",
      "----- starting point of Episode 49 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 2), 4, 1, 11)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 11)\n",
      "----- starting point of Episode 49 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.9999999999999999, 9)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.8999999999999999, 17)\n",
      "----- starting point of Episode 49 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 2, 1, 17)\n",
      "comm next state for agent 1: ((3, 3), 2, 1, 17)\n",
      "----- starting point of Episode 49 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 4), 4, 1, 21)\n",
      "comm next state for agent 1: ((3, 4), 4, 1, 21)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7f4c010ef8b0>, <__main__.Case object at 0x7f4c011079d0>, <__main__.Case object at 0x7f4c01107a60>, <__main__.Case object at 0x7f4c01107fd0>, <__main__.Case object at 0x7f4c01105f30>, <__main__.Case object at 0x7f4c010fc3a0>, <__main__.Case object at 0x7f4c010fe620>, <__main__.Case object at 0x7f4c01110df0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7f4c010ef4f0>, <__main__.Case object at 0x7f4c010ef490>, <__main__.Case object at 0x7f4c01107d30>, <__main__.Case object at 0x7f4c01105f90>, <__main__.Case object at 0x7f4c013ff250>, <__main__.Case object at 0x7f4c011054e0>, <__main__.Case object at 0x7f4c010fec20>, <__main__.Case object at 0x7f4c010fe770>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 3, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.4999999999999999, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.9999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.9999999999999999, time steps: 13\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.9999999999999999, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 11\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 1), 3, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((3, 0), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 0 is found. Updated case base with higher trust value: ((4, 0), 3, 0.9999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7f4c01106ef0>, <__main__.Case object at 0x7f4c01107970>, <__main__.Case object at 0x7f4c01107940>, <__main__.Case object at 0x7f4c011044c0>, <__main__.Case object at 0x7f4c010fdc00>, <__main__.Case object at 0x7f4c010ff040>, <__main__.Case object at 0x7f4c011106a0>, <__main__.Case object at 0x7f4c011105b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7f4c01104ac0>, <__main__.Case object at 0x7f4c011078b0>, <__main__.Case object at 0x7f4c01107a90>, <__main__.Case object at 0x7f4c011079a0>, <__main__.Case object at 0x7f4c010fc910>, <__main__.Case object at 0x7f4c010fd330>, <__main__.Case object at 0x7f4c010feb30>, <__main__.Case object at 0x7f4c011101f0>]\n",
      "case content after REVISE for agent 1, problem: (3, 4), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 1, time steps: 11\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 3, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 9\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.3999999999999999, time steps: 13\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.3999999999999999, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.3999999999999999, time steps: 11\n",
      "Episode succeeded, case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 1)\n",
      "Integrated case process. comm case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 2, 1)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 1), 4, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((1, 0), 2, 0.8999999999999999)\n",
      "Integrated case process. Similar comm case for agent 1 is found. Updated case base with higher trust value: ((0, 0), 4, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "Episode: 49, Total Steps: 8, Total Rewards: [143, 143], Status Episode: True\n",
      "------------------------------------------End of episode 49 loop--------------------\n",
      "Success rate: 80.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import json\n",
    "import psutil\n",
    "import pynvml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from environment_ma_reward_distance_dynamic import Env\n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, num_actions, env, alpha, gamma, epsilon):\n",
    "        self.env = env\n",
    "        self.num_actions = num_actions\n",
    "        self.learning_rate = alpha\n",
    "        self.discount_factor = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_tables = [defaultdict(lambda: [0.0] * num_actions) for _ in range(env.num_agents)]\n",
    "\n",
    "    @staticmethod\n",
    "    def arg_max(state_action):\n",
    "        max_index_list = []\n",
    "        max_value = state_action[0]\n",
    "        for index, value in enumerate(state_action):\n",
    "            if value > max_value:\n",
    "                max_index_list.clear()\n",
    "                max_value = value\n",
    "                max_index_list.append(index)\n",
    "            elif value == max_value:\n",
    "                max_index_list.append(index)\n",
    "        return random.choice(max_index_list)\n",
    "\n",
    "    def choose_action(self, agent_idx, state):\n",
    "        state = tuple(state)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            state_action = self.q_tables[agent_idx][state]\n",
    "            action = self.arg_max(state_action)\n",
    "        return action\n",
    "\n",
    "    def learn(self, agent_idx, state, action, reward, next_state):\n",
    "        state = tuple(state)\n",
    "        next_state = tuple(next_state)\n",
    "        current_q = self.q_tables[agent_idx][state][action]\n",
    "        max_next_q = max(self.q_tables[agent_idx][next_state])\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)\n",
    "        self.q_tables[agent_idx][state][action] = new_q\n",
    "\n",
    "\n",
    "class Case:\n",
    "\n",
    "    def __init__(self, problem, solution, trust_value=0.5, total_time_steps=0):\n",
    "        self.problem = ast.literal_eval(problem) if isinstance(problem, str) else problem\n",
    "        self.solution = solution\n",
    "        self.trust_value = trust_value\n",
    "        self.total_time_steps = total_time_steps  # New attribute for total time steps\n",
    "\n",
    "    @staticmethod\n",
    "    def sim_q(state1, state2):\n",
    "        state1 = np.atleast_1d(state1)\n",
    "        state2 = np.atleast_1d(state2)\n",
    "        CNDMaxDist = 6\n",
    "        v = state1.size\n",
    "        DistQ = np.sum([Case.dist_q(Objic, Objip) for Objic, Objip in zip(state1, state2)])\n",
    "        similarity = (CNDMaxDist * v - DistQ) / (CNDMaxDist * v)\n",
    "        return similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def dist_q(X1, X2):\n",
    "        return np.min(np.abs(X1 - X2))\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(state, case_base, threshold=0.1):\n",
    "        state = ast.literal_eval(state) if isinstance(state, str) else state\n",
    "        for case in case_base:\n",
    "            if state == case.problem: \n",
    "                return case\n",
    "\n",
    "    @staticmethod\n",
    "    def reuse(agent_idx, c, own_temp_case_base, comm_temp_case_base, source='own'):\n",
    "        \"\"\"Reuse step for adding cases to temporary case bases.\"\"\"\n",
    "        if source == 'own':\n",
    "            own_temp_case_base.append(c)\n",
    "        elif source == 'comm':\n",
    "            comm_temp_case_base.append(c)\n",
    "\n",
    "    @staticmethod\n",
    "    def revise(agent_idx, case_base, temporary_case_base, successful_episodes):\n",
    "        for case in case_base:\n",
    "            if any((case.problem, case.solution) == (temp_case.problem, temp_case.solution) for temp_case in temporary_case_base):\n",
    "                if successful_episodes:\n",
    "                    case.trust_value += 0.1\n",
    "                else:\n",
    "                    case.trust_value -= 0.4\n",
    "            else:\n",
    "                if successful_episodes:\n",
    "                    case.trust_value -= 0.4\n",
    "            \n",
    "            case.trust_value = max(0, min(case.trust_value, 1))\n",
    "            print(f\"case content after REVISE for agent {agent_idx}, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}, time steps: {case.total_time_steps}\")\n",
    "\n",
    "    @staticmethod\n",
    "    # def retain(agent_idx, case_base, own_temp_case_base, comm_temp_case_base, successful_episodes, threshold=0.49):\n",
    "    #     # if successful_episodes:\n",
    "    #     #     \"\"\"Retain step for combining cases from both temporary bases and adding them to the main case base.\"\"\"\n",
    "    #     #     combined_cases = own_temp_case_base + comm_temp_case_base\n",
    "    #     #     for temp_case in combined_cases:\n",
    "    #     #         existing_case = next((case for case in case_base if case.problem == temp_case.problem), None)\n",
    "    #     #         if existing_case:\n",
    "    #     #             if (temp_case.total_time_steps < existing_case.total_time_steps) or \\\n",
    "    #     #             (temp_case.total_time_steps == existing_case.total_time_steps and temp_case.trust_value > existing_case.trust_value):\n",
    "    #     #                 existing_case.solution = temp_case.solution\n",
    "    #     #                 existing_case.trust_value = temp_case.trust_value\n",
    "    #     #                 existing_case.total_time_steps = temp_case.total_time_steps\n",
    "    #     #                 print(f\"Updated existing case with better metrics: {existing_case.problem}, {existing_case.solution}, {existing_case.trust_value}, {existing_case.total_time_steps}\")\n",
    "    #     #         else:\n",
    "    #     #             case_base.append(temp_case)\n",
    "    #     #             print(f\"New case added: {temp_case.problem}, {temp_case.solution}, {temp_case.trust_value}, {temp_case.total_time_steps}\")\n",
    "        \n",
    "\n",
    "    #     if successful_episodes:\n",
    "    #         for temp_case in reversed(own_temp_case_base):\n",
    "    #             state = tuple(np.atleast_1d(temp_case.problem))\n",
    "    #             if not any(tuple(np.atleast_1d(case.problem)) == state for case in case_base):\n",
    "    #                 case_base.append(temp_case)\n",
    "    #                 # Case.added_states.add(state)\n",
    "    #                 print(f\"Episode succeeded, case for agent {agent_idx} {temp_case.problem} is empty. Temporary case base stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value,}\")         \n",
    "    #             else:\n",
    "    #                 # existing_case = next((case for case in case_base if tuple(np.atleast_1d(case.problem)) == state), None)\n",
    "    #                 # if existing_case and existing_case.trust_value < temp_case.trust_value:\n",
    "    #                 #     existing_case.solution = temp_case.solution\n",
    "    #                 #     existing_case.trust_value = max(0, temp_case.trust_value)\n",
    "    #                 #     print(f\"Episode succeeded, similar case for agent {agent_idx} is found. Updated case base with higher trust value: {existing_case.problem, existing_case.solution, existing_case.trust_value}\")\n",
    "    #                 # else:\n",
    "    #                     print(f\"Episode succeeded, case {temp_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value,}\")    \n",
    "    #     else:\n",
    "    #         print(f\"Episode not succeeded, temporary case base for agent {agent_idx} not stored to the case base\")\n",
    "\n",
    "    #     # Filter cases with trust values above the threshold\n",
    "    #     case_base[:] = [case for case in case_base if case.trust_value >= threshold]\n",
    "\n",
    "    #     for case in case_base:\n",
    "    #         print(f\"cases content after RETAIN for agent {agent_idx}, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}, time steps: {case.total_time_steps}\")\n",
    "\n",
    "    #     return case_base\n",
    "\n",
    "    def retain(agent_idx, case_base, own_temp_case_base, comm_temp_case_base, successful_episodes, threshold=0.49):\n",
    "\n",
    "        if successful_episodes:\n",
    "            for temp_case in reversed(own_temp_case_base):\n",
    "                state = tuple(np.atleast_1d(temp_case.problem))\n",
    "    \n",
    "                if not any(tuple(np.atleast_1d(case.problem)) == state for case in case_base):\n",
    "                    case_base.append(temp_case)\n",
    "                    # Case.added_states.add(state)\n",
    "                    print(f\"Episode succeeded, case {temp_case.problem} is empty. Temporary case base stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value}\")         \n",
    "                else:\n",
    "                    print(f\"Episode succeeded, case {temp_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value}\")    \n",
    "        else:\n",
    "            print(f\"Episode not succeeded, temporary case base from own experience is not stored to the case base\")\n",
    "        \n",
    "\n",
    "        # Optional: Use a dictionary for faster lookups\n",
    "        case_base_dict = {tuple(np.atleast_1d(case.problem)): case for case in case_base}\n",
    "\n",
    "        for temp_comm_case in reversed(comm_temp_case_base):\n",
    "            state_comm = tuple(np.atleast_1d(temp_comm_case.problem))\n",
    "            \n",
    "            existing_case = case_base_dict.get(state_comm)  # Use dictionary for O(1) lookup\n",
    "\n",
    "            if existing_case is None:\n",
    "                case_base.append(temp_comm_case)\n",
    "                case_base_dict[state_comm] = temp_comm_case  # Update dictionary\n",
    "                print(f\"Integrated case process. comm case {temp_comm_case.problem} is empty. Temporary case base stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")         \n",
    "            elif existing_case.trust_value < temp_comm_case.trust_value:\n",
    "                existing_case.solution = temp_comm_case.solution\n",
    "                existing_case.trust_value = max(0, temp_comm_case.trust_value)\n",
    "                print(f\"Integrated case process. Similar comm case for agent {agent_idx} is found. Updated case base with higher trust value: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")\n",
    "            else:\n",
    "                print(f\"Integrated case process. comm case {temp_comm_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")   \n",
    "\n",
    "\n",
    "        case_base[:] = [case for case in case_base if case.trust_value >= threshold]\n",
    "\n",
    "        for case in case_base:\n",
    "            print(f\"cases content after RETAIN, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}\")\n",
    "\n",
    "        return case_base\n",
    "    \n",
    "\n",
    "class QCBRL:\n",
    "    def __init__(self, num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render):\n",
    "        self.num_actions = num_actions\n",
    "        self.env = env\n",
    "        self.episodes = episodes\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.render = render\n",
    "        self.epsilon_decay = epsilon_decay  \n",
    "        self.epsilon_min = epsilon_min  \n",
    "\n",
    "        self.problem_solvers = [ProblemSolver(num_actions, self.env, alpha, gamma, epsilon) for _ in range(self.env.num_agents)]\n",
    "        self.case_bases = [[] for _ in range(self.env.num_agents)]  # Individual case bases for each agent\n",
    "        self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for own experiences\n",
    "        self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for communication experiences\n",
    "        self.successful_episodes = [0] * self.env.num_agents\n",
    "        self.rewards_per_episode = [[] for _ in range(self.env.num_agents)]  \n",
    "        self.total_successful_episodes = 0 \n",
    "        self.action_type = 0\n",
    "\n",
    "    def run(self):\n",
    "        rewards = []\n",
    "        memory_usage = []\n",
    "        gpu_memory_usage = []\n",
    "        num_successful_episodes = 0\n",
    "        total_steps_list = []\n",
    "        success_steps = []\n",
    "\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "        for episode in range(episodes):\n",
    "            states = self.env.reset()\n",
    "            episode_reward = [0] * self.env.num_agents\n",
    "            total_steps = 0 \n",
    "            self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            success_count = [0] * self.env.num_agents\n",
    "            dones = [False] * self.env.num_agents\n",
    "            win_states = [False] * self.env.num_agents\n",
    "            successful_episodes = False\n",
    "\n",
    "            while not(all(dones)):\n",
    "                print(f\"----- starting point of Episode {episode} in steps {total_steps} loop -----\")\n",
    "                \n",
    "                actions = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    # print(f\"state before take action: {state}\")\n",
    "                    action = self.take_action(agent_idx, state)\n",
    "                    actions.append(action)\n",
    "\n",
    "                # print(f\"actions pass to the environment\")\n",
    "                next_states, rewards, dones = self.env.step(actions)\n",
    "\n",
    "                win_states = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    action = actions[agent_idx]\n",
    "                    reward = rewards[agent_idx]\n",
    "                    next_state = next_states[agent_idx]\n",
    "\n",
    "                    physical_state = tuple(state[0])\n",
    "                    win_state = state[1]\n",
    "                    comm_state = state[2]  # Communication state containing messages from other agents\n",
    "\n",
    "                    physical_next_state = tuple(next_state[0])\n",
    "                    win_next_state = next_state[1]\n",
    "                    comm_next_state = tuple(next_state[2]) if next_state[2] != 0 else next_state[2]\n",
    "\n",
    "                    physical_action = action[0]\n",
    "                    comm_action = action[1]\n",
    "\n",
    "                    # Process messages received from other agents\n",
    "                    print(f\"comm next state for agent {agent_idx}: {comm_next_state}\")\n",
    "                    # print(f\"comm next state content: {comm_next_state[0]}\")\n",
    "                    \n",
    "                    # if all(element is None for element in comm_next_state):\n",
    "                    # if (comm_next_state == [None]) or (comm_next_state is None):\n",
    "                    if (comm_next_state == 0):\n",
    "                        pass\n",
    "                    else:\n",
    "                        comm_case = Case(problem=comm_next_state[0], solution=comm_next_state[1], trust_value=comm_next_state[2], total_time_steps=comm_next_state[3])\n",
    "                        Case.reuse(agent_idx, comm_case, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='comm')\n",
    "\n",
    "                    # print(f\"state agent {agent_idx} before update: {physical_state}\")\n",
    "                    # print(f\"win state agent {agent_idx} before update: {win_next_state}\")\n",
    "                    # print(f\"action agent {agent_idx} before update: {physical_action}\")\n",
    "                    # print(f\"reward agent {agent_idx} before update: {reward}\")\n",
    "                    # print(f\"next state agent {agent_idx} before update: {physical_next_state}\")\n",
    "\n",
    "                    c = Case(physical_state, physical_action, total_time_steps=total_steps)\n",
    "                    Case.reuse(agent_idx, c, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='own')\n",
    "\n",
    "                    if self.action_type == 0:\n",
    "                        print(f\"action type of agent: {agent_idx}: problem solver, agent learned\")\n",
    "                        self.problem_solvers[agent_idx].learn(agent_idx, physical_state, physical_action, reward, physical_next_state)\n",
    "\n",
    "                    if (win_next_state): \n",
    "                        success_count[agent_idx] += 1\n",
    "                        # print(f\"agent{agent_idx} hit !!!!!\")\n",
    "                    # else:\n",
    "                    #     print(f\"agent{agent_idx} not hit !!!!!\")\n",
    "\n",
    "                    episode_reward[agent_idx] += reward\n",
    "                    win_states.append(win_next_state)  \n",
    "\n",
    "                states = next_states\n",
    "                total_steps += 1\n",
    "\n",
    "                self.env.render()\n",
    "                \n",
    "            if self.env.win_flag:\n",
    "                self.total_successful_episodes += 1\n",
    "                success_steps.append(total_steps)\n",
    "                successful_episodes = True\n",
    "                \n",
    "\n",
    "            \n",
    "            for agent_idx in range(self.env.num_agents):\n",
    "                print(f\"win status of agent {agent_idx}  before update the case base: {win_states[agent_idx]}\")\n",
    "                self.rewards_per_episode[agent_idx].append(episode_reward[agent_idx])\n",
    "\n",
    "                print(f\"agent{agent_idx} own temp case base: {self.own_temp_case_bases[agent_idx]}\")\n",
    "                print(f\"agent{agent_idx} comm temp case base: {self.comm_temp_case_bases[agent_idx]}\")\n",
    "                \n",
    "                \n",
    "                Case.revise(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], win_states[agent_idx])\n",
    "                self.case_bases[agent_idx] = Case.retain(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], win_states[agent_idx])\n",
    "               \n",
    "                \n",
    "            self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "            \n",
    "            memory_usage.append(psutil.virtual_memory().percent)\n",
    "            gpu_memory_usage.append(pynvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**2)\n",
    "\n",
    "            print(f\"Episode: {episode}, Total Steps: {total_steps}, Total Rewards: {episode_reward}, Status Episode: {successful_episodes}\")\n",
    "            print(f\"------------------------------------------End of episode {episode} loop--------------------\")\n",
    "\n",
    "        # self.save_case_base_temporary()  # Save temporary case base after training\n",
    "        # self.save_case_base()  # Save case base after training\n",
    "\n",
    "        success_rate = self.total_successful_episodes / episodes * 100\n",
    "\n",
    "        return self.rewards_per_episode, success_rate, memory_usage, gpu_memory_usage, success_steps\n",
    "\n",
    "    def take_action(self, agent_idx, state):\n",
    "        # print(f\"state detected in take action function: {state}\")\n",
    "        physical_state = tuple(state[0])\n",
    "        win_state = state[1]\n",
    "        comm_state = state[2]\n",
    "\n",
    "        similar_solution = Case.retrieve(physical_state, self.case_bases[agent_idx])\n",
    "        if similar_solution is not None:\n",
    "            physical_action = similar_solution.solution\n",
    "            comm_action = (similar_solution.problem, similar_solution.solution, similar_solution.trust_value, similar_solution.total_time_steps)\n",
    "            self.action_type = 1\n",
    "            # print(f\"Problem detected as a similiar soulution in case base: {similar_solution.problem}\")\n",
    "            print(f\"Physical Action for Agent {agent_idx} from case base: {physical_action}\")\n",
    "            # print(f\"Communication Action for Agent {agent_idx} from case base: {comm_action}\")\n",
    "            # print(f\"Trust value detected as a similiar solution in case base: {similar_solution.trust_value}\")\n",
    "        else:\n",
    "            physical_action = self.problem_solvers[agent_idx].choose_action(agent_idx, physical_state)\n",
    "            comm_action = 0  # No communication action if using problem solver action\n",
    "            self.action_type = 0\n",
    "            print(f\"Physical Action for Agent {agent_idx} from problem solver: {physical_action}\")\n",
    "\n",
    "        # print(f\"physical action returned from the take action: {physical_action}\")\n",
    "        # print(f\"comm action returned from the take action: {comm_action}\")\n",
    "\n",
    "        return (physical_action, comm_action)\n",
    "\n",
    "    def case_exists_in_case_base(self, case, case_base):\n",
    "        \"\"\"Check if a case exists in the given case base.\"\"\"\n",
    "        return any(existing_case.problem == case.problem and existing_case.solution == case.solution for existing_case in case_base)\n",
    "        \n",
    "    \n",
    "    def save_case_base_temporary(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_temporary_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": int(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps)} for case in self.own_temp_case_bases[agent_idx] + self.comm_temp_case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Temporary case base for Agent {agent_idx} saved successfully.\")\n",
    "\n",
    "    def save_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": int(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps)} for case in self.case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Case base for Agent {agent_idx} saved successfully.\")\n",
    "        \n",
    "    def load_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            try:\n",
    "                with open(filename, 'r') as file:\n",
    "                    case_base_data = json.load(file)\n",
    "                    self.case_bases[agent_idx] = [Case(np.array(case[\"problem\"]), case[\"solution\"], case[\"trust_value\"], case[\"total_time_steps\"]) for case in case_base_data]\n",
    "                    print(f\"Case base for Agent {agent_idx} loaded successfully.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Case base file for Agent {agent_idx} not found. Starting with an empty case base.\")\n",
    "\n",
    "    def display_success_rate(self, success_rate):\n",
    "        print(f\"Success rate: {success_rate}%\")\n",
    "\n",
    "\n",
    "    def plot_rewards(self, rewards):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            plt.plot([reward for reward in rewards[agent_idx]], label=f'Agent {agent_idx}')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.title('Rewards over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_total_steps(self, total_steps_list):\n",
    "        plt.plot(total_steps_list)\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Steps')\n",
    "        plt.title('Total Steps for Successful Episodes over Episodes')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_resources(self, memory_usage, gpu_memory_usage):\n",
    "        plt.plot(memory_usage, label='Memory (%)')\n",
    "        plt.plot(gpu_memory_usage, label='GPU Memory (MB)')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Resource Usage')\n",
    "        plt.title('Resource Usage over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_agents = 2\n",
    "    num_obstacles = 3\n",
    "    obstacles_random_steps = 20\n",
    "    is_agent_silent = False\n",
    "    episodes=50\n",
    "    max_steps=1000\n",
    "    alpha=0.1\n",
    "    gamma=0.9\n",
    "    epsilon=0.2\n",
    "    epsilon_decay = 0.995  \n",
    "    epsilon_min = 0.01  \n",
    "    render = True\n",
    "\n",
    "    env = Env(num_agents=num_agents, num_obstacles=num_obstacles, obstacles_random_steps = obstacles_random_steps, is_agent_silent=is_agent_silent)\n",
    "    \n",
    "    num_actions = len(env.action_space)\n",
    "    \n",
    "    agent = QCBRL(num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render)\n",
    "    rewards, success_rate, memory_usage, gpu_memory_usage, total_step_list = agent.run()\n",
    "\n",
    "    agent.display_success_rate(success_rate)\n",
    "    agent.plot_rewards(rewards)\n",
    "    agent.plot_total_steps(total_step_list)\n",
    "    agent.plot_resources(memory_usage, gpu_memory_usage)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
