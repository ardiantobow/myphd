{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- starting point of Episode 0 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10924d0>, <__main__.Case object at 0x7dcde1093880>, <__main__.Case object at 0x7dcde10938e0>, <__main__.Case object at 0x7dcde10d1570>, <__main__.Case object at 0x7dcde10d25c0>, <__main__.Case object at 0x7dcde10d3460>, <__main__.Case object at 0x7dcde10d3d90>, <__main__.Case object at 0x7dcde10d3ee0>, <__main__.Case object at 0x7dcde10d9390>, <__main__.Case object at 0x7dcde10d9c60>, <__main__.Case object at 0x7dcde10da680>, <__main__.Case object at 0x7dcde10db0a0>, <__main__.Case object at 0x7dcde10dbc10>, <__main__.Case object at 0x7dcde10dbc70>, <__main__.Case object at 0x7dcde10e4f40>, <__main__.Case object at 0x7dcde10e5960>, <__main__.Case object at 0x7dcde10e64d0>, <__main__.Case object at 0x7dcde10e6e90>, <__main__.Case object at 0x7dcde10e77f0>, <__main__.Case object at 0x7dcde10e7940>, <__main__.Case object at 0x7dcde10ecdf0>, <__main__.Case object at 0x7dcde10ed6c0>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde10ef6a0>, <__main__.Case object at 0x7dcde10eff70>, <__main__.Case object at 0x7dcde10f8ac0>, <__main__.Case object at 0x7dcde10f9420>, <__main__.Case object at 0x7dcde10f9f90>, <__main__.Case object at 0x7dcde10fa950>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde1093ca0>, <__main__.Case object at 0x7dcde10d0bb0>, <__main__.Case object at 0x7dcde10d2440>, <__main__.Case object at 0x7dcde10d2980>, <__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10d87f0>, <__main__.Case object at 0x7dcde10d8d30>, <__main__.Case object at 0x7dcde10d9750>, <__main__.Case object at 0x7dcde10da170>, <__main__.Case object at 0x7dcde10dab90>, <__main__.Case object at 0x7dcde10db5b0>, <__main__.Case object at 0x7dcde10dbfd0>, <__main__.Case object at 0x7dcde10e4a30>, <__main__.Case object at 0x7dcde10e5450>, <__main__.Case object at 0x7dcde10e5e70>, <__main__.Case object at 0x7dcde10e6da0>, <__main__.Case object at 0x7dcde10e72e0>, <__main__.Case object at 0x7dcde10ec250>, <__main__.Case object at 0x7dcde10ec790>, <__main__.Case object at 0x7dcde10ed1b0>, <__main__.Case object at 0x7dcde10ee0e0>, <__main__.Case object at 0x7dcde10ee620>, <__main__.Case object at 0x7dcde10ef040>, <__main__.Case object at 0x7dcde10efa60>, <__main__.Case object at 0x7dcde10f89d0>, <__main__.Case object at 0x7dcde10f8f10>, <__main__.Case object at 0x7dcde10f9930>, <__main__.Case object at 0x7dcde10fa860>, <__main__.Case object at 0x7dcde10fb2b0>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 0, Total Steps: 30, Total Rewards: [-39, -14], Status Episode: False\n",
      "------------------------------------------End of episode 0 loop--------------------\n",
      "----- starting point of Episode 1 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde1093880>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde1109de0>, <__main__.Case object at 0x7dcde110a230>, <__main__.Case object at 0x7dcde110a320>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110a680>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110a7a0>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110aad0>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110abc0>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110ae00>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde1108400>, <__main__.Case object at 0x7dcde11092d0>, <__main__.Case object at 0x7dcde110a1a0>, <__main__.Case object at 0x7dcde110a2f0>, <__main__.Case object at 0x7dcde110a3e0>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110a560>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110a800>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110a9b0>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110ad10>, <__main__.Case object at 0x7dcde110ada0>, <__main__.Case object at 0x7dcde110ae60>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 1, Total Steps: 19, Total Rewards: [-22, -28], Status Episode: False\n",
      "------------------------------------------End of episode 1 loop--------------------\n",
      "----- starting point of Episode 2 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde1093880>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110a230>, <__main__.Case object at 0x7dcde110a680>, <__main__.Case object at 0x7dcde110a6e0>, <__main__.Case object at 0x7dcde110a110>, <__main__.Case object at 0x7dcde110aaa0>, <__main__.Case object at 0x7dcde1108400>, <__main__.Case object at 0x7dcde110a1a0>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110a290>, <__main__.Case object at 0x7dcde110a800>, <__main__.Case object at 0x7dcde110a9b0>, <__main__.Case object at 0x7dcde110a3e0>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110a140>, <__main__.Case object at 0x7dcde110b820>, <__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110b700>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110b250>, <__main__.Case object at 0x7dcde110b1c0>, <__main__.Case object at 0x7dcde110b340>, <__main__.Case object at 0x7dcde110b190>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110ae30>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110aef0>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110bbb0>, <__main__.Case object at 0x7dcde110bdc0>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110bc40>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110bfa0>, <__main__.Case object at 0x7dcde11141c0>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110a320>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110aad0>, <__main__.Case object at 0x7dcde110ad40>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde11092d0>, <__main__.Case object at 0x7dcde110a2f0>, <__main__.Case object at 0x7dcde110a500>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110ab00>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110b850>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110b6a0>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b430>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110b0d0>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110b9d0>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110bb20>, <__main__.Case object at 0x7dcde110bbe0>, <__main__.Case object at 0x7dcde110bcd0>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110be20>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde1114040>, <__main__.Case object at 0x7dcde1114160>, <__main__.Case object at 0x7dcde1114220>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 2, Total Steps: 44, Total Rewards: [-16, -53], Status Episode: False\n",
      "------------------------------------------End of episode 2 loop--------------------\n",
      "----- starting point of Episode 3 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde1093880>, <__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110a5f0>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde1109d80>, <__main__.Case object at 0x7dcde110a290>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110b760>, <__main__.Case object at 0x7dcde110a140>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110bb50>, <__main__.Case object at 0x7dcde110bc40>, <__main__.Case object at 0x7dcde110ae60>, <__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110a8f0>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde11098d0>, <__main__.Case object at 0x7dcde110a680>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde1108400>, <__main__.Case object at 0x7dcde110a560>, <__main__.Case object at 0x7dcde110a800>, <__main__.Case object at 0x7dcde110ad10>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110b1f0>, <__main__.Case object at 0x7dcde110b250>, <__main__.Case object at 0x7dcde110ae30>, <__main__.Case object at 0x7dcde110aef0>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde1109de0>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110abc0>, <__main__.Case object at 0x7dcde110a500>]\n",
      "agent1 comm temp case base: []\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 3) is empty. Temporary case base stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) is empty. Temporary case base stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 0, 0.5)\n",
      "Episode succeeded, case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 1, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 0, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "Episode: 3, Total Steps: 24, Total Rewards: [-33, 42], Status Episode: False\n",
      "------------------------------------------End of episode 3 loop--------------------\n",
      "----- starting point of Episode 4 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.5, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.5, 3)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.5, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.5, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 0.5, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 0.5, 8)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 48 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 49 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 50 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 51 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 52 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 53 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 54 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 55 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 56 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 57 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 58 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 59 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 60 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 61 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 62 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 63 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 64 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 65 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 66 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 67 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 68 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 69 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 70 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 71 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 72 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 73 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 74 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 75 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 76 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 77 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 78 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 79 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 80 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 81 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 82 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 83 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 84 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 85 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 86 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 87 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 88 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 89 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 90 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 91 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 92 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 93 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 94 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 95 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 96 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 97 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 98 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 99 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 100 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 101 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 102 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 103 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 104 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 105 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 106 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 107 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 108 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 109 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 110 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 111 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 112 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 113 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 114 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 115 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 116 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 117 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 118 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 119 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 120 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 121 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 122 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 123 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 124 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 125 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 126 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 127 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 128 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 129 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 4 in steps 130 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.5, 23)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110bfa0>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110bbb0>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110baf0>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110b520>, <__main__.Case object at 0x7dcde110b6d0>, <__main__.Case object at 0x7dcde110b850>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110b400>, <__main__.Case object at 0x7dcde1114160>, <__main__.Case object at 0x7dcde11142b0>, <__main__.Case object at 0x7dcde11143d0>, <__main__.Case object at 0x7dcde11144f0>, <__main__.Case object at 0x7dcde1114610>, <__main__.Case object at 0x7dcde1114730>, <__main__.Case object at 0x7dcde1114850>, <__main__.Case object at 0x7dcde1114970>, <__main__.Case object at 0x7dcde1114a90>, <__main__.Case object at 0x7dcde1114bb0>, <__main__.Case object at 0x7dcde1114cd0>, <__main__.Case object at 0x7dcde1114df0>, <__main__.Case object at 0x7dcde1114f10>, <__main__.Case object at 0x7dcde1115030>, <__main__.Case object at 0x7dcde1115150>, <__main__.Case object at 0x7dcde1115270>, <__main__.Case object at 0x7dcde1115390>, <__main__.Case object at 0x7dcde11154b0>, <__main__.Case object at 0x7dcde11155d0>, <__main__.Case object at 0x7dcde11156f0>, <__main__.Case object at 0x7dcde1115840>, <__main__.Case object at 0x7dcde1115930>, <__main__.Case object at 0x7dcde1115a50>, <__main__.Case object at 0x7dcde1115b70>, <__main__.Case object at 0x7dcde1115cc0>, <__main__.Case object at 0x7dcde1115db0>, <__main__.Case object at 0x7dcde1115ed0>, <__main__.Case object at 0x7dcde1115ff0>, <__main__.Case object at 0x7dcde1116140>, <__main__.Case object at 0x7dcde1116230>, <__main__.Case object at 0x7dcde1116350>, <__main__.Case object at 0x7dcde1116470>, <__main__.Case object at 0x7dcde11165c0>, <__main__.Case object at 0x7dcde11166b0>, <__main__.Case object at 0x7dcde11167d0>, <__main__.Case object at 0x7dcde11168f0>, <__main__.Case object at 0x7dcde1116a40>, <__main__.Case object at 0x7dcde1116b30>, <__main__.Case object at 0x7dcde1116c50>, <__main__.Case object at 0x7dcde1116d70>, <__main__.Case object at 0x7dcde1116ec0>, <__main__.Case object at 0x7dcde1116fb0>, <__main__.Case object at 0x7dcde11170d0>, <__main__.Case object at 0x7dcde11171f0>, <__main__.Case object at 0x7dcde1117340>, <__main__.Case object at 0x7dcde1117430>, <__main__.Case object at 0x7dcde1117550>, <__main__.Case object at 0x7dcde1117670>, <__main__.Case object at 0x7dcde11177c0>, <__main__.Case object at 0x7dcde11178b0>, <__main__.Case object at 0x7dcde11179d0>, <__main__.Case object at 0x7dcde1117af0>, <__main__.Case object at 0x7dcde1117c40>, <__main__.Case object at 0x7dcde1117d30>, <__main__.Case object at 0x7dcde1117e50>, <__main__.Case object at 0x7dcde1117f70>, <__main__.Case object at 0x7dcde111c070>, <__main__.Case object at 0x7dcde111c1f0>, <__main__.Case object at 0x7dcde111c310>, <__main__.Case object at 0x7dcde111c430>, <__main__.Case object at 0x7dcde111c550>, <__main__.Case object at 0x7dcde111c670>, <__main__.Case object at 0x7dcde111c790>, <__main__.Case object at 0x7dcde111c8b0>, <__main__.Case object at 0x7dcde111c9d0>, <__main__.Case object at 0x7dcde111caf0>, <__main__.Case object at 0x7dcde111cc10>, <__main__.Case object at 0x7dcde111cd30>, <__main__.Case object at 0x7dcde111ce50>, <__main__.Case object at 0x7dcde111cf70>, <__main__.Case object at 0x7dcde111d090>, <__main__.Case object at 0x7dcde111d1b0>, <__main__.Case object at 0x7dcde111d2d0>, <__main__.Case object at 0x7dcde111d3f0>, <__main__.Case object at 0x7dcde111d510>, <__main__.Case object at 0x7dcde111d630>, <__main__.Case object at 0x7dcde111d750>, <__main__.Case object at 0x7dcde111d870>, <__main__.Case object at 0x7dcde111d990>, <__main__.Case object at 0x7dcde111dab0>, <__main__.Case object at 0x7dcde111dc00>, <__main__.Case object at 0x7dcde111dcf0>, <__main__.Case object at 0x7dcde111de10>, <__main__.Case object at 0x7dcde111df30>, <__main__.Case object at 0x7dcde111e080>, <__main__.Case object at 0x7dcde111e170>, <__main__.Case object at 0x7dcde111e290>, <__main__.Case object at 0x7dcde111e3b0>, <__main__.Case object at 0x7dcde111e500>, <__main__.Case object at 0x7dcde111e5f0>, <__main__.Case object at 0x7dcde111e710>, <__main__.Case object at 0x7dcde111e830>, <__main__.Case object at 0x7dcde111e980>, <__main__.Case object at 0x7dcde111ea70>, <__main__.Case object at 0x7dcde111eb90>, <__main__.Case object at 0x7dcde111ecb0>, <__main__.Case object at 0x7dcde111ee00>, <__main__.Case object at 0x7dcde111eef0>, <__main__.Case object at 0x7dcde111f010>, <__main__.Case object at 0x7dcde111f130>, <__main__.Case object at 0x7dcde111f280>, <__main__.Case object at 0x7dcde111f370>, <__main__.Case object at 0x7dcde111f4c0>, <__main__.Case object at 0x7dcde111f610>, <__main__.Case object at 0x7dcde111f760>, <__main__.Case object at 0x7dcde111f850>, <__main__.Case object at 0x7dcde111f970>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde10fbfa0>, <__main__.Case object at 0x7dcde1093880>, <__main__.Case object at 0x7dcde110a290>, <__main__.Case object at 0x7dcde110b1c0>, <__main__.Case object at 0x7dcde110b8e0>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110bf10>, <__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110b070>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110b280>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110ab00>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110a950>, <__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde1114250>, <__main__.Case object at 0x7dcde1114370>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde1114490>, <__main__.Case object at 0x7dcde11146d0>, <__main__.Case object at 0x7dcde11147f0>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde1114910>, <__main__.Case object at 0x7dcde1114b50>, <__main__.Case object at 0x7dcde1114c70>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde1114d90>, <__main__.Case object at 0x7dcde1114fd0>, <__main__.Case object at 0x7dcde11150f0>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde1115210>, <__main__.Case object at 0x7dcde1115450>, <__main__.Case object at 0x7dcde1115570>, <__main__.Case object at 0x7dcde11157b0>, <__main__.Case object at 0x7dcde1115690>, <__main__.Case object at 0x7dcde11158d0>, <__main__.Case object at 0x7dcde11159f0>, <__main__.Case object at 0x7dcde1115c30>, <__main__.Case object at 0x7dcde1115b10>, <__main__.Case object at 0x7dcde1115d50>, <__main__.Case object at 0x7dcde1115e70>, <__main__.Case object at 0x7dcde11160b0>, <__main__.Case object at 0x7dcde1115f90>, <__main__.Case object at 0x7dcde11161d0>, <__main__.Case object at 0x7dcde11162f0>, <__main__.Case object at 0x7dcde1116530>, <__main__.Case object at 0x7dcde1116410>, <__main__.Case object at 0x7dcde1116650>, <__main__.Case object at 0x7dcde1116770>, <__main__.Case object at 0x7dcde11169b0>, <__main__.Case object at 0x7dcde1116890>, <__main__.Case object at 0x7dcde1116ad0>, <__main__.Case object at 0x7dcde1116bf0>, <__main__.Case object at 0x7dcde1116e30>, <__main__.Case object at 0x7dcde1116d10>, <__main__.Case object at 0x7dcde1116f50>, <__main__.Case object at 0x7dcde1117070>, <__main__.Case object at 0x7dcde11172b0>, <__main__.Case object at 0x7dcde1117190>, <__main__.Case object at 0x7dcde11173d0>, <__main__.Case object at 0x7dcde11174f0>, <__main__.Case object at 0x7dcde1117730>, <__main__.Case object at 0x7dcde1117610>, <__main__.Case object at 0x7dcde1117850>, <__main__.Case object at 0x7dcde1117970>, <__main__.Case object at 0x7dcde1117bb0>, <__main__.Case object at 0x7dcde1117a90>, <__main__.Case object at 0x7dcde1117cd0>, <__main__.Case object at 0x7dcde1117df0>, <__main__.Case object at 0x7dcde1117f40>, <__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde111c190>, <__main__.Case object at 0x7dcde111c2b0>, <__main__.Case object at 0x7dcde1116e60>, <__main__.Case object at 0x7dcde111c3d0>, <__main__.Case object at 0x7dcde111c610>, <__main__.Case object at 0x7dcde111c730>, <__main__.Case object at 0x7dcde11172e0>, <__main__.Case object at 0x7dcde111c850>, <__main__.Case object at 0x7dcde111ca90>, <__main__.Case object at 0x7dcde111cbb0>, <__main__.Case object at 0x7dcde1117760>, <__main__.Case object at 0x7dcde111ccd0>, <__main__.Case object at 0x7dcde111cf10>, <__main__.Case object at 0x7dcde111d030>, <__main__.Case object at 0x7dcde1117be0>, <__main__.Case object at 0x7dcde111d150>, <__main__.Case object at 0x7dcde111d390>, <__main__.Case object at 0x7dcde111d4b0>, <__main__.Case object at 0x7dcde11169e0>, <__main__.Case object at 0x7dcde111d5d0>, <__main__.Case object at 0x7dcde111d810>, <__main__.Case object at 0x7dcde111d930>, <__main__.Case object at 0x7dcde111db70>, <__main__.Case object at 0x7dcde111da50>, <__main__.Case object at 0x7dcde111dc90>, <__main__.Case object at 0x7dcde111ddb0>, <__main__.Case object at 0x7dcde111dff0>, <__main__.Case object at 0x7dcde111ded0>, <__main__.Case object at 0x7dcde111e110>, <__main__.Case object at 0x7dcde111e230>, <__main__.Case object at 0x7dcde111e470>, <__main__.Case object at 0x7dcde111e350>, <__main__.Case object at 0x7dcde111e590>, <__main__.Case object at 0x7dcde111e6b0>, <__main__.Case object at 0x7dcde111e8f0>, <__main__.Case object at 0x7dcde111e9b0>, <__main__.Case object at 0x7dcde111ea10>, <__main__.Case object at 0x7dcde111eb30>, <__main__.Case object at 0x7dcde111ed70>, <__main__.Case object at 0x7dcde111ec50>, <__main__.Case object at 0x7dcde111ee90>, <__main__.Case object at 0x7dcde111efb0>, <__main__.Case object at 0x7dcde111f1f0>, <__main__.Case object at 0x7dcde111f0d0>, <__main__.Case object at 0x7dcde111f310>, <__main__.Case object at 0x7dcde111f460>, <__main__.Case object at 0x7dcde111f6d0>, <__main__.Case object at 0x7dcde111f5b0>, <__main__.Case object at 0x7dcde111f7f0>]\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 3, 0.5)\n",
      "Integrated case process. comm case (4, 3) is empty. Temporary case base stored to the case base: ((4, 3), 2, 0.5)\n",
      "Integrated case process. comm case (3, 3) is empty. Temporary case base stored to the case base: ((3, 3), 4, 0.5)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 2, 0.5)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110a110>, <__main__.Case object at 0x7dcde110bc70>, <__main__.Case object at 0x7dcde110a140>, <__main__.Case object at 0x7dcde110ba90>, <__main__.Case object at 0x7dcde110a320>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110aad0>, <__main__.Case object at 0x7dcde110b130>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110be50>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110bb20>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde110b9a0>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b7f0>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde11140d0>, <__main__.Case object at 0x7dcde11141f0>, <__main__.Case object at 0x7dcde1114310>, <__main__.Case object at 0x7dcde1114430>, <__main__.Case object at 0x7dcde1114550>, <__main__.Case object at 0x7dcde11144c0>, <__main__.Case object at 0x7dcde1114790>, <__main__.Case object at 0x7dcde11148b0>, <__main__.Case object at 0x7dcde11149d0>, <__main__.Case object at 0x7dcde1114940>, <__main__.Case object at 0x7dcde1114c10>, <__main__.Case object at 0x7dcde1114d30>, <__main__.Case object at 0x7dcde1114e50>, <__main__.Case object at 0x7dcde1114dc0>, <__main__.Case object at 0x7dcde1115090>, <__main__.Case object at 0x7dcde11151b0>, <__main__.Case object at 0x7dcde11152d0>, <__main__.Case object at 0x7dcde1115240>, <__main__.Case object at 0x7dcde1115510>, <__main__.Case object at 0x7dcde1115630>, <__main__.Case object at 0x7dcde1115750>, <__main__.Case object at 0x7dcde11156c0>, <__main__.Case object at 0x7dcde1115990>, <__main__.Case object at 0x7dcde1115ab0>, <__main__.Case object at 0x7dcde1115bd0>, <__main__.Case object at 0x7dcde1115b40>, <__main__.Case object at 0x7dcde1115e10>, <__main__.Case object at 0x7dcde1115f30>, <__main__.Case object at 0x7dcde1116050>, <__main__.Case object at 0x7dcde1115fc0>, <__main__.Case object at 0x7dcde1116290>, <__main__.Case object at 0x7dcde11163b0>, <__main__.Case object at 0x7dcde11164d0>, <__main__.Case object at 0x7dcde1116440>, <__main__.Case object at 0x7dcde1116710>, <__main__.Case object at 0x7dcde1116830>, <__main__.Case object at 0x7dcde1116950>, <__main__.Case object at 0x7dcde11168c0>, <__main__.Case object at 0x7dcde1116b90>, <__main__.Case object at 0x7dcde1116cb0>, <__main__.Case object at 0x7dcde1116dd0>, <__main__.Case object at 0x7dcde1116d40>, <__main__.Case object at 0x7dcde1117010>, <__main__.Case object at 0x7dcde1117130>, <__main__.Case object at 0x7dcde1117250>, <__main__.Case object at 0x7dcde11171c0>, <__main__.Case object at 0x7dcde1117490>, <__main__.Case object at 0x7dcde11175b0>, <__main__.Case object at 0x7dcde11176d0>, <__main__.Case object at 0x7dcde1117640>, <__main__.Case object at 0x7dcde1117910>, <__main__.Case object at 0x7dcde1117a30>, <__main__.Case object at 0x7dcde1117b50>, <__main__.Case object at 0x7dcde1117ac0>, <__main__.Case object at 0x7dcde1117d90>, <__main__.Case object at 0x7dcde1117eb0>, <__main__.Case object at 0x7dcde1117fd0>, <__main__.Case object at 0x7dcde111c130>, <__main__.Case object at 0x7dcde111c250>, <__main__.Case object at 0x7dcde111c370>, <__main__.Case object at 0x7dcde111c490>, <__main__.Case object at 0x7dcde111c400>, <__main__.Case object at 0x7dcde111c6d0>, <__main__.Case object at 0x7dcde111c7f0>, <__main__.Case object at 0x7dcde111c910>, <__main__.Case object at 0x7dcde111c880>, <__main__.Case object at 0x7dcde111cb50>, <__main__.Case object at 0x7dcde111cc70>, <__main__.Case object at 0x7dcde111cd90>, <__main__.Case object at 0x7dcde111cd00>, <__main__.Case object at 0x7dcde111cfd0>, <__main__.Case object at 0x7dcde111d0f0>, <__main__.Case object at 0x7dcde111d210>, <__main__.Case object at 0x7dcde111d180>, <__main__.Case object at 0x7dcde111d450>, <__main__.Case object at 0x7dcde111d570>, <__main__.Case object at 0x7dcde111d690>, <__main__.Case object at 0x7dcde111d600>, <__main__.Case object at 0x7dcde111d8d0>, <__main__.Case object at 0x7dcde111d9f0>, <__main__.Case object at 0x7dcde111db10>, <__main__.Case object at 0x7dcde111da80>, <__main__.Case object at 0x7dcde111dd50>, <__main__.Case object at 0x7dcde111de70>, <__main__.Case object at 0x7dcde111df90>, <__main__.Case object at 0x7dcde111df00>, <__main__.Case object at 0x7dcde111e1d0>, <__main__.Case object at 0x7dcde111e2f0>, <__main__.Case object at 0x7dcde111e410>, <__main__.Case object at 0x7dcde111e380>, <__main__.Case object at 0x7dcde111e650>, <__main__.Case object at 0x7dcde111e770>, <__main__.Case object at 0x7dcde111e890>, <__main__.Case object at 0x7dcde111e800>, <__main__.Case object at 0x7dcde111ead0>, <__main__.Case object at 0x7dcde111ebf0>, <__main__.Case object at 0x7dcde111ed10>, <__main__.Case object at 0x7dcde111ec80>, <__main__.Case object at 0x7dcde111ef50>, <__main__.Case object at 0x7dcde111f070>, <__main__.Case object at 0x7dcde111f190>, <__main__.Case object at 0x7dcde111f100>, <__main__.Case object at 0x7dcde111f3d0>, <__main__.Case object at 0x7dcde111f520>, <__main__.Case object at 0x7dcde111f670>, <__main__.Case object at 0x7dcde111f5e0>, <__main__.Case object at 0x7dcde111f8b0>, <__main__.Case object at 0x7dcde111f9d0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.6, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "Episode: 4, Total Steps: 131, Total Rewards: [-140, 45], Status Episode: False\n",
      "------------------------------------------End of episode 4 loop--------------------\n",
      "----- starting point of Episode 5 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.6, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.6, 3)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.6, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.6, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 0.6, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 0.6, 8)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.6, 23)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110bbe0>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110b6d0>, <__main__.Case object at 0x7dcde110ada0>, <__main__.Case object at 0x7dcde110a110>, <__main__.Case object at 0x7dcde110ba90>, <__main__.Case object at 0x7dcde110b130>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110ab00>, <__main__.Case object at 0x7dcde110a950>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110bbb0>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110baf0>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde1108eb0>]\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.5, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.5, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.5, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.5, time steps: 2\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110be20>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110b430>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110bc70>, <__main__.Case object at 0x7dcde110a320>, <__main__.Case object at 0x7dcde110ae30>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.7, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.7, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.7, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.7, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.7, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.7, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.7, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7\n",
      "Episode: 5, Total Steps: 17, Total Rewards: [-26, 45], Status Episode: False\n",
      "------------------------------------------End of episode 5 loop--------------------\n",
      "----- starting point of Episode 6 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.7, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.7, 3)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.7, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 0.7, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 0.7, 8)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 48 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 49 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 50 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 51 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 52 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 53 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 54 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 55 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 56 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 57 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 58 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 59 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 60 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 61 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 62 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 63 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 64 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 65 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 66 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 67 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 68 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 69 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 70 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 71 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7, 23)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110b250>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110b430>, <__main__.Case object at 0x7dcde110a7a0>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110bb20>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110a140>, <__main__.Case object at 0x7dcde111ca90>, <__main__.Case object at 0x7dcde111c7c0>, <__main__.Case object at 0x7dcde111c460>, <__main__.Case object at 0x7dcde111f9d0>, <__main__.Case object at 0x7dcde111d030>, <__main__.Case object at 0x7dcde111d540>, <__main__.Case object at 0x7dcde111d810>, <__main__.Case object at 0x7dcde111da50>, <__main__.Case object at 0x7dcde111dff0>, <__main__.Case object at 0x7dcde111e230>, <__main__.Case object at 0x7dcde111e590>, <__main__.Case object at 0x7dcde111e9b0>, <__main__.Case object at 0x7dcde111ed70>, <__main__.Case object at 0x7dcde111efb0>, <__main__.Case object at 0x7dcde111f310>, <__main__.Case object at 0x7dcde111f5b0>, <__main__.Case object at 0x7dcde111c310>, <__main__.Case object at 0x7dcde111c670>, <__main__.Case object at 0x7dcde111c9d0>, <__main__.Case object at 0x7dcde111cd30>, <__main__.Case object at 0x7dcde111d090>, <__main__.Case object at 0x7dcde111d3f0>, <__main__.Case object at 0x7dcde111d780>, <__main__.Case object at 0x7dcde111dab0>, <__main__.Case object at 0x7dcde111de10>, <__main__.Case object at 0x7dcde111e170>, <__main__.Case object at 0x7dcde111ce20>, <__main__.Case object at 0x7dcde111e830>, <__main__.Case object at 0x7dcde111eb90>, <__main__.Case object at 0x7dcde111eef0>, <__main__.Case object at 0x7dcde111dba0>, <__main__.Case object at 0x7dcde111f610>, <__main__.Case object at 0x7dcde111f970>, <__main__.Case object at 0x7dcde111c280>, <__main__.Case object at 0x7dcde111c6d0>, <__main__.Case object at 0x7dcde111c940>, <__main__.Case object at 0x7dcde111cca0>, <__main__.Case object at 0x7dcde111d000>, <__main__.Case object at 0x7dcde111d450>, <__main__.Case object at 0x7dcde111d6c0>, <__main__.Case object at 0x7dcde111da20>, <__main__.Case object at 0x7dcde111dd80>, <__main__.Case object at 0x7dcde111e1d0>, <__main__.Case object at 0x7dcde111e440>, <__main__.Case object at 0x7dcde111e7a0>, <__main__.Case object at 0x7dcde111eb00>, <__main__.Case object at 0x7dcde111ef50>, <__main__.Case object at 0x7dcde111f1c0>, <__main__.Case object at 0x7dcde111f550>, <__main__.Case object at 0x7dcde111f8e0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110b280>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110bd30>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110b9d0>, <__main__.Case object at 0x7dcde110bfa0>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110bc70>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110ad40>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110abc0>, <__main__.Case object at 0x7dcde111cc40>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde111c730>, <__main__.Case object at 0x7dcde111c100>, <__main__.Case object at 0x7dcde111f700>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde111d420>, <__main__.Case object at 0x7dcde111db70>, <__main__.Case object at 0x7dcde111ddb0>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde111e740>, <__main__.Case object at 0x7dcde111e8f0>, <__main__.Case object at 0x7dcde111eb30>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde111ee90>, <__main__.Case object at 0x7dcde111f6d0>, <__main__.Case object at 0x7dcde111c1f0>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde111c550>, <__main__.Case object at 0x7dcde111cc10>, <__main__.Case object at 0x7dcde111cf70>, <__main__.Case object at 0x7dcde111d630>, <__main__.Case object at 0x7dcde111d870>, <__main__.Case object at 0x7dcde111d990>, <__main__.Case object at 0x7dcde111dcf0>, <__main__.Case object at 0x7dcde111e3b0>, <__main__.Case object at 0x7dcde111e5f0>, <__main__.Case object at 0x7dcde111e710>, <__main__.Case object at 0x7dcde111ea70>, <__main__.Case object at 0x7dcde111f130>, <__main__.Case object at 0x7dcde111ee00>, <__main__.Case object at 0x7dcde111f4c0>, <__main__.Case object at 0x7dcde111f850>, <__main__.Case object at 0x7dcde111c4c0>, <__main__.Case object at 0x7dcde111c160>, <__main__.Case object at 0x7dcde111c820>, <__main__.Case object at 0x7dcde111cb80>, <__main__.Case object at 0x7dcde111d240>, <__main__.Case object at 0x7dcde111cee0>, <__main__.Case object at 0x7dcde111d5a0>, <__main__.Case object at 0x7dcde111d900>, <__main__.Case object at 0x7dcde111dfc0>, <__main__.Case object at 0x7dcde111dc60>, <__main__.Case object at 0x7dcde111e320>, <__main__.Case object at 0x7dcde111e680>, <__main__.Case object at 0x7dcde111ed40>, <__main__.Case object at 0x7dcde111e9e0>, <__main__.Case object at 0x7dcde111f0a0>, <__main__.Case object at 0x7dcde111f400>]\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.5, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.5, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.5, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.5, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.5, time steps: 2\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110a950>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110baf0>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110ab60>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110aef0>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110b130>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110b880>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110b9a0>, <__main__.Case object at 0x7dcde110bcd0>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde111d0c0>, <__main__.Case object at 0x7dcde111ca30>, <__main__.Case object at 0x7dcde111c5b0>, <__main__.Case object at 0x7dcde111c8e0>, <__main__.Case object at 0x7dcde111eda0>, <__main__.Case object at 0x7dcde111d330>, <__main__.Case object at 0x7dcde111d660>, <__main__.Case object at 0x7dcde111d390>, <__main__.Case object at 0x7dcde111dc90>, <__main__.Case object at 0x7dcde111ded0>, <__main__.Case object at 0x7dcde111e470>, <__main__.Case object at 0x7dcde111e2c0>, <__main__.Case object at 0x7dcde111ea10>, <__main__.Case object at 0x7dcde111ec50>, <__main__.Case object at 0x7dcde111f1f0>, <__main__.Case object at 0x7dcde111f040>, <__main__.Case object at 0x7dcde111c070>, <__main__.Case object at 0x7dcde111c430>, <__main__.Case object at 0x7dcde111c790>, <__main__.Case object at 0x7dcde111c580>, <__main__.Case object at 0x7dcde111ce50>, <__main__.Case object at 0x7dcde111d1b0>, <__main__.Case object at 0x7dcde111d510>, <__main__.Case object at 0x7dcde111d300>, <__main__.Case object at 0x7dcde111dc00>, <__main__.Case object at 0x7dcde111df30>, <__main__.Case object at 0x7dcde111e290>, <__main__.Case object at 0x7dcde111c9a0>, <__main__.Case object at 0x7dcde111e980>, <__main__.Case object at 0x7dcde111ecb0>, <__main__.Case object at 0x7dcde111f010>, <__main__.Case object at 0x7dcde111d720>, <__main__.Case object at 0x7dcde111f760>, <__main__.Case object at 0x7dcde111c040>, <__main__.Case object at 0x7dcde111c3a0>, <__main__.Case object at 0x7dcde111c250>, <__main__.Case object at 0x7dcde111ca60>, <__main__.Case object at 0x7dcde111cdc0>, <__main__.Case object at 0x7dcde111d120>, <__main__.Case object at 0x7dcde111cfd0>, <__main__.Case object at 0x7dcde111d7e0>, <__main__.Case object at 0x7dcde111db40>, <__main__.Case object at 0x7dcde111dea0>, <__main__.Case object at 0x7dcde111dd50>, <__main__.Case object at 0x7dcde111e560>, <__main__.Case object at 0x7dcde111e8c0>, <__main__.Case object at 0x7dcde111ec20>, <__main__.Case object at 0x7dcde111ead0>, <__main__.Case object at 0x7dcde111f2e0>, <__main__.Case object at 0x7dcde111f6a0>, <__main__.Case object at 0x7dcde111ff40>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.7999999999999999, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.7999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.7999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.7999999999999999, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.7999999999999999, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.7999999999999999, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.7999999999999999, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7999999999999999\n",
      "Episode: 6, Total Steps: 72, Total Rewards: [-81, 45], Status Episode: False\n",
      "------------------------------------------End of episode 6 loop--------------------\n",
      "----- starting point of Episode 7 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.7999999999999999, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.7999999999999999, 3)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.7999999999999999, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7999999999999999, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 0.7999999999999999, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 0.7999999999999999, 8)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 7 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.7999999999999999, 23)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110bfa0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110ba30>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110bdc0>, <__main__.Case object at 0x7dcde110ada0>, <__main__.Case object at 0x7dcde110bc40>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110a140>, <__main__.Case object at 0x7dcde110a950>, <__main__.Case object at 0x7dcde110ab60>, <__main__.Case object at 0x7dcde110b6d0>, <__main__.Case object at 0x7dcde110b6a0>, <__main__.Case object at 0x7dcde110b400>, <__main__.Case object at 0x7dcde110b0d0>, <__main__.Case object at 0x7dcde110be50>, <__main__.Case object at 0x7dcde111ff70>, <__main__.Case object at 0x7dcde111c730>, <__main__.Case object at 0x7dcde111d930>, <__main__.Case object at 0x7dcde111e3e0>, <__main__.Case object at 0x7dcde111eb30>, <__main__.Case object at 0x7dcde111c1c0>, <__main__.Case object at 0x7dcde111cc10>, <__main__.Case object at 0x7dcde111d990>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110bb50>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110b7f0>, <__main__.Case object at 0x7dcde111e4a0>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde111c610>, <__main__.Case object at 0x7dcde111e0b0>, <__main__.Case object at 0x7dcde111e8f0>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde111f880>]\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.4, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.6, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.4, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 1, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 1, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 3, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 3, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde110b280>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110b9d0>, <__main__.Case object at 0x7dcde110a110>, <__main__.Case object at 0x7dcde110b850>, <__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110b520>, <__main__.Case object at 0x7dcde110a7a0>, <__main__.Case object at 0x7dcde110bb20>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110ba90>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde111d180>, <__main__.Case object at 0x7dcde111cb20>, <__main__.Case object at 0x7dcde111c100>, <__main__.Case object at 0x7dcde111c190>, <__main__.Case object at 0x7dcde111e740>, <__main__.Case object at 0x7dcde111f460>, <__main__.Case object at 0x7dcde111c4f0>, <__main__.Case object at 0x7dcde111f6d0>, <__main__.Case object at 0x7dcde111c340>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.8999999999999999, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.8999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.8999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.8999999999999999, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.8999999999999999, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.8999999999999999, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.8999999999999999, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8999999999999999\n",
      "Episode: 7, Total Steps: 30, Total Rewards: [21, 45], Status Episode: True\n",
      "------------------------------------------End of episode 7 loop--------------------\n",
      "----- starting point of Episode 8 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.8999999999999999, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 21)\n",
      "----- starting point of Episode 8 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.8999999999999999, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 22)\n",
      "----- starting point of Episode 8 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.8999999999999999, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 24)\n",
      "----- starting point of Episode 8 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.8999999999999999, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.6, 3)\n",
      "----- starting point of Episode 8 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 0.8999999999999999, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.6, 5)\n",
      "----- starting point of Episode 8 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 0.8999999999999999, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.6, 6)\n",
      "----- starting point of Episode 8 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8999999999999999, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.6, 6)\n",
      "----- starting point of Episode 8 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8999999999999999, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.6, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110bdc0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110b100>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.7, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.7, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.7, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.7, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.7, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 1, tv: 0.4, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 1, tv: 0.4, time steps: 12\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 3, tv: 0.4, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110ae30>, <__main__.Case object at 0x7dcde110bfa0>, <__main__.Case object at 0x7dcde110bc10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110ac50>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110bb50>, <__main__.Case object at 0x7dcde110b7f0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde1108a00>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.9999999999999999, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.9999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.9999999999999999, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.9999999999999999, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.9999999999999999, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 0.9999999999999999, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.9999999999999999, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "Episode: 8, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 8 loop--------------------\n",
      "----- starting point of Episode 9 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.9999999999999999, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 21)\n",
      "----- starting point of Episode 9 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 0.9999999999999999, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.6, 22)\n",
      "----- starting point of Episode 9 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.9999999999999999, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 24)\n",
      "----- starting point of Episode 9 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.9999999999999999, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.7, 3)\n",
      "----- starting point of Episode 9 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 0.9999999999999999, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.7, 5)\n",
      "----- starting point of Episode 9 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 0.9999999999999999, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7, 6)\n",
      "----- starting point of Episode 9 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.9999999999999999, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7, 6)\n",
      "----- starting point of Episode 9 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.9999999999999999, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110bd30>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110aad0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110ae30>, <__main__.Case object at 0x7dcde110b010>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.7999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.7999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.7999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.7999999999999999, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.7999999999999999, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7999999999999999, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7999999999999999, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110bfa0>, <__main__.Case object at 0x7dcde110b640>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110b880>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110b490>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.4, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.4, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.4, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 9, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 9 loop--------------------\n",
      "----- starting point of Episode 10 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7, 21)\n",
      "----- starting point of Episode 10 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7, 22)\n",
      "----- starting point of Episode 10 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7, 24)\n",
      "----- starting point of Episode 10 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.7999999999999999, 3)\n",
      "----- starting point of Episode 10 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.7999999999999999, 5)\n",
      "----- starting point of Episode 10 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7999999999999999, 6)\n",
      "----- starting point of Episode 10 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7999999999999999, 6)\n",
      "----- starting point of Episode 10 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7999999999999999, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110bd30>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110bb50>, <__main__.Case object at 0x7dcde110ac80>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110ae30>, <__main__.Case object at 0x7dcde110b880>, <__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde110a410>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.8999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.8999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.8999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.8999999999999999, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.8999999999999999, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7999999999999999, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7999999999999999, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110aa10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110afe0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.7)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.7)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.7)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "Episode: 10, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 10 loop--------------------\n",
      "----- starting point of Episode 11 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7999999999999999, 21)\n",
      "----- starting point of Episode 11 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7999999999999999, 22)\n",
      "----- starting point of Episode 11 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7999999999999999, 24)\n",
      "----- starting point of Episode 11 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.8999999999999999, 3)\n",
      "----- starting point of Episode 11 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.8999999999999999, 5)\n",
      "----- starting point of Episode 11 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.8999999999999999, 6)\n",
      "----- starting point of Episode 11 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.8999999999999999, 6)\n",
      "----- starting point of Episode 11 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.8999999999999999, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110abf0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110aad0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110b5e0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.9999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.9999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.9999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.9999999999999999, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.9999999999999999, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.8999999999999999, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.8999999999999999, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110b070>, <__main__.Case object at 0x7dcde110a3b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110b7f0>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110ac20>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 11, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 11 loop--------------------\n",
      "----- starting point of Episode 12 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.8999999999999999, 21)\n",
      "----- starting point of Episode 12 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.8999999999999999, 22)\n",
      "----- starting point of Episode 12 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.8999999999999999, 24)\n",
      "----- starting point of Episode 12 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 0.9999999999999999, 3)\n",
      "----- starting point of Episode 12 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.9999999999999999, 5)\n",
      "----- starting point of Episode 12 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.9999999999999999, 6)\n",
      "----- starting point of Episode 12 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.9999999999999999, 6)\n",
      "----- starting point of Episode 12 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.9999999999999999, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110bb20>, <__main__.Case object at 0x7dcde110bb80>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110b0a0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.9999999999999999, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.9999999999999999, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.5, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.5, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110b1f0>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110b5b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110a8f0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.5, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.5, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.5, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "Episode: 12, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 12 loop--------------------\n",
      "----- starting point of Episode 13 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.9999999999999999, 21)\n",
      "----- starting point of Episode 13 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.9999999999999999, 22)\n",
      "----- starting point of Episode 13 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.9999999999999999, 24)\n",
      "----- starting point of Episode 13 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 13 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 13 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 13 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 13 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110bdf0>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110acb0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110bb50>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110bac0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.4, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.4, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110bb20>, <__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110b490>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110aad0>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110b220>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.4, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.4, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.4, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 13, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 13 loop--------------------\n",
      "----- starting point of Episode 14 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 14 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 14 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 14 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 14 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 14 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 14 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 14 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde110b8b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110ae30>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110b7f0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110bdf0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde1109e40>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110a8c0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 14, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 14 loop--------------------\n",
      "----- starting point of Episode 15 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 15 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 15 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 15 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 15 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 15 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 15 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 15 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110bd30>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110b640>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110a440>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.9, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.9, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.9\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110b070>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110bdf0>, <__main__.Case object at 0x7dcde110b010>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110bdc0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.9, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.9, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.9, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.9\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.9\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9\n",
      "Episode: 15, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 15 loop--------------------\n",
      "----- starting point of Episode 16 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 16 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 16 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 16 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 16 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 16 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 16 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 16 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110bdc0>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110b550>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110a470>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.8, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.8, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.8\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110b790>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110b0a0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.8, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.8, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.8, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8\n",
      "Episode: 16, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 16 loop--------------------\n",
      "----- starting point of Episode 17 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 17 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 17 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 17 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 17 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 17 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 17 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 17 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110bfd0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110a650>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110bd00>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110b2b0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.7000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.7000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.7000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7000000000000001\n",
      "Episode: 17, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 17 loop--------------------\n",
      "----- starting point of Episode 18 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 18 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 18 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 18 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 18 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 18 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 18 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 18 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110b730>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110af80>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.6000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110b670>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110aec0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6000000000000001\n",
      "Episode: 18, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 18 loop--------------------\n",
      "----- starting point of Episode 19 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 19 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 19 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 19 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 19 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 19 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 19 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 19 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110b070>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110ace0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10fb6d0>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110b580>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.5000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.5000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110a7a0>, <__main__.Case object at 0x7dcde110ba60>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110beb0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.5000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.5000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.5000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5000000000000001\n",
      "Episode: 19, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 19 loop--------------------\n",
      "----- starting point of Episode 20 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 20 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 20 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 20 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 20 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 20 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 20 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 20 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110b0a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110aa70>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.40000000000000013, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.40000000000000013, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110b160>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110bfd0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.40000000000000013, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.40000000000000013, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.40000000000000013, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 20, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 20 loop--------------------\n",
      "----- starting point of Episode 21 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 21 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 21 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 21 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 21 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 21 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 21 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 21 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110b2b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110b010>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110af80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110abf0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 21, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 21 loop--------------------\n",
      "----- starting point of Episode 22 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 22 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 22 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 22 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 22 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 22 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 22 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 22 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110b220>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110ae00>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.9, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.9, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.9\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110b040>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110b5e0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.9, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.9, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.9, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.9\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.9\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9\n",
      "Episode: 22, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 22 loop--------------------\n",
      "----- starting point of Episode 23 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 23 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 23 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 23 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 23 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 23 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 23 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 23 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110b460>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110beb0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.8, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.8, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.8\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b880>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110b2b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110b940>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.8, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.8, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.8, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8\n",
      "Episode: 23, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 23 loop--------------------\n",
      "----- starting point of Episode 24 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 24 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 24 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 24 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 24 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 24 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 24 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 24 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110ab30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10fb6d0>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110aa40>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110b9a0>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110b880>, <__main__.Case object at 0x7dcde110afe0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110b730>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.7000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.7000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.7000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7000000000000001\n",
      "Episode: 24, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 24 loop--------------------\n",
      "----- starting point of Episode 25 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 25 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 25 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 25 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 25 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 25 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 25 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 25 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110aa70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110b070>, <__main__.Case object at 0x7dcde110b0a0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.6000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110be80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110af80>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6000000000000001\n",
      "Episode: 25, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 25 loop--------------------\n",
      "----- starting point of Episode 26 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 26 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 26 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 26 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 26 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 26 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 26 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 26 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10fb6d0>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110ac50>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110bd90>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110b9a0>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110bf70>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.5000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.5000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110bd00>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110b5b0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.5000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.5000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.5000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5000000000000001\n",
      "Episode: 26, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 26 loop--------------------\n",
      "----- starting point of Episode 27 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 27 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 27 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 27 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 27 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 27 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 27 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 27 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110af50>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10fb6d0>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110ac50>, <__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde110b970>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.40000000000000013, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.40000000000000013, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110a650>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde110bd60>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.40000000000000013, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.40000000000000013, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.40000000000000013, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 27, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 27 loop--------------------\n",
      "----- starting point of Episode 28 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 28 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 28 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 28 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 28 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 28 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 28 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 28 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110b9a0>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b580>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110ac50>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110ae00>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110abf0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110b880>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 28, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 28 loop--------------------\n",
      "----- starting point of Episode 29 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 29 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 29 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 29 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 29 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 29 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 29 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 29 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110b880>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110a8f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110a770>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.9, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.9, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.9\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110b100>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110b070>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110bc10>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.9, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.9, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.9, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.9\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.9\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9\n",
      "Episode: 29, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 29 loop--------------------\n",
      "----- starting point of Episode 30 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 30 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 30 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 30 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 30 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 30 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 30 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 30 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde110a470>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110b9a0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.8, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.8, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.8\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110b070>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110aec0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde110b580>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.8, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.8, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.8, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8\n",
      "Episode: 30, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 30 loop--------------------\n",
      "----- starting point of Episode 31 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 31 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 31 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 31 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 31 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 31 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 31 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 31 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110af50>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110b070>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110afe0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110a860>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110bd00>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.7000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.7000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.7000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7000000000000001\n",
      "Episode: 31, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 31 loop--------------------\n",
      "----- starting point of Episode 32 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 32 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 32 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 32 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 32 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 32 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 32 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 32 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110a7a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde110add0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.6000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110a2c0>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110aa10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110a3b0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6000000000000001\n",
      "Episode: 32, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 32 loop--------------------\n",
      "----- starting point of Episode 33 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 33 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 33 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 33 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 33 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 33 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 33 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 33 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110b9a0>, <__main__.Case object at 0x7dcde110bd60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110a170>, <__main__.Case object at 0x7dcde110a860>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.5000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.5000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110acb0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110b070>, <__main__.Case object at 0x7dcde110aa40>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.5000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.5000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.5000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5000000000000001\n",
      "Episode: 33, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 33 loop--------------------\n",
      "----- starting point of Episode 34 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 34 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 34 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 34 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 34 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 34 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 34 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 34 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110ac50>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde1108a00>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110bee0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.40000000000000013, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.40000000000000013, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110ac80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110b220>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.40000000000000013, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.40000000000000013, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.40000000000000013, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 34, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 34 loop--------------------\n",
      "----- starting point of Episode 35 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 35 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 35 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 35 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 35 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 35 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 35 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 35 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110a7d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b880>, <__main__.Case object at 0x7dcde110b9a0>, <__main__.Case object at 0x7dcde110a170>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110ac50>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110a6b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde10fb6d0>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110b940>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 35, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 35 loop--------------------\n",
      "----- starting point of Episode 36 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 36 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 36 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 36 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 36 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 36 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 36 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 36 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110bdc0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110b9a0>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110a0b0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.9, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.9, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.9\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110a0e0>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110ac50>, <__main__.Case object at 0x7dcde110a1d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110b730>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.9, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.9, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.9, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.9\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.9\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9\n",
      "Episode: 36, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 36 loop--------------------\n",
      "----- starting point of Episode 37 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 37 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 37 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 37 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 37 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 37 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 37 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 37 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110bfa0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110a7d0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.8, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.8, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.8\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110ac80>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde1108eb0>, <__main__.Case object at 0x7dcde110a0e0>, <__main__.Case object at 0x7dcde110aa40>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110aad0>, <__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110bf70>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.8, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.8, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.8, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8\n",
      "Episode: 37, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 37 loop--------------------\n",
      "----- starting point of Episode 38 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 38 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 38 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 38 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((3, 0), 2, 1, 3)\n",
      "----- starting point of Episode 38 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 5)\n",
      "----- starting point of Episode 38 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 38 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "----- starting point of Episode 38 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 6)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110ac50>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110b220>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110b460>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7000000000000001, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110aad0>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110af50>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde110bd60>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.7000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.7000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.7000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7000000000000001\n",
      "Episode: 38, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 38 loop--------------------\n",
      "----- starting point of Episode 39 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 21)\n",
      "----- starting point of Episode 39 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 22)\n",
      "----- starting point of Episode 39 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 39 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 39 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "----- starting point of Episode 39 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 24)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110bdc0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110a410>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7000000000000001, time steps: 2\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b520>, <__main__.Case object at 0x7dcde110b5b0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110bca0>, <__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde1109cc0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde110a3b0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.9, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.9\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6000000000000001\n",
      "Episode: 39, Total Steps: 6, Total Rewards: [-11, 45], Status Episode: False\n",
      "------------------------------------------End of episode 39 loop--------------------\n",
      "----- starting point of Episode 40 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 21)\n",
      "----- starting point of Episode 40 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.6, 22)\n",
      "----- starting point of Episode 40 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 24)\n",
      "----- starting point of Episode 40 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 24)\n",
      "----- starting point of Episode 40 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 24)\n",
      "----- starting point of Episode 40 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 24)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110b850>, <__main__.Case object at 0x7dcde110acb0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110a0e0>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110ac80>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 24\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 21\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7000000000000001, time steps: 2\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110b9a0>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110b520>, <__main__.Case object at 0x7dcde110b8b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110bd00>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.8, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.5000000000000001, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.5000000000000001, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.5000000000000001, time steps: 21\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.8\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5000000000000001\n",
      "Episode: 40, Total Steps: 6, Total Rewards: [-11, 45], Status Episode: False\n",
      "------------------------------------------End of episode 40 loop--------------------\n",
      "----- starting point of Episode 41 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 41 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde110bd00>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110bf10>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110bbe0>, <__main__.Case object at 0x7dcde110b280>, <__main__.Case object at 0x7dcde110ada0>, <__main__.Case object at 0x7dcde110be50>, <__main__.Case object at 0x7dcde110b430>, <__main__.Case object at 0x7dcde110bb50>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde111c400>, <__main__.Case object at 0x7dcde111d870>, <__main__.Case object at 0x7dcde111c610>, <__main__.Case object at 0x7dcde111cf70>, <__main__.Case object at 0x7dcde111ddb0>, <__main__.Case object at 0x7dcde111c550>, <__main__.Case object at 0x7dcde111d1e0>, <__main__.Case object at 0x7dcde111ee90>, <__main__.Case object at 0x7dcde111f100>, <__main__.Case object at 0x7dcde111ef80>, <__main__.Case object at 0x7dcde111e380>, <__main__.Case object at 0x7dcde111d900>, <__main__.Case object at 0x7dcde111d0f0>, <__main__.Case object at 0x7dcde111c700>, <__main__.Case object at 0x7dcde111f580>, <__main__.Case object at 0x7dcde111ea70>, <__main__.Case object at 0x7dcde111f9a0>, <__main__.Case object at 0x7dcde111cfa0>, <__main__.Case object at 0x7dcde111d030>, <__main__.Case object at 0x7dcde111da50>, <__main__.Case object at 0x7dcde111e6b0>, <__main__.Case object at 0x7dcde111efb0>, <__main__.Case object at 0x7dcde111c310>, <__main__.Case object at 0x7dcde111cd30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110bbb0>, <__main__.Case object at 0x7dcde110aef0>, <__main__.Case object at 0x7dcde110bcd0>, <__main__.Case object at 0x7dcde110ab00>, <__main__.Case object at 0x7dcde110bc40>, <__main__.Case object at 0x7dcde110bb20>, <__main__.Case object at 0x7dcde110a7a0>, <__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde111dcc0>, <__main__.Case object at 0x7dcde111e920>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde111e8f0>, <__main__.Case object at 0x7dcde111cf40>, <__main__.Case object at 0x7dcde111cc40>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde111eaa0>, <__main__.Case object at 0x7dcde111e9e0>, <__main__.Case object at 0x7dcde111e320>, <__main__.Case object at 0x7dcde110b9d0>, <__main__.Case object at 0x7dcde111dfc0>, <__main__.Case object at 0x7dcde111c880>, <__main__.Case object at 0x7dcde111f850>, <__main__.Case object at 0x7dcde110ba30>, <__main__.Case object at 0x7dcde111edd0>, <__main__.Case object at 0x7dcde111dcf0>, <__main__.Case object at 0x7dcde111f9d0>, <__main__.Case object at 0x7dcde111e230>, <__main__.Case object at 0x7dcde111d810>, <__main__.Case object at 0x7dcde111ed70>, <__main__.Case object at 0x7dcde111f5b0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7000000000000001, time steps: 2\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110b520>, <__main__.Case object at 0x7dcde110bfa0>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110b760>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110baf0>, <__main__.Case object at 0x7dcde110ab60>, <__main__.Case object at 0x7dcde110be20>, <__main__.Case object at 0x7dcde1109de0>, <__main__.Case object at 0x7dcde110b1f0>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde111c340>, <__main__.Case object at 0x7dcde111ccd0>, <__main__.Case object at 0x7dcde111e0b0>, <__main__.Case object at 0x7dcde111f400>, <__main__.Case object at 0x7dcde111c1f0>, <__main__.Case object at 0x7dcde111ff40>, <__main__.Case object at 0x7dcde111db70>, <__main__.Case object at 0x7dcde111caf0>, <__main__.Case object at 0x7dcde111f460>, <__main__.Case object at 0x7dcde111e680>, <__main__.Case object at 0x7dcde111de70>, <__main__.Case object at 0x7dcde111d600>, <__main__.Case object at 0x7dcde111d5a0>, <__main__.Case object at 0x7dcde111c4c0>, <__main__.Case object at 0x7dcde111f370>, <__main__.Case object at 0x7dcde111e6e0>, <__main__.Case object at 0x7dcde111ea40>, <__main__.Case object at 0x7dcde111c460>, <__main__.Case object at 0x7dcde111d540>, <__main__.Case object at 0x7dcde111dff0>, <__main__.Case object at 0x7dcde111d9c0>, <__main__.Case object at 0x7dcde111f310>, <__main__.Case object at 0x7dcde111c670>, <__main__.Case object at 0x7dcde111d090>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.9, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.40000000000000013, time steps: 24\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.40000000000000013, time steps: 22\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.40000000000000013, time steps: 21\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.9\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 41, Total Steps: 44, Total Rewards: [-53, 45], Status Episode: False\n",
      "------------------------------------------End of episode 41 loop--------------------\n",
      "----- starting point of Episode 42 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 42 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 42 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 42 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 42 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 42 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110b040>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110a320>, <__main__.Case object at 0x7dcde110ab00>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110bc10>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7000000000000001, time steps: 2\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7000000000000001\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110aef0>, <__main__.Case object at 0x7dcde110bc40>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.8, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.8\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 42, Total Steps: 6, Total Rewards: [-13, 45], Status Episode: False\n",
      "------------------------------------------End of episode 42 loop--------------------\n",
      "----- starting point of Episode 43 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 43 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.8, 23)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10fb6d0>, <__main__.Case object at 0x7dcde110bf70>, <__main__.Case object at 0x7dcde1109cc0>, <__main__.Case object at 0x7dcde110a320>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110b2e0>, <__main__.Case object at 0x7dcde110bb50>, <__main__.Case object at 0x7dcde110b280>, <__main__.Case object at 0x7dcde110bf10>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110b9d0>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110aec0>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110ba60>, <__main__.Case object at 0x7dcde110be20>, <__main__.Case object at 0x7dcde110a9e0>, <__main__.Case object at 0x7dcde110a860>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110b940>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde110bc70>, <__main__.Case object at 0x7dcde110b6a0>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110b850>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110a7a0>, <__main__.Case object at 0x7dcde110b520>, <__main__.Case object at 0x7dcde110b580>, <__main__.Case object at 0x7dcde110b760>, <__main__.Case object at 0x7dcde110ab60>, <__main__.Case object at 0x7dcde10eeb30>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.9, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.9, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.9, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.9, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.9, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.6000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6000000000000001, time steps: 2\n",
      "Episode succeeded, case (3, 4) is empty. Temporary case base stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (2, 4) is empty. Temporary case base stored to the case base: ((2, 4), 4, 0.5)\n",
      "Episode succeeded, case (1, 4) is empty. Temporary case base stored to the case base: ((1, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 4) is empty. Temporary case base stored to the case base: ((0, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 2, 0.5)\n",
      "Episode succeeded, case (0, 3) is empty. Temporary case base stored to the case base: ((0, 3), 2, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 1, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 3, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 3, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 3, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 2, 0.5)\n",
      "Episode succeeded, case (0, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 3), 2, 0.5)\n",
      "Episode succeeded, case (0, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 3), 0, 0.5)\n",
      "Episode succeeded, case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.9\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.9\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.9\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.9\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.9\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 4), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 4), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 4), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110bc40>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110bac0>, <__main__.Case object at 0x7dcde110aef0>, <__main__.Case object at 0x7dcde110b2b0>, <__main__.Case object at 0x7dcde110bdc0>, <__main__.Case object at 0x7dcde110bbe0>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110b790>, <__main__.Case object at 0x7dcde110ac50>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110b100>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110baf0>, <__main__.Case object at 0x7dcde1109de0>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde110af20>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 0.9, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.9\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 43, Total Steps: 21, Total Rewards: [30, 45], Status Episode: True\n",
      "------------------------------------------End of episode 43 loop--------------------\n",
      "----- starting point of Episode 44 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 0)\n",
      "----- starting point of Episode 44 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.5, 1)\n",
      "----- starting point of Episode 44 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 1), 3, 0.5, 2)\n",
      "----- starting point of Episode 44 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((0, 1), 2, 0.5, 6)\n",
      "----- starting point of Episode 44 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((0, 2), 2, 0.5, 7)\n",
      "----- starting point of Episode 44 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.5, 15)\n",
      "----- starting point of Episode 44 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.9, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.5, 15)\n",
      "----- starting point of Episode 44 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.9, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.5, 15)\n",
      "----- starting point of Episode 44 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.9, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.5, 15)\n",
      "----- starting point of Episode 44 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 0.9, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.5, 15)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110a440>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110b760>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110ba30>, <__main__.Case object at 0x7dcde1108a00>, <__main__.Case object at 0x7dcde110ada0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110a0e0>, <__main__.Case object at 0x7dcde110bc70>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110b250>, <__main__.Case object at 0x7dcde110be50>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110b7f0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.8, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.8, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.8, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.8, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.8, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.5000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.5000000000000001, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.6, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (2, 4), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (1, 4), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 4), solution: 4, tv: 0.6, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 3), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (2, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 4), 4, 0.5)\n",
      "Episode succeeded, case (1, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 3), 2, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.8\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.8\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.8\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.8\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.8\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 4), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 4), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 4), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110a110>, <__main__.Case object at 0x7dcde110a770>, <__main__.Case object at 0x7dcde110bc10>, <__main__.Case object at 0x7dcde110ac20>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110af20>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110b6a0>, <__main__.Case object at 0x7dcde110b4f0>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110a320>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110b400>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110b2b0>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1.0, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 3) is empty. Temporary case base stored to the case base: ((0, 3), 2, 0.5)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 2, 0.5)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 0.5)\n",
      "Integrated case process. comm case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 3, 0.5)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1.0\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "Episode: 44, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 44 loop--------------------\n",
      "----- starting point of Episode 45 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 0)\n",
      "----- starting point of Episode 45 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.6, 1)\n",
      "----- starting point of Episode 45 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 1), 3, 0.6, 2)\n",
      "----- starting point of Episode 45 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((0, 1), 2, 0.6, 6)\n",
      "----- starting point of Episode 45 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((0, 2), 2, 0.6, 7)\n",
      "----- starting point of Episode 45 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.6, 15)\n",
      "----- starting point of Episode 45 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1.0, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.6, 15)\n",
      "----- starting point of Episode 45 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1.0, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.6, 15)\n",
      "----- starting point of Episode 45 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1.0, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.6, 15)\n",
      "----- starting point of Episode 45 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1.0, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.6, 15)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110b400>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110ab00>, <__main__.Case object at 0x7dcde110aef0>, <__main__.Case object at 0x7dcde110a650>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110be50>, <__main__.Case object at 0x7dcde110a320>, <__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde110b850>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110b5e0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.7000000000000001, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.7000000000000001, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.7000000000000001, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.7000000000000001, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.7000000000000001, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.40000000000000013, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.40000000000000013, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.7, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (2, 4), solution: 4, tv: 0.7, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (1, 4), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 4), solution: 4, tv: 0.7, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 3), solution: 2, tv: 0.7, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 2, tv: 0.7, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.7, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 3, tv: 0.7, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.7, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 0\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (2, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 4), 4, 0.5)\n",
      "Episode succeeded, case (1, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 3), 2, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 4), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 4), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 4), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110ba00>, <__main__.Case object at 0x7dcde110bbb0>, <__main__.Case object at 0x7dcde110bc40>, <__main__.Case object at 0x7dcde110bcd0>, <__main__.Case object at 0x7dcde110ba30>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110b520>, <__main__.Case object at 0x7dcde110b9d0>, <__main__.Case object at 0x7dcde1109de0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110b430>, <__main__.Case object at 0x7dcde110bf10>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110b130>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (0, 3), solution: 2, tv: 0.4, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 2, tv: 0.4, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.4, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 3, tv: 0.4, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.4, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.4, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 45, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 45 loop--------------------\n",
      "----- starting point of Episode 46 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7, 0)\n",
      "----- starting point of Episode 46 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.7, 1)\n",
      "----- starting point of Episode 46 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 1), 3, 0.7, 2)\n",
      "----- starting point of Episode 46 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((0, 1), 2, 0.7, 6)\n",
      "----- starting point of Episode 46 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((0, 2), 2, 0.7, 7)\n",
      "----- starting point of Episode 46 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7, 15)\n",
      "----- starting point of Episode 46 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7, 15)\n",
      "----- starting point of Episode 46 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7, 15)\n",
      "----- starting point of Episode 46 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7, 15)\n",
      "----- starting point of Episode 46 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7, 15)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110b3d0>, <__main__.Case object at 0x7dcde110b640>, <__main__.Case object at 0x7dcde110beb0>, <__main__.Case object at 0x7dcde110b250>, <__main__.Case object at 0x7dcde110a1d0>, <__main__.Case object at 0x7dcde110b730>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110ba90>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d98a0>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110b550>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110ada0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.6000000000000001, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.6000000000000001, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.6000000000000001, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.6000000000000001, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.6000000000000001, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.7999999999999999, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (2, 4), solution: 4, tv: 0.7999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (1, 4), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 4), solution: 4, tv: 0.7999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 3), solution: 2, tv: 0.7999999999999999, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 2, tv: 0.7999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.7999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 3, tv: 0.7999999999999999, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.7999999999999999, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 0\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (2, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 4), 4, 0.5)\n",
      "Episode succeeded, case (1, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 3), 2, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.6000000000000001\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 4), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 4), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 4), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110afe0>, <__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110bf10>, <__main__.Case object at 0x7dcde110be80>, <__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110aa10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde1109de0>, <__main__.Case object at 0x7dcde110a0e0>, <__main__.Case object at 0x7dcde110acb0>, <__main__.Case object at 0x7dcde110bd90>, <__main__.Case object at 0x7dcde110b970>, <__main__.Case object at 0x7dcde110bc70>, <__main__.Case object at 0x7dcde110af80>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110b520>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 3) is empty. Temporary case base stored to the case base: ((0, 3), 2, 0.7)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 2, 0.7)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 0.7)\n",
      "Integrated case process. comm case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 3, 0.7)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.7)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.7)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "Episode: 46, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 46 loop--------------------\n",
      "----- starting point of Episode 47 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7999999999999999, 0)\n",
      "----- starting point of Episode 47 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.7999999999999999, 1)\n",
      "----- starting point of Episode 47 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 1), 3, 0.7999999999999999, 2)\n",
      "----- starting point of Episode 47 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((0, 1), 2, 0.7999999999999999, 6)\n",
      "----- starting point of Episode 47 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((0, 2), 2, 0.7999999999999999, 7)\n",
      "----- starting point of Episode 47 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7999999999999999, 15)\n",
      "----- starting point of Episode 47 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7999999999999999, 15)\n",
      "----- starting point of Episode 47 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7999999999999999, 15)\n",
      "----- starting point of Episode 47 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7999999999999999, 15)\n",
      "----- starting point of Episode 47 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.7999999999999999, 15)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde110a470>, <__main__.Case object at 0x7dcde110bc70>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110b250>, <__main__.Case object at 0x7dcde110bcd0>, <__main__.Case object at 0x7dcde110bfd0>, <__main__.Case object at 0x7dcde110aef0>, <__main__.Case object at 0x7dcde110bdf0>, <__main__.Case object at 0x7dcde110b8b0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10f8610>, <__main__.Case object at 0x7dcde110a3b0>, <__main__.Case object at 0x7dcde110aa40>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110b0d0>, <__main__.Case object at 0x7dcde1109e40>, <__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110ab60>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.5000000000000001, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.5000000000000001, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.5000000000000001, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.5000000000000001, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.5000000000000001, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.8999999999999999, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (2, 4), solution: 4, tv: 0.8999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (1, 4), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 4), solution: 4, tv: 0.8999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 3), solution: 2, tv: 0.8999999999999999, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 2, tv: 0.8999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.8999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 3, tv: 0.8999999999999999, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.8999999999999999, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.9, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.9, time steps: 2\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (2, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 4), 4, 0.5)\n",
      "Episode succeeded, case (1, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 3), 2, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 0.5000000000000001\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 4), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 4), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 4), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.9\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110a410>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110b400>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110b7f0>, <__main__.Case object at 0x7dcde110ba90>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110bd60>, <__main__.Case object at 0x7dcde110a7a0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110a650>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110b760>, <__main__.Case object at 0x7dcde110bbb0>, <__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110b460>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (0, 3), solution: 2, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 2, tv: 0.6, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 3, tv: 0.6, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 47, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 47 loop--------------------\n",
      "----- starting point of Episode 48 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.8999999999999999, 0)\n",
      "----- starting point of Episode 48 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.8999999999999999, 1)\n",
      "----- starting point of Episode 48 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 1), 3, 0.8999999999999999, 2)\n",
      "----- starting point of Episode 48 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((0, 1), 2, 0.8999999999999999, 6)\n",
      "----- starting point of Episode 48 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((0, 2), 2, 0.8999999999999999, 7)\n",
      "----- starting point of Episode 48 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.8999999999999999, 15)\n",
      "----- starting point of Episode 48 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.8999999999999999, 15)\n",
      "----- starting point of Episode 48 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.8999999999999999, 15)\n",
      "----- starting point of Episode 48 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.8999999999999999, 15)\n",
      "----- starting point of Episode 48 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.8999999999999999, 15)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde10ee1d0>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110b3a0>, <__main__.Case object at 0x7dcde110bf10>, <__main__.Case object at 0x7dcde110b430>, <__main__.Case object at 0x7dcde110b280>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110b7f0>, <__main__.Case object at 0x7dcde110b9d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10933a0>, <__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde110ae60>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110af50>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde10fbeb0>, <__main__.Case object at 0x7dcde110b220>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.40000000000000013, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.40000000000000013, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.40000000000000013, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.40000000000000013, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 2, tv: 0.40000000000000013, time steps: 3\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 0.9999999999999999, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (2, 4), solution: 4, tv: 0.9999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (1, 4), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 4), solution: 4, tv: 0.9999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 3), solution: 2, tv: 0.9999999999999999, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 2, tv: 0.9999999999999999, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.9999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 3, tv: 0.9999999999999999, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.9999999999999999, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.8, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.8, time steps: 2\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (2, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 4), 4, 0.5)\n",
      "Episode succeeded, case (1, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 3), 2, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 4), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 4), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 4), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.8\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110ad40>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110bbe0>, <__main__.Case object at 0x7dcde110ab00>, <__main__.Case object at 0x7dcde110bbb0>, <__main__.Case object at 0x7dcde110bc70>, <__main__.Case object at 0x7dcde110ba30>, <__main__.Case object at 0x7dcde110bf40>, <__main__.Case object at 0x7dcde110abf0>, <__main__.Case object at 0x7dcde110a8c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110a7a0>, <__main__.Case object at 0x7dcde110add0>, <__main__.Case object at 0x7dcde110b490>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110b5e0>, <__main__.Case object at 0x7dcde110b010>, <__main__.Case object at 0x7dcde110aa70>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110b8b0>, <__main__.Case object at 0x7dcde110a440>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (0, 3), solution: 2, tv: 0.5, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 2, tv: 0.5, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.5, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 3, tv: 0.5, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.5, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.5, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "Episode: 48, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 48 loop--------------------\n",
      "----- starting point of Episode 49 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 2)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.9999999999999999, 0)\n",
      "----- starting point of Episode 49 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 2, 1, 3)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.9999999999999999, 1)\n",
      "----- starting point of Episode 49 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 5)\n",
      "comm next state for agent 1: ((1, 1), 3, 0.9999999999999999, 2)\n",
      "----- starting point of Episode 49 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 6)\n",
      "comm next state for agent 1: ((0, 1), 2, 0.9999999999999999, 6)\n",
      "----- starting point of Episode 49 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 7)\n",
      "comm next state for agent 1: ((0, 2), 2, 0.9999999999999999, 7)\n",
      "----- starting point of Episode 49 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 8)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.9999999999999999, 15)\n",
      "----- starting point of Episode 49 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.9999999999999999, 15)\n",
      "----- starting point of Episode 49 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.9999999999999999, 15)\n",
      "----- starting point of Episode 49 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.9999999999999999, 15)\n",
      "----- starting point of Episode 49 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 3, 1, 23)\n",
      "comm next state for agent 1: ((0, 3), 2, 0.9999999999999999, 15)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7dcde1093880>, <__main__.Case object at 0x7dcde110b670>, <__main__.Case object at 0x7dcde110ba90>, <__main__.Case object at 0x7dcde110a590>, <__main__.Case object at 0x7dcde110ac20>, <__main__.Case object at 0x7dcde110bee0>, <__main__.Case object at 0x7dcde110b280>, <__main__.Case object at 0x7dcde110ad40>, <__main__.Case object at 0x7dcde110bbb0>, <__main__.Case object at 0x7dcde110af20>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7dcde10d3880>, <__main__.Case object at 0x7dcde10eeb30>, <__main__.Case object at 0x7dcde110b0a0>, <__main__.Case object at 0x7dcde110b460>, <__main__.Case object at 0x7dcde110b310>, <__main__.Case object at 0x7dcde110a0b0>, <__main__.Case object at 0x7dcde110bf10>, <__main__.Case object at 0x7dcde110b7f0>, <__main__.Case object at 0x7dcde1092da0>, <__main__.Case object at 0x7dcde110ba30>]\n",
      "case content after REVISE for agent 0, problem: (3, 4), solution: 4, tv: 1, time steps: 20\n",
      "case content after REVISE for agent 0, problem: (2, 4), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (1, 4), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 4), solution: 4, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (0, 3), solution: 2, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 2, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.7000000000000001, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.7000000000000001, time steps: 2\n",
      "Episode succeeded, case (3, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 4), 4, 0.5)\n",
      "Episode succeeded, case (2, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 4), 4, 0.5)\n",
      "Episode succeeded, case (1, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 4), 4, 0.5)\n",
      "Episode succeeded, case (0, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 3), 2, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 3) is empty. Temporary case base stored to the case base: ((4, 3), 2, 1)\n",
      "Integrated case process. comm case (3, 3) is empty. Temporary case base stored to the case base: ((3, 3), 4, 1)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 2, 1)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (3, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 4), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7000000000000001\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7dcde110b160>, <__main__.Case object at 0x7dcde110bc40>, <__main__.Case object at 0x7dcde110b220>, <__main__.Case object at 0x7dcde110a7d0>, <__main__.Case object at 0x7dcde110ab30>, <__main__.Case object at 0x7dcde110ab60>, <__main__.Case object at 0x7dcde110b430>, <__main__.Case object at 0x7dcde110b9d0>, <__main__.Case object at 0x7dcde110bbe0>, <__main__.Case object at 0x7dcde110bf40>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7dcde110a8c0>, <__main__.Case object at 0x7dcde110aa10>, <__main__.Case object at 0x7dcde110bb80>, <__main__.Case object at 0x7dcde110a8f0>, <__main__.Case object at 0x7dcde110ace0>, <__main__.Case object at 0x7dcde110ae90>, <__main__.Case object at 0x7dcde110ae00>, <__main__.Case object at 0x7dcde110a6b0>, <__main__.Case object at 0x7dcde110b370>, <__main__.Case object at 0x7dcde110b400>]\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 3, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 5\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 2, tv: 1, time steps: 3\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (0, 3), solution: 2, tv: 0.4, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 2, tv: 0.4, time steps: 7\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.4, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 3, tv: 0.4, time steps: 2\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.4, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.4, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "Episode: 49, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 49 loop--------------------\n",
      "Success rate: 78.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABamklEQVR4nO3dd1gUV9sG8HuXsnTpTVFRbNiDDbuigC22xNgi9miwYTeJNUaiSdQYjUaNEt9o7CWaRMGKGnuJ3YivXbADArIs7Pn+4GNe1wVlcVl0vH/XxaV75uzZMw+r3JyZ2VEIIQSIiIiIZEpZ1BMgIiIiKkwMO0RERCRrDDtEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7REQkiYqKgkKhwPXr1036ugqFAlOmTDHpa9K7g2GH3hk5/4nnfJmbm6N48eLo3bs37ty5U9TTe2uULl0abdu2zXXb8ePHoVAoEBUVZdpJvaP27t2r855+8Wv16tVFPUWiN4J5UU+AyNSmTZsGX19fpKen4/Dhw4iKisKBAwdw7tw5WFlZFfX0iAw2bNgw1K5dW689MDDQ4LE+/vhjdO3aFSqVyhhTI3ojMOzQO6dVq1aoVasWAKB///5wdXXFzJkz8fvvv6NLly5FPLuC0Wq1yMjIYFiTodTUVNja2r60T6NGjfDBBx8Y5fXMzMxgZmZmlLGI3hQ8jEXvvEaNGgEArl69qtN+6dIlfPDBB3B2doaVlRVq1aqF33//XaePRqPB1KlTUa5cOVhZWcHFxQUNGzZETEyMTr/du3ejUaNGsLW1haOjI9q3b4+LFy/q9OnduzdKly6tN78pU6ZAoVDotCkUCgwZMgQrV65E5cqVoVKpsH37dgDAnTt30K9fP3h7e0OlUsHX1xeDBw9GRkaG9PzExESMGDECPj4+UKlU8PPzw8yZM6HVag0rXj4kJCSgT58+KFGiBFQqFby8vNC+fXudc0K2bNmCNm3aSHMuW7YsvvzyS2RlZemNt2DBApQpUwbW1taoU6cO9u/fj6ZNm6Jp06Y6/dRqNSZPngw/Pz+oVCr4+Phg7NixUKvV+Zr3unXrEBAQAGtra7i6uqJnz546hzu//fZbKBQK3LhxQ++5EyZMgKWlJZ48eSK1HTlyBKGhoShWrBhsbGzQpEkTHDx4UOd5Od/rCxcuoHv37nByckLDhg3zNd9Xef49U6FCBVhZWSEgIACxsbE6/XI7Z+f48eMICQmBq6srrK2t4evri759++o8LzU1FaNGjZLeUxUqVMC3334LIYROP7VajYiICLi5ucHe3h7vv/8+bt++neuc79y5g759+8LDwwMqlQqVK1fGsmXL9Pr98MMPqFy5MmxsbODk5IRatWph1apVBawUyRFXduidl/OfupOTk9R2/vx5NGjQAMWLF8f48eNha2uLtWvXokOHDtiwYQM6duwIIPuHU2RkJPr37486deogOTkZx48fx8mTJ9GyZUsAwM6dO9GqVSuUKVMGU6ZMwbNnz/DDDz+gQYMGOHnyZK4BJz92796NtWvXYsiQIXB1dUXp0qVx9+5d1KlTB4mJiRg4cCAqVqyIO3fuYP369UhLS4OlpSXS0tLQpEkT3LlzB5988glKliyJv//+GxMmTEB8fDzmzp37OuXU07lzZ5w/fx5Dhw5F6dKlcf/+fcTExODmzZvSvkdFRcHOzg4jR46EnZ0ddu/ejUmTJiE5ORnffPONNNbChQsxZMgQNGrUCBEREbh+/To6dOgAJycnlChRQuqn1Wrx/vvv48CBAxg4cCAqVaqEs2fPYs6cOfj333+xefPml845KioKffr0Qe3atREZGYl79+7h+++/x8GDB3Hq1Ck4OjqiS5cuGDt2LNauXYsxY8boPH/t2rUIDg6W3lO7d+9Gq1atEBAQgMmTJ0OpVGL58uVo3rw59u/fjzp16ug8/8MPP0S5cuUwY8YMvbCQm6dPn+Lhw4d67S4uLjpBed++fVizZg2GDRsGlUqFH3/8EaGhoTh69CiqVKmS69j3799HcHAw3NzcMH78eDg6OuL69evYuHGj1EcIgffffx979uxBv379UKNGDezYsQNjxozBnTt3MGfOHKlv//798euvv6J79+6oX78+du/ejTZt2ui97r1791CvXj0ppLm5ueGvv/5Cv379kJycjBEjRgAAlixZgmHDhuGDDz7A8OHDkZ6ejjNnzuDIkSPo3r37K2tH7whB9I5Yvny5ACB27twpHjx4IG7duiXWr18v3NzchEqlErdu3ZL6BgUFiapVq4r09HSpTavVivr164ty5cpJbdWrVxdt2rR56evWqFFDuLu7i0ePHklt//zzj1AqlaJXr15SW1hYmChVqpTe8ydPnixe/KcKQCiVSnH+/Hmd9l69egmlUimOHTumN45WqxVCCPHll18KW1tb8e+//+psHz9+vDAzMxM3b9586f6UKlUqz30+duyYACCWL18uhBDiyZMnAoD45ptvXjpmWlqaXtsnn3wibGxspO+BWq0WLi4uonbt2kKj0Uj9oqKiBADRpEkTqe0///mPUCqVYv/+/TpjLlq0SAAQBw8ezHMuGRkZwt3dXVSpUkU8e/ZMat+2bZsAICZNmiS1BQYGioCAAJ3nHz16VAAQK1asEEJk171cuXIiJCRE+h7k7LOvr69o2bKl1Jbzve7WrVue83venj17BIA8v+Lj46W+OW3Hjx+X2m7cuCGsrKxEx44dpbacfyfXrl0TQgixadMmASDX91SOzZs3CwBi+vTpOu0ffPCBUCgUIi4uTgghxOnTpwUA8emnn+r06969uwAgJk+eLLX169dPeHl5iYcPH+r07dq1qyhWrJj0nmnfvr2oXLlyPqpF7zIexqJ3TosWLeDm5gYfHx988MEHsLW1xe+//y6tDDx+/Bi7d+9Gly5dpN+YHz58iEePHiEkJARXrlyRDmc4Ojri/PnzuHLlSq6vFR8fj9OnT6N3795wdnaW2qtVq4aWLVvizz//LPB+NGnSBP7+/tJjrVaLzZs3o127dtI5Sc/L+Q1/3bp1aNSoEZycnKR9e/jwIVq0aIGsrCy9wxqvw9raGpaWlti7d6/OIZ3c+uXIqXmjRo2QlpaGS5cuAcg+lPLo0SMMGDAA5ub/W5Tu0aOHzqpczj5WqlQJFStW1NnH5s2bAwD27NmT51yOHz+O+/fv49NPP9U5B6pNmzaoWLEi/vjjD6nto48+wokTJ3QOga5ZswYqlQrt27cHAJw+fRpXrlxB9+7d8ejRI2kuqampCAoKQmxsrN7hw0GDBuU5v9xMmjQJMTExel/Pv+eA7BOWAwICpMclS5ZE+/btsWPHjlwPGQLZ73EA2LZtGzQaTa59/vzzT5iZmWHYsGE67aNGjYIQAn/99ZfUD4Bev5xVmhxCCGzYsAHt2rWDEELnexgSEoKkpCScPHlSmt/t27dx7Nixl1SI3nU8jEXvnAULFqB8+fJISkrCsmXLEBsbq3PlSVxcHIQQmDhxIiZOnJjrGPfv30fx4sUxbdo0tG/fHuXLl0eVKlUQGhqKjz/+GNWqVQMA6XyOChUq6I1RqVIl7NixI18noObG19dX5/GDBw+QnJyc5+GIHFeuXMGZM2fg5uaW5769rpxgpVKpMHPmTIwaNQoeHh6oV68e2rZti169esHT01Pqf/78eXzxxRfYvXs3kpOTdcZKSkoC8L9a+vn56Ww3NzfXOxR45coVXLx4sUD7+LLvWcWKFXHgwAHp8YcffoiRI0dizZo1+OyzzyCEwLp169CqVSs4ODhIcwGAsLCwPF8zKSlJJ7C9+L19lapVq6JFixav7FeuXDm9tvLlyyMtLQ0PHjzQ+Z7kaNKkCTp37oypU6dizpw5aNq0KTp06IDu3btL/25u3LgBb29v2Nvb6zy3UqVK0vacP5VKJcqWLavT78VaP3jwAImJiVi8eDEWL16c677kfA/HjRuHnTt3ok6dOvDz80NwcDC6d++OBg0avLIe9O5g2KF3Tp06daSVjw4dOqBhw4bo3r07Ll++DDs7O+m37NGjRyMkJCTXMXJ+4DZu3BhXr17Fli1bEB0djaVLl2LOnDlYtGgR+vfvb9C8XjwJOUdev3E/vxpiCK1Wi5YtW2Ls2LG5bi9fvvxLn29lZYVnz57lui0tLU3qk2PEiBFo164dNm/ejB07dmDixImIjIzE7t27UbNmTSQmJqJJkyZwcHDAtGnTULZsWVhZWeHkyZMYN25cgU6a1mq1qFq1KmbPnp3rdh8fH4PHzI23tzcaNWqEtWvX4rPPPsPhw4dx8+ZNzJw5U2cuAPDNN9+gRo0auY5jZ2en87ig39vCoFAosH79ehw+fBhbt27Fjh070LdvX3z33Xc4fPiw3tyNIadmPXv2zDMk5vxCUalSJVy+fBnbtm3D9u3bsWHDBvz444+YNGkSpk6davS50duJYYfeaWZmZoiMjESzZs0wf/58jB8/HmXKlAEAWFhY5Ou3ZWdnZ/Tp0wd9+vRBSkoKGjdujClTpqB///4oVaoUAODy5ct6z7t06RJcXV2lVR0nJyckJibq9cvtap/cuLm5wcHBAefOnXtpv7JlyyIlJSVf+5abUqVK4cKFC7luy9nPnP1+/jVHjRqFUaNG4cqVK6hRowa+++47/Prrr9i7dy8ePXqEjRs3onHjxtJzrl27pve6QPbKW7NmzaT2zMxMXL9+Xfrhl/N6//zzD4KCgvIMkS/bv5x9yTns9fz+vbhvH330ET799FNcvnwZa9asgY2NDdq1a6czFwBwcHAocM2NJbfDrf/++y9sbGzyXAXLUa9ePdSrVw9fffUVVq1ahR49emD16tXS+3znzp14+vSpzupOziHInJqVKlUKWq0WV69e1VnNefHfR86VWllZWfmqma2tLT766CN89NFHyMjIQKdOnfDVV19hwoQJ/DgGAsBLz4nQtGlT1KlTB3PnzkV6ejrc3d3RtGlT/PTTT4iPj9fr/+DBA+nvjx490tlmZ2cHPz8/6fJmLy8v1KhRA7/88otOkDl37hyio6PRunVrqa1s2bJISkrCmTNnpLb4+Hhs2rQpX/uhVCrRoUMHbN26FcePH9fbLv7/qp4uXbrg0KFD2LFjh16fxMREZGZmvvR1Wrdujdu3b+td0aRWq7F06VK4u7vjvffeA5C90pOenq7Tr2zZsrC3t5dqlPOZLuK5q44yMjLw448/6jyvVq1acHFxwZIlS3TmuHLlSr3zgbp06YI7d+5gyZIlevN/9uwZUlNT89y/WrVqwd3dHYsWLdK5TP2vv/7CxYsX9a4c6ty5M8zMzPDbb79h3bp1aNu2rc5hyYCAAJQtWxbffvstUlJS9F7v+fdTYTt06JB0rgsA3Lp1C1u2bEFwcHCen63z5MkTvSvCclaocurTunVrZGVlYf78+Tr95syZA4VCgVatWgGA9Oe8efN0+r14BaCZmRk6d+6MDRs25BreX/Zv0NLSEv7+/hBC5HmOEb17uLJDBGDMmDH48MMPERUVhUGDBmHBggVo2LAhqlatigEDBqBMmTK4d+8eDh06hNu3b+Off/4BAPj7+6Np06YICAiAs7Mzjh8/jvXr12PIkCHS2N988w1atWqFwMBA9OvXT7r0vFixYjr3AuratSvGjRuHjh07YtiwYUhLS8PChQtRvnx5nR9QLzNjxgxER0ejSZMm0iXX8fHxWLduHQ4cOABHR0eMGTMGv//+O9q2bYvevXsjICAAqampOHv2LNavX4/r16/D1dU1z9cYOHAgli1bhg8//BB9+/ZFzZo18ejRI6xZswbnzp3DihUrYGlpCSB71SAoKAhdunSBv78/zM3NsWnTJty7dw9du3YFANSvXx9OTk4ICwvDsGHDoFAo8J///EfvB6ylpSWmTJmCoUOHonnz5ujSpQuuX7+OqKgolC1bVmcF5+OPP8batWsxaNAg7NmzBw0aNEBWVhYuXbqEtWvXYseOHbmexA1kr+jNnDkTffr0QZMmTdCtWzfp0vPSpUsjIiJCp7+7uzuaNWuG2bNn4+nTp/joo490tiuVSixduhStWrVC5cqV0adPHxQvXhx37tzBnj174ODggK1bt+br+5uX/fv364VKIPtQz/MrXlWqVEFISIjOpecAXnq455dffsGPP/6Ijh07omzZsnj69CmWLFkCBwcHKay3a9cOzZo1w+eff47r16+jevXqiI6OxpYtWzBixAhpdatGjRro1q0bfvzxRyQlJaF+/frYtWsX4uLi9F7366+/xp49e1C3bl0MGDAA/v7+ePz4MU6ePImdO3fi8ePHAIDg4GB4enqiQYMG8PDwwMWLFzF//ny0adNG7xwieocV1WVgRKaWc0ltbpfQZmVlibJly4qyZcuKzMxMIYQQV69eFb169RKenp7CwsJCFC9eXLRt21asX79eet706dNFnTp1hKOjo7C2thYVK1YUX331lcjIyNAZf+fOnaJBgwbC2tpaODg4iHbt2okLFy7ozSM6OlpUqVJFWFpaigoVKohff/01z0vPw8PDc93PGzduiF69ekmX1JcpU0aEh4cLtVot9Xn69KmYMGGC8PPzE5aWlsLV1VXUr19ffPvtt3pzz82TJ09ERESE8PX1FRYWFsLBwUE0a9ZM/PXXXzr9Hj58KMLDw0XFihWFra2tKFasmKhbt65Yu3atTr+DBw+KevXqCWtra+Ht7S3Gjh0rduzYIQCIPXv26PSdN2+eKFWqlFCpVKJOnTri4MGDIiAgQISGhur0y8jIEDNnzhSVK1cWKpVKODk5iYCAADF16lSRlJT0yn1cs2aNqFmzplCpVMLZ2Vn06NFD3L59O9e+S5YsEQCEvb29zuXqzzt16pTo1KmTcHFxESqVSpQqVUp06dJF7Nq1S+qT871+8ODBK+cnxKsvPX/+Uu6c98yvv/4qypUrJ1QqlahZs6ZefV+89PzkyZOiW7duomTJkkKlUgl3d3fRtm1bnUvYhch+T0VERAhvb29hYWEhypUrJ7755hudy+2FEOLZs2di2LBhwsXFRdja2op27dqJW7du6c1XCCHu3bsnwsPDhY+Pj7CwsBCenp4iKChILF68WOrz008/icaNG0t1LVu2rBgzZky+vsf07lAIkY9PrCIiekNptVq4ubmhU6dOuR62omwKhQLh4eF6h5qI3gU8Z4eI3hrp6el6h7dWrFiBx48f690ugogoB8/ZIaK3xuHDhxEREYEPP/wQLi4uOHnyJH7++WdUqVIFH374YVFPj4jeUAw7RPTWKF26NHx8fDBv3jw8fvwYzs7O6NWrF77++mvppGgiohfxnB0iIiKSNZ6zQ0RERLLGsENERESyxnN2kH3p6t27d2Fvb2/wR8sTERFR0RBC4OnTp/D29oZSmff6DcMOgLt37xrtxoBERERkWrdu3UKJEiXy3M6wA0gfKX7r1i04ODgYbVyNRoPo6GgEBwfDwsLCaONS7lhv02K9TYv1Ni3W27QKWu/k5GT4+Pi88tYgDDuAdOjKwcHB6GHHxsYGDg4O/MdiAqy3abHepsV6mxbrbVqvW+9XnYLCE5SJiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWeCPQwiIEkJEKsyw1kJEKCN5IrtBpNKy3KbHepsV6mxbrbXwWNsArbthZWIo07ERGRmLjxo24dOkSrK2tUb9+fcycORMVKlSQ+jRt2hT79u3Ted4nn3yCRYsWSY9v3ryJwYMHY8+ePbCzs0NYWBgiIyNhbl6Eu6dJg8U3pdAWAM4U3TTeJRYA621CrLdpsd6mxXoXgs/uApa2RfLSRRp29u3bh/DwcNSuXRuZmZn47LPPEBwcjAsXLsDW9n8FGTBgAKZNmyY9trGxkf6elZWFNm3awNPTE3///Tfi4+PRq1cvWFhYYMaMGSbdHyIiInrzFGnY2b59u87jqKgouLu748SJE2jcuLHUbmNjA09Pz1zHiI6OxoULF7Bz5054eHigRo0a+PLLLzFu3DhMmTIFlpaWhboPebKwgWbMDezYEY2QkGBYWHAZtLBpNBrW24RYb9NivU2L9S4EFjav7lNI3qhzdpKSkgAAzs7OOu0rV67Er7/+Ck9PT7Rr1w4TJ06UVncOHTqEqlWrwsPDQ+ofEhKCwYMH4/z586hZs6bpduB5CgVgaYssM1X2sh3/sRQ+hYb1NiXW27RYb9NivWXljQk7Wq0WI0aMQIMGDVClShWpvXv37ihVqhS8vb1x5swZjBs3DpcvX8bGjRsBAAkJCTpBB4D0OCEhIdfXUqvVUKvV0uPk5GQA2Uleo9EYbZ9yxjLmmJQ31tu0WG/TYr1Ni/U2rYLWO7/935iwEx4ejnPnzuHAgQM67QMHDpT+XrVqVXh5eSEoKAhXr15F2bJlC/RakZGRmDp1ql57dHS0zvlAxhITE2P0MSlvrLdpsd6mxXqbFuttWobWOy0tLV/93oiwM2TIEGzbtg2xsbEoUaLES/vWrVsXABAXF4eyZcvC09MTR48e1elz7949AMjzPJ8JEyZg5MiR0uPk5GT4+PggODgYDg4Or7MrOjQaDWJiYtCyZUse8zUB1tu0WG/TYr1Ni/U2rYLWO+fIzKsUadgRQmDo0KHYtGkT9u7dC19f31c+5/Tp0wAALy8vAEBgYCC++uor3L9/H+7u7gCyk6GDgwP8/f1zHUOlUkGlUum1W1hYFMqburDGpdyx3qbFepsW621arLdpGVrv/PYt0rATHh6OVatWYcuWLbC3t5fOsSlWrBisra1x9epVrFq1Cq1bt4aLiwvOnDmDiIgING7cGNWqVQMABAcHw9/fHx9//DFmzZqFhIQEfPHFFwgPD8810BAREdG7pUhvF7Fw4UIkJSWhadOm8PLykr7WrFkDALC0tMTOnTsRHByMihUrYtSoUejcuTO2bt0qjWFmZoZt27bBzMwMgYGB6NmzJ3r16qXzuTxERET07iryw1gv4+Pjo/fpybkpVaoU/vzzT2NNi4iIiGSENwIlIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIlkr0rATGRmJ2rVrw97eHu7u7ujQoQMuX76s0yc9PR3h4eFwcXGBnZ0dOnfujHv37un0uXnzJtq0aQMbGxu4u7tjzJgxyMzMNOWuEBER0RuqSMPOvn37EB4ejsOHDyMmJgYajQbBwcFITU2V+kRERGDr1q1Yt24d9u3bh7t376JTp07S9qysLLRp0wYZGRn4+++/8csvvyAqKgqTJk0qil0iIiKiN4x5Ub749u3bdR5HRUXB3d0dJ06cQOPGjZGUlISff/4Zq1atQvPmzQEAy5cvR6VKlXD48GHUq1cP0dHRuHDhAnbu3AkPDw/UqFEDX375JcaNG4cpU6bA0tKyKHaNiIiI3hBFGnZelJSUBABwdnYGAJw4cQIajQYtWrSQ+lSsWBElS5bEoUOHUK9ePRw6dAhVq1aFh4eH1CckJASDBw/G+fPnUbNmTb3XUavVUKvV0uPk5GQAgEajgUajMdr+5IxlzDEpb6y3abHepsV6mxbrbVoFrXd++78xYUer1WLEiBFo0KABqlSpAgBISEiApaUlHB0ddfp6eHggISFB6vN80MnZnrMtN5GRkZg6dapee3R0NGxsbF53V/TExMQYfUzKG+ttWqy3abHepsV6m5ah9U5LS8tXvzcm7ISHh+PcuXM4cOBAob/WhAkTMHLkSOlxcnIyfHx8EBwcDAcHB6O9jkajQUxMDFq2bAkLCwujjUu5Y71Ni/U2LdbbtFhv0ypovXOOzLzKGxF2hgwZgm3btiE2NhYlSpSQ2j09PZGRkYHExESd1Z179+7B09NT6nP06FGd8XKu1srp8yKVSgWVSqXXbmFhUShv6sIal3LHepsW621arLdpsd6mZWi989u3SK/GEkJgyJAh2LRpE3bv3g1fX1+d7QEBAbCwsMCuXbuktsuXL+PmzZsIDAwEAAQGBuLs2bO4f/++1CcmJgYODg7w9/c3zY4QERHRG6tIV3bCw8OxatUqbNmyBfb29tI5NsWKFYO1tTWKFSuGfv36YeTIkXB2doaDgwOGDh2KwMBA1KtXDwAQHBwMf39/fPzxx5g1axYSEhLwxRdfIDw8PNfVGyIiInq3FGnYWbhwIQCgadOmOu3Lly9H7969AQBz5syBUqlE586doVarERISgh9//FHqa2Zmhm3btmHw4MEIDAyEra0twsLCMG3aNFPtBhEREb3BijTsCCFe2cfKygoLFizAggUL8uxTqlQp/Pnnn8acGhEREckE741FREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREslagsJOZmYmdO3fip59+wtOnTwEAd+/eRUpKilEnR0RERPS6zA19wo0bNxAaGoqbN29CrVajZcuWsLe3x8yZM6FWq7Fo0aLCmCcRERFRgRi8sjN8+HDUqlULT548gbW1tdTesWNH7Nq1y6iTIyIiInpdBq/s7N+/H3///TcsLS112kuXLo07d+4YbWJERERExmDwyo5Wq0VWVpZe++3bt2Fvb2+USREREREZi8FhJzg4GHPnzpUeKxQKpKSkYPLkyWjdurUx50ZERET02gw+jPXdd98hJCQE/v7+SE9PR/fu3XHlyhW4urrit99+K4w5EhERERWYwWGnRIkS+Oeff7B69WqcOXMGKSkp6NevH3r06KFzwjIRERHRm8DgsAMA5ubm6Nmzp7HnQkRERGR0Boed33//Pdd2hUIBKysr+Pn5wdfX97UnRkRERGQMBoedDh06QKFQQAih057TplAo0LBhQ2zevBlOTk5GmygRERFRQRh8NVZMTAxq166NmJgYJCUlISkpCTExMahbty62bduG2NhYPHr0CKNHjy6M+RIREREZxOCVneHDh2Px4sWoX7++1BYUFAQrKysMHDgQ58+fx9y5c9G3b1+jTpSIiIioIAxe2bl69SocHBz02h0cHPDf//4XAFCuXDk8fPjw9WdHRERE9JoMDjsBAQEYM2YMHjx4ILU9ePAAY8eORe3atQEAV65cgY+Pj/FmSURERFRABh/G+vnnn9G+fXuUKFFCCjS3bt1CmTJlsGXLFgBASkoKvvjiC+POlIiIiKgADA47FSpUwIULFxAdHY1///1XamvZsiWUyuyFog4dOhh1kkREREQFVaAPFVQqlQgNDUVoaKix50NERERkVAUKO6mpqdi3bx9u3ryJjIwMnW3Dhg0zysSIiIiIjMHgsHPq1Cm0bt0aaWlpSE1NhbOzMx4+fAgbGxu4u7sz7BAREdEbxeCrsSIiItCuXTs8efIE1tbWOHz4MG7cuIGAgAB8++23hTFHIiIiogIzOOycPn0ao0aNglKphJmZGdRqNXx8fDBr1ix89tlnhTFHIiIiogIzOOxYWFhIV125u7vj5s2bAIBixYrh1q1bxp0dERER0Wsy+JydmjVr4tixYyhXrhyaNGmCSZMm4eHDh/jPf/6DKlWqFMYciYiIiArM4JWdGTNmwMvLCwDw1VdfwcnJCYMHD8aDBw+wePFio0+QiIiI6HUYHHZq1aqFZs2aAcg+jLV9+3YkJyfjxIkTqF69ukFjxcbGol27dvD29oZCocDmzZt1tvfu3RsKhULn68XP9nn8+DF69OgBBwcHODo6ol+/fkhJSTF0t4iIiEimDA47z549Q1pamvT4xo0bmDt3LqKjow1+8dTUVFSvXh0LFizIs09oaCji4+Olr99++01ne48ePXD+/HnExMRg27ZtiI2NxcCBAw2eCxEREcmTwefstG/fHp06dcKgQYOQmJiIOnXqwNLSEg8fPsTs2bMxePDgfI/VqlUrtGrV6qV9VCoVPD09c9128eJFbN++HceOHUOtWrUAAD/88ANat26Nb7/9Ft7e3vnfMSIiIpIlg8POyZMnMWfOHADA+vXr4enpiVOnTmHDhg2YNGmSQWEnP/bu3Qt3d3c4OTmhefPmmD59OlxcXAAAhw4dgqOjoxR0AKBFixZQKpU4cuQIOnbsmOuYarUaarVaepycnAwA0Gg00Gg0Rpt7zljGHJPyxnqbFuttWqy3abHeplXQeue3v8FhJy0tDfb29gCA6OhodOrUCUqlEvXq1cONGzcMHe6lQkND0alTJ/j6+uLq1av47LPP0KpVKxw6dAhmZmZISEiAu7u7znPMzc3h7OyMhISEPMeNjIzE1KlT9dqjo6NhY2Nj1H0AgJiYGKOPSXljvU2L9TYt1tu0WG/TMrTez59W8zIGhx0/Pz9s3rwZHTt2xI4dOxAREQEAuH//PhwcHAwd7qW6du0q/b1q1aqoVq0aypYti7179yIoKKjA406YMAEjR46UHicnJ8PHxwfBwcFG3QeNRoOYmBi0bNkSFhYWRhuXcsd6mxbrbVqvW2+tVguNRgMhRCHMTn4yMzPx999/o379+jA3L9BtJMkAudVboVDA3NwcZmZmeT4v58jMqxj8HZw0aRK6d++OiIgIBAUFITAwEED2qkjNmjUNHc4gZcqUgaurK+Li4hAUFARPT0/cv39fp09mZiYeP36c53k+QPZ5QCqVSq/dwsKiUP7TLqxxKXest2mx3qZVkHpnZGTg+vXr0Gq1hTQr+RFCwNPTE/Hx8VAoFEU9Hdl7Wb0dHR3h6emZ6/chv/8WDA47H3zwARo2bIj4+HidS82DgoLyPEfGWG7fvo1Hjx5Jn/MTGBiIxMREnDhxAgEBAQCA3bt3Q6vVom7duoU6FyKit4EQAvHx8TAzM4OPj4/0Cfj0clqtFikpKbCzs2PNTCC3egshkJaWJi1q5PzsL4gCrc15enrqrZzUqVPH4HFSUlIQFxcnPb527RpOnz4NZ2dnODs7Y+rUqejcuTM8PT1x9epVjB07Fn5+fggJCQEAVKpUCaGhoRgwYAAWLVoEjUaDIUOGoGvXrrwSi4gI2avdaWlp8Pb2LpRzEuVKq9UiIyMDVlZWDDsmkFe9ra2tAWSfKuPu7v7SQ1ovk++wU7NmzVyXkIoVK4by5ctjxIgRqFSpkkEvfvz4cekDCgFI59GEhYVh4cKFOHPmDH755RckJibC29sbwcHB+PLLL3UOQa1cuRJDhgxBUFAQlEolOnfujHnz5hk0DyIiucrKygIAWFpaFvFMiAomJ6RrNJrCDzsdOnTItT0xMREnT55EjRo1sHv3bjRo0CDfL960adOXniy3Y8eOV47h7OyMVatW5fs1iYjeRTzvhN5Wxnjv5jvsTJ48+aXbP//8c0yaNAm7du167UkRERERGYvRDkR2794dZ8+eNdZwRERE75zLly/D09MTT58+LfAYFy5cQIkSJZCammrEmb3djBZ2zMzMeFkjEREZRc6NoAcNGqS3LTw8HAqFAr179zb9xArZhAkTMHToUOnDe69fv47GjRvD1tYWjRs3xvXr13X6t23bFhs2bNBp8/f3R7169TB79mxTTfuNZ7Sws3HjRvj7+xtrOCIiesf5+Phg9erVePbsmdSWnp6OVatWoWTJkkU4s7wJIZCZmVmg5968eRPbtm3TCXGjRo1C8eLFcfr0aXh5eWH06NHStjVr1kgX5ryoT58+WLhwYYHnIjf5Djvz5s3L9evLL79Ehw4dMHnyZEyaNKkw50pERO+Q9957Dz4+Pti4caPUtnHjRpQsWVLvQ2y1Wi0iIyPh6+sLa2trVK9eHevXr5e27927FwqFAjt27EDNmjVhbW2N5s2b4/79+/jrr79QqVIlODg4oHv37jq3IFCr1Rg2bBjc3d1hZWWFhg0b4tixY3rj/vXXXwgICIBKpcKvv/4KpVKJ48eP68xx7ty5KFWqVJ5HQdauXYvq1aujePHiUtvFixcRFhaGcuXKoXfv3rh48SKA7IuDvvjiCyxYsCDXsVq2bInHjx9j3759ryrzOyHfJyjn3PzzRQ4ODqhQoQJiY2OlT1MmIqI3kxACzzRZRfLa1hZmBl9Z07dvXyxfvhw9evQAACxbtgx9+vTB3r17dfpFRkbi119/xaJFi1CuXDnExsaiZ8+ecHNzQ5MmTaR+U6ZMwfz582FjY4MuXbqgS5cuUKlUWLVqFVJSUtCxY0f88MMPGDNmDABg3Lhx2LBhA3755ReUKlUKs2bNQkhICOLi4uDs7CyNO378eHz77bcoU6YMnJyc0KJFCyxfvlznRtXLly9H79698/zcnv379+v0B4Dq1atj586dCA4ORnR0NKpVqwYAGDNmDMLDw+Hj45PrWJaWlqhRowb279//WrdXkot8h51r164V5jyIiMgEnmmy4D/p1R/rURguTAuBjaVhn2Xbs2dPTJgwQbrR9MGDB7F69WqdsKNWqzFjxgzs3LlT+qW7TJkyOHDgAH766SedsDN9+nTpI1L69euHCRMm4OrVqyhTpgyA7LsE7NmzB2PGjEFqaioWLVqEqKgotGrVCgCwZMkSxMTE4Oeff5YCEQBMmzYNLVu2lB73798fgwYNwuzZs6FSqXDy5EmcPXsWW7ZsyXNfb9y4oRd2vv32W3zyyScoXbo0qlWrhp9++gmxsbE4ffo0Zs6ciS5duuD48eMIDg7GvHnzdD5Pydvb2+g36H5b8e5mRET0xnJzc0ObNm0QFRUFIQTatGkDV1dXnT5xcXFIS0vTCRtA9j3BXjzclbMyAgAeHh6wsbGRgk5O29GjRwFk/5Kv0Wh0Pj/OwsICderUkQ4n5XgxpHTo0AHh4eHYtGkTunbtiqioKDRr1gylS5fOc1+fPXsGKysrnbbixYtj27Zt0mO1Wo2QkBD88ssvmD59Ouzt7XH58mWEhobip59+wtChQ6W+1tbW+b4ruNwx7BARvUOsLcxwYVpIkb12QfTt2xdDhgwBgFzPUUlJSQEA/PHHHzrnuwDQu+nz8zeOVCgUejeSVCgUBbqy2NbWVuexpaUlevXqheXLl6NTp05YtWoVvv/++5eO4erqiidPnry0z4wZMxAcHIyAgAAMGDAA06dPh4WFBTp16oTdu3frhJ3Hjx+jbNmyBu+LHDHsEBG9QxQKhcGHkopaaGgoMjIyoFAopHsjPs/f3x8qlQo3b97UOWT1unx9fWFpaYmDBw+iVKlSALJvWXDs2DGMGDHilc/v378/qlSpgh9//BGZmZno1KnTS/vXrFkTFy5cyHP7xYsXsWrVKpw+fRpA9q1ANBqNNK+cW4PkOHfuHD744INXzvNd8Ha944mI6J1jZmYmHTbK7d5I9vb2GD16NCIiIqDVatGwYUMkJSXh4MGDcHBwQFhYWIFe19bWFoMGDcKYMWPg7OyMkiVLYtasWUhLS0O/fv1e+fxKlSqhXr16GDduHPr27Svd1DIvISEh6N+/P7KysvT2UwiBgQMHYs6cOdIqUoMGDbBkyRKUL18eK1asQLdu3aT+169fx507d9CiRYsC7Ln88FauRET0xnNwcICDg0Oe27/88ktMnDgRkZGRqFSpEkJDQ/HHH3/A19f3tV43MjISnTt3xscff4z33nsPcXFx2LFjB5ycnPL1/H79+iEjIwN9+/Z9Zd9WrVrB3NwcO3fu1Nu2ePFieHh4oG3btlLblClTkJ6ejrp168LPzw/h4eHStt9++w3BwcHSitQ7TxRAbGys6NGjh6hXr564ffu2EEKIFStWiP379xdkuCKXlJQkAIikpCSjjpuRkSE2b94sMjIyjDou5Y71Ni3W27QKWu9nz56JCxcuiGfPnhXSzOQpKytLPHnyRGRlZb3WONOmTRNVq1bNd//58+eL4ODg13pNtVotSpYsKQ4cOPBa45jSy+r9svdwfn9+G7yys2HDBoSEhMDa2hqnTp2CWq0GACQlJWHGjBlGjmJERERvn5SUFJw7dw7z58/XOWn4VT755BM0btz4te6NdfPmTXz22Wc6V5G96wwOO9OnT8eiRYuwZMkSnbPYGzRogJMnTxp1ckRERG+jIUOGICAgAE2bNs3XIawc5ubm+Pzzz6V7YxWEn58fPvnkkwI/X44MPkH58uXLaNy4sV57sWLFkJiYaIw5ERERvdWioqIQFRVV1NOg/2fwyo6npyfi4uL02g8cOKDzwUxEREREbwKDw86AAQMwfPhwHDlyBAqFAnfv3sXKlSsxevRoDB48uDDmSERERFRgBh/GGj9+PLRaLYKCgpCWlobGjRtDpVJh9OjRBp2ERURERGQKBocdhUKBzz//HGPGjEFcXBxSUlLg7+8POzu7wpgfERER0WsxOOwkJSUhKysLzs7O8Pf3l9ofP34Mc3Pzl37oExEREZGpGXzOTteuXbF69Wq99rVr16Jr165GmRQRERGRsRgcdo4cOYJmzZrptTdt2hRHjhwxyqSIiIio6EycOBEDBw4s1Nd4+PAh3N3dcfv27UJ9HaAAYUetViMzM1OvXaPR4NmzZ0aZFBERUUJCAoYPHw4/Pz9YWVnBw8MDDRo0wMKFC5GWlib1K126NBQKBRQKBWxtbfHee+9h3bp10vbevXujQ4cOeuPv3bsXCoXipZ8RZ2ZmBoVCgcOHD+u0q9VquLi4QKFQYO/eva+7q2+UhIQEfP/99/j888+ltt69e0OhUGDQoEF6/cPDw6FQKNC7d2+9/jlfLi4uCA0NxZkzZ6Q+rq6u6NWrFyZPnlyo+wMUIOzUqVMHixcv1mtftGgRAgICjDIpIiJ6t/33v/9FzZo1ER0djRkzZuDUqVM4dOgQxo4di23btundLHPatGmIj4/HqVOnULt2bXz00Uf4+++/jTIXHx8fLF++XKdt06ZNb/SFORkZGQV+7tKlS1G/fn29m4j6+Phg9erVOgsb6enpWLVqFUqWLKk3TmhoKOLj4xEfH49du3bB3Nxc50amANCnTx+sXLkSjx8/LvB886NAt4tYunQpGjdujKlTp2Lq1Klo3Lgxli1bxntjERGRUXz66acwNzfH8ePH0aVLF1SqVAllypRB+/bt8ccff6Bdu3Y6/e3t7eHp6Yny5ctjwYIFsLa2xtatW40yl7CwML0f8suWLUNYWJhe31u3bqFLly5wdHSEs7Mz2rdvj+vXr0vbc1aZZsyYAQ8PDzg6OmLatGnIzMzEmDFj4OzsjBIlSuiFq7Nnz6J58+awtraGi4sLBg4ciJSUFL1xv/rqK3h7e6NChQqYNm0aqlSpojfHGjVqYOLEiXnu7+rVq/XqCwDvvfcefHx8sHHjRqlt48aNKFmyJGrWrKnXX6VSwdPTE56enqhRowbGjx+PW7du4cGDB1KfypUrw9vbG5s2bcpzPsZgcNhp0KABDh8+DB8fH6xduxZbt26Fn58fzpw5g0aNGhXGHImIyFiEADJSi+ZLiHxN8dGjR4iOjkZ4eDhsbW1z7aNQKPJ8vrm5OSwsLF5rdeN5AQEBKF26NDZs2AAg+0absbGx+Pjjj3X6aTQahISEwN7eHvv378fBgwdhZ2eH0NBQnbns3r0bd+/eRWxsLGbPno3Jkyejbdu2cHJywpEjRzBo0CB88skn0rksqampCAkJgZOTE44dO4Z169Zh586dGDJkiM7r79q1C5cvX0ZMTAy2bduGvn374uLFizh27JjU59SpUzhz5gz69OmT674+fvwYFy5cQK1atXLd3rdvX50gtmzZsjzHel5KSgp+/fVX+Pn5wcXFRWdbnTp1cODAgVeO8ToMuvRco9Hgk08+wcSJE7Fy5crCmhMRERUWTRoww7toXvuzu4Bl7uHleXFxcRBCoEKFCjrtrq6uSE9PB5B9nsjMmTP1npuRkYHvvvsOSUlJaN68uXHmjewf8suWLUPPnj0RFRWF1q1bw83NTafPmjVroNVqsXTpUimMLV++HI6Ojti7dy+Cg4MBAM7Ozpg3bx6USiUqVKiAWbNmIS0tDZ999hkAYMKECfj6669x4MABdO3aFatWrUJ6ejpWrFghhb/58+ejXbt2mDlzJjw8PAAAtra2WLp0KSwtLaU5hYSEYPny5ahdu7Y0nyZNmuR5e6ebN29CCAFv79zfIz179sSECRNw48YNAMDBgwexevXqXM9b2rZtm3SoLzU1FV5eXti2bRuUSt11Fm9vb5w6dSqPyhuHQSs7FhYWUrIlIiIypaNHj+L06dOoXLky1Gq1zrZx48bBzs4ONjY2mDlzJr7++mu0adPGaK/ds2dPHDp0CP/9738RFRWV653M//nnH8TFxcHe3h52dnaws7ODs7Mz0tPTcfXqValf5cqVdX7ge3h4oGrVqtJjMzMzuLi44P79+wCAixcvonr16jqrXA0aNIBWq8Xly5eltqpVq+oEHSD7Fk+//fYb0tPTkZGRgVWrVr30Luw5h+qsrKxy3e7m5oY2bdogKioKy5cvR5s2beDq6ppr32bNmuH06dM4ffo0jh49ipCQELRq1UoKSjmsra11TjgvDAZ/qGCHDh2wefNmREREFMZ8iIioMFnYZK+wFNVr54Ofnx8UCoXOD3IA0mqEtbW13nPGjBmD3r17w87ODh4eHjqHuRwcHPR+wAJAYmIizMzM8jxU9jwXFxe0bdsW/fr1Q3p6Olq1aoWnT5/q9ElJSUFAQECuRz6eXwWysLDQ2aZQKHJt02q1r5zX83Lbj3bt2kGlUmHTpk2wtLSERqPBBx98kOcYOcHlyZMneitXOfr27SsdQluwYMFL5+Pn5yc9Xrp0KYoVK4YlS5Zg+vTpUvvjx4/zDEzGYnDYKVeuHKZNm4aDBw8iICBAr7jDhg0z2uSIiMjIFIp8HUoqSi4uLmjZsiXmz5+PoUOH5iuMuLq66vxgfV6FChWwevVqqNVqqFQqqf3kyZPw9fXVCxp56du3L1q3bo1x48bBzMxMb/t7772HNWvWwN3d3ah3E6hUqRKioqKQmpoq1eLgwYPSYbCXMTc3R1hYGJYvXw5LS0t07do117CYo2zZsnBwcMCFCxdQvnz5XPvknIOkUCgQEhKS7/1QKBRQKpV6H1Nz7tw5NGnSJN/jFITBYefnn3+Go6MjTpw4gRMnTuhsUygUDDtERPTafvzxRzRo0AC1atXClClTUK1aNSiVShw7dgyXLl0y6KNOevTogWnTpqFXr14YO3YsihUrhtjYWMydOxezZs3K9zihoaF48OBBnkGmR48e+Oabb9C+fXtMmzYNJUqUwI0bN7Bx40aMHTsWJUqUyPdrvTju5MmTERYWhilTpuDBgwcYOnQoPv74Y+l8nZfp378/KlWqBCA7JL2MUqlEixYtcODAgVw/mwjIPsx28eJF6e95UavVSEhIAJC9UjR//nykpKToXOmVlpaGEydO6Kz0FAaDw861a9cKYx5ERESSsmXL4tSpU5gxYwYmTJiA27dvQ6VSwd/fH6NHj8ann36a77EcHR2xf/9+jB8/Hu+//z6SkpLg5+eH2bNno1+/fvkeR6FQvPRwi42NDWJjYzFu3Dh06tQJT58+RfHixREUFPRaKz02NjbYsWMHhg8fjtq1a8PGxgadO3fG7Nmz8/X8cuXKoX79+nj8+DHq1q37yv79+/fHgAEDMGvWLL2TiXPkZ3+2b98OLy8vANkfDVCxYkWsW7cOTZs2lfps2bIFJUuWRKNGjZCcnJyv/SkIhRD5vBZQxpKTk1GsWDEkJSUZdelRo9Hgzz//ROvWrfO9TEoFx3qbFuttWgWtd3p6Oq5duwZfX988TzolfVqtFsnJyXBwcMjzB/7bQgiBcuXK4dNPP8XIkSPz1b9u3bqIiIhAt27dCnVu9erVw7Bhw9C1a9c86/2y93B+f34bvLLzsrO4gexr7omIiKjoPXjwAKtXr0ZCQkK+Pg8HyF7BWrx4Mc6ePVuoc3v48CE6deqEbt26obDXXQwOO0+ePNF5rNFocO7cOSQmJhr1Mw2IiIjo9bi7u8PV1RWLFy+Gk5NTvp9Xo0YN1KhRo/AmhuyTyseOHQsAb17Yye0jnbVaLQYPHoyyZcsaZVJERET0+nimSjajHIhUKpUYOXIk5syZY4zhiIiIiIzGaGddXb16FZmZmcYajoiIjIi/4dPbyhjvXYMPY714JrcQAvHx8fjjjz9yvQMsEREVnZzPQcnIyHjph8kRvalybiXxOld9Ghx2XrxZl1KphJubG7777rtXXqlFRESmZW5uDhsbGzx48AAWFhZv/WXUpqLVapGRkYH09HTWzARyq7cQAmlpabh//z4cHR1f+gGGr2Jw2NmzZ0+BX4yIiExLoVDAy8sL165dy/X+UJQ7IQSePXsGa2trnftsUeF4Wb0dHR3h6en5WuMbHHZyPHjwQLpJW4UKFfK8YRgRERUtS0tLlCtXDhkZGUU9lbeGRqNBbGwsGjduzA/NNIG86m1hYfFaKzo5DA47qampGDp0KFasWCHdkdXMzAy9evXCDz/8ABub/N3VloiITEepVPITlA1gZmaGzMxMWFlZMeyYQGHX2+ADkSNHjsS+ffuwdetWJCYmIjExEVu2bMG+ffswatQoo0+QiIiI6HUYvLKzYcMGrF+/XudGXq1bt4a1tTW6dOmChQsXGnN+RERERK/F4JWdtLS0XG8p7+7uLl0eRkRERPSmMDjsBAYGYvLkyUhPT5fanj17hqlTpyIwMNCokyMiIiJ6XQYfxvr+++8REhKCEiVKoHr16gCAf/75B1ZWVtixY4fRJ0hERET0OgwOO1WqVMGVK1ewcuVKXLp0CQDQrVs39OjRg5/OSURERG+cAn3Ojo2NDQYMGGDsuRAREREZncHn7Pzyyy/4448/pMdjx46Fo6Mj6tevz0/nJCIiojeOwWFnxowZ0uGqQ4cOYf78+Zg1axZcXV0RERFh9AkSERERvQ6DD2PdunULfn5+AIDNmzfjgw8+wMCBA9GgQQOdz94hIiIiehMYvLJjZ2eHR48eAQCio6PRsmVLAICVlRWePXtm3NkRERERvSaDV3ZatmyJ/v37o2bNmvj333/RunVrAMD58+dRunRpY8+PiIiI6LUYvLKzYMECBAYG4sGDB9iwYQNcXFwAACdOnEC3bt2MPkEiIiKi12Hwyo6joyPmz5+v1z516lSjTIiIiIjImAxe2QGA/fv3o2fPnqhfvz7u3LkDAPjPf/6DAwcOGDRObGws2rVrB29vbygUCmzevFlnuxACkyZNgpeXF6ytrdGiRQtcuXJFp8/jx4/Ro0cPODg4wNHREf369UNKSkpBdouIiIhkyOCws2HDBoSEhMDa2honT56EWq0GACQlJWHGjBkGjZWamorq1atjwYIFuW6fNWsW5s2bh0WLFuHIkSOwtbVFSEiIzn25evTogfPnzyMmJgbbtm1DbGwsBg4caOhuERERkUwZHHamT5+ORYsWYcmSJbCwsJDaGzRogJMnTxo0VqtWrTB9+nR07NhRb5sQAnPnzsUXX3yB9u3bo1q1alixYgXu3r0rrQBdvHgR27dvx9KlS1G3bl00bNgQP/zwA1avXo27d+8aumtEREQkQwafs3P58mU0btxYr71YsWJITEw0xpwAANeuXUNCQgJatGih8xp169bFoUOH0LVrVxw6dAiOjo6oVauW1KdFixZQKpU4cuRIriEKANRqtbQiBQDJyckAAI1GA41GY7R9yBnLmGNS3lhv02K9TYv1Ni3W27QKWu/89jc47Hh6eiIuLk7vMvMDBw6gTJkyhg6Xp4SEBACAh4eHTruHh4e0LSEhAe7u7jrbzc3N4ezsLPXJTWRkZK4nVEdHR8PGxuZ1p64nJibG6GNS3lhv02K9TYv1Ni3W27QMrXdaWlq++hkcdgYMGIDhw4dj2bJlUCgUuHv3Lg4dOoTRo0dj4sSJhg5XJCZMmICRI0dKj5OTk+Hj44Pg4GA4ODgY7XU0Gg1iYmLQsmVLnUN+VDhYb9NivU2L9TYt1tu0ClrvnCMzr2Jw2Bk/fjy0Wi2CgoKQlpaGxo0bQ6VSYfTo0Rg6dKihw+XJ09MTAHDv3j14eXlJ7ffu3UONGjWkPvfv39d5XmZmJh4/fiw9PzcqlQoqlUqv3cLColDe1IU1LuWO9TYt1tu0WG/TYr1Ny9B657evwScoKxQKfP7553j8+DHOnTuHw4cP48GDB/jyyy+NersIX19feHp6YteuXVJbcnIyjhw5gsDAQABAYGAgEhMTceLECanP7t27odVqUbduXaPNhYiIiN5eBq/s5LC0tIS/vz+A7BN+Z8+ejVmzZr30XJkXpaSkIC4uTnp87do1nD59Gs7OzihZsiRGjBiB6dOno1y5cvD19cXEiRPh7e2NDh06AAAqVaqE0NBQDBgwAIsWLYJGo8GQIUPQtWtXeHt7F3TXiIiISEbyHXbUajWmTJmCmJgYWFpaYuzYsejQoQOWL1+Ozz//HGZmZoiIiDDoxY8fP45mzZpJj3POowkLC0NUVBTGjh2L1NRUDBw4EImJiWjYsCG2b98OKysr6TkrV67EkCFDEBQUBKVSic6dO2PevHkGzYOIiIjkK99hZ9KkSfjpp5/QokUL/P333/jwww/Rp08fHD58GLNnz8aHH34IMzMzg168adOmEELkuV2hUGDatGmYNm1ann2cnZ2xatUqg16XiIiI3h35Djvr1q3DihUr8P777+PcuXOoVq0aMjMz8c8//0ChUBTmHImIiIgKLN8nKN++fRsBAQEAgCpVqkClUiEiIoJBh4iIiN5o+Q47WVlZsLS0lB6bm5vDzs6uUCZFREREZCz5PowlhEDv3r2lz6dJT0/HoEGDYGtrq9Nv48aNxp0hERER0WvId9gJCwvTedyzZ0+jT4aIiIjI2PIddpYvX16Y8yAiIiIqFAZ/gjIRERHR24Rhh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGTtjQ47U6ZMgUKh0PmqWLGitD09PR3h4eFwcXGBnZ0dOnfujHv37hXhjImIiOhN80aHHQCoXLky4uPjpa8DBw5I2yIiIrB161asW7cO+/btw927d9GpU6cinC0RERG9acyLegKvYm5uDk9PT732pKQk/Pzzz1i1ahWaN28OAFi+fDkqVaqEw4cPo169eqaeKhEREb2B3viwc+XKFXh7e8PKygqBgYGIjIxEyZIlceLECWg0GrRo0ULqW7FiRZQsWRKHDh16adhRq9VQq9XS4+TkZACARqOBRqMx2txzxjLmmJQ31tu0WG/TYr1Ni/U2rYLWO7/9FUIIYfCsTOSvv/5CSkoKKlSogPj4eEydOhV37tzBuXPnsHXrVvTp00cntABAnTp10KxZM8ycOTPPcadMmYKpU6fqta9atQo2NjZG3w8iIiIyvrS0NHTv3h1JSUlwcHDIs98bHXZelJiYiFKlSmH27NmwtrYucNjJbWXHx8cHDx8+fGmxDKXRaBATE4OWLVvCwsLCaONS7lhv02K9TYv1Ni3W27QKWu/k5GS4urq+Muy88Yexnufo6Ijy5csjLi4OLVu2REZGBhITE+Ho6Cj1uXfvXq7n+DxPpVJBpVLptVtYWBTKm7qwxqXcsd6mxXqbFuttWqy3aRla7/z2feOvxnpeSkoKrl69Ci8vLwQEBMDCwgK7du2Stl++fBk3b95EYGBgEc6SiIiI3iRv9MrO6NGj0a5dO5QqVQp3797F5MmTYWZmhm7duqFYsWLo168fRo4cCWdnZzg4OGDo0KEIDAzklVhEREQkeaPDzu3bt9GtWzc8evQIbm5uaNiwIQ4fPgw3NzcAwJw5c6BUKtG5c2eo1WqEhITgxx9/LOJZExER0ZvkjQ47q1evful2KysrLFiwAAsWLDDRjIiIiOht81ads0NERERkKIYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjXzop6AnD1KUSM5A3iSlgGVJWCuVMBMqZD+VCgURT1FIiIi2WPYKUTdfz6O/z40x8QTe3Pdbvb/ocdMoUB+co+FmRIqcyVUFkpYmimhMjeDyiK7zdLcDCrz7IW6LK1AplYgS6tFZpaAVuQ8FsjM+v8/tVpoBZCp1SIr67nt//+nVojngplSCmjPhzUzpWnDmkKh0AuM5mb/m58SAvfvK/FH0mkoFaZZtFQqoVOf5/9U5vypUACvKJUQeO57pX3he5X9Z5ZWmGSfcigU0H8PmP1vH5UQuHZDiXM7/oXS7OX1NlM8N47Z/973//seKqB4VZHySSuE7r8BrYBWq/se1wrx0ve2+f//MpIz1vPfh8wsgSzxv7Fz9uPFWimfG09phF9ssrKycO6eAsnHbsPMzMwIlaKXKYp6K3P+zf3//2vSv5Hn/u0pFfn7l5LrOGbP/f/0/+/vF382SO/tLOP/n1OzpBOsLYvmvcuwU4QM/wGWVWhzkQ8lzjy+X9STeIcosfvu9aKexDvEDGv+e6GoJ/EOYb2NafeoJijjZlckr82wU4h2DG+AP/74E6GtWkFpZi6tqEi/XT732+KrCAFkZGmRkamFOjML6kwt1JnPPdZkP9b9bVz3t02z/1+FMFNkJ/z//Rar1Ev9wP/CWJbQX2XI2Q9T0go8VzOtzopHplYgQ5OJf86cRZUqVUz2m5gQ+qti2bX6//mJ7O/zqygU+isLOitGZtkrDaZcSxPixe+57opJhiYLcVf/izJlfKFU5r2yIwT+/7dF/fd9zliaLOO9lxTIXgXVXwH833tdAd05/W91U/d9ZW6W/RtwXqtbZgoFtAJ6z3u+XposLYyxd0Krxb179+Dh4QHFS+pNxlEU9X7+/5Pc/s1laZGv/08E8hpDIDNLK/2//r8VH2Uu//8Yd8UVyP53WVQYdgpZTviwMM/5JnP5ubBoNBrY3z+D1nV8YGFhUdTTkT2NRoM//4xD69AKrLcJZNf7T7RuXZP1NgHWW1746wERERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREcmabMLOggULULp0aVhZWaFu3bo4evRoUU+JiIiI3gCyCDtr1qzByJEjMXnyZJw8eRLVq1dHSEgI7t/nDSGJiIjedbIIO7Nnz8aAAQPQp08f+Pv7Y9GiRbCxscGyZcuKempERERUxN76G4FmZGTgxIkTmDBhgtSmVCrRokULHDp0KNfnqNVqqNVq6XFycjKA7Bu/aTQao80tZyxjjkl5Y71Ni/U2LdbbtFhv0ypovfPb/60POw8fPkRWVhY8PDx02j08PHDp0qVcnxMZGYmpU6fqtUdHR8PGxsboc4yJiTH6mJQ31tu0WG/TYr1Ni/U2LUPrnZaWlq9+b33YKYgJEyZg5MiR0uOkpCSULFkSgYGBsLe3N9rraDQa7NmzB82aNYOFhYXRxqXcsd6mxXqbFuttWqy3aRW03k+fPgUACCFe2u+tDzuurq4wMzPDvXv3dNrv3bsHT0/PXJ+jUqmgUqmkxzmHsXx9fQtvokRERFQonj59imLFiuW5/a0PO5aWlggICMCuXbvQoUMHAIBWq8WuXbswZMiQfI3h7e2NW7duwd7eHgqFwmhzS05Oho+PD27dugUHBwejjUu5Y71Ni/U2LdbbtFhv0ypovYUQePr0Kby9vV/a760POwAwcuRIhIWFoVatWqhTpw7mzp2L1NRU9OnTJ1/PVyqVKFGiRKHNz8HBgf9YTIj1Ni3W27RYb9NivU2rIPV+2YpODlmEnY8++ggPHjzApEmTkJCQgBo1amD79u16Jy0TERHRu0cWYQcAhgwZku/DVkRERPTukMWHCr6pVCoVJk+erHMyNBUe1tu0WG/TYr1Ni/U2rcKut0K86notIiIiorcYV3aIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2CtGCBQtQunRpWFlZoW7dujh69GhRT0kWYmNj0a5dO3h7e0OhUGDz5s0624UQmDRpEry8vGBtbY0WLVrgypUrRTPZt1xkZCRq164Ne3t7uLu7o0OHDrh8+bJOn/T0dISHh8PFxQV2dnbo3Lmz3u1bKP8WLlyIatWqSR+uFhgYiL/++kvaznoXnq+//hoKhQIjRoyQ2lhv45oyZQoUCoXOV8WKFaXthVVvhp1CsmbNGowcORKTJ0/GyZMnUb16dYSEhOD+/ftFPbW3XmpqKqpXr44FCxbkun3WrFmYN28eFi1ahCNHjsDW1hYhISFIT0838Uzffvv27UN4eDgOHz6MmJgYaDQaBAcHIzU1VeoTERGBrVu3Yt26ddi3bx/u3r2LTp06FeGs324lSpTA119/jRMnTuD48eNo3rw52rdvj/PnzwNgvQvLsWPH8NNPP6FatWo67ay38VWuXBnx8fHS14EDB6RthVZvQYWiTp06Ijw8XHqclZUlvL29RWRkZBHOSn4AiE2bNkmPtVqt8PT0FN98843UlpiYKFQqlfjtt9+KYIbycv/+fQFA7Nu3TwiRXVsLCwuxbt06qc/FixcFAHHo0KGimqbsODk5iaVLl7LeheTp06eiXLlyIiYmRjRp0kQMHz5cCMH3d2GYPHmyqF69eq7bCrPeXNkpBBkZGThx4gRatGghtSmVSrRo0QKHDh0qwpnJ37Vr15CQkKBT+2LFiqFu3bqsvREkJSUBAJydnQEAJ06cgEaj0al3xYoVUbJkSdbbCLKysrB69WqkpqYiMDCQ9S4k4eHhaNOmjU5dAb6/C8uVK1fg7e2NMmXKoEePHrh58yaAwq23bG4X8SZ5+PAhsrKy9O7N5eHhgUuXLhXRrN4NCQkJAJBr7XO2UcFotVqMGDECDRo0QJUqVQBk19vS0hKOjo46fVnv13P27FkEBgYiPT0ddnZ22LRpE/z9/XH69GnW28hWr16NkydP4tixY3rb+P42vrp16yIqKgoVKlRAfHw8pk6dikaNGuHcuXOFWm+GHSLKl/DwcJw7d07n+DoVjgoVKuD06dNISkrC+vXrERYWhn379hX1tGTn1q1bGD58OGJiYmBlZVXU03kntGrVSvp7tWrVULduXZQqVQpr166FtbV1ob0uD2MVAldXV5iZmemdQX7v3j14enoW0azeDTn1Ze2Na8iQIdi2bRv27NmDEiVKSO2enp7IyMhAYmKiTn/W+/VYWlrCz88PAQEBiIyMRPXq1fH999+z3kZ24sQJ3L9/H++99x7Mzc1hbm6Offv2Yd68eTA3N4eHhwfrXcgcHR1Rvnx5xMXFFer7m2GnEFhaWiIgIAC7du2S2rRaLXbt2oXAwMAinJn8+fr6wtPTU6f2ycnJOHLkCGtfAEIIDBkyBJs2bcLu3bvh6+ursz0gIAAWFhY69b58+TJu3rzJehuRVquFWq1mvY0sKCgIZ8+exenTp6WvWrVqoUePHtLfWe/ClZKSgqtXr8LLy6tw39+vdXoz5Wn16tVCpVKJqKgoceHCBTFw4EDh6OgoEhISinpqb72nT5+KU6dOiVOnTgkAYvbs2eLUqVPixo0bQgghvv76a+Ho6Ci2bNkizpw5I9q3by98fX3Fs2fPinjmb5/BgweLYsWKib1794r4+HjpKy0tTeozaNAgUbJkSbF7925x/PhxERgYKAIDA4tw1m+38ePHi3379olr166JM2fOiPHjxwuFQiGio6OFEKx3YXv+aiwhWG9jGzVqlNi7d6+4du2aOHjwoGjRooVwdXUV9+/fF0IUXr0ZdgrRDz/8IEqWLCksLS1FnTp1xOHDh4t6SrKwZ88eAUDvKywsTAiRffn5xIkThYeHh1CpVCIoKEhcvny5aCf9lsqtzgDE8uXLpT7Pnj0Tn376qXBychI2NjaiY8eOIj4+vugm/Zbr27evKFWqlLC0tBRubm4iKChICjpCsN6F7cWww3ob10cffSS8vLyEpaWlKF68uPjoo49EXFyctL2w6q0QQojXWxsiIiIienPxnB0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdInprXb9+HQqFAqdPny601+jduzc6dOhQaOMTUeFj2CGiItO7d28oFAq9r9DQ0Hw938fHB/Hx8ahSpUohz5SI3mbmRT0BInq3hYaGYvny5TptKpUqX881MzPj3aeJ6JW4skNERUqlUsHT01Pny8nJCQCgUCiwcOFCtGrVCtbW1ihTpgzWr18vPffFw1hPnjxBjx494ObmBmtra5QrV04nSJ09exbNmzeHtbU1XFxcMHDgQKSkpEjbs7KyMHLkSDg6OsLFxQVjx47Fi3fU0Wq1iIyMhK+vL6ytrVG9enWdORHRm4dhh4jeaBMnTkTnzp3xzz//oEePHujatSsuXryYZ98LFy7gr7/+wsWLF7Fw4UK4uroCAFJTUxESEgInJyccO3YM69atw86dOzFkyBDp+d999x2ioqKwbNkyHDhwAI8fP8amTZt0XiMyMhIrVqzAokWLcP78eURERKBnz57Yt29f4RWBiF7Pa99KlIiogMLCwoSZmZmwtbXV+frqq6+EENl3XR80aJDOc+rWrSsGDx4shBDi2rVrAoA4deqUEEKIdu3aiT59+uT6WosXLxZOTk4iJSVFavvjjz+EUqkUCQkJQgghvLy8xKxZs6TtGo1GlChRQrRv314IIUR6erqwsbERf//9t87Y/fr1E926dSt4IYioUPGcHSIqUs2aNcPChQt12pydnaW/BwYG6mwLDAzM8+qrwYMHo3Pnzjh58iSCg4PRoUMH1K9fHwBw8eJFVK9eHba2tlL/Bg0aQKvV4vLly7CyskJ8fDzq1q0rbTc3N0etWrWkQ1lxcXFIS0tDy5YtdV43IyMDNWvWNHznicgkGHaIqEjZ2trCz8/PKGO1atUKN27cwJ9//omYmBgEBQUhPDwc3377rVHGzzm/548//kDx4sV1tuX3pGoiMj2es0NEb7TDhw/rPa5UqVKe/d3c3BAWFoZff/0Vc+fOxeLFiwEAlSpVwj///IPU1FSp78GDB6FUKlGhQgUUK1YMXl5eOHLkiLQ9MzMTJ06ckB77+/tDpVLh5s2b8PPz0/ny8fEx1i4TkZFxZYeIipRarUZCQoJOm7m5uXRi8bp161CrVi00bNgQK1euxNGjR/Hzzz/nOtakSZMQEBCAypUrQ61WY9u2bVIw6tGjByZPnoywsDBMmTIFDx48wNChQ/Hxxx/Dw8MDADB8+HB8/fXXKFeuHCpWrIjZs2cjMTFRGt/e3h6jR49GREQEtFotGjZsiKSkJBw8eBAODg4ICwsrhAoR0eti2CGiIrV9+3Z4eXnptFWoUAGXLl0CAEydOhWrV6/Gp59+Ci8vL/z222/w9/fPdSxLS0tMmDAB169fh7W1NRo1aoTVq1cDAGxsbLBjxw4MHz4ctWvXho2NDTp37ozZs2dLzx81ahTi4+MRFhYGpVKJvn37omPHjkhKSpL6fPnll3Bzc0NkZCT++9//wtHREe+99x4+++wzY5eGiIxEIcQLHyJBRPSGUCgU2LRpE2/XQESvhefsEBERkawx7BAREZGs8ZwdInpj8Sg7ERkDV3aIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjW/g+6z0GaAze8RQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import json\n",
    "import psutil\n",
    "import pynvml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from environment_ma_reward_distance_dynamic import Env\n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, num_actions, env, alpha, gamma, epsilon):\n",
    "        self.env = env\n",
    "        self.num_actions = num_actions\n",
    "        self.learning_rate = alpha\n",
    "        self.discount_factor = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_tables = [defaultdict(lambda: [0.0] * num_actions) for _ in range(env.num_agents)]\n",
    "\n",
    "    @staticmethod\n",
    "    def arg_max(state_action):\n",
    "        max_index_list = []\n",
    "        max_value = state_action[0]\n",
    "        for index, value in enumerate(state_action):\n",
    "            if value > max_value:\n",
    "                max_index_list.clear()\n",
    "                max_value = value\n",
    "                max_index_list.append(index)\n",
    "            elif value == max_value:\n",
    "                max_index_list.append(index)\n",
    "        return random.choice(max_index_list)\n",
    "\n",
    "    def choose_action(self, agent_idx, state):\n",
    "        state = tuple(state)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            state_action = self.q_tables[agent_idx][state]\n",
    "            action = self.arg_max(state_action)\n",
    "        return action\n",
    "\n",
    "    def learn(self, agent_idx, state, action, reward, next_state):\n",
    "        state = tuple(state)\n",
    "        next_state = tuple(next_state)\n",
    "        current_q = self.q_tables[agent_idx][state][action]\n",
    "        max_next_q = max(self.q_tables[agent_idx][next_state])\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)\n",
    "        self.q_tables[agent_idx][state][action] = new_q\n",
    "\n",
    "\n",
    "class Case:\n",
    "\n",
    "    def __init__(self, problem, solution, trust_value=0.5, total_time_steps=0):\n",
    "        self.problem = ast.literal_eval(problem) if isinstance(problem, str) else problem\n",
    "        self.solution = solution\n",
    "        self.trust_value = trust_value\n",
    "        self.total_time_steps = total_time_steps  # New attribute for total time steps\n",
    "\n",
    "    @staticmethod\n",
    "    def sim_q(state1, state2):\n",
    "        state1 = np.atleast_1d(state1)\n",
    "        state2 = np.atleast_1d(state2)\n",
    "        CNDMaxDist = 6\n",
    "        v = state1.size\n",
    "        DistQ = np.sum([Case.dist_q(Objic, Objip) for Objic, Objip in zip(state1, state2)])\n",
    "        similarity = (CNDMaxDist * v - DistQ) / (CNDMaxDist * v)\n",
    "        return similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def dist_q(X1, X2):\n",
    "        return np.min(np.abs(X1 - X2))\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(state, case_base, threshold=0.1):\n",
    "        state = ast.literal_eval(state) if isinstance(state, str) else state\n",
    "        for case in case_base:\n",
    "            if state == case.problem: \n",
    "                return case\n",
    "\n",
    "    @staticmethod\n",
    "    def reuse(agent_idx, c, own_temp_case_base, comm_temp_case_base, source='own'):\n",
    "        \"\"\"Reuse step for adding cases to temporary case bases.\"\"\"\n",
    "        if source == 'own':\n",
    "            own_temp_case_base.append(c)\n",
    "        elif source == 'comm':\n",
    "            comm_temp_case_base.append(c)\n",
    "\n",
    "    @staticmethod\n",
    "    def revise(agent_idx, case_base, temporary_case_base, successful_episodes):\n",
    "        for case in case_base:\n",
    "            if any((case.problem, case.solution) == (temp_case.problem, temp_case.solution) for temp_case in temporary_case_base):\n",
    "                if successful_episodes:\n",
    "                    case.trust_value += 0.1\n",
    "                else:\n",
    "                    case.trust_value -= 0.4\n",
    "            else:\n",
    "                if successful_episodes:\n",
    "                    case.trust_value -= 0.1\n",
    "            \n",
    "            case.trust_value = max(0, min(case.trust_value, 1))\n",
    "            print(f\"case content after REVISE for agent {agent_idx}, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}, time steps: {case.total_time_steps}\")\n",
    "\n",
    "    @staticmethod\n",
    "    # def retain(agent_idx, case_base, own_temp_case_base, comm_temp_case_base, successful_episodes, threshold=0.49):\n",
    "    #     # if successful_episodes:\n",
    "    #     #     \"\"\"Retain step for combining cases from both temporary bases and adding them to the main case base.\"\"\"\n",
    "    #     #     combined_cases = own_temp_case_base + comm_temp_case_base\n",
    "    #     #     for temp_case in combined_cases:\n",
    "    #     #         existing_case = next((case for case in case_base if case.problem == temp_case.problem), None)\n",
    "    #     #         if existing_case:\n",
    "    #     #             if (temp_case.total_time_steps < existing_case.total_time_steps) or \\\n",
    "    #     #             (temp_case.total_time_steps == existing_case.total_time_steps and temp_case.trust_value > existing_case.trust_value):\n",
    "    #     #                 existing_case.solution = temp_case.solution\n",
    "    #     #                 existing_case.trust_value = temp_case.trust_value\n",
    "    #     #                 existing_case.total_time_steps = temp_case.total_time_steps\n",
    "    #     #                 print(f\"Updated existing case with better metrics: {existing_case.problem}, {existing_case.solution}, {existing_case.trust_value}, {existing_case.total_time_steps}\")\n",
    "    #     #         else:\n",
    "    #     #             case_base.append(temp_case)\n",
    "    #     #             print(f\"New case added: {temp_case.problem}, {temp_case.solution}, {temp_case.trust_value}, {temp_case.total_time_steps}\")\n",
    "        \n",
    "\n",
    "    #     if successful_episodes:\n",
    "    #         for temp_case in reversed(own_temp_case_base):\n",
    "    #             state = tuple(np.atleast_1d(temp_case.problem))\n",
    "    #             if not any(tuple(np.atleast_1d(case.problem)) == state for case in case_base):\n",
    "    #                 case_base.append(temp_case)\n",
    "    #                 # Case.added_states.add(state)\n",
    "    #                 print(f\"Episode succeeded, case for agent {agent_idx} {temp_case.problem} is empty. Temporary case base stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value,}\")         \n",
    "    #             else:\n",
    "    #                 # existing_case = next((case for case in case_base if tuple(np.atleast_1d(case.problem)) == state), None)\n",
    "    #                 # if existing_case and existing_case.trust_value < temp_case.trust_value:\n",
    "    #                 #     existing_case.solution = temp_case.solution\n",
    "    #                 #     existing_case.trust_value = max(0, temp_case.trust_value)\n",
    "    #                 #     print(f\"Episode succeeded, similar case for agent {agent_idx} is found. Updated case base with higher trust value: {existing_case.problem, existing_case.solution, existing_case.trust_value}\")\n",
    "    #                 # else:\n",
    "    #                     print(f\"Episode succeeded, case {temp_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value,}\")    \n",
    "    #     else:\n",
    "    #         print(f\"Episode not succeeded, temporary case base for agent {agent_idx} not stored to the case base\")\n",
    "\n",
    "    #     # Filter cases with trust values above the threshold\n",
    "    #     case_base[:] = [case for case in case_base if case.trust_value >= threshold]\n",
    "\n",
    "    #     for case in case_base:\n",
    "    #         print(f\"cases content after RETAIN for agent {agent_idx}, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}, time steps: {case.total_time_steps}\")\n",
    "\n",
    "    #     return case_base\n",
    "\n",
    "    def retain(agent_idx, case_base, own_temp_case_base, comm_temp_case_base, successful_episodes, threshold=0.49):\n",
    "\n",
    "        if successful_episodes:\n",
    "            for temp_case in reversed(own_temp_case_base):\n",
    "                state = tuple(np.atleast_1d(temp_case.problem))\n",
    "    \n",
    "                if not any(tuple(np.atleast_1d(case.problem)) == state for case in case_base):\n",
    "                    case_base.append(temp_case)\n",
    "                    # Case.added_states.add(state)\n",
    "                    print(f\"Episode succeeded, case {temp_case.problem} is empty. Temporary case base stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value}\")         \n",
    "                else:\n",
    "                    print(f\"Episode succeeded, case {temp_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value}\")    \n",
    "        else:\n",
    "            print(f\"Episode not succeeded, temporary case base from own experience is not stored to the case base\")\n",
    "        \n",
    "\n",
    "        for temp_comm_case in reversed(comm_temp_case_base):\n",
    "            state_comm = tuple(np.atleast_1d(temp_comm_case.problem))\n",
    "\n",
    "            if not any(tuple(np.atleast_1d(case.problem)) == state_comm for case in case_base):\n",
    "                case_base.append(temp_comm_case)\n",
    "                print(f\"Integrated case process. comm case {temp_comm_case.problem} is empty. Temporary case base stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")         \n",
    "            # else:    \n",
    "            #     existing_case = next((case for case in case_base if tuple(np.atleast_1d(case.problem)) == state_comm), None)\n",
    "            #     if existing_case and existing_case.trust_value < temp_comm_case.trust_value:\n",
    "            #         existing_case.solution = temp_comm_case.solution\n",
    "            #         existing_case.trust_value = max(0, temp_comm_case.trust_value)\n",
    "            #         print(f\"Integrated case process. Similar comm case for agent {agent_idx} is found. Updated case base with higher trust value: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")\n",
    "            #     else:\n",
    "            #         print(f\"Integrated case process. comm case {temp_comm_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")   \n",
    "\n",
    "\n",
    "        case_base[:] = [case for case in case_base if case.trust_value >= threshold]\n",
    "\n",
    "        for case in case_base:\n",
    "            print(f\"cases content after RETAIN, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}\")\n",
    "\n",
    "        return case_base\n",
    "    \n",
    "\n",
    "class QCBRL:\n",
    "    def __init__(self, num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render):\n",
    "        self.num_actions = num_actions\n",
    "        self.env = env\n",
    "        self.episodes = episodes\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.render = render\n",
    "        self.epsilon_decay = epsilon_decay  \n",
    "        self.epsilon_min = epsilon_min  \n",
    "\n",
    "        self.problem_solvers = [ProblemSolver(num_actions, self.env, alpha, gamma, epsilon) for _ in range(self.env.num_agents)]\n",
    "        self.case_bases = [[] for _ in range(self.env.num_agents)]  # Individual case bases for each agent\n",
    "        self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for own experiences\n",
    "        self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for communication experiences\n",
    "        self.successful_episodes = [0] * self.env.num_agents\n",
    "        self.rewards_per_episode = [[] for _ in range(self.env.num_agents)]  \n",
    "        self.total_successful_episodes = 0 \n",
    "        self.action_type = 0\n",
    "\n",
    "    def run(self):\n",
    "        rewards = []\n",
    "        memory_usage = []\n",
    "        gpu_memory_usage = []\n",
    "        num_successful_episodes = 0\n",
    "        total_steps_list = []\n",
    "        success_steps = []\n",
    "\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "        for episode in range(episodes):\n",
    "            states = self.env.reset()\n",
    "            episode_reward = [0] * self.env.num_agents\n",
    "            total_steps = 0 \n",
    "            self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            success_count = [0] * self.env.num_agents\n",
    "            dones = [False] * self.env.num_agents\n",
    "            win_states = [False] * self.env.num_agents\n",
    "            successful_episodes = False\n",
    "\n",
    "            while not(all(dones)):\n",
    "                print(f\"----- starting point of Episode {episode} in steps {total_steps} loop -----\")\n",
    "                \n",
    "                actions = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    # print(f\"state before take action: {state}\")\n",
    "                    action = self.take_action(agent_idx, state)\n",
    "                    actions.append(action)\n",
    "\n",
    "                # print(f\"actions pass to the environment\")\n",
    "                next_states, rewards, dones = self.env.step(actions)\n",
    "\n",
    "                win_states = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    action = actions[agent_idx]\n",
    "                    reward = rewards[agent_idx]\n",
    "                    next_state = next_states[agent_idx]\n",
    "\n",
    "                    physical_state = tuple(state[0])\n",
    "                    win_state = state[1]\n",
    "                    comm_state = state[2]  # Communication state containing messages from other agents\n",
    "\n",
    "                    physical_next_state = tuple(next_state[0])\n",
    "                    win_next_state = next_state[1]\n",
    "                    comm_next_state = tuple(next_state[2]) if next_state[2] != 0 else next_state[2]\n",
    "\n",
    "                    physical_action = action[0]\n",
    "                    comm_action = action[1]\n",
    "\n",
    "                    # Process messages received from other agents\n",
    "                    print(f\"comm next state for agent {agent_idx}: {comm_next_state}\")\n",
    "                    # print(f\"comm next state content: {comm_next_state[0]}\")\n",
    "                    \n",
    "                    # if all(element is None for element in comm_next_state):\n",
    "                    # if (comm_next_state == [None]) or (comm_next_state is None):\n",
    "                    if (comm_next_state == 0):\n",
    "                        pass\n",
    "                    else:\n",
    "                        comm_case = Case(problem=comm_next_state[0], solution=comm_next_state[1], trust_value=comm_next_state[2], total_time_steps=comm_next_state[3])\n",
    "                        Case.reuse(agent_idx, comm_case, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='comm')\n",
    "\n",
    "                    # print(f\"state agent {agent_idx} before update: {physical_state}\")\n",
    "                    # print(f\"win state agent {agent_idx} before update: {win_next_state}\")\n",
    "                    # print(f\"action agent {agent_idx} before update: {physical_action}\")\n",
    "                    # print(f\"reward agent {agent_idx} before update: {reward}\")\n",
    "                    # print(f\"next state agent {agent_idx} before update: {physical_next_state}\")\n",
    "\n",
    "                    c = Case(physical_state, physical_action, total_time_steps=total_steps)\n",
    "                    Case.reuse(agent_idx, c, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='own')\n",
    "\n",
    "                    if self.action_type == 0:\n",
    "                        print(f\"action type of agent: {agent_idx}: problem solver, agent learned\")\n",
    "                        self.problem_solvers[agent_idx].learn(agent_idx, physical_state, physical_action, reward, physical_next_state)\n",
    "\n",
    "                    if (win_next_state): \n",
    "                        success_count[agent_idx] += 1\n",
    "                        # print(f\"agent{agent_idx} hit !!!!!\")\n",
    "                    # else:\n",
    "                    #     print(f\"agent{agent_idx} not hit !!!!!\")\n",
    "\n",
    "                    episode_reward[agent_idx] += reward\n",
    "                    win_states.append(win_next_state)  \n",
    "\n",
    "                states = next_states\n",
    "                total_steps += 1\n",
    "\n",
    "                self.env.render()\n",
    "                \n",
    "            if self.env.win_flag:\n",
    "                self.total_successful_episodes += 1\n",
    "                success_steps.append(total_steps)\n",
    "                successful_episodes = True\n",
    "                \n",
    "\n",
    "            \n",
    "            for agent_idx in range(self.env.num_agents):\n",
    "                print(f\"win status of agent {agent_idx}  before update the case base: {win_states[agent_idx]}\")\n",
    "                self.rewards_per_episode[agent_idx].append(episode_reward[agent_idx])\n",
    "\n",
    "                print(f\"agent{agent_idx} own temp case base: {self.own_temp_case_bases[agent_idx]}\")\n",
    "                print(f\"agent{agent_idx} comm temp case base: {self.comm_temp_case_bases[agent_idx]}\")\n",
    "                \n",
    "                \n",
    "                Case.revise(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], win_states[agent_idx])\n",
    "                self.case_bases[agent_idx] = Case.retain(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], win_states[agent_idx])\n",
    "               \n",
    "                \n",
    "            self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "            \n",
    "            memory_usage.append(psutil.virtual_memory().percent)\n",
    "            gpu_memory_usage.append(pynvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**2)\n",
    "\n",
    "            print(f\"Episode: {episode}, Total Steps: {total_steps}, Total Rewards: {episode_reward}, Status Episode: {successful_episodes}\")\n",
    "            print(f\"------------------------------------------End of episode {episode} loop--------------------\")\n",
    "\n",
    "        # self.save_case_base_temporary()  # Save temporary case base after training\n",
    "        # self.save_case_base()  # Save case base after training\n",
    "\n",
    "        success_rate = self.total_successful_episodes / episodes * 100\n",
    "\n",
    "        return self.rewards_per_episode, success_rate, memory_usage, gpu_memory_usage, success_steps\n",
    "\n",
    "    def take_action(self, agent_idx, state):\n",
    "        # print(f\"state detected in take action function: {state}\")\n",
    "        physical_state = tuple(state[0])\n",
    "        win_state = state[1]\n",
    "        comm_state = state[2]\n",
    "\n",
    "        similar_solution = Case.retrieve(physical_state, self.case_bases[agent_idx])\n",
    "        if similar_solution is not None:\n",
    "            physical_action = similar_solution.solution\n",
    "            comm_action = (similar_solution.problem, similar_solution.solution, similar_solution.trust_value, similar_solution.total_time_steps)\n",
    "            self.action_type = 1\n",
    "            # print(f\"Problem detected as a similiar soulution in case base: {similar_solution.problem}\")\n",
    "            print(f\"Physical Action for Agent {agent_idx} from case base: {physical_action}\")\n",
    "            # print(f\"Communication Action for Agent {agent_idx} from case base: {comm_action}\")\n",
    "            # print(f\"Trust value detected as a similiar solution in case base: {similar_solution.trust_value}\")\n",
    "        else:\n",
    "            physical_action = self.problem_solvers[agent_idx].choose_action(agent_idx, physical_state)\n",
    "            comm_action = 0  # No communication action if using problem solver action\n",
    "            self.action_type = 0\n",
    "            print(f\"Physical Action for Agent {agent_idx} from problem solver: {physical_action}\")\n",
    "\n",
    "        # print(f\"physical action returned from the take action: {physical_action}\")\n",
    "        # print(f\"comm action returned from the take action: {comm_action}\")\n",
    "\n",
    "        return (physical_action, comm_action)\n",
    "\n",
    "    def case_exists_in_case_base(self, case, case_base):\n",
    "        \"\"\"Check if a case exists in the given case base.\"\"\"\n",
    "        return any(existing_case.problem == case.problem and existing_case.solution == case.solution for existing_case in case_base)\n",
    "        \n",
    "    \n",
    "    def save_case_base_temporary(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_temporary_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": int(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps)} for case in self.own_temp_case_bases[agent_idx] + self.comm_temp_case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Temporary case base for Agent {agent_idx} saved successfully.\")\n",
    "\n",
    "    def save_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": int(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps)} for case in self.case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Case base for Agent {agent_idx} saved successfully.\")\n",
    "        \n",
    "    def load_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            try:\n",
    "                with open(filename, 'r') as file:\n",
    "                    case_base_data = json.load(file)\n",
    "                    self.case_bases[agent_idx] = [Case(np.array(case[\"problem\"]), case[\"solution\"], case[\"trust_value\"], case[\"total_time_steps\"]) for case in case_base_data]\n",
    "                    print(f\"Case base for Agent {agent_idx} loaded successfully.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Case base file for Agent {agent_idx} not found. Starting with an empty case base.\")\n",
    "\n",
    "    def display_success_rate(self, success_rate):\n",
    "        print(f\"Success rate: {success_rate}%\")\n",
    "\n",
    "\n",
    "    def plot_rewards(self, rewards):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            plt.plot([reward for reward in rewards[agent_idx]], label=f'Agent {agent_idx}')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.title('Rewards over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_total_steps(self, total_steps_list):\n",
    "        plt.plot(total_steps_list)\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Steps')\n",
    "        plt.title('Total Steps for Successful Episodes over Episodes')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_resources(self, memory_usage, gpu_memory_usage):\n",
    "        plt.plot(memory_usage, label='Memory (%)')\n",
    "        plt.plot(gpu_memory_usage, label='GPU Memory (MB)')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Resource Usage')\n",
    "        plt.title('Resource Usage over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_agents = 2\n",
    "    num_obstacles = 3\n",
    "    obstacles_random_steps = 20\n",
    "    is_agent_silent = False\n",
    "    episodes=50\n",
    "    max_steps=1000\n",
    "    alpha=0.1\n",
    "    gamma=0.9\n",
    "    epsilon=0.2\n",
    "    epsilon_decay = 0.995  \n",
    "    epsilon_min = 0.01  \n",
    "    render = True\n",
    "\n",
    "    env = Env(num_agents=num_agents, num_obstacles=num_obstacles, obstacles_random_steps = obstacles_random_steps, is_agent_silent=is_agent_silent)\n",
    "    \n",
    "    num_actions = len(env.action_space)\n",
    "    \n",
    "    agent = QCBRL(num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render)\n",
    "    rewards, success_rate, memory_usage, gpu_memory_usage, total_step_list = agent.run()\n",
    "\n",
    "    agent.display_success_rate(success_rate)\n",
    "    agent.plot_rewards(rewards)\n",
    "    agent.plot_total_steps(total_step_list)\n",
    "    agent.plot_resources(memory_usage, gpu_memory_usage)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
